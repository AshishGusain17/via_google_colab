{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sports_balls_detection_using_tf.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshishGusain17/via_google_colab/blob/master/sports_balls_detection_using_tf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBTj42vQXcMi",
        "colab_type": "code",
        "outputId": "99f2503b-bdea-41e9-ba99-3cda64613307",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "!git clone https://github.com/tensorflow/models"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects:   5% (1/18)\u001b[K\rremote: Counting objects:  11% (2/18)\u001b[K\rremote: Counting objects:  16% (3/18)\u001b[K\rremote: Counting objects:  22% (4/18)\u001b[K\rremote: Counting objects:  27% (5/18)\u001b[K\rremote: Counting objects:  33% (6/18)\u001b[K\rremote: Counting objects:  38% (7/18)\u001b[K\rremote: Counting objects:  44% (8/18)\u001b[K\rremote: Counting objects:  50% (9/18)\u001b[K\rremote: Counting objects:  55% (10/18)\u001b[K\rremote: Counting objects:  61% (11/18)\u001b[K\rremote: Counting objects:  66% (12/18)\u001b[K\rremote: Counting objects:  72% (13/18)\u001b[K\rremote: Counting objects:  77% (14/18)\u001b[K\rremote: Counting objects:  83% (15/18)\u001b[K\rremote: Counting objects:  88% (16/18)\u001b[K\rremote: Counting objects:  94% (17/18)\u001b[K\rremote: Counting objects: 100% (18/18)\u001b[K\rremote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 34112 (delta 4), reused 9 (delta 2), pack-reused 34094\u001b[K\n",
            "Receiving objects: 100% (34112/34112), 512.11 MiB | 39.22 MiB/s, done.\n",
            "Resolving deltas: 100% (21863/21863), done.\n",
            "Checking out files: 100% (3010/3010), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trTtqpmHEWit",
        "colab_type": "code",
        "outputId": "e4566e00-a020-40d5-e947-0bee4d731340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "source": [
        "!pip install --user Cython\n",
        "!pip install --user contextlib2\n",
        "!pip install --user pillow\n",
        "!pip install --user lxml\n",
        "!pip install --user jupyter\n",
        "!pip install --user matplotlib"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (0.29.14)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (0.5.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (6.2.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (4.2.6)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (1.0.0)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter) (5.2.0)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter) (4.6.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from jupyter) (4.6.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter) (5.6.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter) (5.2.2)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from jupyter) (7.5.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter) (5.3.4)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter) (1.0.18)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter) (5.5.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from jupyter-console->jupyter) (2.1.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter) (4.6.1)\n",
            "Requirement already satisfied: traitlets in /usr/local/lib/python3.6/dist-packages (from qtconsole->jupyter) (4.3.3)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->jupyter) (4.5.3)\n",
            "Requirement already satisfied: nbformat>=4.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (5.0.4)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (3.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (0.6.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (0.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (1.4.2)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (0.4.4)\n",
            "Requirement already satisfied: jinja2>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter) (2.11.1)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter) (0.8.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->jupyter) (3.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->jupyter-console->jupyter) (2.6.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->jupyter-console->jupyter) (17.0.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter) (0.1.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter) (1.12.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter) (4.4.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter) (45.1.0)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython->jupyter-console->jupyter) (0.8.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.4->nbconvert->jupyter) (2.6.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.4->nbconvert->jupyter) (1.1.1)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->jupyter) (0.6.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.1.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.6.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.17.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib) (45.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZK05pHYEeqk",
        "colab_type": "code",
        "outputId": "bfb2db37-0fdd-4d15-aa56-9aad2fc57f6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python /content/models/research/setup.py build\n",
        "!python /content/models/research/setup.py install"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running build\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating object_detection.egg-info\n",
            "writing object_detection.egg-info/PKG-INFO\n",
            "writing dependency_links to object_detection.egg-info/dependency_links.txt\n",
            "writing requirements to object_detection.egg-info/requires.txt\n",
            "writing top-level names to object_detection.egg-info/top_level.txt\n",
            "writing manifest file 'object_detection.egg-info/SOURCES.txt'\n",
            "reading manifest file 'object_detection.egg-info/SOURCES.txt'\n",
            "writing manifest file 'object_detection.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "warning: install_lib: 'build/lib' does not exist -- no Python modules to install\n",
            "\n",
            "creating build\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying object_detection.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying object_detection.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying object_detection.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying object_detection.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying object_detection.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/object_detection-0.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing object_detection-0.1-py3.6.egg\n",
            "Removing /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg\n",
            "Copying object_detection-0.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "object-detection 0.1 is already the active version in easy-install.pth\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg\n",
            "Processing dependencies for object-detection==0.1\n",
            "Searching for Cython==0.29.14\n",
            "Best match: Cython 0.29.14\n",
            "Adding Cython 0.29.14 to easy-install.pth file\n",
            "Installing cygdb script to /usr/local/bin\n",
            "Installing cython script to /usr/local/bin\n",
            "Installing cythonize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for matplotlib==3.1.2\n",
            "Best match: matplotlib 3.1.2\n",
            "Adding matplotlib 3.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for Pillow==6.2.2\n",
            "Best match: Pillow 6.2.2\n",
            "Adding Pillow 6.2.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for kiwisolver==1.1.0\n",
            "Best match: kiwisolver 1.1.0\n",
            "Adding kiwisolver 1.1.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for python-dateutil==2.6.1\n",
            "Best match: python-dateutil 2.6.1\n",
            "Adding python-dateutil 2.6.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for numpy==1.17.5\n",
            "Best match: numpy 1.17.5\n",
            "Adding numpy 1.17.5 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.6 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for pyparsing==2.4.6\n",
            "Best match: pyparsing 2.4.6\n",
            "Adding pyparsing 2.4.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for cycler==0.10.0\n",
            "Best match: cycler 0.10.0\n",
            "Adding cycler 0.10.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for setuptools==45.1.0\n",
            "Best match: setuptools 45.1.0\n",
            "Adding setuptools 45.1.0 to easy-install.pth file\n",
            "Installing easy_install script to /usr/local/bin\n",
            "Installing easy_install-3.8 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Searching for six==1.12.0\n",
            "Best match: six 1.12.0\n",
            "Adding six 1.12.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.6/dist-packages\n",
            "Finished processing dependencies for object-detection==0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfTB_OwTjVva",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KKHo5pG_x5Dg",
        "colab_type": "code",
        "outputId": "f017f39f-d6d9-4b8d-83ae-f17621b108b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa4Ziv5ux5uX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp -r --recursive '/content/drive/My Drive/sports_ball_detection/faster_rcnn_resnet101_coco_2018_01_28' '/content/models/research/object_detection'\n",
        "!cp -r --recursive '/content/drive/My Drive/sports_ball_detection/training' '/content/models/research/object_detection'\n",
        "!cp -r --recursive '/content/drive/My Drive/sports_ball_detection/images' '/content/models/research/object_detection'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNXxD8eZ2YsQ",
        "colab_type": "code",
        "outputId": "33fda4de-0889-4b6d-e24d-f75cdf8d9dac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%cd content/models/research\n",
        "%set_env PYTHONPATH=/content/models/research:/content/models/research/slim\n",
        "%cd object_detection/legacy\n",
        "!python3 train.py --logtostderr --train_dir=../training --pipeline_config_path=../training/faster_rcnn_resnet101_coco.config\n",
        "%cd ..\n",
        "%cd ..\n",
        "%cd ..\n",
        "%cd ..\n",
        "%cd .."
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n",
            "env: PYTHONPATH=/content/models/research:/content/models/research/slim\n",
            "/content/models/research/object_detection/legacy\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From train.py:56: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From train.py:56: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\n",
            "\n",
            "WARNING:tensorflow:From train.py:185: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/absl/app.py:250: main (from __main__) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use object_detection/model_main.py.\n",
            "W0205 13:13:45.026271 140689526667136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/absl/app.py:250: main (from __main__) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use object_detection/model_main.py.\n",
            "WARNING:tensorflow:From train.py:91: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0205 13:13:45.026459 140689526667136 module_wrapper.py:139] From train.py:91: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0205 13:13:45.026711 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:102: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From train.py:96: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n",
            "\n",
            "W0205 13:13:45.029012 140689526667136 module_wrapper.py:139] From train.py:96: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:267: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.create_global_step\n",
            "W0205 13:13:45.036381 140689526667136 deprecation.py:323] From /content/models/research/object_detection/legacy/trainer.py:267: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.create_global_step\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "W0205 13:13:45.043061 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:182: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
            "\n",
            "W0205 13:13:45.043277 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/data_decoders/tf_example_decoder.py:197: The name tf.VarLenFeature is deprecated. Please use tf.io.VarLenFeature instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "W0205 13:13:45.055240 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/builders/dataset_builder.py:64: The name tf.gfile.Glob is deprecated. Please use tf.io.gfile.glob instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:71: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "W0205 13:13:45.055927 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/builders/dataset_builder.py:71: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
            "\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0205 13:13:45.056038 140689526667136 dataset_builder.py:72] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "W0205 13:13:45.062890 140689526667136 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:86: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.parallel_interleave(...)`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0205 13:13:45.063031 140689526667136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0205 13:13:45.082360 140689526667136 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:155: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:43: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
            "W0205 13:13:45.620818 140689526667136 deprecation.py:323] From /content/models/research/object_detection/builders/dataset_builder.py:43: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:44: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "W0205 13:13:45.629587 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/builders/dataset_builder.py:44: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/dataset_builder.py:44: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "W0205 13:13:45.629825 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/builders/dataset_builder.py:44: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:627: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0205 13:13:45.637696 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/core/preprocessor.py:627: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
            "W0205 13:13:45.674891 140689526667136 deprecation.py:323] From /content/models/research/object_detection/core/batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:752: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "W0205 13:13:45.677918 140689526667136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:752: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:752: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "W0205 13:13:45.678805 140689526667136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:752: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/prefetcher.py:51: The name tf.PaddingFIFOQueue is deprecated. Please use tf.queue.PaddingFIFOQueue instead.\n",
            "\n",
            "W0205 13:13:45.683001 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/core/prefetcher.py:51: The name tf.PaddingFIFOQueue is deprecated. Please use tf.queue.PaddingFIFOQueue instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/prefetcher.py:58: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "W0205 13:13:45.685851 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/core/prefetcher.py:58: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:286: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "W0205 13:13:45.688357 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/legacy/trainer.py:286: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/slim/deployment/model_deploy.py:192: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0205 13:13:45.688645 140689526667136 module_wrapper.py:139] From /content/models/research/slim/deployment/model_deploy.py:192: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/slim/deployment/model_deploy.py:192: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "W0205 13:13:45.688748 140689526667136 module_wrapper.py:139] From /content/models/research/slim/deployment/model_deploy.py:192: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:2689: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0205 13:13:45.731960 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/core/preprocessor.py:2689: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0205 13:13:45.771023 140689526667136 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0205 13:13:45.772840 140689526667136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "W0205 13:13:48.823045 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0205 13:13:48.833455 140689526667136 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0205 13:13:48.853238 140689526667136 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0205 13:13:48.853705 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0205 13:13:48.853851 140689526667136 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/box_list_ops.py:174: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0205 13:13:48.900899 140689526667136 deprecation.py:323] From /content/models/research/object_detection/core/box_list_ops.py:174: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0205 13:13:49.440402 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/box_coders/faster_rcnn_box_coder.py:82: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/minibatch_sampler.py:85: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
            "\n",
            "W0205 13:13:49.478590 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/core/minibatch_sampler.py:85: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/spatial_transform_ops.py:419: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "W0205 13:13:49.707011 140689526667136 deprecation.py:506] From /content/models/research/object_detection/utils/spatial_transform_ops.py:419: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:191: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0205 13:13:49.721128 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:191: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0205 13:13:49.721455 140689526667136 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "W0205 13:13:49.986256 140689526667136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0205 13:13:49.989208 140689526667136 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0205 13:13:50.010046 140689526667136 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
            "\n",
            "W0205 13:13:50.242234 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/core/losses.py:177: The name tf.losses.huber_loss is deprecated. Please use tf.compat.v1.losses.huber_loss instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
            "\n",
            "W0205 13:13:50.243337 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/core/losses.py:183: The name tf.losses.Reduction is deprecated. Please use tf.compat.v1.losses.Reduction instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/losses.py:350: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "W0205 13:13:50.285965 140689526667136 deprecation.py:323] From /content/models/research/object_detection/core/losses.py:350: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:209: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.\n",
            "\n",
            "W0205 13:13:50.501426 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/legacy/trainer.py:209: The name tf.losses.add_loss is deprecated. Please use tf.compat.v1.losses.add_loss instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/optimizer_builder.py:157: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0205 13:13:50.501834 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/builders/optimizer_builder.py:157: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/builders/optimizer_builder.py:58: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
            "\n",
            "W0205 13:13:50.508311 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/builders/optimizer_builder.py:58: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:323: The name tf.check_numerics is deprecated. Please use tf.debugging.check_numerics instead.\n",
            "\n",
            "W0205 13:13:52.721914 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/legacy/trainer.py:323: The name tf.check_numerics is deprecated. Please use tf.debugging.check_numerics instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:354: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "W0205 13:13:56.744661 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/legacy/trainer.py:354: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:356: The name tf.losses.get_losses is deprecated. Please use tf.compat.v1.losses.get_losses instead.\n",
            "\n",
            "W0205 13:13:57.268237 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/legacy/trainer.py:356: The name tf.losses.get_losses is deprecated. Please use tf.compat.v1.losses.get_losses instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:360: The name tf.losses.get_total_loss is deprecated. Please use tf.compat.v1.losses.get_total_loss instead.\n",
            "\n",
            "W0205 13:13:57.271784 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/legacy/trainer.py:360: The name tf.losses.get_total_loss is deprecated. Please use tf.compat.v1.losses.get_total_loss instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:369: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "W0205 13:13:57.276784 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/legacy/trainer.py:369: The name tf.summary.merge is deprecated. Please use tf.compat.v1.summary.merge instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:372: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0205 13:13:57.295371 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/legacy/trainer.py:372: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/legacy/trainer.py:377: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0205 13:13:57.295586 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/legacy/trainer.py:377: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "W0205 13:13:57.934814 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/utils/variables_helper.py:179: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2768: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0205 13:13:57.935091 140689526667136 deprecation.py:323] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:2768: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
            "\n",
            "W0205 13:13:57.938920 140689526667136 module_wrapper.py:139] From /content/models/research/object_detection/utils/variables_helper.py:139: The name tf.train.NewCheckpointReader is deprecated. Please use tf.compat.v1.train.NewCheckpointReader instead.\n",
            "\n",
            "W0205 13:13:57.941120 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.941252 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.941326 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.941383 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.941442 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.941504 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.941558 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.941611 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.941668 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.941722 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.941774 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.941830 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.941880 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.941930 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.941986 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.942045 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.942098 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.942154 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.942224 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.942274 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.942331 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.942385 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.942438 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.942493 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.942549 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.942601 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.942658 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.942716 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.942768 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.942824 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.942884 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.942936 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.942997 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.943050 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.943103 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.943160 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.943232 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.943284 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.943344 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.943395 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.943446 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.943504 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.943556 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.943606 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.943664 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.943714 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.943765 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.943823 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.943874 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.943924 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.943982 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.944047 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.944101 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.944159 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.944227 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.944278 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.944335 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.944385 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.944436 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.944493 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.944545 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.944595 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.944652 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.944703 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.944755 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.944812 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.944863 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.944913 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.944970 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.945032 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.945087 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.945145 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.945210 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.945264 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:57.945322 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.014656 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.014769 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.014858 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.014937 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.015006 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.015081 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.015148 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.015247 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.015327 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.015397 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.015468 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.015566 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.015643 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.015715 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.015804 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.015878 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.015947 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.016025 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.016096 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.016179 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.016262 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.016352 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.016424 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.016510 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.016587 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.016660 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.016738 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.016813 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.016887 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.016964 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.017037 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.017109 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.017203 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.017281 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.017354 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.017432 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.017511 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.017585 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.017664 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.017734 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.017806 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.017885 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.017957 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.018028 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.018108 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.018198 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.018273 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.018352 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.018426 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.018498 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.018587 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.018660 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.018732 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.018833 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.018903 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.018972 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.019048 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.019118 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.019198 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.019287 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.019374 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.019443 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.019527 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.019598 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.019667 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.019745 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.019814 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.019882 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.019961 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.020033 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.020101 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.020195 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.020270 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.020337 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.020413 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.020483 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.020574 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.020648 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.020714 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.020780 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.020853 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.020920 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.020985 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.021057 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.021125 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.021204 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.021279 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.021345 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.021409 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.021482 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.021558 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.021621 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.021692 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.021759 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.021823 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.021893 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.021960 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.022024 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.022094 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.022158 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.022241 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.022313 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.022378 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.022441 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.022521 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.022591 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.022671 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.022754 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.022840 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.022909 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.022984 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.023054 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.023122 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.023212 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.023284 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.023350 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.023424 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.023519 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.023591 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.023667 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.023741 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.023811 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.023888 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.023970 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.024038 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.024113 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.024196 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.024268 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.024345 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.024416 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.024492 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.024595 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.024669 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.024750 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.024824 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.024894 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.024980 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.025057 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.025127 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.025215 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.025297 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.025372 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.025441 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.025527 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.025604 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.025684 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.025774 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.025846 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.025918 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.025996 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.026066 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.026136 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.026232 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.026309 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.026380 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.026456 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.026540 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.026613 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.026690 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.026764 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.026836 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.026915 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.026985 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.027056 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.027136 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.027226 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.027298 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.027377 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.027452 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.027641 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.027802 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.027915 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.028026 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.028126 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.028237 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.028330 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.028445 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.028553 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.028645 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.028743 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.028834 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.028922 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.029016 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.029107 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.029211 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.029312 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.029400 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.029487 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.029594 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.029684 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.029770 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.029864 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.029955 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.030043 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.030140 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.030251 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.030340 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.030436 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.030535 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.030630 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.030751 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.030843 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.030931 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.031088 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.031429 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.031607 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.031733 140689526667136 variables_helper.py:157] Variable [FirstStageFeatureExtractor/resnet_v1_101/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.031824 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.031913 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.032020 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.032112 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.032218 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.032317 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.032406 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.032493 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.032588 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.032675 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.032763 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.032864 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.032954 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.033051 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.033149 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.033258 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.033346 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.033440 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.033528 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.033616 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.033708 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.033795 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.033881 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.033976 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.034075 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.034177 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.034277 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/weights/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.034365 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/beta/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.034451 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm/gamma/Momentum] is not available in checkpoint\n",
            "W0205 13:13:58.034543 140689526667136 variables_helper.py:157] Variable [SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/weights/Momentum] is not available in checkpoint\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/slim/python/slim/learning.py:742: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.MonitoredTrainingSession\n",
            "W0205 13:13:58.989343 140689526667136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/slim/python/slim/learning.py:742: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.MonitoredTrainingSession\n",
            "2020-02-05 13:14:00.093972: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-02-05 13:14:00.094274: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x14861d40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-02-05 13:14:00.094323: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-02-05 13:14:00.099353: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-02-05 13:14:00.309154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-05 13:14:00.309864: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xee60000 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-02-05 13:14:00.309892: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-02-05 13:14:00.310990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-05 13:14:00.311488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-02-05 13:14:00.326392: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-05 13:14:00.557258: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-02-05 13:14:00.678684: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-02-05 13:14:00.701153: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-02-05 13:14:00.963159: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-02-05 13:14:00.997888: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-02-05 13:14:01.494352: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-02-05 13:14:01.494547: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-05 13:14:01.495122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-05 13:14:01.495599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-02-05 13:14:01.498851: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-05 13:14:01.500048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-02-05 13:14:01.500074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-02-05 13:14:01.500084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-02-05 13:14:01.500984: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-05 13:14:01.501572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-05 13:14:01.502039: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-02-05 13:14:01.502072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from ../faster_rcnn_resnet101_coco_2018_01_28/model.ckpt\n",
            "I0205 13:14:05.355551 140689526667136 saver.py:1284] Restoring parameters from ../faster_rcnn_resnet101_coco_2018_01_28/model.ckpt\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0205 13:14:06.315677 140689526667136 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0205 13:14:06.718834 140689526667136 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Starting Session.\n",
            "I0205 13:14:13.424708 140689526667136 learning.py:754] Starting Session.\n",
            "INFO:tensorflow:Saving checkpoint to path ../training/model.ckpt\n",
            "I0205 13:14:13.744523 140686000895744 supervisor.py:1117] Saving checkpoint to path ../training/model.ckpt\n",
            "INFO:tensorflow:Starting Queues.\n",
            "I0205 13:14:13.749335 140689526667136 learning.py:768] Starting Queues.\n",
            "2020-02-05 13:14:16.058332: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-02-05 13:14:26.031986: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "INFO:tensorflow:global_step/sec: 0\n",
            "I0205 13:14:26.807245 140686034466560 supervisor.py:1099] global_step/sec: 0\n",
            "INFO:tensorflow:Recording summary at step 0.\n",
            "I0205 13:14:35.543614 140686026073856 supervisor.py:1050] Recording summary at step 0.\n",
            "2020-02-05 13:14:38.408254: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 237794304 exceeds 10% of system memory.\n",
            "2020-02-05 13:14:38.578696: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 237794304 exceeds 10% of system memory.\n",
            "INFO:tensorflow:global step 1: loss = 3.1962 (24.188 sec/step)\n",
            "I0205 13:14:38.734687 140689526667136 learning.py:507] global step 1: loss = 3.1962 (24.188 sec/step)\n",
            "INFO:tensorflow:global step 2: loss = 2.9639 (2.405 sec/step)\n",
            "I0205 13:14:41.477006 140689526667136 learning.py:507] global step 2: loss = 2.9639 (2.405 sec/step)\n",
            "INFO:tensorflow:global step 3: loss = 2.6857 (2.586 sec/step)\n",
            "I0205 13:14:44.064592 140689526667136 learning.py:507] global step 3: loss = 2.6857 (2.586 sec/step)\n",
            "INFO:tensorflow:global step 4: loss = 2.3788 (0.995 sec/step)\n",
            "I0205 13:14:45.061596 140689526667136 learning.py:507] global step 4: loss = 2.3788 (0.995 sec/step)\n",
            "INFO:tensorflow:global step 5: loss = 2.1469 (0.378 sec/step)\n",
            "I0205 13:14:45.441322 140689526667136 learning.py:507] global step 5: loss = 2.1469 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 6: loss = 1.8460 (0.383 sec/step)\n",
            "I0205 13:14:45.826202 140689526667136 learning.py:507] global step 6: loss = 1.8460 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 7: loss = 1.5919 (0.420 sec/step)\n",
            "I0205 13:14:46.248217 140689526667136 learning.py:507] global step 7: loss = 1.5919 (0.420 sec/step)\n",
            "INFO:tensorflow:global step 8: loss = 1.7037 (2.491 sec/step)\n",
            "I0205 13:14:48.740499 140689526667136 learning.py:507] global step 8: loss = 1.7037 (2.491 sec/step)\n",
            "INFO:tensorflow:global step 9: loss = 1.1013 (0.449 sec/step)\n",
            "I0205 13:14:49.190946 140689526667136 learning.py:507] global step 9: loss = 1.1013 (0.449 sec/step)\n",
            "INFO:tensorflow:global step 10: loss = 0.9682 (0.378 sec/step)\n",
            "I0205 13:14:49.570914 140689526667136 learning.py:507] global step 10: loss = 0.9682 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 11: loss = 0.8945 (0.368 sec/step)\n",
            "I0205 13:14:49.941133 140689526667136 learning.py:507] global step 11: loss = 0.8945 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 12: loss = 0.7579 (0.414 sec/step)\n",
            "I0205 13:14:50.357343 140689526667136 learning.py:507] global step 12: loss = 0.7579 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 13: loss = 1.2336 (0.379 sec/step)\n",
            "I0205 13:14:50.738333 140689526667136 learning.py:507] global step 13: loss = 1.2336 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 14: loss = 0.7893 (2.511 sec/step)\n",
            "I0205 13:14:53.251089 140689526667136 learning.py:507] global step 14: loss = 0.7893 (2.511 sec/step)\n",
            "INFO:tensorflow:global step 15: loss = 0.6206 (0.361 sec/step)\n",
            "I0205 13:14:53.613908 140689526667136 learning.py:507] global step 15: loss = 0.6206 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 16: loss = 0.7114 (0.366 sec/step)\n",
            "I0205 13:14:53.981415 140689526667136 learning.py:507] global step 16: loss = 0.7114 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 17: loss = 1.0699 (0.381 sec/step)\n",
            "I0205 13:14:54.364312 140689526667136 learning.py:507] global step 17: loss = 1.0699 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 18: loss = 0.7536 (2.538 sec/step)\n",
            "I0205 13:14:56.903346 140689526667136 learning.py:507] global step 18: loss = 0.7536 (2.538 sec/step)\n",
            "INFO:tensorflow:global step 19: loss = 0.5567 (0.380 sec/step)\n",
            "I0205 13:14:57.284597 140689526667136 learning.py:507] global step 19: loss = 0.5567 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 20: loss = 0.5471 (0.359 sec/step)\n",
            "I0205 13:14:57.645188 140689526667136 learning.py:507] global step 20: loss = 0.5471 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 21: loss = 0.5181 (0.360 sec/step)\n",
            "I0205 13:14:58.006491 140689526667136 learning.py:507] global step 21: loss = 0.5181 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 22: loss = 0.5185 (1.581 sec/step)\n",
            "I0205 13:14:59.589367 140689526667136 learning.py:507] global step 22: loss = 0.5185 (1.581 sec/step)\n",
            "INFO:tensorflow:global step 23: loss = 0.6222 (2.401 sec/step)\n",
            "I0205 13:15:01.991955 140689526667136 learning.py:507] global step 23: loss = 0.6222 (2.401 sec/step)\n",
            "INFO:tensorflow:global step 24: loss = 0.6676 (0.353 sec/step)\n",
            "I0205 13:15:02.346998 140689526667136 learning.py:507] global step 24: loss = 0.6676 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 25: loss = 0.4896 (2.207 sec/step)\n",
            "I0205 13:15:04.555377 140689526667136 learning.py:507] global step 25: loss = 0.4896 (2.207 sec/step)\n",
            "INFO:tensorflow:global step 26: loss = 0.4889 (2.577 sec/step)\n",
            "I0205 13:15:07.133810 140689526667136 learning.py:507] global step 26: loss = 0.4889 (2.577 sec/step)\n",
            "INFO:tensorflow:global step 27: loss = 0.5690 (2.203 sec/step)\n",
            "I0205 13:15:09.338252 140689526667136 learning.py:507] global step 27: loss = 0.5690 (2.203 sec/step)\n",
            "INFO:tensorflow:global step 28: loss = 0.5010 (0.393 sec/step)\n",
            "I0205 13:15:09.732995 140689526667136 learning.py:507] global step 28: loss = 0.5010 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 29: loss = 0.4592 (2.692 sec/step)\n",
            "I0205 13:15:12.426448 140689526667136 learning.py:507] global step 29: loss = 0.4592 (2.692 sec/step)\n",
            "INFO:tensorflow:global step 30: loss = 1.3495 (0.397 sec/step)\n",
            "I0205 13:15:12.824692 140689526667136 learning.py:507] global step 30: loss = 1.3495 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 31: loss = 0.4457 (2.554 sec/step)\n",
            "I0205 13:15:15.379769 140689526667136 learning.py:507] global step 31: loss = 0.4457 (2.554 sec/step)\n",
            "INFO:tensorflow:global step 32: loss = 0.4633 (0.368 sec/step)\n",
            "I0205 13:15:15.751617 140689526667136 learning.py:507] global step 32: loss = 0.4633 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 33: loss = 0.4038 (2.179 sec/step)\n",
            "I0205 13:15:17.933305 140689526667136 learning.py:507] global step 33: loss = 0.4038 (2.179 sec/step)\n",
            "INFO:tensorflow:global step 34: loss = 0.4694 (0.366 sec/step)\n",
            "I0205 13:15:18.301207 140689526667136 learning.py:507] global step 34: loss = 0.4694 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 35: loss = 0.4049 (0.347 sec/step)\n",
            "I0205 13:15:18.649929 140689526667136 learning.py:507] global step 35: loss = 0.4049 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 36: loss = 0.4610 (0.390 sec/step)\n",
            "I0205 13:15:19.041487 140689526667136 learning.py:507] global step 36: loss = 0.4610 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 37: loss = 0.3941 (0.391 sec/step)\n",
            "I0205 13:15:19.434459 140689526667136 learning.py:507] global step 37: loss = 0.3941 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 38: loss = 0.3791 (2.607 sec/step)\n",
            "I0205 13:15:22.042676 140689526667136 learning.py:507] global step 38: loss = 0.3791 (2.607 sec/step)\n",
            "INFO:tensorflow:global step 39: loss = 0.6028 (2.564 sec/step)\n",
            "I0205 13:15:24.607793 140689526667136 learning.py:507] global step 39: loss = 0.6028 (2.564 sec/step)\n",
            "INFO:tensorflow:global step 40: loss = 0.3347 (2.590 sec/step)\n",
            "I0205 13:15:27.199820 140689526667136 learning.py:507] global step 40: loss = 0.3347 (2.590 sec/step)\n",
            "INFO:tensorflow:global step 41: loss = 0.4463 (0.374 sec/step)\n",
            "I0205 13:15:27.575057 140689526667136 learning.py:507] global step 41: loss = 0.4463 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 42: loss = 0.3645 (0.392 sec/step)\n",
            "I0205 13:15:27.969424 140689526667136 learning.py:507] global step 42: loss = 0.3645 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 43: loss = 0.3210 (0.398 sec/step)\n",
            "I0205 13:15:28.368840 140689526667136 learning.py:507] global step 43: loss = 0.3210 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 44: loss = 0.3046 (0.434 sec/step)\n",
            "I0205 13:15:28.804215 140689526667136 learning.py:507] global step 44: loss = 0.3046 (0.434 sec/step)\n",
            "INFO:tensorflow:global step 45: loss = 0.3201 (1.085 sec/step)\n",
            "I0205 13:15:29.890975 140689526667136 learning.py:507] global step 45: loss = 0.3201 (1.085 sec/step)\n",
            "INFO:tensorflow:global step 46: loss = 0.2793 (2.414 sec/step)\n",
            "I0205 13:15:32.307372 140689526667136 learning.py:507] global step 46: loss = 0.2793 (2.414 sec/step)\n",
            "INFO:tensorflow:global step 47: loss = 0.3626 (0.376 sec/step)\n",
            "I0205 13:15:32.684838 140689526667136 learning.py:507] global step 47: loss = 0.3626 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 48: loss = 0.6354 (2.504 sec/step)\n",
            "I0205 13:15:35.191145 140689526667136 learning.py:507] global step 48: loss = 0.6354 (2.504 sec/step)\n",
            "INFO:tensorflow:global step 49: loss = 0.3444 (0.360 sec/step)\n",
            "I0205 13:15:35.553246 140689526667136 learning.py:507] global step 49: loss = 0.3444 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 50: loss = 0.2574 (0.396 sec/step)\n",
            "I0205 13:15:35.950889 140689526667136 learning.py:507] global step 50: loss = 0.2574 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 51: loss = 0.2874 (0.385 sec/step)\n",
            "I0205 13:15:36.337780 140689526667136 learning.py:507] global step 51: loss = 0.2874 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 52: loss = 0.5604 (0.384 sec/step)\n",
            "I0205 13:15:36.723228 140689526667136 learning.py:507] global step 52: loss = 0.5604 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 53: loss = 0.2643 (0.442 sec/step)\n",
            "I0205 13:15:37.166401 140689526667136 learning.py:507] global step 53: loss = 0.2643 (0.442 sec/step)\n",
            "INFO:tensorflow:global step 54: loss = 0.2358 (0.413 sec/step)\n",
            "I0205 13:15:37.580766 140689526667136 learning.py:507] global step 54: loss = 0.2358 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 55: loss = 0.2807 (0.370 sec/step)\n",
            "I0205 13:15:37.952405 140689526667136 learning.py:507] global step 55: loss = 0.2807 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 56: loss = 0.2913 (0.372 sec/step)\n",
            "I0205 13:15:38.325897 140689526667136 learning.py:507] global step 56: loss = 0.2913 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 57: loss = 0.2415 (1.632 sec/step)\n",
            "I0205 13:15:39.959247 140689526667136 learning.py:507] global step 57: loss = 0.2415 (1.632 sec/step)\n",
            "INFO:tensorflow:global step 58: loss = 0.3921 (0.386 sec/step)\n",
            "I0205 13:15:40.346915 140689526667136 learning.py:507] global step 58: loss = 0.3921 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 59: loss = 0.2690 (0.410 sec/step)\n",
            "I0205 13:15:40.758715 140689526667136 learning.py:507] global step 59: loss = 0.2690 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 60: loss = 1.1655 (0.398 sec/step)\n",
            "I0205 13:15:41.158420 140689526667136 learning.py:507] global step 60: loss = 1.1655 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 61: loss = 0.1912 (0.394 sec/step)\n",
            "I0205 13:15:41.554547 140689526667136 learning.py:507] global step 61: loss = 0.1912 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 62: loss = 1.5615 (2.579 sec/step)\n",
            "I0205 13:15:44.135087 140689526667136 learning.py:507] global step 62: loss = 1.5615 (2.579 sec/step)\n",
            "INFO:tensorflow:global step 63: loss = 0.4940 (1.610 sec/step)\n",
            "I0205 13:15:45.746639 140689526667136 learning.py:507] global step 63: loss = 0.4940 (1.610 sec/step)\n",
            "INFO:tensorflow:global step 64: loss = 0.2226 (0.384 sec/step)\n",
            "I0205 13:15:46.132593 140689526667136 learning.py:507] global step 64: loss = 0.2226 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 65: loss = 0.3099 (0.367 sec/step)\n",
            "I0205 13:15:46.501232 140689526667136 learning.py:507] global step 65: loss = 0.3099 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 66: loss = 0.2811 (0.373 sec/step)\n",
            "I0205 13:15:46.875980 140689526667136 learning.py:507] global step 66: loss = 0.2811 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 67: loss = 0.2714 (2.732 sec/step)\n",
            "I0205 13:15:49.609590 140689526667136 learning.py:507] global step 67: loss = 0.2714 (2.732 sec/step)\n",
            "INFO:tensorflow:global step 68: loss = 3.2761 (0.371 sec/step)\n",
            "I0205 13:15:49.982244 140689526667136 learning.py:507] global step 68: loss = 3.2761 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 69: loss = 1.3049 (0.372 sec/step)\n",
            "I0205 13:15:50.356196 140689526667136 learning.py:507] global step 69: loss = 1.3049 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 70: loss = 0.2236 (2.526 sec/step)\n",
            "I0205 13:15:52.883882 140689526667136 learning.py:507] global step 70: loss = 0.2236 (2.526 sec/step)\n",
            "INFO:tensorflow:global step 71: loss = 0.1642 (0.390 sec/step)\n",
            "I0205 13:15:53.275825 140689526667136 learning.py:507] global step 71: loss = 0.1642 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 72: loss = 0.2174 (2.543 sec/step)\n",
            "I0205 13:15:55.820432 140689526667136 learning.py:507] global step 72: loss = 0.2174 (2.543 sec/step)\n",
            "INFO:tensorflow:global step 73: loss = 0.1673 (0.374 sec/step)\n",
            "I0205 13:15:56.195664 140689526667136 learning.py:507] global step 73: loss = 0.1673 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 74: loss = 0.2253 (2.610 sec/step)\n",
            "I0205 13:15:58.806843 140689526667136 learning.py:507] global step 74: loss = 0.2253 (2.610 sec/step)\n",
            "INFO:tensorflow:global step 75: loss = 3.1216 (0.381 sec/step)\n",
            "I0205 13:15:59.189038 140689526667136 learning.py:507] global step 75: loss = 3.1216 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 76: loss = 0.1540 (0.400 sec/step)\n",
            "I0205 13:15:59.590868 140689526667136 learning.py:507] global step 76: loss = 0.1540 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 77: loss = 0.1817 (0.400 sec/step)\n",
            "I0205 13:15:59.992532 140689526667136 learning.py:507] global step 77: loss = 0.1817 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 78: loss = 0.2104 (2.483 sec/step)\n",
            "I0205 13:16:02.477719 140689526667136 learning.py:507] global step 78: loss = 0.2104 (2.483 sec/step)\n",
            "INFO:tensorflow:global step 79: loss = 0.1249 (0.957 sec/step)\n",
            "I0205 13:16:03.436070 140689526667136 learning.py:507] global step 79: loss = 0.1249 (0.957 sec/step)\n",
            "INFO:tensorflow:global step 80: loss = 0.1332 (2.554 sec/step)\n",
            "I0205 13:16:05.991357 140689526667136 learning.py:507] global step 80: loss = 0.1332 (2.554 sec/step)\n",
            "INFO:tensorflow:global step 81: loss = 0.1286 (0.357 sec/step)\n",
            "I0205 13:16:06.349417 140689526667136 learning.py:507] global step 81: loss = 0.1286 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 82: loss = 0.4395 (0.377 sec/step)\n",
            "I0205 13:16:06.728231 140689526667136 learning.py:507] global step 82: loss = 0.4395 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 83: loss = 0.4210 (0.394 sec/step)\n",
            "I0205 13:16:07.123362 140689526667136 learning.py:507] global step 83: loss = 0.4210 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 84: loss = 0.2259 (2.217 sec/step)\n",
            "I0205 13:16:09.342276 140689526667136 learning.py:507] global step 84: loss = 0.2259 (2.217 sec/step)\n",
            "INFO:tensorflow:global step 85: loss = 0.1389 (0.379 sec/step)\n",
            "I0205 13:16:09.722725 140689526667136 learning.py:507] global step 85: loss = 0.1389 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 86: loss = 0.1596 (1.666 sec/step)\n",
            "I0205 13:16:11.389777 140689526667136 learning.py:507] global step 86: loss = 0.1596 (1.666 sec/step)\n",
            "INFO:tensorflow:global step 87: loss = 0.1657 (0.442 sec/step)\n",
            "I0205 13:16:11.833622 140689526667136 learning.py:507] global step 87: loss = 0.1657 (0.442 sec/step)\n",
            "INFO:tensorflow:global step 88: loss = 1.4175 (0.391 sec/step)\n",
            "I0205 13:16:12.226773 140689526667136 learning.py:507] global step 88: loss = 1.4175 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 89: loss = 0.7727 (0.410 sec/step)\n",
            "I0205 13:16:12.639115 140689526667136 learning.py:507] global step 89: loss = 0.7727 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 90: loss = 0.2323 (2.716 sec/step)\n",
            "I0205 13:16:15.367356 140689526667136 learning.py:507] global step 90: loss = 0.2323 (2.716 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 0.824516\n",
            "I0205 13:16:15.962194 140686034466560 supervisor.py:1099] global_step/sec: 0.824516\n",
            "INFO:tensorflow:global step 91: loss = 0.1853 (0.689 sec/step)\n",
            "I0205 13:16:16.075851 140689526667136 learning.py:507] global step 91: loss = 0.1853 (0.689 sec/step)\n",
            "INFO:tensorflow:global step 92: loss = 0.2181 (0.673 sec/step)\n",
            "I0205 13:16:16.789992 140689526667136 learning.py:507] global step 92: loss = 0.2181 (0.673 sec/step)\n",
            "INFO:tensorflow:global step 93: loss = 0.1701 (0.647 sec/step)\n",
            "I0205 13:16:17.438572 140689526667136 learning.py:507] global step 93: loss = 0.1701 (0.647 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 93.\n",
            "I0205 13:16:18.011678 140686026073856 supervisor.py:1050] Recording summary at step 93.\n",
            "INFO:tensorflow:global step 94: loss = 0.1179 (0.582 sec/step)\n",
            "I0205 13:16:18.023777 140689526667136 learning.py:507] global step 94: loss = 0.1179 (0.582 sec/step)\n",
            "INFO:tensorflow:global step 95: loss = 0.1011 (0.351 sec/step)\n",
            "I0205 13:16:18.376616 140689526667136 learning.py:507] global step 95: loss = 0.1011 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 96: loss = 0.1392 (2.719 sec/step)\n",
            "I0205 13:16:21.097072 140689526667136 learning.py:507] global step 96: loss = 0.1392 (2.719 sec/step)\n",
            "INFO:tensorflow:global step 97: loss = 0.1021 (0.450 sec/step)\n",
            "I0205 13:16:21.548366 140689526667136 learning.py:507] global step 97: loss = 0.1021 (0.450 sec/step)\n",
            "INFO:tensorflow:global step 98: loss = 0.6665 (0.369 sec/step)\n",
            "I0205 13:16:21.918816 140689526667136 learning.py:507] global step 98: loss = 0.6665 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 99: loss = 0.1878 (0.387 sec/step)\n",
            "I0205 13:16:22.307473 140689526667136 learning.py:507] global step 99: loss = 0.1878 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 100: loss = 0.1217 (1.614 sec/step)\n",
            "I0205 13:16:23.923027 140689526667136 learning.py:507] global step 100: loss = 0.1217 (1.614 sec/step)\n",
            "INFO:tensorflow:global step 101: loss = 0.1545 (0.396 sec/step)\n",
            "I0205 13:16:24.321120 140689526667136 learning.py:507] global step 101: loss = 0.1545 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 102: loss = 0.4153 (0.363 sec/step)\n",
            "I0205 13:16:24.686077 140689526667136 learning.py:507] global step 102: loss = 0.4153 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 103: loss = 0.1674 (1.045 sec/step)\n",
            "I0205 13:16:25.732872 140689526667136 learning.py:507] global step 103: loss = 0.1674 (1.045 sec/step)\n",
            "INFO:tensorflow:global step 104: loss = 0.3769 (0.430 sec/step)\n",
            "I0205 13:16:26.164644 140689526667136 learning.py:507] global step 104: loss = 0.3769 (0.430 sec/step)\n",
            "INFO:tensorflow:global step 105: loss = 0.0971 (0.447 sec/step)\n",
            "I0205 13:16:26.613564 140689526667136 learning.py:507] global step 105: loss = 0.0971 (0.447 sec/step)\n",
            "INFO:tensorflow:global step 106: loss = 0.1409 (2.598 sec/step)\n",
            "I0205 13:16:29.213263 140689526667136 learning.py:507] global step 106: loss = 0.1409 (2.598 sec/step)\n",
            "INFO:tensorflow:global step 107: loss = 2.1885 (0.432 sec/step)\n",
            "I0205 13:16:29.646605 140689526667136 learning.py:507] global step 107: loss = 2.1885 (0.432 sec/step)\n",
            "INFO:tensorflow:global step 108: loss = 0.1465 (2.621 sec/step)\n",
            "I0205 13:16:32.269347 140689526667136 learning.py:507] global step 108: loss = 0.1465 (2.621 sec/step)\n",
            "INFO:tensorflow:global step 109: loss = 0.0919 (2.545 sec/step)\n",
            "I0205 13:16:34.815997 140689526667136 learning.py:507] global step 109: loss = 0.0919 (2.545 sec/step)\n",
            "INFO:tensorflow:global step 110: loss = 0.2723 (0.369 sec/step)\n",
            "I0205 13:16:35.186878 140689526667136 learning.py:507] global step 110: loss = 0.2723 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 111: loss = 0.1556 (0.393 sec/step)\n",
            "I0205 13:16:35.581779 140689526667136 learning.py:507] global step 111: loss = 0.1556 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 112: loss = 2.0875 (1.051 sec/step)\n",
            "I0205 13:16:36.634085 140689526667136 learning.py:507] global step 112: loss = 2.0875 (1.051 sec/step)\n",
            "INFO:tensorflow:global step 113: loss = 0.0888 (2.715 sec/step)\n",
            "I0205 13:16:39.350082 140689526667136 learning.py:507] global step 113: loss = 0.0888 (2.715 sec/step)\n",
            "INFO:tensorflow:global step 114: loss = 0.2436 (0.878 sec/step)\n",
            "I0205 13:16:40.229099 140689526667136 learning.py:507] global step 114: loss = 0.2436 (0.878 sec/step)\n",
            "INFO:tensorflow:global step 115: loss = 0.1426 (2.478 sec/step)\n",
            "I0205 13:16:42.708434 140689526667136 learning.py:507] global step 115: loss = 0.1426 (2.478 sec/step)\n",
            "INFO:tensorflow:global step 116: loss = 0.1657 (0.365 sec/step)\n",
            "I0205 13:16:43.075406 140689526667136 learning.py:507] global step 116: loss = 0.1657 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 117: loss = 0.1206 (0.372 sec/step)\n",
            "I0205 13:16:43.449637 140689526667136 learning.py:507] global step 117: loss = 0.1206 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 118: loss = 1.3508 (1.553 sec/step)\n",
            "I0205 13:16:45.004648 140689526667136 learning.py:507] global step 118: loss = 1.3508 (1.553 sec/step)\n",
            "INFO:tensorflow:global step 119: loss = 0.0850 (0.385 sec/step)\n",
            "I0205 13:16:45.392940 140689526667136 learning.py:507] global step 119: loss = 0.0850 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 120: loss = 0.5737 (0.387 sec/step)\n",
            "I0205 13:16:45.781668 140689526667136 learning.py:507] global step 120: loss = 0.5737 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 121: loss = 0.1379 (0.378 sec/step)\n",
            "I0205 13:16:46.161313 140689526667136 learning.py:507] global step 121: loss = 0.1379 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 122: loss = 0.0717 (0.365 sec/step)\n",
            "I0205 13:16:46.527787 140689526667136 learning.py:507] global step 122: loss = 0.0717 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 123: loss = 0.2082 (0.383 sec/step)\n",
            "I0205 13:16:46.912019 140689526667136 learning.py:507] global step 123: loss = 0.2082 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 124: loss = 0.1391 (0.389 sec/step)\n",
            "I0205 13:16:47.302896 140689526667136 learning.py:507] global step 124: loss = 0.1391 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 125: loss = 0.7380 (1.664 sec/step)\n",
            "I0205 13:16:48.968428 140689526667136 learning.py:507] global step 125: loss = 0.7380 (1.664 sec/step)\n",
            "INFO:tensorflow:global step 126: loss = 0.0855 (0.382 sec/step)\n",
            "I0205 13:16:49.352392 140689526667136 learning.py:507] global step 126: loss = 0.0855 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 127: loss = 0.0958 (0.405 sec/step)\n",
            "I0205 13:16:49.758910 140689526667136 learning.py:507] global step 127: loss = 0.0958 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 128: loss = 0.1476 (0.378 sec/step)\n",
            "I0205 13:16:50.138753 140689526667136 learning.py:507] global step 128: loss = 0.1476 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 129: loss = 0.1858 (0.387 sec/step)\n",
            "I0205 13:16:50.527922 140689526667136 learning.py:507] global step 129: loss = 0.1858 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 130: loss = 0.6671 (0.406 sec/step)\n",
            "I0205 13:16:50.935878 140689526667136 learning.py:507] global step 130: loss = 0.6671 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 131: loss = 0.0807 (0.362 sec/step)\n",
            "I0205 13:16:51.299393 140689526667136 learning.py:507] global step 131: loss = 0.0807 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 132: loss = 0.1308 (0.388 sec/step)\n",
            "I0205 13:16:51.688580 140689526667136 learning.py:507] global step 132: loss = 0.1308 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 133: loss = 0.0866 (0.370 sec/step)\n",
            "I0205 13:16:52.059979 140689526667136 learning.py:507] global step 133: loss = 0.0866 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 134: loss = 1.1642 (0.394 sec/step)\n",
            "I0205 13:16:52.455680 140689526667136 learning.py:507] global step 134: loss = 1.1642 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 135: loss = 0.0690 (0.409 sec/step)\n",
            "I0205 13:16:52.867362 140689526667136 learning.py:507] global step 135: loss = 0.0690 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 136: loss = 2.1068 (0.399 sec/step)\n",
            "I0205 13:16:53.268578 140689526667136 learning.py:507] global step 136: loss = 2.1068 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 137: loss = 0.1641 (0.389 sec/step)\n",
            "I0205 13:16:53.659031 140689526667136 learning.py:507] global step 137: loss = 0.1641 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 138: loss = 0.1231 (0.406 sec/step)\n",
            "I0205 13:16:54.066797 140689526667136 learning.py:507] global step 138: loss = 0.1231 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 139: loss = 0.5029 (0.387 sec/step)\n",
            "I0205 13:16:54.455743 140689526667136 learning.py:507] global step 139: loss = 0.5029 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 140: loss = 0.1463 (0.387 sec/step)\n",
            "I0205 13:16:54.844756 140689526667136 learning.py:507] global step 140: loss = 0.1463 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 141: loss = 0.1490 (1.572 sec/step)\n",
            "I0205 13:16:56.418461 140689526667136 learning.py:507] global step 141: loss = 0.1490 (1.572 sec/step)\n",
            "INFO:tensorflow:global step 142: loss = 0.0681 (0.368 sec/step)\n",
            "I0205 13:16:56.788005 140689526667136 learning.py:507] global step 142: loss = 0.0681 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 143: loss = 0.0893 (0.410 sec/step)\n",
            "I0205 13:16:57.199493 140689526667136 learning.py:507] global step 143: loss = 0.0893 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 144: loss = 0.1565 (0.388 sec/step)\n",
            "I0205 13:16:57.589283 140689526667136 learning.py:507] global step 144: loss = 0.1565 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 145: loss = 0.8827 (0.383 sec/step)\n",
            "I0205 13:16:57.974136 140689526667136 learning.py:507] global step 145: loss = 0.8827 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 146: loss = 0.1333 (0.395 sec/step)\n",
            "I0205 13:16:58.371679 140689526667136 learning.py:507] global step 146: loss = 0.1333 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 147: loss = 0.8427 (0.376 sec/step)\n",
            "I0205 13:16:58.749267 140689526667136 learning.py:507] global step 147: loss = 0.8427 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 148: loss = 0.6832 (0.406 sec/step)\n",
            "I0205 13:16:59.156943 140689526667136 learning.py:507] global step 148: loss = 0.6832 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 149: loss = 0.0656 (0.388 sec/step)\n",
            "I0205 13:16:59.546530 140689526667136 learning.py:507] global step 149: loss = 0.0656 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 150: loss = 0.1398 (0.397 sec/step)\n",
            "I0205 13:16:59.945511 140689526667136 learning.py:507] global step 150: loss = 0.1398 (0.397 sec/step)\n",
            "2020-02-05 13:16:59.990735: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 237794304 exceeds 10% of system memory.\n",
            "INFO:tensorflow:global step 151: loss = 0.7450 (1.329 sec/step)\n",
            "I0205 13:17:01.276130 140689526667136 learning.py:507] global step 151: loss = 0.7450 (1.329 sec/step)\n",
            "INFO:tensorflow:global step 152: loss = 0.0821 (0.387 sec/step)\n",
            "I0205 13:17:01.664861 140689526667136 learning.py:507] global step 152: loss = 0.0821 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 153: loss = 0.0999 (2.514 sec/step)\n",
            "I0205 13:17:04.180561 140689526667136 learning.py:507] global step 153: loss = 0.0999 (2.514 sec/step)\n",
            "INFO:tensorflow:global step 154: loss = 0.1544 (0.358 sec/step)\n",
            "I0205 13:17:04.540268 140689526667136 learning.py:507] global step 154: loss = 0.1544 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 155: loss = 0.1896 (1.605 sec/step)\n",
            "I0205 13:17:06.146377 140689526667136 learning.py:507] global step 155: loss = 0.1896 (1.605 sec/step)\n",
            "INFO:tensorflow:global step 156: loss = 0.0506 (0.368 sec/step)\n",
            "I0205 13:17:06.516024 140689526667136 learning.py:507] global step 156: loss = 0.0506 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 157: loss = 0.7229 (0.428 sec/step)\n",
            "I0205 13:17:06.945542 140689526667136 learning.py:507] global step 157: loss = 0.7229 (0.428 sec/step)\n",
            "INFO:tensorflow:global step 158: loss = 0.8305 (0.400 sec/step)\n",
            "I0205 13:17:07.347234 140689526667136 learning.py:507] global step 158: loss = 0.8305 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 159: loss = 0.5007 (0.383 sec/step)\n",
            "I0205 13:17:07.732141 140689526667136 learning.py:507] global step 159: loss = 0.5007 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 160: loss = 0.6617 (0.403 sec/step)\n",
            "I0205 13:17:08.136915 140689526667136 learning.py:507] global step 160: loss = 0.6617 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 161: loss = 0.0847 (1.077 sec/step)\n",
            "I0205 13:17:09.215548 140689526667136 learning.py:507] global step 161: loss = 0.0847 (1.077 sec/step)\n",
            "INFO:tensorflow:global step 162: loss = 0.0783 (0.387 sec/step)\n",
            "I0205 13:17:09.604485 140689526667136 learning.py:507] global step 162: loss = 0.0783 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 163: loss = 0.0950 (2.508 sec/step)\n",
            "I0205 13:17:12.113847 140689526667136 learning.py:507] global step 163: loss = 0.0950 (2.508 sec/step)\n",
            "INFO:tensorflow:global step 164: loss = 0.0756 (0.386 sec/step)\n",
            "I0205 13:17:12.501375 140689526667136 learning.py:507] global step 164: loss = 0.0756 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 165: loss = 0.5633 (0.360 sec/step)\n",
            "I0205 13:17:12.862268 140689526667136 learning.py:507] global step 165: loss = 0.5633 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 166: loss = 0.1605 (0.389 sec/step)\n",
            "I0205 13:17:13.253215 140689526667136 learning.py:507] global step 166: loss = 0.1605 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 167: loss = 0.0668 (0.414 sec/step)\n",
            "I0205 13:17:13.669046 140689526667136 learning.py:507] global step 167: loss = 0.0668 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 168: loss = 0.1418 (0.439 sec/step)\n",
            "I0205 13:17:14.109989 140689526667136 learning.py:507] global step 168: loss = 0.1418 (0.439 sec/step)\n",
            "INFO:tensorflow:global step 169: loss = 0.1835 (0.410 sec/step)\n",
            "I0205 13:17:14.521935 140689526667136 learning.py:507] global step 169: loss = 0.1835 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 170: loss = 0.1239 (0.380 sec/step)\n",
            "I0205 13:17:14.903292 140689526667136 learning.py:507] global step 170: loss = 0.1239 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 171: loss = 0.0672 (1.655 sec/step)\n",
            "I0205 13:17:16.559335 140689526667136 learning.py:507] global step 171: loss = 0.0672 (1.655 sec/step)\n",
            "INFO:tensorflow:global step 172: loss = 0.2503 (0.395 sec/step)\n",
            "I0205 13:17:16.956505 140689526667136 learning.py:507] global step 172: loss = 0.2503 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 173: loss = 0.1609 (0.380 sec/step)\n",
            "I0205 13:17:17.337837 140689526667136 learning.py:507] global step 173: loss = 0.1609 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 174: loss = 0.2064 (0.368 sec/step)\n",
            "I0205 13:17:17.708060 140689526667136 learning.py:507] global step 174: loss = 0.2064 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 175: loss = 0.5831 (2.287 sec/step)\n",
            "I0205 13:17:19.996488 140689526667136 learning.py:507] global step 175: loss = 0.5831 (2.287 sec/step)\n",
            "INFO:tensorflow:global step 176: loss = 0.0916 (0.421 sec/step)\n",
            "I0205 13:17:20.418968 140689526667136 learning.py:507] global step 176: loss = 0.0916 (0.421 sec/step)\n",
            "INFO:tensorflow:global step 177: loss = 0.1107 (0.374 sec/step)\n",
            "I0205 13:17:20.794320 140689526667136 learning.py:507] global step 177: loss = 0.1107 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 178: loss = 0.1078 (0.390 sec/step)\n",
            "I0205 13:17:21.186225 140689526667136 learning.py:507] global step 178: loss = 0.1078 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 179: loss = 0.1079 (0.392 sec/step)\n",
            "I0205 13:17:21.580059 140689526667136 learning.py:507] global step 179: loss = 0.1079 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 180: loss = 1.9737 (0.460 sec/step)\n",
            "I0205 13:17:22.041354 140689526667136 learning.py:507] global step 180: loss = 1.9737 (0.460 sec/step)\n",
            "INFO:tensorflow:global step 181: loss = 1.7810 (0.386 sec/step)\n",
            "I0205 13:17:22.429519 140689526667136 learning.py:507] global step 181: loss = 1.7810 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 182: loss = 1.2607 (0.368 sec/step)\n",
            "I0205 13:17:22.799479 140689526667136 learning.py:507] global step 182: loss = 1.2607 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 183: loss = 0.0540 (0.367 sec/step)\n",
            "I0205 13:17:23.167872 140689526667136 learning.py:507] global step 183: loss = 0.0540 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 184: loss = 0.1055 (0.394 sec/step)\n",
            "I0205 13:17:23.565521 140689526667136 learning.py:507] global step 184: loss = 0.1055 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 185: loss = 0.0700 (0.400 sec/step)\n",
            "I0205 13:17:23.967673 140689526667136 learning.py:507] global step 185: loss = 0.0700 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 186: loss = 0.0680 (0.388 sec/step)\n",
            "I0205 13:17:24.357160 140689526667136 learning.py:507] global step 186: loss = 0.0680 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 187: loss = 1.7786 (0.376 sec/step)\n",
            "I0205 13:17:24.735121 140689526667136 learning.py:507] global step 187: loss = 1.7786 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 188: loss = 0.1720 (0.404 sec/step)\n",
            "I0205 13:17:25.140403 140689526667136 learning.py:507] global step 188: loss = 0.1720 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 189: loss = 0.1154 (0.387 sec/step)\n",
            "I0205 13:17:25.529834 140689526667136 learning.py:507] global step 189: loss = 0.1154 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 190: loss = 0.9866 (0.370 sec/step)\n",
            "I0205 13:17:25.901612 140689526667136 learning.py:507] global step 190: loss = 0.9866 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 191: loss = 0.2238 (0.392 sec/step)\n",
            "I0205 13:17:26.294883 140689526667136 learning.py:507] global step 191: loss = 0.2238 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 192: loss = 0.0840 (2.559 sec/step)\n",
            "I0205 13:17:28.855101 140689526667136 learning.py:507] global step 192: loss = 0.0840 (2.559 sec/step)\n",
            "INFO:tensorflow:global step 193: loss = 0.1269 (2.750 sec/step)\n",
            "I0205 13:17:31.606785 140689526667136 learning.py:507] global step 193: loss = 0.1269 (2.750 sec/step)\n",
            "INFO:tensorflow:global step 194: loss = 0.1206 (0.427 sec/step)\n",
            "I0205 13:17:32.034785 140689526667136 learning.py:507] global step 194: loss = 0.1206 (0.427 sec/step)\n",
            "INFO:tensorflow:global step 195: loss = 0.2661 (0.384 sec/step)\n",
            "I0205 13:17:32.420558 140689526667136 learning.py:507] global step 195: loss = 0.2661 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 196: loss = 0.0588 (1.060 sec/step)\n",
            "I0205 13:17:33.481760 140689526667136 learning.py:507] global step 196: loss = 0.0588 (1.060 sec/step)\n",
            "INFO:tensorflow:global step 197: loss = 0.0614 (0.476 sec/step)\n",
            "I0205 13:17:33.959911 140689526667136 learning.py:507] global step 197: loss = 0.0614 (0.476 sec/step)\n",
            "INFO:tensorflow:global step 198: loss = 1.1445 (0.384 sec/step)\n",
            "I0205 13:17:34.345475 140689526667136 learning.py:507] global step 198: loss = 1.1445 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 199: loss = 0.9810 (0.392 sec/step)\n",
            "I0205 13:17:34.739122 140689526667136 learning.py:507] global step 199: loss = 0.9810 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 200: loss = 0.1168 (0.397 sec/step)\n",
            "I0205 13:17:35.137822 140689526667136 learning.py:507] global step 200: loss = 0.1168 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 201: loss = 0.0749 (0.377 sec/step)\n",
            "I0205 13:17:35.516434 140689526667136 learning.py:507] global step 201: loss = 0.0749 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 202: loss = 0.6171 (0.388 sec/step)\n",
            "I0205 13:17:35.906210 140689526667136 learning.py:507] global step 202: loss = 0.6171 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 203: loss = 0.2899 (0.459 sec/step)\n",
            "I0205 13:17:36.368158 140689526667136 learning.py:507] global step 203: loss = 0.2899 (0.459 sec/step)\n",
            "INFO:tensorflow:global step 204: loss = 1.6155 (0.380 sec/step)\n",
            "I0205 13:17:36.749307 140689526667136 learning.py:507] global step 204: loss = 1.6155 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 205: loss = 0.1475 (0.377 sec/step)\n",
            "I0205 13:17:37.128235 140689526667136 learning.py:507] global step 205: loss = 0.1475 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 206: loss = 0.3532 (0.383 sec/step)\n",
            "I0205 13:17:37.513326 140689526667136 learning.py:507] global step 206: loss = 0.3532 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 207: loss = 0.0489 (0.418 sec/step)\n",
            "I0205 13:17:37.932838 140689526667136 learning.py:507] global step 207: loss = 0.0489 (0.418 sec/step)\n",
            "INFO:tensorflow:global step 208: loss = 0.1531 (0.407 sec/step)\n",
            "I0205 13:17:38.341642 140689526667136 learning.py:507] global step 208: loss = 0.1531 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 209: loss = 0.1260 (0.392 sec/step)\n",
            "I0205 13:17:38.735246 140689526667136 learning.py:507] global step 209: loss = 0.1260 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 210: loss = 2.0143 (0.364 sec/step)\n",
            "I0205 13:17:39.101032 140689526667136 learning.py:507] global step 210: loss = 2.0143 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 211: loss = 1.0706 (0.400 sec/step)\n",
            "I0205 13:17:39.502491 140689526667136 learning.py:507] global step 211: loss = 1.0706 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 212: loss = 0.2425 (0.385 sec/step)\n",
            "I0205 13:17:39.889527 140689526667136 learning.py:507] global step 212: loss = 0.2425 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 213: loss = 0.0614 (2.651 sec/step)\n",
            "I0205 13:17:42.541960 140689526667136 learning.py:507] global step 213: loss = 0.0614 (2.651 sec/step)\n",
            "INFO:tensorflow:global step 214: loss = 0.6623 (0.371 sec/step)\n",
            "I0205 13:17:42.914458 140689526667136 learning.py:507] global step 214: loss = 0.6623 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 215: loss = 0.3996 (0.381 sec/step)\n",
            "I0205 13:17:43.297095 140689526667136 learning.py:507] global step 215: loss = 0.3996 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 216: loss = 0.0505 (0.375 sec/step)\n",
            "I0205 13:17:43.673855 140689526667136 learning.py:507] global step 216: loss = 0.0505 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 217: loss = 0.2064 (1.550 sec/step)\n",
            "I0205 13:17:45.225275 140689526667136 learning.py:507] global step 217: loss = 0.2064 (1.550 sec/step)\n",
            "INFO:tensorflow:global step 218: loss = 0.0403 (0.398 sec/step)\n",
            "I0205 13:17:45.625026 140689526667136 learning.py:507] global step 218: loss = 0.0403 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 219: loss = 0.1174 (0.379 sec/step)\n",
            "I0205 13:17:46.006108 140689526667136 learning.py:507] global step 219: loss = 0.1174 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 220: loss = 0.0688 (0.359 sec/step)\n",
            "I0205 13:17:46.366393 140689526667136 learning.py:507] global step 220: loss = 0.0688 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 221: loss = 0.2048 (0.372 sec/step)\n",
            "I0205 13:17:46.739801 140689526667136 learning.py:507] global step 221: loss = 0.2048 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 222: loss = 0.0837 (0.394 sec/step)\n",
            "I0205 13:17:47.135934 140689526667136 learning.py:507] global step 222: loss = 0.0837 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 223: loss = 0.4399 (0.396 sec/step)\n",
            "I0205 13:17:47.534150 140689526667136 learning.py:507] global step 223: loss = 0.4399 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 224: loss = 0.2748 (1.185 sec/step)\n",
            "I0205 13:17:48.721037 140689526667136 learning.py:507] global step 224: loss = 0.2748 (1.185 sec/step)\n",
            "INFO:tensorflow:global step 225: loss = 0.9448 (0.383 sec/step)\n",
            "I0205 13:17:49.105986 140689526667136 learning.py:507] global step 225: loss = 0.9448 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 226: loss = 0.5343 (2.612 sec/step)\n",
            "I0205 13:17:51.719552 140689526667136 learning.py:507] global step 226: loss = 0.5343 (2.612 sec/step)\n",
            "INFO:tensorflow:global step 227: loss = 2.2017 (0.355 sec/step)\n",
            "I0205 13:17:52.075602 140689526667136 learning.py:507] global step 227: loss = 2.2017 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 228: loss = 1.1090 (0.404 sec/step)\n",
            "I0205 13:17:52.481034 140689526667136 learning.py:507] global step 228: loss = 1.1090 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 229: loss = 1.7740 (1.630 sec/step)\n",
            "I0205 13:17:54.112924 140689526667136 learning.py:507] global step 229: loss = 1.7740 (1.630 sec/step)\n",
            "INFO:tensorflow:global step 230: loss = 0.1671 (1.013 sec/step)\n",
            "I0205 13:17:55.127048 140689526667136 learning.py:507] global step 230: loss = 0.1671 (1.013 sec/step)\n",
            "INFO:tensorflow:global step 231: loss = 0.1877 (0.383 sec/step)\n",
            "I0205 13:17:55.511662 140689526667136 learning.py:507] global step 231: loss = 0.1877 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 232: loss = 0.1316 (0.354 sec/step)\n",
            "I0205 13:17:55.868015 140689526667136 learning.py:507] global step 232: loss = 0.1316 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 233: loss = 0.0929 (0.401 sec/step)\n",
            "I0205 13:17:56.270599 140689526667136 learning.py:507] global step 233: loss = 0.0929 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 234: loss = 0.2712 (0.398 sec/step)\n",
            "I0205 13:17:56.670447 140689526667136 learning.py:507] global step 234: loss = 0.2712 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 235: loss = 1.9497 (0.381 sec/step)\n",
            "I0205 13:17:57.053313 140689526667136 learning.py:507] global step 235: loss = 1.9497 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 236: loss = 0.5782 (0.461 sec/step)\n",
            "I0205 13:17:57.516160 140689526667136 learning.py:507] global step 236: loss = 0.5782 (0.461 sec/step)\n",
            "INFO:tensorflow:global step 237: loss = 0.5126 (0.366 sec/step)\n",
            "I0205 13:17:57.884253 140689526667136 learning.py:507] global step 237: loss = 0.5126 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 238: loss = 0.5638 (0.361 sec/step)\n",
            "I0205 13:17:58.246831 140689526667136 learning.py:507] global step 238: loss = 0.5638 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 239: loss = 0.3553 (0.384 sec/step)\n",
            "I0205 13:17:58.632940 140689526667136 learning.py:507] global step 239: loss = 0.3553 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 240: loss = 0.3356 (0.383 sec/step)\n",
            "I0205 13:17:59.017803 140689526667136 learning.py:507] global step 240: loss = 0.3356 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 241: loss = 0.3420 (2.770 sec/step)\n",
            "I0205 13:18:01.789671 140689526667136 learning.py:507] global step 241: loss = 0.3420 (2.770 sec/step)\n",
            "INFO:tensorflow:global step 242: loss = 0.2904 (1.659 sec/step)\n",
            "I0205 13:18:03.449547 140689526667136 learning.py:507] global step 242: loss = 0.2904 (1.659 sec/step)\n",
            "INFO:tensorflow:global step 243: loss = 0.1587 (0.400 sec/step)\n",
            "I0205 13:18:03.850726 140689526667136 learning.py:507] global step 243: loss = 0.1587 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 244: loss = 0.0679 (1.001 sec/step)\n",
            "I0205 13:18:04.853299 140689526667136 learning.py:507] global step 244: loss = 0.0679 (1.001 sec/step)\n",
            "INFO:tensorflow:global step 245: loss = 0.2641 (0.391 sec/step)\n",
            "I0205 13:18:05.245784 140689526667136 learning.py:507] global step 245: loss = 0.2641 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 246: loss = 1.0116 (0.376 sec/step)\n",
            "I0205 13:18:05.623286 140689526667136 learning.py:507] global step 246: loss = 1.0116 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 247: loss = 1.6100 (0.396 sec/step)\n",
            "I0205 13:18:06.020745 140689526667136 learning.py:507] global step 247: loss = 1.6100 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 248: loss = 0.0496 (0.389 sec/step)\n",
            "I0205 13:18:06.411179 140689526667136 learning.py:507] global step 248: loss = 0.0496 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 249: loss = 0.4070 (0.371 sec/step)\n",
            "I0205 13:18:06.784101 140689526667136 learning.py:507] global step 249: loss = 0.4070 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 250: loss = 0.3238 (0.388 sec/step)\n",
            "I0205 13:18:07.173680 140689526667136 learning.py:507] global step 250: loss = 0.3238 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 251: loss = 0.5685 (0.368 sec/step)\n",
            "I0205 13:18:07.543928 140689526667136 learning.py:507] global step 251: loss = 0.5685 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 252: loss = 0.1698 (0.402 sec/step)\n",
            "I0205 13:18:07.947756 140689526667136 learning.py:507] global step 252: loss = 0.1698 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 253: loss = 0.1294 (0.423 sec/step)\n",
            "I0205 13:18:08.372965 140689526667136 learning.py:507] global step 253: loss = 0.1294 (0.423 sec/step)\n",
            "INFO:tensorflow:global step 254: loss = 0.3944 (0.373 sec/step)\n",
            "I0205 13:18:08.747465 140689526667136 learning.py:507] global step 254: loss = 0.3944 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 255: loss = 0.5671 (0.394 sec/step)\n",
            "I0205 13:18:09.143007 140689526667136 learning.py:507] global step 255: loss = 0.5671 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 256: loss = 1.9918 (0.397 sec/step)\n",
            "I0205 13:18:09.541937 140689526667136 learning.py:507] global step 256: loss = 1.9918 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 257: loss = 0.1769 (2.515 sec/step)\n",
            "I0205 13:18:12.057817 140689526667136 learning.py:507] global step 257: loss = 0.1769 (2.515 sec/step)\n",
            "INFO:tensorflow:global step 258: loss = 0.1676 (0.361 sec/step)\n",
            "I0205 13:18:12.421635 140689526667136 learning.py:507] global step 258: loss = 0.1676 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 259: loss = 0.2118 (0.378 sec/step)\n",
            "I0205 13:18:12.801077 140689526667136 learning.py:507] global step 259: loss = 0.2118 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 260: loss = 0.1776 (0.360 sec/step)\n",
            "I0205 13:18:13.163504 140689526667136 learning.py:507] global step 260: loss = 0.1776 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 261: loss = 0.5232 (0.414 sec/step)\n",
            "I0205 13:18:13.579568 140689526667136 learning.py:507] global step 261: loss = 0.5232 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 262: loss = 3.0941 (0.417 sec/step)\n",
            "I0205 13:18:14.018614 140689526667136 learning.py:507] global step 262: loss = 3.0941 (0.417 sec/step)\n",
            "INFO:tensorflow:global step 263: loss = 0.0669 (1.065 sec/step)\n",
            "I0205 13:18:15.228417 140689526667136 learning.py:507] global step 263: loss = 0.0669 (1.065 sec/step)\n",
            "INFO:tensorflow:global step 264: loss = 0.0965 (0.633 sec/step)\n",
            "I0205 13:18:15.868046 140689526667136 learning.py:507] global step 264: loss = 0.0965 (0.633 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 1.45028\n",
            "I0205 13:18:15.938727 140686034466560 supervisor.py:1099] global_step/sec: 1.45028\n",
            "INFO:tensorflow:global step 265: loss = 1.8413 (0.509 sec/step)\n",
            "I0205 13:18:16.416248 140689526667136 learning.py:507] global step 265: loss = 1.8413 (0.509 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 265.\n",
            "I0205 13:18:17.803126 140686026073856 supervisor.py:1050] Recording summary at step 265.\n",
            "INFO:tensorflow:global step 266: loss = 0.0462 (1.766 sec/step)\n",
            "I0205 13:18:18.184436 140689526667136 learning.py:507] global step 266: loss = 0.0462 (1.766 sec/step)\n",
            "INFO:tensorflow:global step 267: loss = 0.9415 (1.656 sec/step)\n",
            "I0205 13:18:19.842013 140689526667136 learning.py:507] global step 267: loss = 0.9415 (1.656 sec/step)\n",
            "INFO:tensorflow:global step 268: loss = 0.0911 (0.385 sec/step)\n",
            "I0205 13:18:20.228549 140689526667136 learning.py:507] global step 268: loss = 0.0911 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 269: loss = 0.2820 (0.375 sec/step)\n",
            "I0205 13:18:20.604961 140689526667136 learning.py:507] global step 269: loss = 0.2820 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 270: loss = 0.2284 (0.384 sec/step)\n",
            "I0205 13:18:20.990701 140689526667136 learning.py:507] global step 270: loss = 0.2284 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 271: loss = 0.2568 (2.652 sec/step)\n",
            "I0205 13:18:23.644399 140689526667136 learning.py:507] global step 271: loss = 0.2568 (2.652 sec/step)\n",
            "INFO:tensorflow:global step 272: loss = 0.3293 (0.378 sec/step)\n",
            "I0205 13:18:24.023984 140689526667136 learning.py:507] global step 272: loss = 0.3293 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 273: loss = 0.4391 (0.378 sec/step)\n",
            "I0205 13:18:24.403468 140689526667136 learning.py:507] global step 273: loss = 0.4391 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 274: loss = 0.9134 (0.353 sec/step)\n",
            "I0205 13:18:24.758369 140689526667136 learning.py:507] global step 274: loss = 0.9134 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 275: loss = 0.0506 (0.393 sec/step)\n",
            "I0205 13:18:25.152957 140689526667136 learning.py:507] global step 275: loss = 0.0506 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 276: loss = 0.1957 (0.378 sec/step)\n",
            "I0205 13:18:25.533057 140689526667136 learning.py:507] global step 276: loss = 0.1957 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 277: loss = 0.1444 (0.370 sec/step)\n",
            "I0205 13:18:25.905155 140689526667136 learning.py:507] global step 277: loss = 0.1444 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 278: loss = 0.8338 (0.381 sec/step)\n",
            "I0205 13:18:26.288302 140689526667136 learning.py:507] global step 278: loss = 0.8338 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 279: loss = 0.5900 (0.379 sec/step)\n",
            "I0205 13:18:26.668772 140689526667136 learning.py:507] global step 279: loss = 0.5900 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 280: loss = 0.9385 (0.389 sec/step)\n",
            "I0205 13:18:27.061392 140689526667136 learning.py:507] global step 280: loss = 0.9385 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 281: loss = 0.2105 (2.250 sec/step)\n",
            "I0205 13:18:29.312809 140689526667136 learning.py:507] global step 281: loss = 0.2105 (2.250 sec/step)\n",
            "INFO:tensorflow:global step 282: loss = 0.7381 (0.449 sec/step)\n",
            "I0205 13:18:29.763711 140689526667136 learning.py:507] global step 282: loss = 0.7381 (0.449 sec/step)\n",
            "INFO:tensorflow:global step 283: loss = 0.1076 (1.587 sec/step)\n",
            "I0205 13:18:31.352704 140689526667136 learning.py:507] global step 283: loss = 0.1076 (1.587 sec/step)\n",
            "INFO:tensorflow:global step 284: loss = 0.6827 (0.465 sec/step)\n",
            "I0205 13:18:31.819705 140689526667136 learning.py:507] global step 284: loss = 0.6827 (0.465 sec/step)\n",
            "INFO:tensorflow:global step 285: loss = 0.8002 (1.616 sec/step)\n",
            "I0205 13:18:33.436908 140689526667136 learning.py:507] global step 285: loss = 0.8002 (1.616 sec/step)\n",
            "INFO:tensorflow:global step 286: loss = 2.0688 (0.403 sec/step)\n",
            "I0205 13:18:33.842067 140689526667136 learning.py:507] global step 286: loss = 2.0688 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 287: loss = 0.6246 (1.338 sec/step)\n",
            "I0205 13:18:35.181468 140689526667136 learning.py:507] global step 287: loss = 0.6246 (1.338 sec/step)\n",
            "INFO:tensorflow:global step 288: loss = 0.1113 (0.377 sec/step)\n",
            "I0205 13:18:35.559485 140689526667136 learning.py:507] global step 288: loss = 0.1113 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 289: loss = 0.1140 (0.381 sec/step)\n",
            "I0205 13:18:35.942251 140689526667136 learning.py:507] global step 289: loss = 0.1140 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 290: loss = 0.6228 (1.064 sec/step)\n",
            "I0205 13:18:37.007852 140689526667136 learning.py:507] global step 290: loss = 0.6228 (1.064 sec/step)\n",
            "INFO:tensorflow:global step 291: loss = 0.2050 (0.401 sec/step)\n",
            "I0205 13:18:37.410156 140689526667136 learning.py:507] global step 291: loss = 0.2050 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 292: loss = 1.7800 (0.453 sec/step)\n",
            "I0205 13:18:37.864720 140689526667136 learning.py:507] global step 292: loss = 1.7800 (0.453 sec/step)\n",
            "INFO:tensorflow:global step 293: loss = 0.0665 (0.376 sec/step)\n",
            "I0205 13:18:38.242385 140689526667136 learning.py:507] global step 293: loss = 0.0665 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 294: loss = 0.1574 (0.390 sec/step)\n",
            "I0205 13:18:38.633719 140689526667136 learning.py:507] global step 294: loss = 0.1574 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 295: loss = 0.2911 (0.370 sec/step)\n",
            "I0205 13:18:39.004889 140689526667136 learning.py:507] global step 295: loss = 0.2911 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 296: loss = 0.8264 (0.409 sec/step)\n",
            "I0205 13:18:39.415256 140689526667136 learning.py:507] global step 296: loss = 0.8264 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 297: loss = 0.1037 (0.380 sec/step)\n",
            "I0205 13:18:39.797316 140689526667136 learning.py:507] global step 297: loss = 0.1037 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 298: loss = 0.2173 (0.397 sec/step)\n",
            "I0205 13:18:40.196465 140689526667136 learning.py:507] global step 298: loss = 0.2173 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 299: loss = 0.1136 (0.416 sec/step)\n",
            "I0205 13:18:40.614271 140689526667136 learning.py:507] global step 299: loss = 0.1136 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 300: loss = 0.2360 (0.369 sec/step)\n",
            "I0205 13:18:40.984508 140689526667136 learning.py:507] global step 300: loss = 0.2360 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 301: loss = 0.6087 (0.363 sec/step)\n",
            "I0205 13:18:41.348814 140689526667136 learning.py:507] global step 301: loss = 0.6087 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 302: loss = 0.3027 (0.412 sec/step)\n",
            "I0205 13:18:41.762209 140689526667136 learning.py:507] global step 302: loss = 0.3027 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 303: loss = 0.2283 (0.405 sec/step)\n",
            "I0205 13:18:42.168287 140689526667136 learning.py:507] global step 303: loss = 0.2283 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 304: loss = 0.0644 (0.374 sec/step)\n",
            "I0205 13:18:42.544100 140689526667136 learning.py:507] global step 304: loss = 0.0644 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 305: loss = 0.4729 (0.377 sec/step)\n",
            "I0205 13:18:42.922827 140689526667136 learning.py:507] global step 305: loss = 0.4729 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 306: loss = 0.0810 (0.376 sec/step)\n",
            "I0205 13:18:43.300671 140689526667136 learning.py:507] global step 306: loss = 0.0810 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 307: loss = 0.1444 (0.384 sec/step)\n",
            "I0205 13:18:43.686259 140689526667136 learning.py:507] global step 307: loss = 0.1444 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 308: loss = 0.6622 (0.384 sec/step)\n",
            "I0205 13:18:44.071866 140689526667136 learning.py:507] global step 308: loss = 0.6622 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 309: loss = 0.7405 (0.457 sec/step)\n",
            "I0205 13:18:44.530491 140689526667136 learning.py:507] global step 309: loss = 0.7405 (0.457 sec/step)\n",
            "INFO:tensorflow:global step 310: loss = 0.1385 (0.414 sec/step)\n",
            "I0205 13:18:44.946211 140689526667136 learning.py:507] global step 310: loss = 0.1385 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 311: loss = 0.1043 (0.398 sec/step)\n",
            "I0205 13:18:45.345548 140689526667136 learning.py:507] global step 311: loss = 0.1043 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 312: loss = 0.5703 (0.369 sec/step)\n",
            "I0205 13:18:45.716564 140689526667136 learning.py:507] global step 312: loss = 0.5703 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 313: loss = 1.9956 (0.372 sec/step)\n",
            "I0205 13:18:46.089920 140689526667136 learning.py:507] global step 313: loss = 1.9956 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 314: loss = 0.0880 (0.374 sec/step)\n",
            "I0205 13:18:46.464885 140689526667136 learning.py:507] global step 314: loss = 0.0880 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 315: loss = 0.4043 (0.395 sec/step)\n",
            "I0205 13:18:46.861591 140689526667136 learning.py:507] global step 315: loss = 0.4043 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 316: loss = 0.5759 (0.381 sec/step)\n",
            "I0205 13:18:47.243965 140689526667136 learning.py:507] global step 316: loss = 0.5759 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 317: loss = 0.7185 (0.406 sec/step)\n",
            "I0205 13:18:47.651871 140689526667136 learning.py:507] global step 317: loss = 0.7185 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 318: loss = 0.1338 (0.377 sec/step)\n",
            "I0205 13:18:48.030560 140689526667136 learning.py:507] global step 318: loss = 0.1338 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 319: loss = 0.4622 (0.377 sec/step)\n",
            "I0205 13:18:48.409124 140689526667136 learning.py:507] global step 319: loss = 0.4622 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 320: loss = 0.9298 (0.367 sec/step)\n",
            "I0205 13:18:48.777687 140689526667136 learning.py:507] global step 320: loss = 0.9298 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 321: loss = 0.1181 (0.370 sec/step)\n",
            "I0205 13:18:49.149501 140689526667136 learning.py:507] global step 321: loss = 0.1181 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 322: loss = 2.2251 (0.390 sec/step)\n",
            "I0205 13:18:49.541211 140689526667136 learning.py:507] global step 322: loss = 2.2251 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 323: loss = 0.3194 (0.359 sec/step)\n",
            "I0205 13:18:49.901753 140689526667136 learning.py:507] global step 323: loss = 0.3194 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 324: loss = 0.3901 (0.376 sec/step)\n",
            "I0205 13:18:50.279859 140689526667136 learning.py:507] global step 324: loss = 0.3901 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 325: loss = 0.3003 (0.401 sec/step)\n",
            "I0205 13:18:50.682712 140689526667136 learning.py:507] global step 325: loss = 0.3003 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 326: loss = 1.4983 (0.358 sec/step)\n",
            "I0205 13:18:51.042292 140689526667136 learning.py:507] global step 326: loss = 1.4983 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 327: loss = 0.2475 (1.706 sec/step)\n",
            "I0205 13:18:52.750007 140689526667136 learning.py:507] global step 327: loss = 0.2475 (1.706 sec/step)\n",
            "INFO:tensorflow:global step 328: loss = 0.2214 (0.397 sec/step)\n",
            "I0205 13:18:53.148463 140689526667136 learning.py:507] global step 328: loss = 0.2214 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 329: loss = 0.2536 (2.703 sec/step)\n",
            "I0205 13:18:55.853323 140689526667136 learning.py:507] global step 329: loss = 0.2536 (2.703 sec/step)\n",
            "INFO:tensorflow:global step 330: loss = 0.1882 (2.511 sec/step)\n",
            "I0205 13:18:58.365489 140689526667136 learning.py:507] global step 330: loss = 0.1882 (2.511 sec/step)\n",
            "INFO:tensorflow:global step 331: loss = 0.1033 (0.356 sec/step)\n",
            "I0205 13:18:58.723443 140689526667136 learning.py:507] global step 331: loss = 0.1033 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 332: loss = 0.0645 (2.237 sec/step)\n",
            "I0205 13:19:00.961736 140689526667136 learning.py:507] global step 332: loss = 0.0645 (2.237 sec/step)\n",
            "INFO:tensorflow:global step 333: loss = 0.1002 (0.388 sec/step)\n",
            "I0205 13:19:01.351675 140689526667136 learning.py:507] global step 333: loss = 0.1002 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 334: loss = 0.0947 (0.398 sec/step)\n",
            "I0205 13:19:01.751710 140689526667136 learning.py:507] global step 334: loss = 0.0947 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 335: loss = 0.7358 (0.488 sec/step)\n",
            "I0205 13:19:02.246349 140689526667136 learning.py:507] global step 335: loss = 0.7358 (0.488 sec/step)\n",
            "INFO:tensorflow:global step 336: loss = 0.5411 (0.376 sec/step)\n",
            "I0205 13:19:02.624474 140689526667136 learning.py:507] global step 336: loss = 0.5411 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 337: loss = 0.1559 (2.550 sec/step)\n",
            "I0205 13:19:05.176009 140689526667136 learning.py:507] global step 337: loss = 0.1559 (2.550 sec/step)\n",
            "INFO:tensorflow:global step 338: loss = 0.8642 (0.977 sec/step)\n",
            "I0205 13:19:06.154722 140689526667136 learning.py:507] global step 338: loss = 0.8642 (0.977 sec/step)\n",
            "INFO:tensorflow:global step 339: loss = 0.2507 (0.374 sec/step)\n",
            "I0205 13:19:06.530362 140689526667136 learning.py:507] global step 339: loss = 0.2507 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 340: loss = 0.7167 (0.347 sec/step)\n",
            "I0205 13:19:06.879487 140689526667136 learning.py:507] global step 340: loss = 0.7167 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 341: loss = 0.2957 (0.394 sec/step)\n",
            "I0205 13:19:07.274740 140689526667136 learning.py:507] global step 341: loss = 0.2957 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 342: loss = 0.8014 (2.473 sec/step)\n",
            "I0205 13:19:09.748880 140689526667136 learning.py:507] global step 342: loss = 0.8014 (2.473 sec/step)\n",
            "INFO:tensorflow:global step 343: loss = 0.5477 (0.365 sec/step)\n",
            "I0205 13:19:10.115223 140689526667136 learning.py:507] global step 343: loss = 0.5477 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 344: loss = 0.9259 (0.384 sec/step)\n",
            "I0205 13:19:10.500554 140689526667136 learning.py:507] global step 344: loss = 0.9259 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 345: loss = 0.4994 (0.369 sec/step)\n",
            "I0205 13:19:10.870892 140689526667136 learning.py:507] global step 345: loss = 0.4994 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 346: loss = 1.1024 (1.033 sec/step)\n",
            "I0205 13:19:11.904952 140689526667136 learning.py:507] global step 346: loss = 1.1024 (1.033 sec/step)\n",
            "INFO:tensorflow:global step 347: loss = 0.2570 (0.387 sec/step)\n",
            "I0205 13:19:12.293181 140689526667136 learning.py:507] global step 347: loss = 0.2570 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 348: loss = 0.5112 (0.415 sec/step)\n",
            "I0205 13:19:12.709280 140689526667136 learning.py:507] global step 348: loss = 0.5112 (0.415 sec/step)\n",
            "INFO:tensorflow:global step 349: loss = 1.1257 (0.374 sec/step)\n",
            "I0205 13:19:13.084629 140689526667136 learning.py:507] global step 349: loss = 1.1257 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 350: loss = 0.1540 (1.000 sec/step)\n",
            "I0205 13:19:14.086934 140689526667136 learning.py:507] global step 350: loss = 0.1540 (1.000 sec/step)\n",
            "INFO:tensorflow:global step 351: loss = 0.2724 (0.392 sec/step)\n",
            "I0205 13:19:14.480735 140689526667136 learning.py:507] global step 351: loss = 0.2724 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 352: loss = 0.3566 (0.392 sec/step)\n",
            "I0205 13:19:14.874519 140689526667136 learning.py:507] global step 352: loss = 0.3566 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 353: loss = 0.3370 (0.362 sec/step)\n",
            "I0205 13:19:15.237920 140689526667136 learning.py:507] global step 353: loss = 0.3370 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 354: loss = 0.1400 (0.382 sec/step)\n",
            "I0205 13:19:15.621656 140689526667136 learning.py:507] global step 354: loss = 0.1400 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 355: loss = 0.5877 (0.409 sec/step)\n",
            "I0205 13:19:16.032695 140689526667136 learning.py:507] global step 355: loss = 0.5877 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 356: loss = 0.1726 (0.362 sec/step)\n",
            "I0205 13:19:16.396211 140689526667136 learning.py:507] global step 356: loss = 0.1726 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 357: loss = 1.1400 (0.349 sec/step)\n",
            "I0205 13:19:16.746995 140689526667136 learning.py:507] global step 357: loss = 1.1400 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 358: loss = 0.1319 (0.372 sec/step)\n",
            "I0205 13:19:17.120502 140689526667136 learning.py:507] global step 358: loss = 0.1319 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 359: loss = 0.0524 (0.381 sec/step)\n",
            "I0205 13:19:17.502738 140689526667136 learning.py:507] global step 359: loss = 0.0524 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 360: loss = 0.1550 (0.395 sec/step)\n",
            "I0205 13:19:17.899510 140689526667136 learning.py:507] global step 360: loss = 0.1550 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 361: loss = 0.0821 (0.369 sec/step)\n",
            "I0205 13:19:18.270274 140689526667136 learning.py:507] global step 361: loss = 0.0821 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 362: loss = 2.1495 (0.362 sec/step)\n",
            "I0205 13:19:18.634398 140689526667136 learning.py:507] global step 362: loss = 2.1495 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 363: loss = 0.1870 (0.400 sec/step)\n",
            "I0205 13:19:19.036465 140689526667136 learning.py:507] global step 363: loss = 0.1870 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 364: loss = 0.4153 (0.396 sec/step)\n",
            "I0205 13:19:19.434630 140689526667136 learning.py:507] global step 364: loss = 0.4153 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 365: loss = 0.3575 (0.366 sec/step)\n",
            "I0205 13:19:19.803020 140689526667136 learning.py:507] global step 365: loss = 0.3575 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 366: loss = 0.8107 (0.407 sec/step)\n",
            "I0205 13:19:20.211095 140689526667136 learning.py:507] global step 366: loss = 0.8107 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 367: loss = 0.1497 (0.367 sec/step)\n",
            "I0205 13:19:20.579909 140689526667136 learning.py:507] global step 367: loss = 0.1497 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 368: loss = 0.7664 (0.374 sec/step)\n",
            "I0205 13:19:20.955387 140689526667136 learning.py:507] global step 368: loss = 0.7664 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 369: loss = 1.0979 (0.406 sec/step)\n",
            "I0205 13:19:21.362600 140689526667136 learning.py:507] global step 369: loss = 1.0979 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 370: loss = 0.1089 (0.393 sec/step)\n",
            "I0205 13:19:21.756893 140689526667136 learning.py:507] global step 370: loss = 0.1089 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 371: loss = 0.2074 (0.338 sec/step)\n",
            "I0205 13:19:22.096218 140689526667136 learning.py:507] global step 371: loss = 0.2074 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 372: loss = 0.1941 (0.415 sec/step)\n",
            "I0205 13:19:22.513015 140689526667136 learning.py:507] global step 372: loss = 0.1941 (0.415 sec/step)\n",
            "INFO:tensorflow:global step 373: loss = 0.1756 (0.385 sec/step)\n",
            "I0205 13:19:22.900200 140689526667136 learning.py:507] global step 373: loss = 0.1756 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 374: loss = 0.2860 (0.358 sec/step)\n",
            "I0205 13:19:23.260258 140689526667136 learning.py:507] global step 374: loss = 0.2860 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 375: loss = 0.0606 (0.385 sec/step)\n",
            "I0205 13:19:23.646895 140689526667136 learning.py:507] global step 375: loss = 0.0606 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 376: loss = 0.1558 (0.360 sec/step)\n",
            "I0205 13:19:24.008842 140689526667136 learning.py:507] global step 376: loss = 0.1558 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 377: loss = 0.3176 (0.457 sec/step)\n",
            "I0205 13:19:24.467307 140689526667136 learning.py:507] global step 377: loss = 0.3176 (0.457 sec/step)\n",
            "INFO:tensorflow:global step 378: loss = 0.1353 (2.531 sec/step)\n",
            "I0205 13:19:27.000090 140689526667136 learning.py:507] global step 378: loss = 0.1353 (2.531 sec/step)\n",
            "INFO:tensorflow:global step 379: loss = 0.6564 (0.385 sec/step)\n",
            "I0205 13:19:27.386448 140689526667136 learning.py:507] global step 379: loss = 0.6564 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 380: loss = 0.1223 (1.621 sec/step)\n",
            "I0205 13:19:29.008640 140689526667136 learning.py:507] global step 380: loss = 0.1223 (1.621 sec/step)\n",
            "INFO:tensorflow:global step 381: loss = 0.3219 (0.450 sec/step)\n",
            "I0205 13:19:29.459968 140689526667136 learning.py:507] global step 381: loss = 0.3219 (0.450 sec/step)\n",
            "INFO:tensorflow:global step 382: loss = 0.4829 (0.420 sec/step)\n",
            "I0205 13:19:29.881940 140689526667136 learning.py:507] global step 382: loss = 0.4829 (0.420 sec/step)\n",
            "INFO:tensorflow:global step 383: loss = 0.0727 (0.396 sec/step)\n",
            "I0205 13:19:30.280231 140689526667136 learning.py:507] global step 383: loss = 0.0727 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 384: loss = 0.1229 (0.413 sec/step)\n",
            "I0205 13:19:30.695216 140689526667136 learning.py:507] global step 384: loss = 0.1229 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 385: loss = 0.9172 (0.379 sec/step)\n",
            "I0205 13:19:31.076141 140689526667136 learning.py:507] global step 385: loss = 0.9172 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 386: loss = 0.9065 (1.676 sec/step)\n",
            "I0205 13:19:32.753934 140689526667136 learning.py:507] global step 386: loss = 0.9065 (1.676 sec/step)\n",
            "INFO:tensorflow:global step 387: loss = 0.0511 (0.420 sec/step)\n",
            "I0205 13:19:33.175614 140689526667136 learning.py:507] global step 387: loss = 0.0511 (0.420 sec/step)\n",
            "INFO:tensorflow:global step 388: loss = 0.0972 (2.200 sec/step)\n",
            "I0205 13:19:35.377144 140689526667136 learning.py:507] global step 388: loss = 0.0972 (2.200 sec/step)\n",
            "INFO:tensorflow:global step 389: loss = 0.3932 (0.381 sec/step)\n",
            "I0205 13:19:35.759753 140689526667136 learning.py:507] global step 389: loss = 0.3932 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 390: loss = 0.0669 (2.322 sec/step)\n",
            "I0205 13:19:38.083344 140689526667136 learning.py:507] global step 390: loss = 0.0669 (2.322 sec/step)\n",
            "INFO:tensorflow:global step 391: loss = 0.8685 (0.386 sec/step)\n",
            "I0205 13:19:38.471101 140689526667136 learning.py:507] global step 391: loss = 0.8685 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 392: loss = 0.0739 (0.384 sec/step)\n",
            "I0205 13:19:38.856803 140689526667136 learning.py:507] global step 392: loss = 0.0739 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 393: loss = 0.0965 (0.381 sec/step)\n",
            "I0205 13:19:39.239075 140689526667136 learning.py:507] global step 393: loss = 0.0965 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 394: loss = 1.6172 (0.381 sec/step)\n",
            "I0205 13:19:39.622142 140689526667136 learning.py:507] global step 394: loss = 1.6172 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 395: loss = 0.6974 (0.368 sec/step)\n",
            "I0205 13:19:39.991706 140689526667136 learning.py:507] global step 395: loss = 0.6974 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 396: loss = 0.0977 (0.400 sec/step)\n",
            "I0205 13:19:40.393353 140689526667136 learning.py:507] global step 396: loss = 0.0977 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 397: loss = 1.4551 (0.355 sec/step)\n",
            "I0205 13:19:40.750448 140689526667136 learning.py:507] global step 397: loss = 1.4551 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 398: loss = 0.2472 (0.429 sec/step)\n",
            "I0205 13:19:41.181441 140689526667136 learning.py:507] global step 398: loss = 0.2472 (0.429 sec/step)\n",
            "INFO:tensorflow:global step 399: loss = 1.5325 (0.366 sec/step)\n",
            "I0205 13:19:41.549953 140689526667136 learning.py:507] global step 399: loss = 1.5325 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 400: loss = 0.4459 (1.031 sec/step)\n",
            "I0205 13:19:42.582076 140689526667136 learning.py:507] global step 400: loss = 0.4459 (1.031 sec/step)\n",
            "INFO:tensorflow:global step 401: loss = 0.5515 (2.882 sec/step)\n",
            "I0205 13:19:45.465453 140689526667136 learning.py:507] global step 401: loss = 0.5515 (2.882 sec/step)\n",
            "INFO:tensorflow:global step 402: loss = 0.4584 (0.374 sec/step)\n",
            "I0205 13:19:45.840933 140689526667136 learning.py:507] global step 402: loss = 0.4584 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 403: loss = 0.2408 (0.987 sec/step)\n",
            "I0205 13:19:46.828883 140689526667136 learning.py:507] global step 403: loss = 0.2408 (0.987 sec/step)\n",
            "INFO:tensorflow:global step 404: loss = 0.1368 (0.385 sec/step)\n",
            "I0205 13:19:47.215101 140689526667136 learning.py:507] global step 404: loss = 0.1368 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 405: loss = 0.0664 (0.425 sec/step)\n",
            "I0205 13:19:47.641685 140689526667136 learning.py:507] global step 405: loss = 0.0664 (0.425 sec/step)\n",
            "INFO:tensorflow:global step 406: loss = 0.0901 (1.664 sec/step)\n",
            "I0205 13:19:49.306566 140689526667136 learning.py:507] global step 406: loss = 0.0901 (1.664 sec/step)\n",
            "INFO:tensorflow:global step 407: loss = 0.5375 (0.399 sec/step)\n",
            "I0205 13:19:49.707391 140689526667136 learning.py:507] global step 407: loss = 0.5375 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 408: loss = 0.4269 (0.390 sec/step)\n",
            "I0205 13:19:50.099058 140689526667136 learning.py:507] global step 408: loss = 0.4269 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 409: loss = 0.6717 (0.416 sec/step)\n",
            "I0205 13:19:50.516691 140689526667136 learning.py:507] global step 409: loss = 0.6717 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 410: loss = 0.0734 (0.970 sec/step)\n",
            "I0205 13:19:51.488312 140689526667136 learning.py:507] global step 410: loss = 0.0734 (0.970 sec/step)\n",
            "INFO:tensorflow:global step 411: loss = 0.1075 (0.387 sec/step)\n",
            "I0205 13:19:51.877121 140689526667136 learning.py:507] global step 411: loss = 0.1075 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 412: loss = 0.2011 (0.404 sec/step)\n",
            "I0205 13:19:52.283233 140689526667136 learning.py:507] global step 412: loss = 0.2011 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 413: loss = 0.1843 (0.500 sec/step)\n",
            "I0205 13:19:52.785211 140689526667136 learning.py:507] global step 413: loss = 0.1843 (0.500 sec/step)\n",
            "INFO:tensorflow:global step 414: loss = 0.0816 (0.510 sec/step)\n",
            "I0205 13:19:53.296568 140689526667136 learning.py:507] global step 414: loss = 0.0816 (0.510 sec/step)\n",
            "INFO:tensorflow:global step 415: loss = 0.5707 (0.396 sec/step)\n",
            "I0205 13:19:53.694462 140689526667136 learning.py:507] global step 415: loss = 0.5707 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 416: loss = 1.1600 (0.951 sec/step)\n",
            "I0205 13:19:54.647234 140689526667136 learning.py:507] global step 416: loss = 1.1600 (0.951 sec/step)\n",
            "INFO:tensorflow:global step 417: loss = 0.2922 (0.380 sec/step)\n",
            "I0205 13:19:55.029247 140689526667136 learning.py:507] global step 417: loss = 0.2922 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 418: loss = 0.2943 (0.366 sec/step)\n",
            "I0205 13:19:55.397144 140689526667136 learning.py:507] global step 418: loss = 0.2943 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 419: loss = 1.6548 (0.374 sec/step)\n",
            "I0205 13:19:55.772667 140689526667136 learning.py:507] global step 419: loss = 1.6548 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 420: loss = 0.0723 (0.390 sec/step)\n",
            "I0205 13:19:56.164723 140689526667136 learning.py:507] global step 420: loss = 0.0723 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 421: loss = 0.5975 (0.434 sec/step)\n",
            "I0205 13:19:56.600613 140689526667136 learning.py:507] global step 421: loss = 0.5975 (0.434 sec/step)\n",
            "INFO:tensorflow:global step 422: loss = 0.4369 (0.405 sec/step)\n",
            "I0205 13:19:57.007390 140689526667136 learning.py:507] global step 422: loss = 0.4369 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 423: loss = 0.4290 (0.380 sec/step)\n",
            "I0205 13:19:57.389036 140689526667136 learning.py:507] global step 423: loss = 0.4290 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 424: loss = 0.2080 (0.385 sec/step)\n",
            "I0205 13:19:57.776070 140689526667136 learning.py:507] global step 424: loss = 0.2080 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 425: loss = 0.1681 (0.393 sec/step)\n",
            "I0205 13:19:58.170667 140689526667136 learning.py:507] global step 425: loss = 0.1681 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 426: loss = 1.1274 (0.383 sec/step)\n",
            "I0205 13:19:58.555775 140689526667136 learning.py:507] global step 426: loss = 1.1274 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 427: loss = 0.6920 (1.658 sec/step)\n",
            "I0205 13:20:00.214881 140689526667136 learning.py:507] global step 427: loss = 0.6920 (1.658 sec/step)\n",
            "INFO:tensorflow:global step 428: loss = 0.6196 (0.388 sec/step)\n",
            "I0205 13:20:00.604042 140689526667136 learning.py:507] global step 428: loss = 0.6196 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 429: loss = 0.1105 (0.365 sec/step)\n",
            "I0205 13:20:00.970649 140689526667136 learning.py:507] global step 429: loss = 0.1105 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 430: loss = 0.2483 (0.393 sec/step)\n",
            "I0205 13:20:01.364998 140689526667136 learning.py:507] global step 430: loss = 0.2483 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 431: loss = 0.0874 (0.384 sec/step)\n",
            "I0205 13:20:01.750328 140689526667136 learning.py:507] global step 431: loss = 0.0874 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 432: loss = 0.1392 (0.394 sec/step)\n",
            "I0205 13:20:02.146264 140689526667136 learning.py:507] global step 432: loss = 0.1392 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 433: loss = 0.0620 (0.412 sec/step)\n",
            "I0205 13:20:02.559752 140689526667136 learning.py:507] global step 433: loss = 0.0620 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 434: loss = 0.1284 (0.403 sec/step)\n",
            "I0205 13:20:02.964072 140689526667136 learning.py:507] global step 434: loss = 0.1284 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 435: loss = 0.0878 (0.382 sec/step)\n",
            "I0205 13:20:03.349045 140689526667136 learning.py:507] global step 435: loss = 0.0878 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 436: loss = 0.4478 (0.381 sec/step)\n",
            "I0205 13:20:03.732220 140689526667136 learning.py:507] global step 436: loss = 0.4478 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 437: loss = 0.1342 (0.358 sec/step)\n",
            "I0205 13:20:04.092374 140689526667136 learning.py:507] global step 437: loss = 0.1342 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 438: loss = 0.2066 (0.383 sec/step)\n",
            "I0205 13:20:04.477351 140689526667136 learning.py:507] global step 438: loss = 0.2066 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 439: loss = 0.4928 (0.400 sec/step)\n",
            "I0205 13:20:04.878845 140689526667136 learning.py:507] global step 439: loss = 0.4928 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 440: loss = 0.0728 (0.368 sec/step)\n",
            "I0205 13:20:05.248199 140689526667136 learning.py:507] global step 440: loss = 0.0728 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 441: loss = 0.6230 (0.375 sec/step)\n",
            "I0205 13:20:05.624190 140689526667136 learning.py:507] global step 441: loss = 0.6230 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 442: loss = 0.4198 (0.416 sec/step)\n",
            "I0205 13:20:06.042156 140689526667136 learning.py:507] global step 442: loss = 0.4198 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 443: loss = 1.1340 (0.353 sec/step)\n",
            "I0205 13:20:06.397054 140689526667136 learning.py:507] global step 443: loss = 1.1340 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 444: loss = 0.4577 (0.389 sec/step)\n",
            "I0205 13:20:06.787835 140689526667136 learning.py:507] global step 444: loss = 0.4577 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 445: loss = 1.3694 (0.385 sec/step)\n",
            "I0205 13:20:07.174304 140689526667136 learning.py:507] global step 445: loss = 1.3694 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 446: loss = 0.1435 (0.361 sec/step)\n",
            "I0205 13:20:07.536728 140689526667136 learning.py:507] global step 446: loss = 0.1435 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 447: loss = 0.5488 (0.360 sec/step)\n",
            "I0205 13:20:07.897992 140689526667136 learning.py:507] global step 447: loss = 0.5488 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 448: loss = 0.3319 (0.384 sec/step)\n",
            "I0205 13:20:08.283356 140689526667136 learning.py:507] global step 448: loss = 0.3319 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 449: loss = 0.1207 (0.380 sec/step)\n",
            "I0205 13:20:08.664750 140689526667136 learning.py:507] global step 449: loss = 0.1207 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 450: loss = 0.0311 (0.388 sec/step)\n",
            "I0205 13:20:09.054425 140689526667136 learning.py:507] global step 450: loss = 0.0311 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 451: loss = 1.2106 (0.364 sec/step)\n",
            "I0205 13:20:09.419636 140689526667136 learning.py:507] global step 451: loss = 1.2106 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 452: loss = 2.3995 (1.263 sec/step)\n",
            "I0205 13:20:10.684842 140689526667136 learning.py:507] global step 452: loss = 2.3995 (1.263 sec/step)\n",
            "INFO:tensorflow:global step 453: loss = 0.0521 (0.382 sec/step)\n",
            "I0205 13:20:11.067845 140689526667136 learning.py:507] global step 453: loss = 0.0521 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 454: loss = 0.4333 (0.366 sec/step)\n",
            "I0205 13:20:11.435559 140689526667136 learning.py:507] global step 454: loss = 0.4333 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 455: loss = 0.6307 (0.377 sec/step)\n",
            "I0205 13:20:11.814646 140689526667136 learning.py:507] global step 455: loss = 0.6307 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 456: loss = 0.1839 (0.387 sec/step)\n",
            "I0205 13:20:12.203467 140689526667136 learning.py:507] global step 456: loss = 0.1839 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 457: loss = 0.2048 (2.426 sec/step)\n",
            "I0205 13:20:14.659460 140689526667136 learning.py:507] global step 457: loss = 0.2048 (2.426 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 1.61693\n",
            "I0205 13:20:15.918865 140686034466560 supervisor.py:1099] global_step/sec: 1.61693\n",
            "INFO:tensorflow:global step 458: loss = 0.4517 (1.096 sec/step)\n",
            "I0205 13:20:15.920294 140689526667136 learning.py:507] global step 458: loss = 0.4517 (1.096 sec/step)\n",
            "INFO:tensorflow:global step 459: loss = 0.5614 (0.838 sec/step)\n",
            "I0205 13:20:16.862558 140689526667136 learning.py:507] global step 459: loss = 0.5614 (0.838 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 459.\n",
            "I0205 13:20:16.969879 140686026073856 supervisor.py:1050] Recording summary at step 459.\n",
            "INFO:tensorflow:global step 460: loss = 0.0640 (0.407 sec/step)\n",
            "I0205 13:20:17.271393 140689526667136 learning.py:507] global step 460: loss = 0.0640 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 461: loss = 0.5421 (0.387 sec/step)\n",
            "I0205 13:20:17.660223 140689526667136 learning.py:507] global step 461: loss = 0.5421 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 462: loss = 0.2824 (1.016 sec/step)\n",
            "I0205 13:20:18.677481 140689526667136 learning.py:507] global step 462: loss = 0.2824 (1.016 sec/step)\n",
            "INFO:tensorflow:global step 463: loss = 1.0832 (0.378 sec/step)\n",
            "I0205 13:20:19.056930 140689526667136 learning.py:507] global step 463: loss = 1.0832 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 464: loss = 0.9748 (0.384 sec/step)\n",
            "I0205 13:20:19.442266 140689526667136 learning.py:507] global step 464: loss = 0.9748 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 465: loss = 0.6511 (0.389 sec/step)\n",
            "I0205 13:20:19.833145 140689526667136 learning.py:507] global step 465: loss = 0.6511 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 466: loss = 0.1073 (0.409 sec/step)\n",
            "I0205 13:20:20.244132 140689526667136 learning.py:507] global step 466: loss = 0.1073 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 467: loss = 0.1263 (0.411 sec/step)\n",
            "I0205 13:20:20.657350 140689526667136 learning.py:507] global step 467: loss = 0.1263 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 468: loss = 0.0554 (0.375 sec/step)\n",
            "I0205 13:20:21.033812 140689526667136 learning.py:507] global step 468: loss = 0.0554 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 469: loss = 0.0860 (0.396 sec/step)\n",
            "I0205 13:20:21.431127 140689526667136 learning.py:507] global step 469: loss = 0.0860 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 470: loss = 1.0646 (0.368 sec/step)\n",
            "I0205 13:20:21.800856 140689526667136 learning.py:507] global step 470: loss = 1.0646 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 471: loss = 0.1862 (0.391 sec/step)\n",
            "I0205 13:20:22.193006 140689526667136 learning.py:507] global step 471: loss = 0.1862 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 472: loss = 0.2438 (0.380 sec/step)\n",
            "I0205 13:20:22.574622 140689526667136 learning.py:507] global step 472: loss = 0.2438 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 473: loss = 0.1419 (0.368 sec/step)\n",
            "I0205 13:20:22.943959 140689526667136 learning.py:507] global step 473: loss = 0.1419 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 474: loss = 0.1288 (0.356 sec/step)\n",
            "I0205 13:20:23.302372 140689526667136 learning.py:507] global step 474: loss = 0.1288 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 475: loss = 0.0466 (0.361 sec/step)\n",
            "I0205 13:20:23.665032 140689526667136 learning.py:507] global step 475: loss = 0.0466 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 476: loss = 0.5685 (0.396 sec/step)\n",
            "I0205 13:20:24.062141 140689526667136 learning.py:507] global step 476: loss = 0.5685 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 477: loss = 1.0645 (0.408 sec/step)\n",
            "I0205 13:20:24.471844 140689526667136 learning.py:507] global step 477: loss = 1.0645 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 478: loss = 0.1317 (0.381 sec/step)\n",
            "I0205 13:20:24.855333 140689526667136 learning.py:507] global step 478: loss = 0.1317 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 479: loss = 1.2981 (0.376 sec/step)\n",
            "I0205 13:20:25.233449 140689526667136 learning.py:507] global step 479: loss = 1.2981 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 480: loss = 0.3706 (0.450 sec/step)\n",
            "I0205 13:20:25.685054 140689526667136 learning.py:507] global step 480: loss = 0.3706 (0.450 sec/step)\n",
            "INFO:tensorflow:global step 481: loss = 0.0742 (0.412 sec/step)\n",
            "I0205 13:20:26.099005 140689526667136 learning.py:507] global step 481: loss = 0.0742 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 482: loss = 0.0855 (2.689 sec/step)\n",
            "I0205 13:20:28.789396 140689526667136 learning.py:507] global step 482: loss = 0.0855 (2.689 sec/step)\n",
            "INFO:tensorflow:global step 483: loss = 0.0638 (0.389 sec/step)\n",
            "I0205 13:20:29.179988 140689526667136 learning.py:507] global step 483: loss = 0.0638 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 484: loss = 0.0666 (0.439 sec/step)\n",
            "I0205 13:20:29.621053 140689526667136 learning.py:507] global step 484: loss = 0.0666 (0.439 sec/step)\n",
            "INFO:tensorflow:global step 485: loss = 0.0857 (0.411 sec/step)\n",
            "I0205 13:20:30.034059 140689526667136 learning.py:507] global step 485: loss = 0.0857 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 486: loss = 0.0597 (0.347 sec/step)\n",
            "I0205 13:20:30.382331 140689526667136 learning.py:507] global step 486: loss = 0.0597 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 487: loss = 0.0780 (0.372 sec/step)\n",
            "I0205 13:20:30.756467 140689526667136 learning.py:507] global step 487: loss = 0.0780 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 488: loss = 0.9869 (0.404 sec/step)\n",
            "I0205 13:20:31.162331 140689526667136 learning.py:507] global step 488: loss = 0.9869 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 489: loss = 0.8367 (0.364 sec/step)\n",
            "I0205 13:20:31.527524 140689526667136 learning.py:507] global step 489: loss = 0.8367 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 490: loss = 0.1100 (0.358 sec/step)\n",
            "I0205 13:20:31.887090 140689526667136 learning.py:507] global step 490: loss = 0.1100 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 491: loss = 0.5729 (0.386 sec/step)\n",
            "I0205 13:20:32.274802 140689526667136 learning.py:507] global step 491: loss = 0.5729 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 492: loss = 0.1700 (0.410 sec/step)\n",
            "I0205 13:20:32.686619 140689526667136 learning.py:507] global step 492: loss = 0.1700 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 493: loss = 0.2338 (0.398 sec/step)\n",
            "I0205 13:20:33.086646 140689526667136 learning.py:507] global step 493: loss = 0.2338 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 494: loss = 0.0700 (0.364 sec/step)\n",
            "I0205 13:20:33.453697 140689526667136 learning.py:507] global step 494: loss = 0.0700 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 495: loss = 0.4907 (0.392 sec/step)\n",
            "I0205 13:20:33.847852 140689526667136 learning.py:507] global step 495: loss = 0.4907 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 496: loss = 0.3554 (0.409 sec/step)\n",
            "I0205 13:20:34.258603 140689526667136 learning.py:507] global step 496: loss = 0.3554 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 497: loss = 0.3665 (0.376 sec/step)\n",
            "I0205 13:20:34.636207 140689526667136 learning.py:507] global step 497: loss = 0.3665 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 498: loss = 0.3210 (0.364 sec/step)\n",
            "I0205 13:20:35.001540 140689526667136 learning.py:507] global step 498: loss = 0.3210 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 499: loss = 0.2790 (0.395 sec/step)\n",
            "I0205 13:20:35.398232 140689526667136 learning.py:507] global step 499: loss = 0.2790 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 500: loss = 0.2260 (0.351 sec/step)\n",
            "I0205 13:20:35.750150 140689526667136 learning.py:507] global step 500: loss = 0.2260 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 501: loss = 1.3233 (0.355 sec/step)\n",
            "I0205 13:20:36.106801 140689526667136 learning.py:507] global step 501: loss = 1.3233 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 502: loss = 0.1394 (0.375 sec/step)\n",
            "I0205 13:20:36.483123 140689526667136 learning.py:507] global step 502: loss = 0.1394 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 503: loss = 0.2090 (0.368 sec/step)\n",
            "I0205 13:20:36.852870 140689526667136 learning.py:507] global step 503: loss = 0.2090 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 504: loss = 0.5941 (0.385 sec/step)\n",
            "I0205 13:20:37.239717 140689526667136 learning.py:507] global step 504: loss = 0.5941 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 505: loss = 0.6350 (0.372 sec/step)\n",
            "I0205 13:20:37.612846 140689526667136 learning.py:507] global step 505: loss = 0.6350 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 506: loss = 0.0590 (0.363 sec/step)\n",
            "I0205 13:20:37.977483 140689526667136 learning.py:507] global step 506: loss = 0.0590 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 507: loss = 0.1616 (1.588 sec/step)\n",
            "I0205 13:20:39.567250 140689526667136 learning.py:507] global step 507: loss = 0.1616 (1.588 sec/step)\n",
            "INFO:tensorflow:global step 508: loss = 0.2828 (0.375 sec/step)\n",
            "I0205 13:20:39.943941 140689526667136 learning.py:507] global step 508: loss = 0.2828 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 509: loss = 0.1815 (0.388 sec/step)\n",
            "I0205 13:20:40.333793 140689526667136 learning.py:507] global step 509: loss = 0.1815 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 510: loss = 1.1509 (0.356 sec/step)\n",
            "I0205 13:20:40.691481 140689526667136 learning.py:507] global step 510: loss = 1.1509 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 511: loss = 0.1192 (0.372 sec/step)\n",
            "I0205 13:20:41.065406 140689526667136 learning.py:507] global step 511: loss = 0.1192 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 512: loss = 0.4415 (0.354 sec/step)\n",
            "I0205 13:20:41.421042 140689526667136 learning.py:507] global step 512: loss = 0.4415 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 513: loss = 0.1057 (0.369 sec/step)\n",
            "I0205 13:20:41.791965 140689526667136 learning.py:507] global step 513: loss = 0.1057 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 514: loss = 0.7575 (0.360 sec/step)\n",
            "I0205 13:20:42.153186 140689526667136 learning.py:507] global step 514: loss = 0.7575 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 515: loss = 0.2582 (0.379 sec/step)\n",
            "I0205 13:20:42.533318 140689526667136 learning.py:507] global step 515: loss = 0.2582 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 516: loss = 0.1461 (0.364 sec/step)\n",
            "I0205 13:20:42.898737 140689526667136 learning.py:507] global step 516: loss = 0.1461 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 517: loss = 0.3035 (0.366 sec/step)\n",
            "I0205 13:20:43.266215 140689526667136 learning.py:507] global step 517: loss = 0.3035 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 518: loss = 0.1125 (0.406 sec/step)\n",
            "I0205 13:20:43.673919 140689526667136 learning.py:507] global step 518: loss = 0.1125 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 519: loss = 1.0364 (0.392 sec/step)\n",
            "I0205 13:20:44.068129 140689526667136 learning.py:507] global step 519: loss = 1.0364 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 520: loss = 0.3407 (0.363 sec/step)\n",
            "I0205 13:20:44.433440 140689526667136 learning.py:507] global step 520: loss = 0.3407 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 521: loss = 0.2184 (1.041 sec/step)\n",
            "I0205 13:20:45.476244 140689526667136 learning.py:507] global step 521: loss = 0.2184 (1.041 sec/step)\n",
            "INFO:tensorflow:global step 522: loss = 0.4562 (0.385 sec/step)\n",
            "I0205 13:20:45.862926 140689526667136 learning.py:507] global step 522: loss = 0.4562 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 523: loss = 0.8931 (0.379 sec/step)\n",
            "I0205 13:20:46.243280 140689526667136 learning.py:507] global step 523: loss = 0.8931 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 524: loss = 1.3597 (0.390 sec/step)\n",
            "I0205 13:20:46.635541 140689526667136 learning.py:507] global step 524: loss = 1.3597 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 525: loss = 0.2005 (0.385 sec/step)\n",
            "I0205 13:20:47.022652 140689526667136 learning.py:507] global step 525: loss = 0.2005 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 526: loss = 0.1318 (1.617 sec/step)\n",
            "I0205 13:20:48.641057 140689526667136 learning.py:507] global step 526: loss = 0.1318 (1.617 sec/step)\n",
            "INFO:tensorflow:global step 527: loss = 0.1239 (0.377 sec/step)\n",
            "I0205 13:20:49.019913 140689526667136 learning.py:507] global step 527: loss = 0.1239 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 528: loss = 0.1733 (0.377 sec/step)\n",
            "I0205 13:20:49.398957 140689526667136 learning.py:507] global step 528: loss = 0.1733 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 529: loss = 0.4214 (0.391 sec/step)\n",
            "I0205 13:20:49.791628 140689526667136 learning.py:507] global step 529: loss = 0.4214 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 530: loss = 0.5872 (0.852 sec/step)\n",
            "I0205 13:20:50.645558 140689526667136 learning.py:507] global step 530: loss = 0.5872 (0.852 sec/step)\n",
            "INFO:tensorflow:global step 531: loss = 0.0812 (0.383 sec/step)\n",
            "I0205 13:20:51.030224 140689526667136 learning.py:507] global step 531: loss = 0.0812 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 532: loss = 0.3111 (1.016 sec/step)\n",
            "I0205 13:20:52.047574 140689526667136 learning.py:507] global step 532: loss = 0.3111 (1.016 sec/step)\n",
            "INFO:tensorflow:global step 533: loss = 0.3050 (0.402 sec/step)\n",
            "I0205 13:20:52.451550 140689526667136 learning.py:507] global step 533: loss = 0.3050 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 534: loss = 2.9836 (0.413 sec/step)\n",
            "I0205 13:20:52.865925 140689526667136 learning.py:507] global step 534: loss = 2.9836 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 535: loss = 0.7325 (0.369 sec/step)\n",
            "I0205 13:20:53.236930 140689526667136 learning.py:507] global step 535: loss = 0.7325 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 536: loss = 0.0811 (0.381 sec/step)\n",
            "I0205 13:20:53.620294 140689526667136 learning.py:507] global step 536: loss = 0.0811 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 537: loss = 0.3390 (0.380 sec/step)\n",
            "I0205 13:20:54.001819 140689526667136 learning.py:507] global step 537: loss = 0.3390 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 538: loss = 0.1583 (0.399 sec/step)\n",
            "I0205 13:20:54.402407 140689526667136 learning.py:507] global step 538: loss = 0.1583 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 539: loss = 0.1967 (0.372 sec/step)\n",
            "I0205 13:20:54.776320 140689526667136 learning.py:507] global step 539: loss = 0.1967 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 540: loss = 0.0796 (0.396 sec/step)\n",
            "I0205 13:20:55.173899 140689526667136 learning.py:507] global step 540: loss = 0.0796 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 541: loss = 0.3928 (0.389 sec/step)\n",
            "I0205 13:20:55.564291 140689526667136 learning.py:507] global step 541: loss = 0.3928 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 542: loss = 0.2259 (0.382 sec/step)\n",
            "I0205 13:20:55.948612 140689526667136 learning.py:507] global step 542: loss = 0.2259 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 543: loss = 0.2163 (0.374 sec/step)\n",
            "I0205 13:20:56.324255 140689526667136 learning.py:507] global step 543: loss = 0.2163 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 544: loss = 1.1082 (0.397 sec/step)\n",
            "I0205 13:20:56.722729 140689526667136 learning.py:507] global step 544: loss = 1.1082 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 545: loss = 0.3606 (0.384 sec/step)\n",
            "I0205 13:20:57.108689 140689526667136 learning.py:507] global step 545: loss = 0.3606 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 546: loss = 0.1424 (0.459 sec/step)\n",
            "I0205 13:20:57.569107 140689526667136 learning.py:507] global step 546: loss = 0.1424 (0.459 sec/step)\n",
            "INFO:tensorflow:global step 547: loss = 1.2164 (0.353 sec/step)\n",
            "I0205 13:20:57.923830 140689526667136 learning.py:507] global step 547: loss = 1.2164 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 548: loss = 0.3594 (1.039 sec/step)\n",
            "I0205 13:20:58.963712 140689526667136 learning.py:507] global step 548: loss = 0.3594 (1.039 sec/step)\n",
            "INFO:tensorflow:global step 549: loss = 0.0701 (0.397 sec/step)\n",
            "I0205 13:20:59.362815 140689526667136 learning.py:507] global step 549: loss = 0.0701 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 550: loss = 0.7874 (0.361 sec/step)\n",
            "I0205 13:20:59.725293 140689526667136 learning.py:507] global step 550: loss = 0.7874 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 551: loss = 0.6240 (0.392 sec/step)\n",
            "I0205 13:21:00.119244 140689526667136 learning.py:507] global step 551: loss = 0.6240 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 552: loss = 0.1108 (0.383 sec/step)\n",
            "I0205 13:21:00.503658 140689526667136 learning.py:507] global step 552: loss = 0.1108 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 553: loss = 0.1414 (0.386 sec/step)\n",
            "I0205 13:21:00.891803 140689526667136 learning.py:507] global step 553: loss = 0.1414 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 554: loss = 0.0562 (0.363 sec/step)\n",
            "I0205 13:21:01.256432 140689526667136 learning.py:507] global step 554: loss = 0.0562 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 555: loss = 1.2041 (0.384 sec/step)\n",
            "I0205 13:21:01.642477 140689526667136 learning.py:507] global step 555: loss = 1.2041 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 556: loss = 0.1431 (0.397 sec/step)\n",
            "I0205 13:21:02.041018 140689526667136 learning.py:507] global step 556: loss = 0.1431 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 557: loss = 0.6671 (1.082 sec/step)\n",
            "I0205 13:21:03.124264 140689526667136 learning.py:507] global step 557: loss = 0.6671 (1.082 sec/step)\n",
            "INFO:tensorflow:global step 558: loss = 0.5211 (1.062 sec/step)\n",
            "I0205 13:21:04.187815 140689526667136 learning.py:507] global step 558: loss = 0.5211 (1.062 sec/step)\n",
            "INFO:tensorflow:global step 559: loss = 0.1542 (0.379 sec/step)\n",
            "I0205 13:21:04.568481 140689526667136 learning.py:507] global step 559: loss = 0.1542 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 560: loss = 0.5264 (0.383 sec/step)\n",
            "I0205 13:21:04.952954 140689526667136 learning.py:507] global step 560: loss = 0.5264 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 561: loss = 0.3601 (0.380 sec/step)\n",
            "I0205 13:21:05.334147 140689526667136 learning.py:507] global step 561: loss = 0.3601 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 562: loss = 0.7085 (1.065 sec/step)\n",
            "I0205 13:21:06.400259 140689526667136 learning.py:507] global step 562: loss = 0.7085 (1.065 sec/step)\n",
            "INFO:tensorflow:global step 563: loss = 0.1184 (0.377 sec/step)\n",
            "I0205 13:21:06.778627 140689526667136 learning.py:507] global step 563: loss = 0.1184 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 564: loss = 0.6948 (0.370 sec/step)\n",
            "I0205 13:21:07.150002 140689526667136 learning.py:507] global step 564: loss = 0.6948 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 565: loss = 0.1112 (0.452 sec/step)\n",
            "I0205 13:21:07.603882 140689526667136 learning.py:507] global step 565: loss = 0.1112 (0.452 sec/step)\n",
            "INFO:tensorflow:global step 566: loss = 0.2037 (0.391 sec/step)\n",
            "I0205 13:21:07.997740 140689526667136 learning.py:507] global step 566: loss = 0.2037 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 567: loss = 1.1207 (0.378 sec/step)\n",
            "I0205 13:21:08.377734 140689526667136 learning.py:507] global step 567: loss = 1.1207 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 568: loss = 0.0857 (0.370 sec/step)\n",
            "I0205 13:21:08.749396 140689526667136 learning.py:507] global step 568: loss = 0.0857 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 569: loss = 0.2113 (0.370 sec/step)\n",
            "I0205 13:21:09.121239 140689526667136 learning.py:507] global step 569: loss = 0.2113 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 570: loss = 0.9513 (0.445 sec/step)\n",
            "I0205 13:21:09.568103 140689526667136 learning.py:507] global step 570: loss = 0.9513 (0.445 sec/step)\n",
            "INFO:tensorflow:global step 571: loss = 0.0707 (0.409 sec/step)\n",
            "I0205 13:21:09.979376 140689526667136 learning.py:507] global step 571: loss = 0.0707 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 572: loss = 0.9500 (0.463 sec/step)\n",
            "I0205 13:21:10.443659 140689526667136 learning.py:507] global step 572: loss = 0.9500 (0.463 sec/step)\n",
            "INFO:tensorflow:global step 573: loss = 0.6879 (0.367 sec/step)\n",
            "I0205 13:21:10.812119 140689526667136 learning.py:507] global step 573: loss = 0.6879 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 574: loss = 0.0637 (0.377 sec/step)\n",
            "I0205 13:21:11.190252 140689526667136 learning.py:507] global step 574: loss = 0.0637 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 575: loss = 0.0740 (0.380 sec/step)\n",
            "I0205 13:21:11.571641 140689526667136 learning.py:507] global step 575: loss = 0.0740 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 576: loss = 0.1088 (0.373 sec/step)\n",
            "I0205 13:21:11.946575 140689526667136 learning.py:507] global step 576: loss = 0.1088 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 577: loss = 0.6996 (0.390 sec/step)\n",
            "I0205 13:21:12.337777 140689526667136 learning.py:507] global step 577: loss = 0.6996 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 578: loss = 1.1530 (0.339 sec/step)\n",
            "I0205 13:21:12.678110 140689526667136 learning.py:507] global step 578: loss = 1.1530 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 579: loss = 0.4035 (0.371 sec/step)\n",
            "I0205 13:21:13.051201 140689526667136 learning.py:507] global step 579: loss = 0.4035 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 580: loss = 0.1066 (0.390 sec/step)\n",
            "I0205 13:21:13.442999 140689526667136 learning.py:507] global step 580: loss = 0.1066 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 581: loss = 0.9205 (0.385 sec/step)\n",
            "I0205 13:21:13.829817 140689526667136 learning.py:507] global step 581: loss = 0.9205 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 582: loss = 0.4499 (2.877 sec/step)\n",
            "I0205 13:21:16.707942 140689526667136 learning.py:507] global step 582: loss = 0.4499 (2.877 sec/step)\n",
            "INFO:tensorflow:global step 583: loss = 0.3493 (0.375 sec/step)\n",
            "I0205 13:21:17.084304 140689526667136 learning.py:507] global step 583: loss = 0.3493 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 584: loss = 0.2024 (0.395 sec/step)\n",
            "I0205 13:21:17.481226 140689526667136 learning.py:507] global step 584: loss = 0.2024 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 585: loss = 0.2984 (0.389 sec/step)\n",
            "I0205 13:21:17.871521 140689526667136 learning.py:507] global step 585: loss = 0.2984 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 586: loss = 0.3331 (0.393 sec/step)\n",
            "I0205 13:21:18.265959 140689526667136 learning.py:507] global step 586: loss = 0.3331 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 587: loss = 0.0961 (0.409 sec/step)\n",
            "I0205 13:21:18.677404 140689526667136 learning.py:507] global step 587: loss = 0.0961 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 588: loss = 0.5279 (0.379 sec/step)\n",
            "I0205 13:21:19.058042 140689526667136 learning.py:507] global step 588: loss = 0.5279 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 589: loss = 0.9649 (0.377 sec/step)\n",
            "I0205 13:21:19.436338 140689526667136 learning.py:507] global step 589: loss = 0.9649 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 590: loss = 0.1350 (0.390 sec/step)\n",
            "I0205 13:21:19.827740 140689526667136 learning.py:507] global step 590: loss = 0.1350 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 591: loss = 0.2995 (0.394 sec/step)\n",
            "I0205 13:21:20.223589 140689526667136 learning.py:507] global step 591: loss = 0.2995 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 592: loss = 0.0775 (0.401 sec/step)\n",
            "I0205 13:21:20.626427 140689526667136 learning.py:507] global step 592: loss = 0.0775 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 593: loss = 0.5460 (0.384 sec/step)\n",
            "I0205 13:21:21.011719 140689526667136 learning.py:507] global step 593: loss = 0.5460 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 594: loss = 0.3775 (0.346 sec/step)\n",
            "I0205 13:21:21.359101 140689526667136 learning.py:507] global step 594: loss = 0.3775 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 595: loss = 0.0687 (0.359 sec/step)\n",
            "I0205 13:21:21.719669 140689526667136 learning.py:507] global step 595: loss = 0.0687 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 596: loss = 0.3521 (0.374 sec/step)\n",
            "I0205 13:21:22.095383 140689526667136 learning.py:507] global step 596: loss = 0.3521 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 597: loss = 0.1266 (0.385 sec/step)\n",
            "I0205 13:21:22.482156 140689526667136 learning.py:507] global step 597: loss = 0.1266 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 598: loss = 0.2258 (0.379 sec/step)\n",
            "I0205 13:21:22.862534 140689526667136 learning.py:507] global step 598: loss = 0.2258 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 599: loss = 0.3375 (0.369 sec/step)\n",
            "I0205 13:21:23.233534 140689526667136 learning.py:507] global step 599: loss = 0.3375 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 600: loss = 0.0471 (1.713 sec/step)\n",
            "I0205 13:21:24.948427 140689526667136 learning.py:507] global step 600: loss = 0.0471 (1.713 sec/step)\n",
            "INFO:tensorflow:global step 601: loss = 0.0607 (0.362 sec/step)\n",
            "I0205 13:21:25.312144 140689526667136 learning.py:507] global step 601: loss = 0.0607 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 602: loss = 0.3667 (0.397 sec/step)\n",
            "I0205 13:21:25.710350 140689526667136 learning.py:507] global step 602: loss = 0.3667 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 603: loss = 0.2449 (0.370 sec/step)\n",
            "I0205 13:21:26.081920 140689526667136 learning.py:507] global step 603: loss = 0.2449 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 604: loss = 0.1124 (0.383 sec/step)\n",
            "I0205 13:21:26.466340 140689526667136 learning.py:507] global step 604: loss = 0.1124 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 605: loss = 0.1136 (0.364 sec/step)\n",
            "I0205 13:21:26.832283 140689526667136 learning.py:507] global step 605: loss = 0.1136 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 606: loss = 0.2942 (1.530 sec/step)\n",
            "I0205 13:21:28.363823 140689526667136 learning.py:507] global step 606: loss = 0.2942 (1.530 sec/step)\n",
            "INFO:tensorflow:global step 607: loss = 0.9457 (0.404 sec/step)\n",
            "I0205 13:21:28.769345 140689526667136 learning.py:507] global step 607: loss = 0.9457 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 608: loss = 2.8105 (0.352 sec/step)\n",
            "I0205 13:21:29.122794 140689526667136 learning.py:507] global step 608: loss = 2.8105 (0.352 sec/step)\n",
            "INFO:tensorflow:global step 609: loss = 0.2611 (0.417 sec/step)\n",
            "I0205 13:21:29.541248 140689526667136 learning.py:507] global step 609: loss = 0.2611 (0.417 sec/step)\n",
            "INFO:tensorflow:global step 610: loss = 0.0585 (0.405 sec/step)\n",
            "I0205 13:21:29.947663 140689526667136 learning.py:507] global step 610: loss = 0.0585 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 611: loss = 0.0740 (0.388 sec/step)\n",
            "I0205 13:21:30.337529 140689526667136 learning.py:507] global step 611: loss = 0.0740 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 612: loss = 0.0631 (0.376 sec/step)\n",
            "I0205 13:21:30.714924 140689526667136 learning.py:507] global step 612: loss = 0.0631 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 613: loss = 2.5006 (0.370 sec/step)\n",
            "I0205 13:21:31.086867 140689526667136 learning.py:507] global step 613: loss = 2.5006 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 614: loss = 0.0768 (0.367 sec/step)\n",
            "I0205 13:21:31.455714 140689526667136 learning.py:507] global step 614: loss = 0.0768 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 615: loss = 0.1356 (0.366 sec/step)\n",
            "I0205 13:21:31.823361 140689526667136 learning.py:507] global step 615: loss = 0.1356 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 616: loss = 0.3905 (0.388 sec/step)\n",
            "I0205 13:21:32.213048 140689526667136 learning.py:507] global step 616: loss = 0.3905 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 617: loss = 0.1669 (0.947 sec/step)\n",
            "I0205 13:21:33.161331 140689526667136 learning.py:507] global step 617: loss = 0.1669 (0.947 sec/step)\n",
            "INFO:tensorflow:global step 618: loss = 0.8331 (0.404 sec/step)\n",
            "I0205 13:21:33.566536 140689526667136 learning.py:507] global step 618: loss = 0.8331 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 619: loss = 0.1450 (0.371 sec/step)\n",
            "I0205 13:21:33.939044 140689526667136 learning.py:507] global step 619: loss = 0.1450 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 620: loss = 0.4651 (0.485 sec/step)\n",
            "I0205 13:21:34.426037 140689526667136 learning.py:507] global step 620: loss = 0.4651 (0.485 sec/step)\n",
            "INFO:tensorflow:global step 621: loss = 0.5239 (0.384 sec/step)\n",
            "I0205 13:21:34.812052 140689526667136 learning.py:507] global step 621: loss = 0.5239 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 622: loss = 0.4212 (0.384 sec/step)\n",
            "I0205 13:21:35.197749 140689526667136 learning.py:507] global step 622: loss = 0.4212 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 623: loss = 0.0707 (0.401 sec/step)\n",
            "I0205 13:21:35.600308 140689526667136 learning.py:507] global step 623: loss = 0.0707 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 624: loss = 0.2022 (0.353 sec/step)\n",
            "I0205 13:21:35.955838 140689526667136 learning.py:507] global step 624: loss = 0.2022 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 625: loss = 0.0783 (2.509 sec/step)\n",
            "I0205 13:21:38.466229 140689526667136 learning.py:507] global step 625: loss = 0.0783 (2.509 sec/step)\n",
            "INFO:tensorflow:global step 626: loss = 0.1117 (0.369 sec/step)\n",
            "I0205 13:21:38.836700 140689526667136 learning.py:507] global step 626: loss = 0.1117 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 627: loss = 0.2626 (1.574 sec/step)\n",
            "I0205 13:21:40.412494 140689526667136 learning.py:507] global step 627: loss = 0.2626 (1.574 sec/step)\n",
            "INFO:tensorflow:global step 628: loss = 0.0910 (0.374 sec/step)\n",
            "I0205 13:21:40.787658 140689526667136 learning.py:507] global step 628: loss = 0.0910 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 629: loss = 0.1565 (0.352 sec/step)\n",
            "I0205 13:21:41.141039 140689526667136 learning.py:507] global step 629: loss = 0.1565 (0.352 sec/step)\n",
            "INFO:tensorflow:global step 630: loss = 0.5129 (0.388 sec/step)\n",
            "I0205 13:21:41.530823 140689526667136 learning.py:507] global step 630: loss = 0.5129 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 631: loss = 0.0531 (0.402 sec/step)\n",
            "I0205 13:21:41.934606 140689526667136 learning.py:507] global step 631: loss = 0.0531 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 632: loss = 0.0962 (0.387 sec/step)\n",
            "I0205 13:21:42.323719 140689526667136 learning.py:507] global step 632: loss = 0.0962 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 633: loss = 0.0734 (0.366 sec/step)\n",
            "I0205 13:21:42.691420 140689526667136 learning.py:507] global step 633: loss = 0.0734 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 634: loss = 0.1151 (0.460 sec/step)\n",
            "I0205 13:21:43.153006 140689526667136 learning.py:507] global step 634: loss = 0.1151 (0.460 sec/step)\n",
            "INFO:tensorflow:global step 635: loss = 0.0758 (0.374 sec/step)\n",
            "I0205 13:21:43.528367 140689526667136 learning.py:507] global step 635: loss = 0.0758 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 636: loss = 0.2916 (0.398 sec/step)\n",
            "I0205 13:21:43.928471 140689526667136 learning.py:507] global step 636: loss = 0.2916 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 637: loss = 0.4546 (0.384 sec/step)\n",
            "I0205 13:21:44.314000 140689526667136 learning.py:507] global step 637: loss = 0.4546 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 638: loss = 0.0749 (0.356 sec/step)\n",
            "I0205 13:21:44.671564 140689526667136 learning.py:507] global step 638: loss = 0.0749 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 639: loss = 0.2153 (0.400 sec/step)\n",
            "I0205 13:21:45.072956 140689526667136 learning.py:507] global step 639: loss = 0.2153 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 640: loss = 0.2999 (1.036 sec/step)\n",
            "I0205 13:21:46.109832 140689526667136 learning.py:507] global step 640: loss = 0.2999 (1.036 sec/step)\n",
            "INFO:tensorflow:global step 641: loss = 0.2337 (0.368 sec/step)\n",
            "I0205 13:21:46.478867 140689526667136 learning.py:507] global step 641: loss = 0.2337 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 642: loss = 0.3392 (0.357 sec/step)\n",
            "I0205 13:21:46.837248 140689526667136 learning.py:507] global step 642: loss = 0.3392 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 643: loss = 0.2644 (0.382 sec/step)\n",
            "I0205 13:21:47.220495 140689526667136 learning.py:507] global step 643: loss = 0.2644 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 644: loss = 0.1446 (0.386 sec/step)\n",
            "I0205 13:21:47.608233 140689526667136 learning.py:507] global step 644: loss = 0.1446 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 645: loss = 1.0564 (0.374 sec/step)\n",
            "I0205 13:21:47.983707 140689526667136 learning.py:507] global step 645: loss = 1.0564 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 646: loss = 0.4122 (0.389 sec/step)\n",
            "I0205 13:21:48.374003 140689526667136 learning.py:507] global step 646: loss = 0.4122 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 647: loss = 0.0399 (0.431 sec/step)\n",
            "I0205 13:21:48.806514 140689526667136 learning.py:507] global step 647: loss = 0.0399 (0.431 sec/step)\n",
            "INFO:tensorflow:global step 648: loss = 0.1431 (0.392 sec/step)\n",
            "I0205 13:21:49.200267 140689526667136 learning.py:507] global step 648: loss = 0.1431 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 649: loss = 0.0832 (1.100 sec/step)\n",
            "I0205 13:21:50.301726 140689526667136 learning.py:507] global step 649: loss = 0.0832 (1.100 sec/step)\n",
            "INFO:tensorflow:global step 650: loss = 0.1104 (0.384 sec/step)\n",
            "I0205 13:21:50.686735 140689526667136 learning.py:507] global step 650: loss = 0.1104 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 651: loss = 0.3888 (0.378 sec/step)\n",
            "I0205 13:21:51.066315 140689526667136 learning.py:507] global step 651: loss = 0.3888 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 652: loss = 0.1091 (0.390 sec/step)\n",
            "I0205 13:21:51.458014 140689526667136 learning.py:507] global step 652: loss = 0.1091 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 653: loss = 0.0781 (0.386 sec/step)\n",
            "I0205 13:21:51.845280 140689526667136 learning.py:507] global step 653: loss = 0.0781 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 654: loss = 0.0655 (0.388 sec/step)\n",
            "I0205 13:21:52.235783 140689526667136 learning.py:507] global step 654: loss = 0.0655 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 655: loss = 0.4112 (0.422 sec/step)\n",
            "I0205 13:21:52.660398 140689526667136 learning.py:507] global step 655: loss = 0.4112 (0.422 sec/step)\n",
            "INFO:tensorflow:global step 656: loss = 0.3190 (0.457 sec/step)\n",
            "I0205 13:21:53.119507 140689526667136 learning.py:507] global step 656: loss = 0.3190 (0.457 sec/step)\n",
            "INFO:tensorflow:global step 657: loss = 0.0748 (0.391 sec/step)\n",
            "I0205 13:21:53.511896 140689526667136 learning.py:507] global step 657: loss = 0.0748 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 658: loss = 0.1516 (0.373 sec/step)\n",
            "I0205 13:21:53.886972 140689526667136 learning.py:507] global step 658: loss = 0.1516 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 659: loss = 1.4333 (0.357 sec/step)\n",
            "I0205 13:21:54.245402 140689526667136 learning.py:507] global step 659: loss = 1.4333 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 660: loss = 0.5060 (0.372 sec/step)\n",
            "I0205 13:21:54.618985 140689526667136 learning.py:507] global step 660: loss = 0.5060 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 661: loss = 1.0398 (0.346 sec/step)\n",
            "I0205 13:21:54.966022 140689526667136 learning.py:507] global step 661: loss = 1.0398 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 662: loss = 0.1351 (1.608 sec/step)\n",
            "I0205 13:21:56.575614 140689526667136 learning.py:507] global step 662: loss = 0.1351 (1.608 sec/step)\n",
            "INFO:tensorflow:global step 663: loss = 0.9723 (1.011 sec/step)\n",
            "I0205 13:21:57.587773 140689526667136 learning.py:507] global step 663: loss = 0.9723 (1.011 sec/step)\n",
            "INFO:tensorflow:global step 664: loss = 0.3349 (0.383 sec/step)\n",
            "I0205 13:21:57.972687 140689526667136 learning.py:507] global step 664: loss = 0.3349 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 665: loss = 0.9981 (0.365 sec/step)\n",
            "I0205 13:21:58.339704 140689526667136 learning.py:507] global step 665: loss = 0.9981 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 666: loss = 0.6810 (0.364 sec/step)\n",
            "I0205 13:21:58.704960 140689526667136 learning.py:507] global step 666: loss = 0.6810 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 667: loss = 0.3065 (0.410 sec/step)\n",
            "I0205 13:21:59.115972 140689526667136 learning.py:507] global step 667: loss = 0.3065 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 668: loss = 0.8931 (0.400 sec/step)\n",
            "I0205 13:21:59.517553 140689526667136 learning.py:507] global step 668: loss = 0.8931 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 669: loss = 0.2443 (0.364 sec/step)\n",
            "I0205 13:21:59.883262 140689526667136 learning.py:507] global step 669: loss = 0.2443 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 670: loss = 0.1040 (0.379 sec/step)\n",
            "I0205 13:22:00.264689 140689526667136 learning.py:507] global step 670: loss = 0.1040 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 671: loss = 0.0578 (0.372 sec/step)\n",
            "I0205 13:22:00.638488 140689526667136 learning.py:507] global step 671: loss = 0.0578 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 672: loss = 0.6729 (0.351 sec/step)\n",
            "I0205 13:22:00.990951 140689526667136 learning.py:507] global step 672: loss = 0.6729 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 673: loss = 0.1318 (1.016 sec/step)\n",
            "I0205 13:22:02.008125 140689526667136 learning.py:507] global step 673: loss = 0.1318 (1.016 sec/step)\n",
            "INFO:tensorflow:global step 674: loss = 0.4795 (0.395 sec/step)\n",
            "I0205 13:22:02.404443 140689526667136 learning.py:507] global step 674: loss = 0.4795 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 675: loss = 0.0811 (1.718 sec/step)\n",
            "I0205 13:22:04.124240 140689526667136 learning.py:507] global step 675: loss = 0.0811 (1.718 sec/step)\n",
            "INFO:tensorflow:global step 676: loss = 0.2737 (0.376 sec/step)\n",
            "I0205 13:22:04.502254 140689526667136 learning.py:507] global step 676: loss = 0.2737 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 677: loss = 0.0836 (0.367 sec/step)\n",
            "I0205 13:22:04.870360 140689526667136 learning.py:507] global step 677: loss = 0.0836 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 678: loss = 0.5216 (1.597 sec/step)\n",
            "I0205 13:22:06.468644 140689526667136 learning.py:507] global step 678: loss = 0.5216 (1.597 sec/step)\n",
            "INFO:tensorflow:global step 679: loss = 0.0395 (0.373 sec/step)\n",
            "I0205 13:22:06.843289 140689526667136 learning.py:507] global step 679: loss = 0.0395 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 680: loss = 0.0635 (0.374 sec/step)\n",
            "I0205 13:22:07.218780 140689526667136 learning.py:507] global step 680: loss = 0.0635 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 681: loss = 0.1139 (0.359 sec/step)\n",
            "I0205 13:22:07.579573 140689526667136 learning.py:507] global step 681: loss = 0.1139 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 682: loss = 0.6787 (0.391 sec/step)\n",
            "I0205 13:22:07.972148 140689526667136 learning.py:507] global step 682: loss = 0.6787 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 683: loss = 0.2570 (0.384 sec/step)\n",
            "I0205 13:22:08.357657 140689526667136 learning.py:507] global step 683: loss = 0.2570 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 684: loss = 0.0942 (0.366 sec/step)\n",
            "I0205 13:22:08.725652 140689526667136 learning.py:507] global step 684: loss = 0.0942 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 685: loss = 0.1666 (0.440 sec/step)\n",
            "I0205 13:22:09.167578 140689526667136 learning.py:507] global step 685: loss = 0.1666 (0.440 sec/step)\n",
            "INFO:tensorflow:global step 686: loss = 0.2297 (0.418 sec/step)\n",
            "I0205 13:22:09.587712 140689526667136 learning.py:507] global step 686: loss = 0.2297 (0.418 sec/step)\n",
            "INFO:tensorflow:global step 687: loss = 0.1400 (0.406 sec/step)\n",
            "I0205 13:22:09.995767 140689526667136 learning.py:507] global step 687: loss = 0.1400 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 688: loss = 0.2583 (0.356 sec/step)\n",
            "I0205 13:22:10.353541 140689526667136 learning.py:507] global step 688: loss = 0.2583 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 689: loss = 0.2075 (0.369 sec/step)\n",
            "I0205 13:22:10.724492 140689526667136 learning.py:507] global step 689: loss = 0.2075 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 690: loss = 0.2408 (0.361 sec/step)\n",
            "I0205 13:22:11.086924 140689526667136 learning.py:507] global step 690: loss = 0.2408 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 691: loss = 0.3371 (2.195 sec/step)\n",
            "I0205 13:22:13.282985 140689526667136 learning.py:507] global step 691: loss = 0.3371 (2.195 sec/step)\n",
            "INFO:tensorflow:global step 692: loss = 0.4457 (0.352 sec/step)\n",
            "I0205 13:22:13.636874 140689526667136 learning.py:507] global step 692: loss = 0.4457 (0.352 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 1.95827\n",
            "I0205 13:22:15.923009 140686034466560 supervisor.py:1099] global_step/sec: 1.95827\n",
            "INFO:tensorflow:global step 693: loss = 0.3961 (2.219 sec/step)\n",
            "I0205 13:22:15.925056 140689526667136 learning.py:507] global step 693: loss = 0.3961 (2.219 sec/step)\n",
            "INFO:tensorflow:global step 694: loss = 0.0840 (0.755 sec/step)\n",
            "I0205 13:22:16.744290 140689526667136 learning.py:507] global step 694: loss = 0.0840 (0.755 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 694.\n",
            "I0205 13:22:17.594220 140686026073856 supervisor.py:1050] Recording summary at step 694.\n",
            "INFO:tensorflow:global step 695: loss = 0.1960 (2.747 sec/step)\n",
            "I0205 13:22:19.492738 140689526667136 learning.py:507] global step 695: loss = 0.1960 (2.747 sec/step)\n",
            "INFO:tensorflow:global step 696: loss = 0.3096 (0.389 sec/step)\n",
            "I0205 13:22:19.883365 140689526667136 learning.py:507] global step 696: loss = 0.3096 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 697: loss = 1.0999 (0.377 sec/step)\n",
            "I0205 13:22:20.262256 140689526667136 learning.py:507] global step 697: loss = 1.0999 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 698: loss = 0.1067 (0.424 sec/step)\n",
            "I0205 13:22:20.688484 140689526667136 learning.py:507] global step 698: loss = 0.1067 (0.424 sec/step)\n",
            "INFO:tensorflow:global step 699: loss = 0.3434 (0.401 sec/step)\n",
            "I0205 13:22:21.090955 140689526667136 learning.py:507] global step 699: loss = 0.3434 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 700: loss = 0.1704 (0.385 sec/step)\n",
            "I0205 13:22:21.477795 140689526667136 learning.py:507] global step 700: loss = 0.1704 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 701: loss = 0.5643 (0.379 sec/step)\n",
            "I0205 13:22:21.859252 140689526667136 learning.py:507] global step 701: loss = 0.5643 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 702: loss = 0.1950 (0.375 sec/step)\n",
            "I0205 13:22:22.236099 140689526667136 learning.py:507] global step 702: loss = 0.1950 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 703: loss = 0.0769 (0.354 sec/step)\n",
            "I0205 13:22:22.591398 140689526667136 learning.py:507] global step 703: loss = 0.0769 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 704: loss = 0.0618 (0.389 sec/step)\n",
            "I0205 13:22:22.981988 140689526667136 learning.py:507] global step 704: loss = 0.0618 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 705: loss = 0.0969 (0.385 sec/step)\n",
            "I0205 13:22:23.368486 140689526667136 learning.py:507] global step 705: loss = 0.0969 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 706: loss = 0.0954 (0.402 sec/step)\n",
            "I0205 13:22:23.771958 140689526667136 learning.py:507] global step 706: loss = 0.0954 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 707: loss = 0.3303 (0.390 sec/step)\n",
            "I0205 13:22:24.163572 140689526667136 learning.py:507] global step 707: loss = 0.3303 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 708: loss = 0.1248 (0.371 sec/step)\n",
            "I0205 13:22:24.536192 140689526667136 learning.py:507] global step 708: loss = 0.1248 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 709: loss = 0.0901 (1.671 sec/step)\n",
            "I0205 13:22:26.208789 140689526667136 learning.py:507] global step 709: loss = 0.0901 (1.671 sec/step)\n",
            "INFO:tensorflow:global step 710: loss = 0.3845 (2.037 sec/step)\n",
            "I0205 13:22:28.247760 140689526667136 learning.py:507] global step 710: loss = 0.3845 (2.037 sec/step)\n",
            "INFO:tensorflow:global step 711: loss = 0.3599 (0.368 sec/step)\n",
            "I0205 13:22:28.617612 140689526667136 learning.py:507] global step 711: loss = 0.3599 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 712: loss = 1.5098 (0.399 sec/step)\n",
            "I0205 13:22:29.018068 140689526667136 learning.py:507] global step 712: loss = 1.5098 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 713: loss = 0.4191 (0.391 sec/step)\n",
            "I0205 13:22:29.410531 140689526667136 learning.py:507] global step 713: loss = 0.4191 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 714: loss = 0.5557 (0.420 sec/step)\n",
            "I0205 13:22:29.833440 140689526667136 learning.py:507] global step 714: loss = 0.5557 (0.420 sec/step)\n",
            "INFO:tensorflow:global step 715: loss = 0.2520 (0.386 sec/step)\n",
            "I0205 13:22:30.221814 140689526667136 learning.py:507] global step 715: loss = 0.2520 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 716: loss = 0.5882 (0.395 sec/step)\n",
            "I0205 13:22:30.618581 140689526667136 learning.py:507] global step 716: loss = 0.5882 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 717: loss = 0.0712 (0.389 sec/step)\n",
            "I0205 13:22:31.008991 140689526667136 learning.py:507] global step 717: loss = 0.0712 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 718: loss = 0.0818 (0.354 sec/step)\n",
            "I0205 13:22:31.365161 140689526667136 learning.py:507] global step 718: loss = 0.0818 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 719: loss = 0.1968 (0.355 sec/step)\n",
            "I0205 13:22:31.721919 140689526667136 learning.py:507] global step 719: loss = 0.1968 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 720: loss = 0.1457 (0.368 sec/step)\n",
            "I0205 13:22:32.091691 140689526667136 learning.py:507] global step 720: loss = 0.1457 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 721: loss = 0.3390 (1.583 sec/step)\n",
            "I0205 13:22:33.676025 140689526667136 learning.py:507] global step 721: loss = 0.3390 (1.583 sec/step)\n",
            "INFO:tensorflow:global step 722: loss = 0.2684 (0.410 sec/step)\n",
            "I0205 13:22:34.087908 140689526667136 learning.py:507] global step 722: loss = 0.2684 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 723: loss = 0.1468 (0.359 sec/step)\n",
            "I0205 13:22:34.448325 140689526667136 learning.py:507] global step 723: loss = 0.1468 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 724: loss = 0.0728 (0.379 sec/step)\n",
            "I0205 13:22:34.828593 140689526667136 learning.py:507] global step 724: loss = 0.0728 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 725: loss = 0.0717 (0.376 sec/step)\n",
            "I0205 13:22:35.205888 140689526667136 learning.py:507] global step 725: loss = 0.0717 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 726: loss = 0.1486 (0.383 sec/step)\n",
            "I0205 13:22:35.590276 140689526667136 learning.py:507] global step 726: loss = 0.1486 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 727: loss = 0.3442 (0.376 sec/step)\n",
            "I0205 13:22:35.968075 140689526667136 learning.py:507] global step 727: loss = 0.3442 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 728: loss = 0.5382 (0.362 sec/step)\n",
            "I0205 13:22:36.331862 140689526667136 learning.py:507] global step 728: loss = 0.5382 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 729: loss = 0.2656 (0.395 sec/step)\n",
            "I0205 13:22:36.728253 140689526667136 learning.py:507] global step 729: loss = 0.2656 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 730: loss = 0.0963 (0.384 sec/step)\n",
            "I0205 13:22:37.114206 140689526667136 learning.py:507] global step 730: loss = 0.0963 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 731: loss = 0.1773 (0.405 sec/step)\n",
            "I0205 13:22:37.520830 140689526667136 learning.py:507] global step 731: loss = 0.1773 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 732: loss = 0.6609 (0.408 sec/step)\n",
            "I0205 13:22:37.930572 140689526667136 learning.py:507] global step 732: loss = 0.6609 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 733: loss = 1.6376 (0.376 sec/step)\n",
            "I0205 13:22:38.307879 140689526667136 learning.py:507] global step 733: loss = 1.6376 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 734: loss = 0.2792 (0.376 sec/step)\n",
            "I0205 13:22:38.685871 140689526667136 learning.py:507] global step 734: loss = 0.2792 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 735: loss = 0.0825 (0.426 sec/step)\n",
            "I0205 13:22:39.113715 140689526667136 learning.py:507] global step 735: loss = 0.0825 (0.426 sec/step)\n",
            "INFO:tensorflow:global step 736: loss = 0.4322 (0.437 sec/step)\n",
            "I0205 13:22:39.552763 140689526667136 learning.py:507] global step 736: loss = 0.4322 (0.437 sec/step)\n",
            "INFO:tensorflow:global step 737: loss = 0.1044 (0.387 sec/step)\n",
            "I0205 13:22:39.941396 140689526667136 learning.py:507] global step 737: loss = 0.1044 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 738: loss = 0.5023 (0.375 sec/step)\n",
            "I0205 13:22:40.318202 140689526667136 learning.py:507] global step 738: loss = 0.5023 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 739: loss = 0.1732 (0.393 sec/step)\n",
            "I0205 13:22:40.712883 140689526667136 learning.py:507] global step 739: loss = 0.1732 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 740: loss = 0.7510 (0.364 sec/step)\n",
            "I0205 13:22:41.078987 140689526667136 learning.py:507] global step 740: loss = 0.7510 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 741: loss = 0.0796 (0.382 sec/step)\n",
            "I0205 13:22:41.462331 140689526667136 learning.py:507] global step 741: loss = 0.0796 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 742: loss = 0.1743 (1.052 sec/step)\n",
            "I0205 13:22:42.515229 140689526667136 learning.py:507] global step 742: loss = 0.1743 (1.052 sec/step)\n",
            "INFO:tensorflow:global step 743: loss = 0.4097 (0.363 sec/step)\n",
            "I0205 13:22:42.880357 140689526667136 learning.py:507] global step 743: loss = 0.4097 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 744: loss = 0.4915 (0.375 sec/step)\n",
            "I0205 13:22:43.256967 140689526667136 learning.py:507] global step 744: loss = 0.4915 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 745: loss = 0.2357 (0.354 sec/step)\n",
            "I0205 13:22:43.612488 140689526667136 learning.py:507] global step 745: loss = 0.2357 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 746: loss = 0.1402 (0.382 sec/step)\n",
            "I0205 13:22:43.995777 140689526667136 learning.py:507] global step 746: loss = 0.1402 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 747: loss = 0.1758 (1.032 sec/step)\n",
            "I0205 13:22:45.028926 140689526667136 learning.py:507] global step 747: loss = 0.1758 (1.032 sec/step)\n",
            "INFO:tensorflow:global step 748: loss = 0.2883 (0.482 sec/step)\n",
            "I0205 13:22:45.512734 140689526667136 learning.py:507] global step 748: loss = 0.2883 (0.482 sec/step)\n",
            "INFO:tensorflow:global step 749: loss = 0.6343 (0.410 sec/step)\n",
            "I0205 13:22:45.924442 140689526667136 learning.py:507] global step 749: loss = 0.6343 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 750: loss = 0.0531 (0.365 sec/step)\n",
            "I0205 13:22:46.291454 140689526667136 learning.py:507] global step 750: loss = 0.0531 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 751: loss = 0.2267 (0.382 sec/step)\n",
            "I0205 13:22:46.675272 140689526667136 learning.py:507] global step 751: loss = 0.2267 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 752: loss = 0.0652 (0.378 sec/step)\n",
            "I0205 13:22:47.054623 140689526667136 learning.py:507] global step 752: loss = 0.0652 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 753: loss = 0.0719 (0.390 sec/step)\n",
            "I0205 13:22:47.446743 140689526667136 learning.py:507] global step 753: loss = 0.0719 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 754: loss = 0.1726 (0.410 sec/step)\n",
            "I0205 13:22:47.858239 140689526667136 learning.py:507] global step 754: loss = 0.1726 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 755: loss = 0.3009 (1.062 sec/step)\n",
            "I0205 13:22:48.922101 140689526667136 learning.py:507] global step 755: loss = 0.3009 (1.062 sec/step)\n",
            "INFO:tensorflow:global step 756: loss = 0.7110 (0.378 sec/step)\n",
            "I0205 13:22:49.301673 140689526667136 learning.py:507] global step 756: loss = 0.7110 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 757: loss = 0.2072 (0.383 sec/step)\n",
            "I0205 13:22:49.686667 140689526667136 learning.py:507] global step 757: loss = 0.2072 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 758: loss = 0.0535 (0.365 sec/step)\n",
            "I0205 13:22:50.052843 140689526667136 learning.py:507] global step 758: loss = 0.0535 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 759: loss = 0.1232 (0.398 sec/step)\n",
            "I0205 13:22:50.452877 140689526667136 learning.py:507] global step 759: loss = 0.1232 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 760: loss = 0.3357 (0.387 sec/step)\n",
            "I0205 13:22:50.841347 140689526667136 learning.py:507] global step 760: loss = 0.3357 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 761: loss = 0.8704 (0.393 sec/step)\n",
            "I0205 13:22:51.236006 140689526667136 learning.py:507] global step 761: loss = 0.8704 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 762: loss = 0.1700 (0.377 sec/step)\n",
            "I0205 13:22:51.614110 140689526667136 learning.py:507] global step 762: loss = 0.1700 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 763: loss = 0.1875 (0.389 sec/step)\n",
            "I0205 13:22:52.004533 140689526667136 learning.py:507] global step 763: loss = 0.1875 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 764: loss = 0.1974 (0.433 sec/step)\n",
            "I0205 13:22:52.439623 140689526667136 learning.py:507] global step 764: loss = 0.1974 (0.433 sec/step)\n",
            "INFO:tensorflow:global step 765: loss = 0.3636 (0.404 sec/step)\n",
            "I0205 13:22:52.846028 140689526667136 learning.py:507] global step 765: loss = 0.3636 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 766: loss = 0.4980 (0.397 sec/step)\n",
            "I0205 13:22:53.244229 140689526667136 learning.py:507] global step 766: loss = 0.4980 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 767: loss = 0.4398 (0.414 sec/step)\n",
            "I0205 13:22:53.659665 140689526667136 learning.py:507] global step 767: loss = 0.4398 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 768: loss = 0.2519 (0.381 sec/step)\n",
            "I0205 13:22:54.042277 140689526667136 learning.py:507] global step 768: loss = 0.2519 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 769: loss = 0.1322 (0.406 sec/step)\n",
            "I0205 13:22:54.449794 140689526667136 learning.py:507] global step 769: loss = 0.1322 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 770: loss = 0.2600 (0.392 sec/step)\n",
            "I0205 13:22:54.843158 140689526667136 learning.py:507] global step 770: loss = 0.2600 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 771: loss = 0.1783 (0.393 sec/step)\n",
            "I0205 13:22:55.237460 140689526667136 learning.py:507] global step 771: loss = 0.1783 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 772: loss = 0.0560 (0.451 sec/step)\n",
            "I0205 13:22:55.690134 140689526667136 learning.py:507] global step 772: loss = 0.0560 (0.451 sec/step)\n",
            "INFO:tensorflow:global step 773: loss = 0.0724 (0.379 sec/step)\n",
            "I0205 13:22:56.070732 140689526667136 learning.py:507] global step 773: loss = 0.0724 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 774: loss = 0.1977 (0.370 sec/step)\n",
            "I0205 13:22:56.442034 140689526667136 learning.py:507] global step 774: loss = 0.1977 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 775: loss = 0.1325 (0.386 sec/step)\n",
            "I0205 13:22:56.829880 140689526667136 learning.py:507] global step 775: loss = 0.1325 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 776: loss = 0.2141 (0.394 sec/step)\n",
            "I0205 13:22:57.225747 140689526667136 learning.py:507] global step 776: loss = 0.2141 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 777: loss = 0.7236 (0.379 sec/step)\n",
            "I0205 13:22:57.606291 140689526667136 learning.py:507] global step 777: loss = 0.7236 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 778: loss = 0.4144 (0.374 sec/step)\n",
            "I0205 13:22:57.981863 140689526667136 learning.py:507] global step 778: loss = 0.4144 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 779: loss = 0.3446 (0.368 sec/step)\n",
            "I0205 13:22:58.352287 140689526667136 learning.py:507] global step 779: loss = 0.3446 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 780: loss = 0.1026 (0.887 sec/step)\n",
            "I0205 13:22:59.240331 140689526667136 learning.py:507] global step 780: loss = 0.1026 (0.887 sec/step)\n",
            "INFO:tensorflow:global step 781: loss = 0.8456 (0.396 sec/step)\n",
            "I0205 13:22:59.638018 140689526667136 learning.py:507] global step 781: loss = 0.8456 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 782: loss = 0.1510 (0.367 sec/step)\n",
            "I0205 13:23:00.006988 140689526667136 learning.py:507] global step 782: loss = 0.1510 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 783: loss = 0.9691 (0.987 sec/step)\n",
            "I0205 13:23:00.995900 140689526667136 learning.py:507] global step 783: loss = 0.9691 (0.987 sec/step)\n",
            "INFO:tensorflow:global step 784: loss = 0.4867 (0.369 sec/step)\n",
            "I0205 13:23:01.366900 140689526667136 learning.py:507] global step 784: loss = 0.4867 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 785: loss = 0.4693 (0.373 sec/step)\n",
            "I0205 13:23:01.741905 140689526667136 learning.py:507] global step 785: loss = 0.4693 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 786: loss = 0.2809 (0.358 sec/step)\n",
            "I0205 13:23:02.101756 140689526667136 learning.py:507] global step 786: loss = 0.2809 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 787: loss = 0.1019 (0.380 sec/step)\n",
            "I0205 13:23:02.483250 140689526667136 learning.py:507] global step 787: loss = 0.1019 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 788: loss = 0.3167 (0.418 sec/step)\n",
            "I0205 13:23:02.902785 140689526667136 learning.py:507] global step 788: loss = 0.3167 (0.418 sec/step)\n",
            "INFO:tensorflow:global step 789: loss = 0.7818 (0.368 sec/step)\n",
            "I0205 13:23:03.272375 140689526667136 learning.py:507] global step 789: loss = 0.7818 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 790: loss = 0.3079 (1.003 sec/step)\n",
            "I0205 13:23:04.276762 140689526667136 learning.py:507] global step 790: loss = 0.3079 (1.003 sec/step)\n",
            "INFO:tensorflow:global step 791: loss = 0.7969 (0.353 sec/step)\n",
            "I0205 13:23:04.631404 140689526667136 learning.py:507] global step 791: loss = 0.7969 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 792: loss = 0.0931 (0.362 sec/step)\n",
            "I0205 13:23:04.995460 140689526667136 learning.py:507] global step 792: loss = 0.0931 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 793: loss = 0.3109 (0.362 sec/step)\n",
            "I0205 13:23:05.359514 140689526667136 learning.py:507] global step 793: loss = 0.3109 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 794: loss = 0.0628 (0.389 sec/step)\n",
            "I0205 13:23:05.752631 140689526667136 learning.py:507] global step 794: loss = 0.0628 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 795: loss = 0.4199 (0.362 sec/step)\n",
            "I0205 13:23:06.116003 140689526667136 learning.py:507] global step 795: loss = 0.4199 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 796: loss = 0.3178 (0.365 sec/step)\n",
            "I0205 13:23:06.482151 140689526667136 learning.py:507] global step 796: loss = 0.3178 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 797: loss = 0.1354 (0.377 sec/step)\n",
            "I0205 13:23:06.860446 140689526667136 learning.py:507] global step 797: loss = 0.1354 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 798: loss = 0.3610 (0.396 sec/step)\n",
            "I0205 13:23:07.257729 140689526667136 learning.py:507] global step 798: loss = 0.3610 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 799: loss = 0.8482 (0.340 sec/step)\n",
            "I0205 13:23:07.599374 140689526667136 learning.py:507] global step 799: loss = 0.8482 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 800: loss = 0.1101 (0.343 sec/step)\n",
            "I0205 13:23:07.943871 140689526667136 learning.py:507] global step 800: loss = 0.1101 (0.343 sec/step)\n",
            "INFO:tensorflow:global step 801: loss = 0.2415 (0.370 sec/step)\n",
            "I0205 13:23:08.315618 140689526667136 learning.py:507] global step 801: loss = 0.2415 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 802: loss = 0.3698 (0.364 sec/step)\n",
            "I0205 13:23:08.680891 140689526667136 learning.py:507] global step 802: loss = 0.3698 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 803: loss = 0.2832 (0.364 sec/step)\n",
            "I0205 13:23:09.046554 140689526667136 learning.py:507] global step 803: loss = 0.2832 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 804: loss = 1.4037 (0.415 sec/step)\n",
            "I0205 13:23:09.463476 140689526667136 learning.py:507] global step 804: loss = 1.4037 (0.415 sec/step)\n",
            "INFO:tensorflow:global step 805: loss = 0.0593 (0.397 sec/step)\n",
            "I0205 13:23:09.862395 140689526667136 learning.py:507] global step 805: loss = 0.0593 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 806: loss = 0.3584 (0.377 sec/step)\n",
            "I0205 13:23:10.241339 140689526667136 learning.py:507] global step 806: loss = 0.3584 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 807: loss = 0.1559 (0.366 sec/step)\n",
            "I0205 13:23:10.608796 140689526667136 learning.py:507] global step 807: loss = 0.1559 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 808: loss = 0.0644 (0.387 sec/step)\n",
            "I0205 13:23:10.997322 140689526667136 learning.py:507] global step 808: loss = 0.0644 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 809: loss = 0.1329 (0.961 sec/step)\n",
            "I0205 13:23:11.959671 140689526667136 learning.py:507] global step 809: loss = 0.1329 (0.961 sec/step)\n",
            "INFO:tensorflow:global step 810: loss = 0.3191 (0.379 sec/step)\n",
            "I0205 13:23:12.340613 140689526667136 learning.py:507] global step 810: loss = 0.3191 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 811: loss = 0.1257 (0.376 sec/step)\n",
            "I0205 13:23:12.718754 140689526667136 learning.py:507] global step 811: loss = 0.1257 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 812: loss = 0.0849 (0.369 sec/step)\n",
            "I0205 13:23:13.089195 140689526667136 learning.py:507] global step 812: loss = 0.0849 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 813: loss = 0.0472 (0.370 sec/step)\n",
            "I0205 13:23:13.460997 140689526667136 learning.py:507] global step 813: loss = 0.0472 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 814: loss = 0.1423 (0.452 sec/step)\n",
            "I0205 13:23:13.914443 140689526667136 learning.py:507] global step 814: loss = 0.1423 (0.452 sec/step)\n",
            "INFO:tensorflow:global step 815: loss = 0.0449 (0.385 sec/step)\n",
            "I0205 13:23:14.301565 140689526667136 learning.py:507] global step 815: loss = 0.0449 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 816: loss = 0.4005 (0.333 sec/step)\n",
            "I0205 13:23:14.636627 140689526667136 learning.py:507] global step 816: loss = 0.4005 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 817: loss = 0.0794 (0.379 sec/step)\n",
            "I0205 13:23:15.017158 140689526667136 learning.py:507] global step 817: loss = 0.0794 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 818: loss = 0.0558 (0.411 sec/step)\n",
            "I0205 13:23:15.430114 140689526667136 learning.py:507] global step 818: loss = 0.0558 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 819: loss = 0.1374 (0.960 sec/step)\n",
            "I0205 13:23:16.391224 140689526667136 learning.py:507] global step 819: loss = 0.1374 (0.960 sec/step)\n",
            "INFO:tensorflow:global step 820: loss = 0.4725 (0.386 sec/step)\n",
            "I0205 13:23:16.778839 140689526667136 learning.py:507] global step 820: loss = 0.4725 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 821: loss = 0.0955 (0.393 sec/step)\n",
            "I0205 13:23:17.173741 140689526667136 learning.py:507] global step 821: loss = 0.0955 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 822: loss = 0.0856 (0.393 sec/step)\n",
            "I0205 13:23:17.568623 140689526667136 learning.py:507] global step 822: loss = 0.0856 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 823: loss = 0.0756 (0.368 sec/step)\n",
            "I0205 13:23:17.938523 140689526667136 learning.py:507] global step 823: loss = 0.0756 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 824: loss = 0.1659 (0.367 sec/step)\n",
            "I0205 13:23:18.306544 140689526667136 learning.py:507] global step 824: loss = 0.1659 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 825: loss = 0.1558 (0.383 sec/step)\n",
            "I0205 13:23:18.690963 140689526667136 learning.py:507] global step 825: loss = 0.1558 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 826: loss = 0.7768 (0.401 sec/step)\n",
            "I0205 13:23:19.093714 140689526667136 learning.py:507] global step 826: loss = 0.7768 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 827: loss = 0.2922 (1.697 sec/step)\n",
            "I0205 13:23:20.793036 140689526667136 learning.py:507] global step 827: loss = 0.2922 (1.697 sec/step)\n",
            "INFO:tensorflow:global step 828: loss = 0.0854 (0.391 sec/step)\n",
            "I0205 13:23:21.186408 140689526667136 learning.py:507] global step 828: loss = 0.0854 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 829: loss = 0.2311 (0.365 sec/step)\n",
            "I0205 13:23:21.553691 140689526667136 learning.py:507] global step 829: loss = 0.2311 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 830: loss = 0.1094 (0.397 sec/step)\n",
            "I0205 13:23:21.951832 140689526667136 learning.py:507] global step 830: loss = 0.1094 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 831: loss = 0.0681 (0.408 sec/step)\n",
            "I0205 13:23:22.361808 140689526667136 learning.py:507] global step 831: loss = 0.0681 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 832: loss = 0.1542 (0.337 sec/step)\n",
            "I0205 13:23:22.700615 140689526667136 learning.py:507] global step 832: loss = 0.1542 (0.337 sec/step)\n",
            "INFO:tensorflow:global step 833: loss = 0.6928 (0.390 sec/step)\n",
            "I0205 13:23:23.092809 140689526667136 learning.py:507] global step 833: loss = 0.6928 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 834: loss = 0.3424 (0.402 sec/step)\n",
            "I0205 13:23:23.496680 140689526667136 learning.py:507] global step 834: loss = 0.3424 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 835: loss = 0.2819 (1.580 sec/step)\n",
            "I0205 13:23:25.078031 140689526667136 learning.py:507] global step 835: loss = 0.2819 (1.580 sec/step)\n",
            "INFO:tensorflow:global step 836: loss = 2.0482 (0.381 sec/step)\n",
            "I0205 13:23:25.460356 140689526667136 learning.py:507] global step 836: loss = 2.0482 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 837: loss = 0.0507 (0.370 sec/step)\n",
            "I0205 13:23:25.831481 140689526667136 learning.py:507] global step 837: loss = 0.0507 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 838: loss = 0.6015 (0.384 sec/step)\n",
            "I0205 13:23:26.216764 140689526667136 learning.py:507] global step 838: loss = 0.6015 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 839: loss = 0.4278 (0.418 sec/step)\n",
            "I0205 13:23:26.636786 140689526667136 learning.py:507] global step 839: loss = 0.4278 (0.418 sec/step)\n",
            "INFO:tensorflow:global step 840: loss = 0.1675 (1.069 sec/step)\n",
            "I0205 13:23:27.707575 140689526667136 learning.py:507] global step 840: loss = 0.1675 (1.069 sec/step)\n",
            "INFO:tensorflow:global step 841: loss = 0.1507 (0.385 sec/step)\n",
            "I0205 13:23:28.094523 140689526667136 learning.py:507] global step 841: loss = 0.1507 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 842: loss = 0.1255 (0.394 sec/step)\n",
            "I0205 13:23:28.489728 140689526667136 learning.py:507] global step 842: loss = 0.1255 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 843: loss = 1.0309 (0.379 sec/step)\n",
            "I0205 13:23:28.871145 140689526667136 learning.py:507] global step 843: loss = 1.0309 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 844: loss = 0.0471 (0.398 sec/step)\n",
            "I0205 13:23:29.271362 140689526667136 learning.py:507] global step 844: loss = 0.0471 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 845: loss = 0.2446 (0.421 sec/step)\n",
            "I0205 13:23:29.694078 140689526667136 learning.py:507] global step 845: loss = 0.2446 (0.421 sec/step)\n",
            "INFO:tensorflow:global step 846: loss = 0.2105 (0.386 sec/step)\n",
            "I0205 13:23:30.081510 140689526667136 learning.py:507] global step 846: loss = 0.2105 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 847: loss = 0.4739 (0.395 sec/step)\n",
            "I0205 13:23:30.478795 140689526667136 learning.py:507] global step 847: loss = 0.4739 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 848: loss = 0.2286 (0.391 sec/step)\n",
            "I0205 13:23:30.871231 140689526667136 learning.py:507] global step 848: loss = 0.2286 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 849: loss = 0.0989 (0.383 sec/step)\n",
            "I0205 13:23:31.256129 140689526667136 learning.py:507] global step 849: loss = 0.0989 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 850: loss = 0.5240 (0.356 sec/step)\n",
            "I0205 13:23:31.613427 140689526667136 learning.py:507] global step 850: loss = 0.5240 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 851: loss = 0.3170 (0.388 sec/step)\n",
            "I0205 13:23:32.003160 140689526667136 learning.py:507] global step 851: loss = 0.3170 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 852: loss = 0.0524 (0.351 sec/step)\n",
            "I0205 13:23:32.356023 140689526667136 learning.py:507] global step 852: loss = 0.0524 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 853: loss = 0.6132 (0.375 sec/step)\n",
            "I0205 13:23:32.732390 140689526667136 learning.py:507] global step 853: loss = 0.6132 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 854: loss = 0.2865 (0.400 sec/step)\n",
            "I0205 13:23:33.134138 140689526667136 learning.py:507] global step 854: loss = 0.2865 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 855: loss = 0.0923 (0.416 sec/step)\n",
            "I0205 13:23:33.551627 140689526667136 learning.py:507] global step 855: loss = 0.0923 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 856: loss = 0.1294 (0.382 sec/step)\n",
            "I0205 13:23:33.935827 140689526667136 learning.py:507] global step 856: loss = 0.1294 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 857: loss = 0.0849 (0.402 sec/step)\n",
            "I0205 13:23:34.340177 140689526667136 learning.py:507] global step 857: loss = 0.0849 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 858: loss = 0.0432 (0.377 sec/step)\n",
            "I0205 13:23:34.718706 140689526667136 learning.py:507] global step 858: loss = 0.0432 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 859: loss = 0.0758 (0.369 sec/step)\n",
            "I0205 13:23:35.090339 140689526667136 learning.py:507] global step 859: loss = 0.0758 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 860: loss = 0.2173 (0.381 sec/step)\n",
            "I0205 13:23:35.473232 140689526667136 learning.py:507] global step 860: loss = 0.2173 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 861: loss = 0.2656 (0.396 sec/step)\n",
            "I0205 13:23:35.871363 140689526667136 learning.py:507] global step 861: loss = 0.2656 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 862: loss = 0.1686 (0.362 sec/step)\n",
            "I0205 13:23:36.234880 140689526667136 learning.py:507] global step 862: loss = 0.1686 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 863: loss = 0.0722 (0.391 sec/step)\n",
            "I0205 13:23:36.627733 140689526667136 learning.py:507] global step 863: loss = 0.0722 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 864: loss = 0.3000 (0.373 sec/step)\n",
            "I0205 13:23:37.002068 140689526667136 learning.py:507] global step 864: loss = 0.3000 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 865: loss = 0.4390 (0.372 sec/step)\n",
            "I0205 13:23:37.375116 140689526667136 learning.py:507] global step 865: loss = 0.4390 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 866: loss = 0.1420 (0.402 sec/step)\n",
            "I0205 13:23:37.778837 140689526667136 learning.py:507] global step 866: loss = 0.1420 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 867: loss = 0.5901 (0.383 sec/step)\n",
            "I0205 13:23:38.163816 140689526667136 learning.py:507] global step 867: loss = 0.5901 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 868: loss = 0.2891 (0.391 sec/step)\n",
            "I0205 13:23:38.556845 140689526667136 learning.py:507] global step 868: loss = 0.2891 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 869: loss = 0.2212 (0.400 sec/step)\n",
            "I0205 13:23:38.958944 140689526667136 learning.py:507] global step 869: loss = 0.2212 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 870: loss = 0.3042 (0.402 sec/step)\n",
            "I0205 13:23:39.362911 140689526667136 learning.py:507] global step 870: loss = 0.3042 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 871: loss = 0.3304 (0.371 sec/step)\n",
            "I0205 13:23:39.735869 140689526667136 learning.py:507] global step 871: loss = 0.3304 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 872: loss = 0.2280 (0.383 sec/step)\n",
            "I0205 13:23:40.120476 140689526667136 learning.py:507] global step 872: loss = 0.2280 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 873: loss = 0.2411 (1.029 sec/step)\n",
            "I0205 13:23:41.151972 140689526667136 learning.py:507] global step 873: loss = 0.2411 (1.029 sec/step)\n",
            "INFO:tensorflow:global step 874: loss = 0.0554 (0.378 sec/step)\n",
            "I0205 13:23:41.531641 140689526667136 learning.py:507] global step 874: loss = 0.0554 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 875: loss = 0.1848 (0.371 sec/step)\n",
            "I0205 13:23:41.904226 140689526667136 learning.py:507] global step 875: loss = 0.1848 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 876: loss = 0.1190 (1.569 sec/step)\n",
            "I0205 13:23:43.475025 140689526667136 learning.py:507] global step 876: loss = 0.1190 (1.569 sec/step)\n",
            "INFO:tensorflow:global step 877: loss = 0.0699 (0.470 sec/step)\n",
            "I0205 13:23:43.946878 140689526667136 learning.py:507] global step 877: loss = 0.0699 (0.470 sec/step)\n",
            "INFO:tensorflow:global step 878: loss = 0.0569 (0.369 sec/step)\n",
            "I0205 13:23:44.317752 140689526667136 learning.py:507] global step 878: loss = 0.0569 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 879: loss = 0.2228 (0.402 sec/step)\n",
            "I0205 13:23:44.721274 140689526667136 learning.py:507] global step 879: loss = 0.2228 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 880: loss = 0.1711 (0.380 sec/step)\n",
            "I0205 13:23:45.102776 140689526667136 learning.py:507] global step 880: loss = 0.1711 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 881: loss = 0.3114 (0.390 sec/step)\n",
            "I0205 13:23:45.494739 140689526667136 learning.py:507] global step 881: loss = 0.3114 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 882: loss = 0.0591 (0.377 sec/step)\n",
            "I0205 13:23:45.872985 140689526667136 learning.py:507] global step 882: loss = 0.0591 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 883: loss = 0.3943 (0.387 sec/step)\n",
            "I0205 13:23:46.261276 140689526667136 learning.py:507] global step 883: loss = 0.3943 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 884: loss = 0.0748 (0.380 sec/step)\n",
            "I0205 13:23:46.643015 140689526667136 learning.py:507] global step 884: loss = 0.0748 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 885: loss = 0.0882 (0.335 sec/step)\n",
            "I0205 13:23:46.979609 140689526667136 learning.py:507] global step 885: loss = 0.0882 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 886: loss = 0.2606 (0.371 sec/step)\n",
            "I0205 13:23:47.352503 140689526667136 learning.py:507] global step 886: loss = 0.2606 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 887: loss = 0.0462 (0.358 sec/step)\n",
            "I0205 13:23:47.712188 140689526667136 learning.py:507] global step 887: loss = 0.0462 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 888: loss = 0.0807 (0.395 sec/step)\n",
            "I0205 13:23:48.109037 140689526667136 learning.py:507] global step 888: loss = 0.0807 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 889: loss = 0.1006 (0.381 sec/step)\n",
            "I0205 13:23:48.492629 140689526667136 learning.py:507] global step 889: loss = 0.1006 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 890: loss = 0.1103 (0.356 sec/step)\n",
            "I0205 13:23:48.850280 140689526667136 learning.py:507] global step 890: loss = 0.1103 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 891: loss = 0.0724 (0.381 sec/step)\n",
            "I0205 13:23:49.233585 140689526667136 learning.py:507] global step 891: loss = 0.0724 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 892: loss = 0.4796 (0.359 sec/step)\n",
            "I0205 13:23:49.594175 140689526667136 learning.py:507] global step 892: loss = 0.4796 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 893: loss = 0.4457 (0.388 sec/step)\n",
            "I0205 13:23:49.983743 140689526667136 learning.py:507] global step 893: loss = 0.4457 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 894: loss = 1.3768 (0.393 sec/step)\n",
            "I0205 13:23:50.378309 140689526667136 learning.py:507] global step 894: loss = 1.3768 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 895: loss = 0.1752 (0.367 sec/step)\n",
            "I0205 13:23:50.747139 140689526667136 learning.py:507] global step 895: loss = 0.1752 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 896: loss = 0.1301 (0.466 sec/step)\n",
            "I0205 13:23:51.214304 140689526667136 learning.py:507] global step 896: loss = 0.1301 (0.466 sec/step)\n",
            "INFO:tensorflow:global step 897: loss = 0.1272 (0.374 sec/step)\n",
            "I0205 13:23:51.590182 140689526667136 learning.py:507] global step 897: loss = 0.1272 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 898: loss = 0.0918 (0.470 sec/step)\n",
            "I0205 13:23:52.061615 140689526667136 learning.py:507] global step 898: loss = 0.0918 (0.470 sec/step)\n",
            "INFO:tensorflow:global step 899: loss = 0.1345 (0.461 sec/step)\n",
            "I0205 13:23:52.523711 140689526667136 learning.py:507] global step 899: loss = 0.1345 (0.461 sec/step)\n",
            "INFO:tensorflow:global step 900: loss = 0.4739 (0.419 sec/step)\n",
            "I0205 13:23:52.944695 140689526667136 learning.py:507] global step 900: loss = 0.4739 (0.419 sec/step)\n",
            "INFO:tensorflow:global step 901: loss = 0.1052 (0.391 sec/step)\n",
            "I0205 13:23:53.337826 140689526667136 learning.py:507] global step 901: loss = 0.1052 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 902: loss = 0.1112 (0.374 sec/step)\n",
            "I0205 13:23:53.713466 140689526667136 learning.py:507] global step 902: loss = 0.1112 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 903: loss = 0.4019 (0.397 sec/step)\n",
            "I0205 13:23:54.112018 140689526667136 learning.py:507] global step 903: loss = 0.4019 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 904: loss = 0.3682 (0.383 sec/step)\n",
            "I0205 13:23:54.496769 140689526667136 learning.py:507] global step 904: loss = 0.3682 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 905: loss = 0.1286 (0.378 sec/step)\n",
            "I0205 13:23:54.876933 140689526667136 learning.py:507] global step 905: loss = 0.1286 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 906: loss = 0.5574 (0.372 sec/step)\n",
            "I0205 13:23:55.250247 140689526667136 learning.py:507] global step 906: loss = 0.5574 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 907: loss = 0.4567 (0.366 sec/step)\n",
            "I0205 13:23:55.617776 140689526667136 learning.py:507] global step 907: loss = 0.4567 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 908: loss = 0.2592 (0.343 sec/step)\n",
            "I0205 13:23:55.962328 140689526667136 learning.py:507] global step 908: loss = 0.2592 (0.343 sec/step)\n",
            "INFO:tensorflow:global step 909: loss = 0.1843 (0.387 sec/step)\n",
            "I0205 13:23:56.350694 140689526667136 learning.py:507] global step 909: loss = 0.1843 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 910: loss = 0.0890 (0.397 sec/step)\n",
            "I0205 13:23:56.750119 140689526667136 learning.py:507] global step 910: loss = 0.0890 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 911: loss = 0.3285 (0.373 sec/step)\n",
            "I0205 13:23:57.125024 140689526667136 learning.py:507] global step 911: loss = 0.3285 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 912: loss = 0.1456 (0.377 sec/step)\n",
            "I0205 13:23:57.504195 140689526667136 learning.py:507] global step 912: loss = 0.1456 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 913: loss = 1.1415 (0.397 sec/step)\n",
            "I0205 13:23:57.902746 140689526667136 learning.py:507] global step 913: loss = 1.1415 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 914: loss = 0.0558 (0.368 sec/step)\n",
            "I0205 13:23:58.272278 140689526667136 learning.py:507] global step 914: loss = 0.0558 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 915: loss = 0.0526 (0.361 sec/step)\n",
            "I0205 13:23:58.634791 140689526667136 learning.py:507] global step 915: loss = 0.0526 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 916: loss = 0.0839 (0.368 sec/step)\n",
            "I0205 13:23:59.004609 140689526667136 learning.py:507] global step 916: loss = 0.0839 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 917: loss = 0.1265 (0.368 sec/step)\n",
            "I0205 13:23:59.374686 140689526667136 learning.py:507] global step 917: loss = 0.1265 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 918: loss = 0.7485 (0.386 sec/step)\n",
            "I0205 13:23:59.763242 140689526667136 learning.py:507] global step 918: loss = 0.7485 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 919: loss = 0.0554 (0.391 sec/step)\n",
            "I0205 13:24:00.156099 140689526667136 learning.py:507] global step 919: loss = 0.0554 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 920: loss = 0.2486 (0.367 sec/step)\n",
            "I0205 13:24:00.524752 140689526667136 learning.py:507] global step 920: loss = 0.2486 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 921: loss = 0.2581 (0.356 sec/step)\n",
            "I0205 13:24:00.882490 140689526667136 learning.py:507] global step 921: loss = 0.2581 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 922: loss = 0.5405 (0.395 sec/step)\n",
            "I0205 13:24:01.279191 140689526667136 learning.py:507] global step 922: loss = 0.5405 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 923: loss = 1.3780 (0.364 sec/step)\n",
            "I0205 13:24:01.644413 140689526667136 learning.py:507] global step 923: loss = 1.3780 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 924: loss = 0.0361 (0.359 sec/step)\n",
            "I0205 13:24:02.005134 140689526667136 learning.py:507] global step 924: loss = 0.0361 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 925: loss = 0.2442 (0.380 sec/step)\n",
            "I0205 13:24:02.387209 140689526667136 learning.py:507] global step 925: loss = 0.2442 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 926: loss = 0.1157 (0.377 sec/step)\n",
            "I0205 13:24:02.766047 140689526667136 learning.py:507] global step 926: loss = 0.1157 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 927: loss = 0.4103 (0.404 sec/step)\n",
            "I0205 13:24:03.172043 140689526667136 learning.py:507] global step 927: loss = 0.4103 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 928: loss = 0.1865 (0.379 sec/step)\n",
            "I0205 13:24:03.553397 140689526667136 learning.py:507] global step 928: loss = 0.1865 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 929: loss = 0.3248 (0.380 sec/step)\n",
            "I0205 13:24:03.935224 140689526667136 learning.py:507] global step 929: loss = 0.3248 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 930: loss = 0.3679 (0.373 sec/step)\n",
            "I0205 13:24:04.309555 140689526667136 learning.py:507] global step 930: loss = 0.3679 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 931: loss = 0.1170 (0.390 sec/step)\n",
            "I0205 13:24:04.700974 140689526667136 learning.py:507] global step 931: loss = 0.1170 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 932: loss = 0.1119 (0.425 sec/step)\n",
            "I0205 13:24:05.127713 140689526667136 learning.py:507] global step 932: loss = 0.1119 (0.425 sec/step)\n",
            "INFO:tensorflow:global step 933: loss = 0.1416 (0.362 sec/step)\n",
            "I0205 13:24:05.491787 140689526667136 learning.py:507] global step 933: loss = 0.1416 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 934: loss = 0.0958 (0.379 sec/step)\n",
            "I0205 13:24:05.872904 140689526667136 learning.py:507] global step 934: loss = 0.0958 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 935: loss = 0.2000 (0.437 sec/step)\n",
            "I0205 13:24:06.311679 140689526667136 learning.py:507] global step 935: loss = 0.2000 (0.437 sec/step)\n",
            "INFO:tensorflow:global step 936: loss = 0.1850 (0.386 sec/step)\n",
            "I0205 13:24:06.698813 140689526667136 learning.py:507] global step 936: loss = 0.1850 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 937: loss = 0.3343 (0.421 sec/step)\n",
            "I0205 13:24:07.121108 140689526667136 learning.py:507] global step 937: loss = 0.3343 (0.421 sec/step)\n",
            "INFO:tensorflow:global step 938: loss = 0.2436 (0.961 sec/step)\n",
            "I0205 13:24:08.084052 140689526667136 learning.py:507] global step 938: loss = 0.2436 (0.961 sec/step)\n",
            "INFO:tensorflow:global step 939: loss = 0.2956 (0.412 sec/step)\n",
            "I0205 13:24:08.497707 140689526667136 learning.py:507] global step 939: loss = 0.2956 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 940: loss = 0.2625 (0.978 sec/step)\n",
            "I0205 13:24:09.477009 140689526667136 learning.py:507] global step 940: loss = 0.2625 (0.978 sec/step)\n",
            "INFO:tensorflow:global step 941: loss = 0.0886 (0.403 sec/step)\n",
            "I0205 13:24:09.881212 140689526667136 learning.py:507] global step 941: loss = 0.0886 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 942: loss = 0.0798 (0.436 sec/step)\n",
            "I0205 13:24:10.319137 140689526667136 learning.py:507] global step 942: loss = 0.0798 (0.436 sec/step)\n",
            "INFO:tensorflow:global step 943: loss = 0.4562 (0.391 sec/step)\n",
            "I0205 13:24:10.711272 140689526667136 learning.py:507] global step 943: loss = 0.4562 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 944: loss = 0.2350 (0.371 sec/step)\n",
            "I0205 13:24:11.084302 140689526667136 learning.py:507] global step 944: loss = 0.2350 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 945: loss = 0.1045 (0.376 sec/step)\n",
            "I0205 13:24:11.462082 140689526667136 learning.py:507] global step 945: loss = 0.1045 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 946: loss = 0.2388 (1.041 sec/step)\n",
            "I0205 13:24:12.504105 140689526667136 learning.py:507] global step 946: loss = 0.2388 (1.041 sec/step)\n",
            "INFO:tensorflow:global step 947: loss = 0.5053 (0.393 sec/step)\n",
            "I0205 13:24:12.898746 140689526667136 learning.py:507] global step 947: loss = 0.5053 (0.393 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path ../training/model.ckpt\n",
            "I0205 13:24:13.744972 140686000895744 supervisor.py:1117] Saving checkpoint to path ../training/model.ckpt\n",
            "INFO:tensorflow:global step 948: loss = 0.3210 (1.924 sec/step)\n",
            "I0205 13:24:14.838060 140689526667136 learning.py:507] global step 948: loss = 0.3210 (1.924 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 2.11699\n",
            "I0205 13:24:16.376942 140686034466560 supervisor.py:1099] global_step/sec: 2.11699\n",
            "INFO:tensorflow:global step 949: loss = 0.6328 (2.098 sec/step)\n",
            "I0205 13:24:17.398622 140689526667136 learning.py:507] global step 949: loss = 0.6328 (2.098 sec/step)\n",
            "INFO:tensorflow:global step 950: loss = 0.2119 (0.585 sec/step)\n",
            "I0205 13:24:18.101044 140689526667136 learning.py:507] global step 950: loss = 0.2119 (0.585 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 950.\n",
            "I0205 13:24:18.193211 140686026073856 supervisor.py:1050] Recording summary at step 950.\n",
            "INFO:tensorflow:global step 951: loss = 0.3346 (0.435 sec/step)\n",
            "I0205 13:24:18.537988 140689526667136 learning.py:507] global step 951: loss = 0.3346 (0.435 sec/step)\n",
            "INFO:tensorflow:global step 952: loss = 0.1773 (0.358 sec/step)\n",
            "I0205 13:24:18.898379 140689526667136 learning.py:507] global step 952: loss = 0.1773 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 953: loss = 0.0654 (0.443 sec/step)\n",
            "I0205 13:24:19.343301 140689526667136 learning.py:507] global step 953: loss = 0.0654 (0.443 sec/step)\n",
            "INFO:tensorflow:global step 954: loss = 0.0922 (0.410 sec/step)\n",
            "I0205 13:24:19.754644 140689526667136 learning.py:507] global step 954: loss = 0.0922 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 955: loss = 1.1136 (0.376 sec/step)\n",
            "I0205 13:24:20.132143 140689526667136 learning.py:507] global step 955: loss = 1.1136 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 956: loss = 0.2662 (0.342 sec/step)\n",
            "I0205 13:24:20.475850 140689526667136 learning.py:507] global step 956: loss = 0.2662 (0.342 sec/step)\n",
            "INFO:tensorflow:global step 957: loss = 0.1145 (0.349 sec/step)\n",
            "I0205 13:24:20.825842 140689526667136 learning.py:507] global step 957: loss = 0.1145 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 958: loss = 0.2297 (0.338 sec/step)\n",
            "I0205 13:24:21.165024 140689526667136 learning.py:507] global step 958: loss = 0.2297 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 959: loss = 0.0584 (0.382 sec/step)\n",
            "I0205 13:24:21.548626 140689526667136 learning.py:507] global step 959: loss = 0.0584 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 960: loss = 0.1088 (0.360 sec/step)\n",
            "I0205 13:24:21.909712 140689526667136 learning.py:507] global step 960: loss = 0.1088 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 961: loss = 0.6101 (0.390 sec/step)\n",
            "I0205 13:24:22.301427 140689526667136 learning.py:507] global step 961: loss = 0.6101 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 962: loss = 1.1219 (0.397 sec/step)\n",
            "I0205 13:24:22.699470 140689526667136 learning.py:507] global step 962: loss = 1.1219 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 963: loss = 0.8925 (0.363 sec/step)\n",
            "I0205 13:24:23.065335 140689526667136 learning.py:507] global step 963: loss = 0.8925 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 964: loss = 0.3574 (1.322 sec/step)\n",
            "I0205 13:24:24.388968 140689526667136 learning.py:507] global step 964: loss = 0.3574 (1.322 sec/step)\n",
            "INFO:tensorflow:global step 965: loss = 0.2412 (0.349 sec/step)\n",
            "I0205 13:24:24.739368 140689526667136 learning.py:507] global step 965: loss = 0.2412 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 966: loss = 0.2143 (0.363 sec/step)\n",
            "I0205 13:24:25.104308 140689526667136 learning.py:507] global step 966: loss = 0.2143 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 967: loss = 0.3268 (0.898 sec/step)\n",
            "I0205 13:24:26.003735 140689526667136 learning.py:507] global step 967: loss = 0.3268 (0.898 sec/step)\n",
            "INFO:tensorflow:global step 968: loss = 0.1471 (0.382 sec/step)\n",
            "I0205 13:24:26.387522 140689526667136 learning.py:507] global step 968: loss = 0.1471 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 969: loss = 0.3383 (0.392 sec/step)\n",
            "I0205 13:24:26.781303 140689526667136 learning.py:507] global step 969: loss = 0.3383 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 970: loss = 0.0990 (0.401 sec/step)\n",
            "I0205 13:24:27.183777 140689526667136 learning.py:507] global step 970: loss = 0.0990 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 971: loss = 0.3356 (0.375 sec/step)\n",
            "I0205 13:24:27.560135 140689526667136 learning.py:507] global step 971: loss = 0.3356 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 972: loss = 0.5404 (0.385 sec/step)\n",
            "I0205 13:24:27.947214 140689526667136 learning.py:507] global step 972: loss = 0.5404 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 973: loss = 0.5125 (0.379 sec/step)\n",
            "I0205 13:24:28.328425 140689526667136 learning.py:507] global step 973: loss = 0.5125 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 974: loss = 0.1402 (0.388 sec/step)\n",
            "I0205 13:24:28.718123 140689526667136 learning.py:507] global step 974: loss = 0.1402 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 975: loss = 0.0996 (0.385 sec/step)\n",
            "I0205 13:24:29.104844 140689526667136 learning.py:507] global step 975: loss = 0.0996 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 976: loss = 0.1187 (0.392 sec/step)\n",
            "I0205 13:24:29.500095 140689526667136 learning.py:507] global step 976: loss = 0.1187 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 977: loss = 0.2957 (0.435 sec/step)\n",
            "I0205 13:24:29.937377 140689526667136 learning.py:507] global step 977: loss = 0.2957 (0.435 sec/step)\n",
            "INFO:tensorflow:global step 978: loss = 0.1580 (0.365 sec/step)\n",
            "I0205 13:24:30.304401 140689526667136 learning.py:507] global step 978: loss = 0.1580 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 979: loss = 0.1199 (0.385 sec/step)\n",
            "I0205 13:24:30.691594 140689526667136 learning.py:507] global step 979: loss = 0.1199 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 980: loss = 0.1010 (0.374 sec/step)\n",
            "I0205 13:24:31.067025 140689526667136 learning.py:507] global step 980: loss = 0.1010 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 981: loss = 2.5083 (1.333 sec/step)\n",
            "I0205 13:24:32.401153 140689526667136 learning.py:507] global step 981: loss = 2.5083 (1.333 sec/step)\n",
            "INFO:tensorflow:global step 982: loss = 0.4129 (0.396 sec/step)\n",
            "I0205 13:24:32.799643 140689526667136 learning.py:507] global step 982: loss = 0.4129 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 983: loss = 0.5507 (0.384 sec/step)\n",
            "I0205 13:24:33.185335 140689526667136 learning.py:507] global step 983: loss = 0.5507 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 984: loss = 0.1966 (0.382 sec/step)\n",
            "I0205 13:24:33.568917 140689526667136 learning.py:507] global step 984: loss = 0.1966 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 985: loss = 0.1520 (0.409 sec/step)\n",
            "I0205 13:24:33.979660 140689526667136 learning.py:507] global step 985: loss = 0.1520 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 986: loss = 0.4702 (0.401 sec/step)\n",
            "I0205 13:24:34.382256 140689526667136 learning.py:507] global step 986: loss = 0.4702 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 987: loss = 0.0802 (1.017 sec/step)\n",
            "I0205 13:24:35.401213 140689526667136 learning.py:507] global step 987: loss = 0.0802 (1.017 sec/step)\n",
            "INFO:tensorflow:global step 988: loss = 0.0570 (0.375 sec/step)\n",
            "I0205 13:24:35.778370 140689526667136 learning.py:507] global step 988: loss = 0.0570 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 989: loss = 0.1329 (1.012 sec/step)\n",
            "I0205 13:24:36.791444 140689526667136 learning.py:507] global step 989: loss = 0.1329 (1.012 sec/step)\n",
            "INFO:tensorflow:global step 990: loss = 0.3619 (0.412 sec/step)\n",
            "I0205 13:24:37.204530 140689526667136 learning.py:507] global step 990: loss = 0.3619 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 991: loss = 0.3229 (0.379 sec/step)\n",
            "I0205 13:24:37.585259 140689526667136 learning.py:507] global step 991: loss = 0.3229 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 992: loss = 0.1259 (0.363 sec/step)\n",
            "I0205 13:24:37.949560 140689526667136 learning.py:507] global step 992: loss = 0.1259 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 993: loss = 0.0855 (0.390 sec/step)\n",
            "I0205 13:24:38.340534 140689526667136 learning.py:507] global step 993: loss = 0.0855 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 994: loss = 0.2080 (0.358 sec/step)\n",
            "I0205 13:24:38.699713 140689526667136 learning.py:507] global step 994: loss = 0.2080 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 995: loss = 0.1065 (0.369 sec/step)\n",
            "I0205 13:24:39.071472 140689526667136 learning.py:507] global step 995: loss = 0.1065 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 996: loss = 0.5213 (0.364 sec/step)\n",
            "I0205 13:24:39.437941 140689526667136 learning.py:507] global step 996: loss = 0.5213 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 997: loss = 0.1719 (0.399 sec/step)\n",
            "I0205 13:24:39.838189 140689526667136 learning.py:507] global step 997: loss = 0.1719 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 998: loss = 0.0448 (0.400 sec/step)\n",
            "I0205 13:24:40.240022 140689526667136 learning.py:507] global step 998: loss = 0.0448 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 999: loss = 0.1227 (0.391 sec/step)\n",
            "I0205 13:24:40.632464 140689526667136 learning.py:507] global step 999: loss = 0.1227 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 1000: loss = 0.2305 (1.569 sec/step)\n",
            "I0205 13:24:42.202847 140689526667136 learning.py:507] global step 1000: loss = 0.2305 (1.569 sec/step)\n",
            "INFO:tensorflow:global step 1001: loss = 0.1468 (0.377 sec/step)\n",
            "I0205 13:24:42.581379 140689526667136 learning.py:507] global step 1001: loss = 0.1468 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 1002: loss = 0.2562 (0.365 sec/step)\n",
            "I0205 13:24:42.947950 140689526667136 learning.py:507] global step 1002: loss = 0.2562 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 1003: loss = 0.1978 (0.420 sec/step)\n",
            "I0205 13:24:43.369850 140689526667136 learning.py:507] global step 1003: loss = 0.1978 (0.420 sec/step)\n",
            "INFO:tensorflow:global step 1004: loss = 0.2936 (0.375 sec/step)\n",
            "I0205 13:24:43.746507 140689526667136 learning.py:507] global step 1004: loss = 0.2936 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 1005: loss = 0.2383 (2.493 sec/step)\n",
            "I0205 13:24:46.240856 140689526667136 learning.py:507] global step 1005: loss = 0.2383 (2.493 sec/step)\n",
            "INFO:tensorflow:global step 1006: loss = 0.4021 (0.383 sec/step)\n",
            "I0205 13:24:46.625651 140689526667136 learning.py:507] global step 1006: loss = 0.4021 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 1007: loss = 0.1357 (0.362 sec/step)\n",
            "I0205 13:24:46.989526 140689526667136 learning.py:507] global step 1007: loss = 0.1357 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 1008: loss = 1.7414 (0.338 sec/step)\n",
            "I0205 13:24:47.328884 140689526667136 learning.py:507] global step 1008: loss = 1.7414 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 1009: loss = 0.0729 (0.367 sec/step)\n",
            "I0205 13:24:47.697240 140689526667136 learning.py:507] global step 1009: loss = 0.0729 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 1010: loss = 0.2545 (0.386 sec/step)\n",
            "I0205 13:24:48.084647 140689526667136 learning.py:507] global step 1010: loss = 0.2545 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 1011: loss = 0.1358 (0.367 sec/step)\n",
            "I0205 13:24:48.453778 140689526667136 learning.py:507] global step 1011: loss = 0.1358 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 1012: loss = 0.1901 (0.386 sec/step)\n",
            "I0205 13:24:48.841149 140689526667136 learning.py:507] global step 1012: loss = 0.1901 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 1013: loss = 0.3370 (0.381 sec/step)\n",
            "I0205 13:24:49.224152 140689526667136 learning.py:507] global step 1013: loss = 0.3370 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1014: loss = 0.0402 (0.391 sec/step)\n",
            "I0205 13:24:49.616760 140689526667136 learning.py:507] global step 1014: loss = 0.0402 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 1015: loss = 0.2099 (0.382 sec/step)\n",
            "I0205 13:24:50.000602 140689526667136 learning.py:507] global step 1015: loss = 0.2099 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 1016: loss = 0.2915 (0.343 sec/step)\n",
            "I0205 13:24:50.345191 140689526667136 learning.py:507] global step 1016: loss = 0.2915 (0.343 sec/step)\n",
            "INFO:tensorflow:global step 1017: loss = 0.4290 (0.418 sec/step)\n",
            "I0205 13:24:50.765496 140689526667136 learning.py:507] global step 1017: loss = 0.4290 (0.418 sec/step)\n",
            "INFO:tensorflow:global step 1018: loss = 0.4721 (0.367 sec/step)\n",
            "I0205 13:24:51.134347 140689526667136 learning.py:507] global step 1018: loss = 0.4721 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 1019: loss = 0.1505 (0.396 sec/step)\n",
            "I0205 13:24:51.532397 140689526667136 learning.py:507] global step 1019: loss = 0.1505 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 1020: loss = 0.1387 (0.370 sec/step)\n",
            "I0205 13:24:51.904515 140689526667136 learning.py:507] global step 1020: loss = 0.1387 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 1021: loss = 0.0603 (0.445 sec/step)\n",
            "I0205 13:24:52.351583 140689526667136 learning.py:507] global step 1021: loss = 0.0603 (0.445 sec/step)\n",
            "INFO:tensorflow:global step 1022: loss = 0.4718 (0.432 sec/step)\n",
            "I0205 13:24:52.785004 140689526667136 learning.py:507] global step 1022: loss = 0.4718 (0.432 sec/step)\n",
            "INFO:tensorflow:global step 1023: loss = 0.7335 (0.385 sec/step)\n",
            "I0205 13:24:53.172265 140689526667136 learning.py:507] global step 1023: loss = 0.7335 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 1024: loss = 0.1751 (0.400 sec/step)\n",
            "I0205 13:24:53.573679 140689526667136 learning.py:507] global step 1024: loss = 0.1751 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 1025: loss = 0.1083 (0.381 sec/step)\n",
            "I0205 13:24:53.955887 140689526667136 learning.py:507] global step 1025: loss = 0.1083 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1026: loss = 0.1047 (0.367 sec/step)\n",
            "I0205 13:24:54.325207 140689526667136 learning.py:507] global step 1026: loss = 0.1047 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 1027: loss = 0.1272 (0.385 sec/step)\n",
            "I0205 13:24:54.712417 140689526667136 learning.py:507] global step 1027: loss = 0.1272 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 1028: loss = 0.0780 (0.383 sec/step)\n",
            "I0205 13:24:55.096835 140689526667136 learning.py:507] global step 1028: loss = 0.0780 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 1029: loss = 0.4693 (0.346 sec/step)\n",
            "I0205 13:24:55.444585 140689526667136 learning.py:507] global step 1029: loss = 0.4693 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 1030: loss = 0.3656 (0.378 sec/step)\n",
            "I0205 13:24:55.824698 140689526667136 learning.py:507] global step 1030: loss = 0.3656 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 1031: loss = 0.3045 (0.371 sec/step)\n",
            "I0205 13:24:56.196960 140689526667136 learning.py:507] global step 1031: loss = 0.3045 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 1032: loss = 0.2086 (0.367 sec/step)\n",
            "I0205 13:24:56.565237 140689526667136 learning.py:507] global step 1032: loss = 0.2086 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 1033: loss = 0.2840 (0.393 sec/step)\n",
            "I0205 13:24:56.960358 140689526667136 learning.py:507] global step 1033: loss = 0.2840 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 1034: loss = 0.1427 (0.372 sec/step)\n",
            "I0205 13:24:57.334495 140689526667136 learning.py:507] global step 1034: loss = 0.1427 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 1035: loss = 0.2584 (0.361 sec/step)\n",
            "I0205 13:24:57.696671 140689526667136 learning.py:507] global step 1035: loss = 0.2584 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 1036: loss = 0.6239 (0.375 sec/step)\n",
            "I0205 13:24:58.073647 140689526667136 learning.py:507] global step 1036: loss = 0.6239 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 1037: loss = 0.3954 (0.386 sec/step)\n",
            "I0205 13:24:58.461155 140689526667136 learning.py:507] global step 1037: loss = 0.3954 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 1038: loss = 0.7002 (0.388 sec/step)\n",
            "I0205 13:24:58.850310 140689526667136 learning.py:507] global step 1038: loss = 0.7002 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 1039: loss = 0.2931 (1.093 sec/step)\n",
            "I0205 13:24:59.944597 140689526667136 learning.py:507] global step 1039: loss = 0.2931 (1.093 sec/step)\n",
            "INFO:tensorflow:global step 1040: loss = 0.0684 (0.366 sec/step)\n",
            "I0205 13:25:00.312334 140689526667136 learning.py:507] global step 1040: loss = 0.0684 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 1041: loss = 0.0784 (0.373 sec/step)\n",
            "I0205 13:25:00.686789 140689526667136 learning.py:507] global step 1041: loss = 0.0784 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 1042: loss = 0.2465 (0.370 sec/step)\n",
            "I0205 13:25:01.058465 140689526667136 learning.py:507] global step 1042: loss = 0.2465 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 1043: loss = 0.2301 (0.952 sec/step)\n",
            "I0205 13:25:02.012573 140689526667136 learning.py:507] global step 1043: loss = 0.2301 (0.952 sec/step)\n",
            "INFO:tensorflow:global step 1044: loss = 0.1893 (0.383 sec/step)\n",
            "I0205 13:25:02.397161 140689526667136 learning.py:507] global step 1044: loss = 0.1893 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 1045: loss = 0.0834 (0.377 sec/step)\n",
            "I0205 13:25:02.775866 140689526667136 learning.py:507] global step 1045: loss = 0.0834 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 1046: loss = 0.9206 (0.410 sec/step)\n",
            "I0205 13:25:03.187751 140689526667136 learning.py:507] global step 1046: loss = 0.9206 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 1047: loss = 0.2466 (0.373 sec/step)\n",
            "I0205 13:25:03.562977 140689526667136 learning.py:507] global step 1047: loss = 0.2466 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 1048: loss = 0.3016 (0.400 sec/step)\n",
            "I0205 13:25:03.964585 140689526667136 learning.py:507] global step 1048: loss = 0.3016 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 1049: loss = 1.4960 (0.342 sec/step)\n",
            "I0205 13:25:04.308106 140689526667136 learning.py:507] global step 1049: loss = 1.4960 (0.342 sec/step)\n",
            "INFO:tensorflow:global step 1050: loss = 0.3417 (0.377 sec/step)\n",
            "I0205 13:25:04.686543 140689526667136 learning.py:507] global step 1050: loss = 0.3417 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 1051: loss = 0.0763 (0.394 sec/step)\n",
            "I0205 13:25:05.082064 140689526667136 learning.py:507] global step 1051: loss = 0.0763 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 1052: loss = 0.5537 (0.388 sec/step)\n",
            "I0205 13:25:05.472532 140689526667136 learning.py:507] global step 1052: loss = 0.5537 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 1053: loss = 0.2100 (0.431 sec/step)\n",
            "I0205 13:25:05.904895 140689526667136 learning.py:507] global step 1053: loss = 0.2100 (0.431 sec/step)\n",
            "INFO:tensorflow:global step 1054: loss = 1.3887 (0.381 sec/step)\n",
            "I0205 13:25:06.287824 140689526667136 learning.py:507] global step 1054: loss = 1.3887 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1055: loss = 0.2007 (0.390 sec/step)\n",
            "I0205 13:25:06.679380 140689526667136 learning.py:507] global step 1055: loss = 0.2007 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 1056: loss = 1.0933 (0.376 sec/step)\n",
            "I0205 13:25:07.057208 140689526667136 learning.py:507] global step 1056: loss = 1.0933 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 1057: loss = 0.6854 (0.393 sec/step)\n",
            "I0205 13:25:07.451696 140689526667136 learning.py:507] global step 1057: loss = 0.6854 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 1058: loss = 0.0764 (0.364 sec/step)\n",
            "I0205 13:25:07.817397 140689526667136 learning.py:507] global step 1058: loss = 0.0764 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 1059: loss = 0.0290 (0.387 sec/step)\n",
            "I0205 13:25:08.206175 140689526667136 learning.py:507] global step 1059: loss = 0.0290 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 1060: loss = 0.2397 (0.357 sec/step)\n",
            "I0205 13:25:08.565104 140689526667136 learning.py:507] global step 1060: loss = 0.2397 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 1061: loss = 0.3411 (0.378 sec/step)\n",
            "I0205 13:25:08.944938 140689526667136 learning.py:507] global step 1061: loss = 0.3411 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 1062: loss = 0.0383 (0.370 sec/step)\n",
            "I0205 13:25:09.316061 140689526667136 learning.py:507] global step 1062: loss = 0.0383 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 1063: loss = 0.0528 (0.348 sec/step)\n",
            "I0205 13:25:09.665791 140689526667136 learning.py:507] global step 1063: loss = 0.0528 (0.348 sec/step)\n",
            "INFO:tensorflow:global step 1064: loss = 0.0969 (0.362 sec/step)\n",
            "I0205 13:25:10.029099 140689526667136 learning.py:507] global step 1064: loss = 0.0969 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 1065: loss = 0.0537 (0.389 sec/step)\n",
            "I0205 13:25:10.419962 140689526667136 learning.py:507] global step 1065: loss = 0.0537 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 1066: loss = 0.2773 (0.373 sec/step)\n",
            "I0205 13:25:10.795086 140689526667136 learning.py:507] global step 1066: loss = 0.2773 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 1067: loss = 0.2467 (0.405 sec/step)\n",
            "I0205 13:25:11.201543 140689526667136 learning.py:507] global step 1067: loss = 0.2467 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 1068: loss = 0.0350 (0.376 sec/step)\n",
            "I0205 13:25:11.579078 140689526667136 learning.py:507] global step 1068: loss = 0.0350 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 1069: loss = 0.3004 (0.371 sec/step)\n",
            "I0205 13:25:11.952142 140689526667136 learning.py:507] global step 1069: loss = 0.3004 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 1070: loss = 0.1145 (0.335 sec/step)\n",
            "I0205 13:25:12.289071 140689526667136 learning.py:507] global step 1070: loss = 0.1145 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 1071: loss = 0.1161 (1.038 sec/step)\n",
            "I0205 13:25:13.328209 140689526667136 learning.py:507] global step 1071: loss = 0.1161 (1.038 sec/step)\n",
            "INFO:tensorflow:global step 1072: loss = 0.2242 (0.379 sec/step)\n",
            "I0205 13:25:13.708820 140689526667136 learning.py:507] global step 1072: loss = 0.2242 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 1073: loss = 0.1734 (0.386 sec/step)\n",
            "I0205 13:25:14.095911 140689526667136 learning.py:507] global step 1073: loss = 0.1734 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 1074: loss = 0.5942 (1.028 sec/step)\n",
            "I0205 13:25:15.125699 140689526667136 learning.py:507] global step 1074: loss = 0.5942 (1.028 sec/step)\n",
            "INFO:tensorflow:global step 1075: loss = 0.2202 (0.378 sec/step)\n",
            "I0205 13:25:15.504487 140689526667136 learning.py:507] global step 1075: loss = 0.2202 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 1076: loss = 0.0368 (1.022 sec/step)\n",
            "I0205 13:25:16.527875 140689526667136 learning.py:507] global step 1076: loss = 0.0368 (1.022 sec/step)\n",
            "INFO:tensorflow:global step 1077: loss = 0.3423 (0.401 sec/step)\n",
            "I0205 13:25:16.930258 140689526667136 learning.py:507] global step 1077: loss = 0.3423 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 1078: loss = 0.3641 (0.385 sec/step)\n",
            "I0205 13:25:17.316812 140689526667136 learning.py:507] global step 1078: loss = 0.3641 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 1079: loss = 0.3627 (0.362 sec/step)\n",
            "I0205 13:25:17.679796 140689526667136 learning.py:507] global step 1079: loss = 0.3627 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 1080: loss = 0.0441 (0.380 sec/step)\n",
            "I0205 13:25:18.063977 140689526667136 learning.py:507] global step 1080: loss = 0.0441 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1081: loss = 0.0994 (0.409 sec/step)\n",
            "I0205 13:25:18.474394 140689526667136 learning.py:507] global step 1081: loss = 0.0994 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 1082: loss = 0.2997 (0.381 sec/step)\n",
            "I0205 13:25:18.857642 140689526667136 learning.py:507] global step 1082: loss = 0.2997 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1083: loss = 0.1606 (0.410 sec/step)\n",
            "I0205 13:25:19.269134 140689526667136 learning.py:507] global step 1083: loss = 0.1606 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 1084: loss = 0.4184 (0.379 sec/step)\n",
            "I0205 13:25:19.649897 140689526667136 learning.py:507] global step 1084: loss = 0.4184 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 1085: loss = 0.0963 (0.388 sec/step)\n",
            "I0205 13:25:20.039187 140689526667136 learning.py:507] global step 1085: loss = 0.0963 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 1086: loss = 0.1589 (0.369 sec/step)\n",
            "I0205 13:25:20.409533 140689526667136 learning.py:507] global step 1086: loss = 0.1589 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 1087: loss = 0.1783 (0.382 sec/step)\n",
            "I0205 13:25:20.793739 140689526667136 learning.py:507] global step 1087: loss = 0.1783 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 1088: loss = 0.6177 (0.383 sec/step)\n",
            "I0205 13:25:21.178625 140689526667136 learning.py:507] global step 1088: loss = 0.6177 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 1089: loss = 0.1178 (0.366 sec/step)\n",
            "I0205 13:25:21.546786 140689526667136 learning.py:507] global step 1089: loss = 0.1178 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 1090: loss = 0.6178 (0.394 sec/step)\n",
            "I0205 13:25:21.942892 140689526667136 learning.py:507] global step 1090: loss = 0.6178 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 1091: loss = 0.1617 (0.396 sec/step)\n",
            "I0205 13:25:22.340649 140689526667136 learning.py:507] global step 1091: loss = 0.1617 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 1092: loss = 0.1110 (0.357 sec/step)\n",
            "I0205 13:25:22.700086 140689526667136 learning.py:507] global step 1092: loss = 0.1110 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 1093: loss = 0.0598 (0.371 sec/step)\n",
            "I0205 13:25:23.072579 140689526667136 learning.py:507] global step 1093: loss = 0.0598 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 1094: loss = 0.1166 (0.380 sec/step)\n",
            "I0205 13:25:23.454028 140689526667136 learning.py:507] global step 1094: loss = 0.1166 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1095: loss = 0.2386 (0.406 sec/step)\n",
            "I0205 13:25:23.861885 140689526667136 learning.py:507] global step 1095: loss = 0.2386 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 1096: loss = 0.1849 (0.438 sec/step)\n",
            "I0205 13:25:24.301436 140689526667136 learning.py:507] global step 1096: loss = 0.1849 (0.438 sec/step)\n",
            "INFO:tensorflow:global step 1097: loss = 0.0860 (0.393 sec/step)\n",
            "I0205 13:25:24.696381 140689526667136 learning.py:507] global step 1097: loss = 0.0860 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 1098: loss = 0.1149 (0.376 sec/step)\n",
            "I0205 13:25:25.075331 140689526667136 learning.py:507] global step 1098: loss = 0.1149 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 1099: loss = 0.4604 (0.373 sec/step)\n",
            "I0205 13:25:25.449985 140689526667136 learning.py:507] global step 1099: loss = 0.4604 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 1100: loss = 0.1641 (0.379 sec/step)\n",
            "I0205 13:25:25.830264 140689526667136 learning.py:507] global step 1100: loss = 0.1641 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 1101: loss = 0.1664 (0.360 sec/step)\n",
            "I0205 13:25:26.191247 140689526667136 learning.py:507] global step 1101: loss = 0.1664 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 1102: loss = 0.3736 (0.408 sec/step)\n",
            "I0205 13:25:26.600775 140689526667136 learning.py:507] global step 1102: loss = 0.3736 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 1103: loss = 0.1359 (1.664 sec/step)\n",
            "I0205 13:25:28.266143 140689526667136 learning.py:507] global step 1103: loss = 0.1359 (1.664 sec/step)\n",
            "INFO:tensorflow:global step 1104: loss = 0.4933 (0.440 sec/step)\n",
            "I0205 13:25:28.707488 140689526667136 learning.py:507] global step 1104: loss = 0.4933 (0.440 sec/step)\n",
            "INFO:tensorflow:global step 1105: loss = 0.2060 (0.398 sec/step)\n",
            "I0205 13:25:29.107002 140689526667136 learning.py:507] global step 1105: loss = 0.2060 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 1106: loss = 0.3050 (0.391 sec/step)\n",
            "I0205 13:25:29.499346 140689526667136 learning.py:507] global step 1106: loss = 0.3050 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 1107: loss = 2.1802 (0.426 sec/step)\n",
            "I0205 13:25:29.927779 140689526667136 learning.py:507] global step 1107: loss = 2.1802 (0.426 sec/step)\n",
            "INFO:tensorflow:global step 1108: loss = 0.2879 (0.386 sec/step)\n",
            "I0205 13:25:30.316283 140689526667136 learning.py:507] global step 1108: loss = 0.2879 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 1109: loss = 0.2492 (0.365 sec/step)\n",
            "I0205 13:25:30.682485 140689526667136 learning.py:507] global step 1109: loss = 0.2492 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 1110: loss = 0.0806 (1.516 sec/step)\n",
            "I0205 13:25:32.200143 140689526667136 learning.py:507] global step 1110: loss = 0.0806 (1.516 sec/step)\n",
            "INFO:tensorflow:global step 1111: loss = 0.0496 (0.370 sec/step)\n",
            "I0205 13:25:32.571965 140689526667136 learning.py:507] global step 1111: loss = 0.0496 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 1112: loss = 0.1022 (0.373 sec/step)\n",
            "I0205 13:25:32.947002 140689526667136 learning.py:507] global step 1112: loss = 0.1022 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 1113: loss = 0.5772 (0.354 sec/step)\n",
            "I0205 13:25:33.303141 140689526667136 learning.py:507] global step 1113: loss = 0.5772 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 1114: loss = 0.1669 (0.360 sec/step)\n",
            "I0205 13:25:33.664754 140689526667136 learning.py:507] global step 1114: loss = 0.1669 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 1115: loss = 0.0412 (0.391 sec/step)\n",
            "I0205 13:25:34.057713 140689526667136 learning.py:507] global step 1115: loss = 0.0412 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 1116: loss = 0.1033 (0.396 sec/step)\n",
            "I0205 13:25:34.460433 140689526667136 learning.py:507] global step 1116: loss = 0.1033 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 1117: loss = 0.2052 (0.448 sec/step)\n",
            "I0205 13:25:34.909458 140689526667136 learning.py:507] global step 1117: loss = 0.2052 (0.448 sec/step)\n",
            "INFO:tensorflow:global step 1118: loss = 0.2625 (0.365 sec/step)\n",
            "I0205 13:25:35.275493 140689526667136 learning.py:507] global step 1118: loss = 0.2625 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 1119: loss = 0.6878 (0.340 sec/step)\n",
            "I0205 13:25:35.616578 140689526667136 learning.py:507] global step 1119: loss = 0.6878 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 1120: loss = 0.2900 (0.349 sec/step)\n",
            "I0205 13:25:35.967212 140689526667136 learning.py:507] global step 1120: loss = 0.2900 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 1121: loss = 0.1243 (0.392 sec/step)\n",
            "I0205 13:25:36.360865 140689526667136 learning.py:507] global step 1121: loss = 0.1243 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 1122: loss = 0.2245 (0.364 sec/step)\n",
            "I0205 13:25:36.726662 140689526667136 learning.py:507] global step 1122: loss = 0.2245 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 1123: loss = 0.0860 (0.382 sec/step)\n",
            "I0205 13:25:37.110416 140689526667136 learning.py:507] global step 1123: loss = 0.0860 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 1124: loss = 0.1648 (0.387 sec/step)\n",
            "I0205 13:25:37.499153 140689526667136 learning.py:507] global step 1124: loss = 0.1648 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 1125: loss = 0.3648 (0.384 sec/step)\n",
            "I0205 13:25:37.884747 140689526667136 learning.py:507] global step 1125: loss = 0.3648 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 1126: loss = 0.1528 (0.379 sec/step)\n",
            "I0205 13:25:38.265388 140689526667136 learning.py:507] global step 1126: loss = 0.1528 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 1127: loss = 0.2089 (0.383 sec/step)\n",
            "I0205 13:25:38.649917 140689526667136 learning.py:507] global step 1127: loss = 0.2089 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 1128: loss = 0.1107 (0.363 sec/step)\n",
            "I0205 13:25:39.014734 140689526667136 learning.py:507] global step 1128: loss = 0.1107 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 1129: loss = 0.2904 (0.379 sec/step)\n",
            "I0205 13:25:39.395343 140689526667136 learning.py:507] global step 1129: loss = 0.2904 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 1130: loss = 0.0804 (0.378 sec/step)\n",
            "I0205 13:25:39.775027 140689526667136 learning.py:507] global step 1130: loss = 0.0804 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 1131: loss = 0.3390 (0.360 sec/step)\n",
            "I0205 13:25:40.136929 140689526667136 learning.py:507] global step 1131: loss = 0.3390 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 1132: loss = 0.3629 (0.350 sec/step)\n",
            "I0205 13:25:40.488486 140689526667136 learning.py:507] global step 1132: loss = 0.3629 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 1133: loss = 0.6162 (0.373 sec/step)\n",
            "I0205 13:25:40.863403 140689526667136 learning.py:507] global step 1133: loss = 0.6162 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 1134: loss = 0.0622 (0.372 sec/step)\n",
            "I0205 13:25:41.236315 140689526667136 learning.py:507] global step 1134: loss = 0.0622 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 1135: loss = 0.1303 (0.387 sec/step)\n",
            "I0205 13:25:41.624186 140689526667136 learning.py:507] global step 1135: loss = 0.1303 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 1136: loss = 0.4250 (0.379 sec/step)\n",
            "I0205 13:25:42.005024 140689526667136 learning.py:507] global step 1136: loss = 0.4250 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 1137: loss = 0.3095 (0.384 sec/step)\n",
            "I0205 13:25:42.390989 140689526667136 learning.py:507] global step 1137: loss = 0.3095 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 1138: loss = 0.1223 (0.392 sec/step)\n",
            "I0205 13:25:42.784227 140689526667136 learning.py:507] global step 1138: loss = 0.1223 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 1139: loss = 0.2358 (0.374 sec/step)\n",
            "I0205 13:25:43.160344 140689526667136 learning.py:507] global step 1139: loss = 0.2358 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 1140: loss = 0.2200 (1.213 sec/step)\n",
            "I0205 13:25:44.375077 140689526667136 learning.py:507] global step 1140: loss = 0.2200 (1.213 sec/step)\n",
            "INFO:tensorflow:global step 1141: loss = 0.2675 (1.516 sec/step)\n",
            "I0205 13:25:45.892085 140689526667136 learning.py:507] global step 1141: loss = 0.2675 (1.516 sec/step)\n",
            "INFO:tensorflow:global step 1142: loss = 0.1037 (0.346 sec/step)\n",
            "I0205 13:25:46.239554 140689526667136 learning.py:507] global step 1142: loss = 0.1037 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 1143: loss = 0.0855 (0.384 sec/step)\n",
            "I0205 13:25:46.626118 140689526667136 learning.py:507] global step 1143: loss = 0.0855 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 1144: loss = 0.2963 (0.377 sec/step)\n",
            "I0205 13:25:47.004600 140689526667136 learning.py:507] global step 1144: loss = 0.2963 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 1145: loss = 0.0283 (0.958 sec/step)\n",
            "I0205 13:25:47.963926 140689526667136 learning.py:507] global step 1145: loss = 0.0283 (0.958 sec/step)\n",
            "INFO:tensorflow:global step 1146: loss = 0.1601 (0.394 sec/step)\n",
            "I0205 13:25:48.359929 140689526667136 learning.py:507] global step 1146: loss = 0.1601 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 1147: loss = 0.1856 (0.377 sec/step)\n",
            "I0205 13:25:48.738619 140689526667136 learning.py:507] global step 1147: loss = 0.1856 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 1148: loss = 0.2106 (0.399 sec/step)\n",
            "I0205 13:25:49.139060 140689526667136 learning.py:507] global step 1148: loss = 0.2106 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 1149: loss = 0.0780 (0.372 sec/step)\n",
            "I0205 13:25:49.513209 140689526667136 learning.py:507] global step 1149: loss = 0.0780 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 1150: loss = 0.2387 (0.426 sec/step)\n",
            "I0205 13:25:49.940460 140689526667136 learning.py:507] global step 1150: loss = 0.2387 (0.426 sec/step)\n",
            "INFO:tensorflow:global step 1151: loss = 0.0936 (0.375 sec/step)\n",
            "I0205 13:25:50.317082 140689526667136 learning.py:507] global step 1151: loss = 0.0936 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 1152: loss = 0.2177 (0.358 sec/step)\n",
            "I0205 13:25:50.676450 140689526667136 learning.py:507] global step 1152: loss = 0.2177 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 1153: loss = 1.3849 (0.382 sec/step)\n",
            "I0205 13:25:51.059984 140689526667136 learning.py:507] global step 1153: loss = 1.3849 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 1154: loss = 0.3828 (0.374 sec/step)\n",
            "I0205 13:25:51.436092 140689526667136 learning.py:507] global step 1154: loss = 0.3828 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 1155: loss = 0.0367 (0.363 sec/step)\n",
            "I0205 13:25:51.800819 140689526667136 learning.py:507] global step 1155: loss = 0.0367 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 1156: loss = 0.2206 (0.441 sec/step)\n",
            "I0205 13:25:52.243885 140689526667136 learning.py:507] global step 1156: loss = 0.2206 (0.441 sec/step)\n",
            "INFO:tensorflow:global step 1157: loss = 0.2710 (0.412 sec/step)\n",
            "I0205 13:25:52.657721 140689526667136 learning.py:507] global step 1157: loss = 0.2710 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 1158: loss = 0.6537 (0.382 sec/step)\n",
            "I0205 13:25:53.041096 140689526667136 learning.py:507] global step 1158: loss = 0.6537 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 1159: loss = 0.3520 (0.377 sec/step)\n",
            "I0205 13:25:53.419519 140689526667136 learning.py:507] global step 1159: loss = 0.3520 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 1160: loss = 0.4415 (0.387 sec/step)\n",
            "I0205 13:25:53.807765 140689526667136 learning.py:507] global step 1160: loss = 0.4415 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 1161: loss = 0.2100 (0.411 sec/step)\n",
            "I0205 13:25:54.220218 140689526667136 learning.py:507] global step 1161: loss = 0.2100 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 1162: loss = 0.7017 (0.366 sec/step)\n",
            "I0205 13:25:54.587533 140689526667136 learning.py:507] global step 1162: loss = 0.7017 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 1163: loss = 0.2874 (0.375 sec/step)\n",
            "I0205 13:25:54.963936 140689526667136 learning.py:507] global step 1163: loss = 0.2874 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 1164: loss = 0.4486 (0.381 sec/step)\n",
            "I0205 13:25:55.346035 140689526667136 learning.py:507] global step 1164: loss = 0.4486 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1165: loss = 0.1827 (1.045 sec/step)\n",
            "I0205 13:25:56.391828 140689526667136 learning.py:507] global step 1165: loss = 0.1827 (1.045 sec/step)\n",
            "INFO:tensorflow:global step 1166: loss = 0.3313 (0.372 sec/step)\n",
            "I0205 13:25:56.765860 140689526667136 learning.py:507] global step 1166: loss = 0.3313 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 1167: loss = 0.1897 (0.360 sec/step)\n",
            "I0205 13:25:57.127348 140689526667136 learning.py:507] global step 1167: loss = 0.1897 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 1168: loss = 0.1298 (0.388 sec/step)\n",
            "I0205 13:25:57.517218 140689526667136 learning.py:507] global step 1168: loss = 0.1298 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 1169: loss = 0.3544 (0.435 sec/step)\n",
            "I0205 13:25:57.954291 140689526667136 learning.py:507] global step 1169: loss = 0.3544 (0.435 sec/step)\n",
            "INFO:tensorflow:global step 1170: loss = 0.3472 (0.386 sec/step)\n",
            "I0205 13:25:58.342431 140689526667136 learning.py:507] global step 1170: loss = 0.3472 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 1171: loss = 0.0856 (0.373 sec/step)\n",
            "I0205 13:25:58.717607 140689526667136 learning.py:507] global step 1171: loss = 0.0856 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 1172: loss = 0.1830 (0.379 sec/step)\n",
            "I0205 13:25:59.098614 140689526667136 learning.py:507] global step 1172: loss = 0.1830 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 1173: loss = 0.2032 (0.406 sec/step)\n",
            "I0205 13:25:59.505782 140689526667136 learning.py:507] global step 1173: loss = 0.2032 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 1174: loss = 0.5007 (0.377 sec/step)\n",
            "I0205 13:25:59.884188 140689526667136 learning.py:507] global step 1174: loss = 0.5007 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 1175: loss = 0.0882 (0.388 sec/step)\n",
            "I0205 13:26:00.274371 140689526667136 learning.py:507] global step 1175: loss = 0.0882 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 1176: loss = 0.1549 (0.340 sec/step)\n",
            "I0205 13:26:00.617106 140689526667136 learning.py:507] global step 1176: loss = 0.1549 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 1177: loss = 0.0997 (0.366 sec/step)\n",
            "I0205 13:26:00.984428 140689526667136 learning.py:507] global step 1177: loss = 0.0997 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 1178: loss = 0.0607 (0.383 sec/step)\n",
            "I0205 13:26:01.369335 140689526667136 learning.py:507] global step 1178: loss = 0.0607 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 1179: loss = 0.4214 (0.363 sec/step)\n",
            "I0205 13:26:01.734444 140689526667136 learning.py:507] global step 1179: loss = 0.4214 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 1180: loss = 0.1225 (0.399 sec/step)\n",
            "I0205 13:26:02.135609 140689526667136 learning.py:507] global step 1180: loss = 0.1225 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 1181: loss = 1.0981 (0.380 sec/step)\n",
            "I0205 13:26:02.517712 140689526667136 learning.py:507] global step 1181: loss = 1.0981 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1182: loss = 0.1093 (0.393 sec/step)\n",
            "I0205 13:26:02.912632 140689526667136 learning.py:507] global step 1182: loss = 0.1093 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 1183: loss = 0.3272 (0.393 sec/step)\n",
            "I0205 13:26:03.307149 140689526667136 learning.py:507] global step 1183: loss = 0.3272 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 1184: loss = 0.2218 (0.389 sec/step)\n",
            "I0205 13:26:03.698188 140689526667136 learning.py:507] global step 1184: loss = 0.2218 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 1185: loss = 0.3909 (0.378 sec/step)\n",
            "I0205 13:26:04.077826 140689526667136 learning.py:507] global step 1185: loss = 0.3909 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 1186: loss = 0.1206 (0.383 sec/step)\n",
            "I0205 13:26:04.461878 140689526667136 learning.py:507] global step 1186: loss = 0.1206 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 1187: loss = 0.0421 (0.369 sec/step)\n",
            "I0205 13:26:04.832193 140689526667136 learning.py:507] global step 1187: loss = 0.0421 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 1188: loss = 0.0773 (0.371 sec/step)\n",
            "I0205 13:26:05.204197 140689526667136 learning.py:507] global step 1188: loss = 0.0773 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 1189: loss = 1.8832 (0.381 sec/step)\n",
            "I0205 13:26:05.587553 140689526667136 learning.py:507] global step 1189: loss = 1.8832 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1190: loss = 0.1506 (0.370 sec/step)\n",
            "I0205 13:26:05.959246 140689526667136 learning.py:507] global step 1190: loss = 0.1506 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 1191: loss = 0.0537 (0.386 sec/step)\n",
            "I0205 13:26:06.346497 140689526667136 learning.py:507] global step 1191: loss = 0.0537 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 1192: loss = 0.1664 (0.366 sec/step)\n",
            "I0205 13:26:06.714399 140689526667136 learning.py:507] global step 1192: loss = 0.1664 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 1193: loss = 0.0671 (0.391 sec/step)\n",
            "I0205 13:26:07.106878 140689526667136 learning.py:507] global step 1193: loss = 0.0671 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 1194: loss = 0.1716 (0.392 sec/step)\n",
            "I0205 13:26:07.499993 140689526667136 learning.py:507] global step 1194: loss = 0.1716 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 1195: loss = 0.1960 (0.376 sec/step)\n",
            "I0205 13:26:07.877926 140689526667136 learning.py:507] global step 1195: loss = 0.1960 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 1196: loss = 0.1617 (0.377 sec/step)\n",
            "I0205 13:26:08.256928 140689526667136 learning.py:507] global step 1196: loss = 0.1617 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 1197: loss = 0.1904 (0.378 sec/step)\n",
            "I0205 13:26:08.636234 140689526667136 learning.py:507] global step 1197: loss = 0.1904 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 1198: loss = 0.7571 (0.363 sec/step)\n",
            "I0205 13:26:09.000872 140689526667136 learning.py:507] global step 1198: loss = 0.7571 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 1199: loss = 0.4619 (0.380 sec/step)\n",
            "I0205 13:26:09.382251 140689526667136 learning.py:507] global step 1199: loss = 0.4619 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1200: loss = 0.1298 (0.355 sec/step)\n",
            "I0205 13:26:09.738923 140689526667136 learning.py:507] global step 1200: loss = 0.1298 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 1201: loss = 0.1443 (0.384 sec/step)\n",
            "I0205 13:26:10.124418 140689526667136 learning.py:507] global step 1201: loss = 0.1443 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 1202: loss = 0.3539 (0.419 sec/step)\n",
            "I0205 13:26:10.544551 140689526667136 learning.py:507] global step 1202: loss = 0.3539 (0.419 sec/step)\n",
            "INFO:tensorflow:global step 1203: loss = 0.2115 (0.362 sec/step)\n",
            "I0205 13:26:10.908294 140689526667136 learning.py:507] global step 1203: loss = 0.2115 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 1204: loss = 0.1093 (0.392 sec/step)\n",
            "I0205 13:26:11.302399 140689526667136 learning.py:507] global step 1204: loss = 0.1093 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 1205: loss = 0.2742 (0.395 sec/step)\n",
            "I0205 13:26:11.699372 140689526667136 learning.py:507] global step 1205: loss = 0.2742 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 1206: loss = 0.1595 (0.395 sec/step)\n",
            "I0205 13:26:12.096005 140689526667136 learning.py:507] global step 1206: loss = 0.1595 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 1207: loss = 0.1911 (1.279 sec/step)\n",
            "I0205 13:26:13.376349 140689526667136 learning.py:507] global step 1207: loss = 0.1911 (1.279 sec/step)\n",
            "INFO:tensorflow:global step 1208: loss = 0.5231 (0.420 sec/step)\n",
            "I0205 13:26:13.831156 140689526667136 learning.py:507] global step 1208: loss = 0.5231 (0.420 sec/step)\n",
            "INFO:tensorflow:global step 1209: loss = 0.5056 (1.513 sec/step)\n",
            "I0205 13:26:15.347123 140689526667136 learning.py:507] global step 1209: loss = 0.5056 (1.513 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 2.18384\n",
            "I0205 13:26:15.891277 140686034466560 supervisor.py:1099] global_step/sec: 2.18384\n",
            "INFO:tensorflow:global step 1210: loss = 0.0752 (0.609 sec/step)\n",
            "I0205 13:26:15.973602 140689526667136 learning.py:507] global step 1210: loss = 0.0752 (0.609 sec/step)\n",
            "INFO:tensorflow:global step 1211: loss = 0.1470 (0.615 sec/step)\n",
            "I0205 13:26:16.590651 140689526667136 learning.py:507] global step 1211: loss = 0.1470 (0.615 sec/step)\n",
            "INFO:tensorflow:global step 1212: loss = 0.1418 (0.635 sec/step)\n",
            "I0205 13:26:17.231547 140689526667136 learning.py:507] global step 1212: loss = 0.1418 (0.635 sec/step)\n",
            "INFO:tensorflow:global step 1213: loss = 0.1398 (0.458 sec/step)\n",
            "I0205 13:26:17.692022 140689526667136 learning.py:507] global step 1213: loss = 0.1398 (0.458 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 1213.\n",
            "I0205 13:26:17.721281 140686026073856 supervisor.py:1050] Recording summary at step 1213.\n",
            "INFO:tensorflow:global step 1214: loss = 0.1514 (0.375 sec/step)\n",
            "I0205 13:26:18.070349 140689526667136 learning.py:507] global step 1214: loss = 0.1514 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 1215: loss = 0.7979 (0.374 sec/step)\n",
            "I0205 13:26:18.446117 140689526667136 learning.py:507] global step 1215: loss = 0.7979 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 1216: loss = 0.1035 (0.403 sec/step)\n",
            "I0205 13:26:18.851014 140689526667136 learning.py:507] global step 1216: loss = 0.1035 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 1217: loss = 0.1193 (0.399 sec/step)\n",
            "I0205 13:26:19.252615 140689526667136 learning.py:507] global step 1217: loss = 0.1193 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 1218: loss = 1.2052 (0.433 sec/step)\n",
            "I0205 13:26:19.687280 140689526667136 learning.py:507] global step 1218: loss = 1.2052 (0.433 sec/step)\n",
            "INFO:tensorflow:global step 1219: loss = 0.2220 (0.379 sec/step)\n",
            "I0205 13:26:20.068229 140689526667136 learning.py:507] global step 1219: loss = 0.2220 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 1220: loss = 0.0820 (0.382 sec/step)\n",
            "I0205 13:26:20.452842 140689526667136 learning.py:507] global step 1220: loss = 0.0820 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 1221: loss = 0.0619 (0.372 sec/step)\n",
            "I0205 13:26:20.827088 140689526667136 learning.py:507] global step 1221: loss = 0.0619 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 1222: loss = 0.0769 (0.368 sec/step)\n",
            "I0205 13:26:21.196511 140689526667136 learning.py:507] global step 1222: loss = 0.0769 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 1223: loss = 0.5238 (0.387 sec/step)\n",
            "I0205 13:26:21.585429 140689526667136 learning.py:507] global step 1223: loss = 0.5238 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 1224: loss = 0.2482 (0.385 sec/step)\n",
            "I0205 13:26:21.971786 140689526667136 learning.py:507] global step 1224: loss = 0.2482 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 1225: loss = 0.2343 (0.395 sec/step)\n",
            "I0205 13:26:22.368353 140689526667136 learning.py:507] global step 1225: loss = 0.2343 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 1226: loss = 0.2038 (0.386 sec/step)\n",
            "I0205 13:26:22.756128 140689526667136 learning.py:507] global step 1226: loss = 0.2038 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 1227: loss = 0.2299 (0.382 sec/step)\n",
            "I0205 13:26:23.139179 140689526667136 learning.py:507] global step 1227: loss = 0.2299 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 1228: loss = 0.0671 (0.370 sec/step)\n",
            "I0205 13:26:23.511029 140689526667136 learning.py:507] global step 1228: loss = 0.0671 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 1229: loss = 0.3659 (0.382 sec/step)\n",
            "I0205 13:26:23.895013 140689526667136 learning.py:507] global step 1229: loss = 0.3659 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 1230: loss = 0.2779 (0.395 sec/step)\n",
            "I0205 13:26:24.291346 140689526667136 learning.py:507] global step 1230: loss = 0.2779 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 1231: loss = 0.1629 (0.364 sec/step)\n",
            "I0205 13:26:24.657065 140689526667136 learning.py:507] global step 1231: loss = 0.1629 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 1232: loss = 0.1850 (0.384 sec/step)\n",
            "I0205 13:26:25.043246 140689526667136 learning.py:507] global step 1232: loss = 0.1850 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 1233: loss = 0.2703 (0.382 sec/step)\n",
            "I0205 13:26:25.426889 140689526667136 learning.py:507] global step 1233: loss = 0.2703 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 1234: loss = 0.8283 (0.385 sec/step)\n",
            "I0205 13:26:25.813408 140689526667136 learning.py:507] global step 1234: loss = 0.8283 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 1235: loss = 0.0682 (0.393 sec/step)\n",
            "I0205 13:26:26.207621 140689526667136 learning.py:507] global step 1235: loss = 0.0682 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 1236: loss = 0.2770 (0.392 sec/step)\n",
            "I0205 13:26:26.601148 140689526667136 learning.py:507] global step 1236: loss = 0.2770 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 1237: loss = 0.1092 (0.370 sec/step)\n",
            "I0205 13:26:26.973181 140689526667136 learning.py:507] global step 1237: loss = 0.1092 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 1238: loss = 0.3751 (0.368 sec/step)\n",
            "I0205 13:26:27.342649 140689526667136 learning.py:507] global step 1238: loss = 0.3751 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 1239: loss = 0.0277 (0.376 sec/step)\n",
            "I0205 13:26:27.720453 140689526667136 learning.py:507] global step 1239: loss = 0.0277 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 1240: loss = 0.5522 (0.420 sec/step)\n",
            "I0205 13:26:28.142136 140689526667136 learning.py:507] global step 1240: loss = 0.5522 (0.420 sec/step)\n",
            "INFO:tensorflow:global step 1241: loss = 0.3435 (0.409 sec/step)\n",
            "I0205 13:26:28.552127 140689526667136 learning.py:507] global step 1241: loss = 0.3435 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 1242: loss = 0.0893 (0.382 sec/step)\n",
            "I0205 13:26:28.935300 140689526667136 learning.py:507] global step 1242: loss = 0.0893 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 1243: loss = 0.1190 (0.404 sec/step)\n",
            "I0205 13:26:29.340755 140689526667136 learning.py:507] global step 1243: loss = 0.1190 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 1244: loss = 0.2080 (0.398 sec/step)\n",
            "I0205 13:26:29.740649 140689526667136 learning.py:507] global step 1244: loss = 0.2080 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 1245: loss = 0.4500 (0.408 sec/step)\n",
            "I0205 13:26:30.150372 140689526667136 learning.py:507] global step 1245: loss = 0.4500 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 1246: loss = 0.2271 (0.378 sec/step)\n",
            "I0205 13:26:30.530184 140689526667136 learning.py:507] global step 1246: loss = 0.2271 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 1247: loss = 0.1919 (1.024 sec/step)\n",
            "I0205 13:26:31.556079 140689526667136 learning.py:507] global step 1247: loss = 0.1919 (1.024 sec/step)\n",
            "INFO:tensorflow:global step 1248: loss = 0.6799 (0.379 sec/step)\n",
            "I0205 13:26:31.937201 140689526667136 learning.py:507] global step 1248: loss = 0.6799 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 1249: loss = 0.1456 (0.357 sec/step)\n",
            "I0205 13:26:32.296240 140689526667136 learning.py:507] global step 1249: loss = 0.1456 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 1250: loss = 0.4313 (0.381 sec/step)\n",
            "I0205 13:26:32.678657 140689526667136 learning.py:507] global step 1250: loss = 0.4313 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1251: loss = 0.1795 (0.399 sec/step)\n",
            "I0205 13:26:33.079705 140689526667136 learning.py:507] global step 1251: loss = 0.1795 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 1252: loss = 0.0370 (0.430 sec/step)\n",
            "I0205 13:26:33.511391 140689526667136 learning.py:507] global step 1252: loss = 0.0370 (0.430 sec/step)\n",
            "INFO:tensorflow:global step 1253: loss = 0.1653 (0.369 sec/step)\n",
            "I0205 13:26:33.882194 140689526667136 learning.py:507] global step 1253: loss = 0.1653 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 1254: loss = 0.4178 (0.395 sec/step)\n",
            "I0205 13:26:34.279058 140689526667136 learning.py:507] global step 1254: loss = 0.4178 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 1255: loss = 0.1761 (0.367 sec/step)\n",
            "I0205 13:26:34.647870 140689526667136 learning.py:507] global step 1255: loss = 0.1761 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 1256: loss = 0.2726 (0.380 sec/step)\n",
            "I0205 13:26:35.029739 140689526667136 learning.py:507] global step 1256: loss = 0.2726 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1257: loss = 0.9737 (0.350 sec/step)\n",
            "I0205 13:26:35.381063 140689526667136 learning.py:507] global step 1257: loss = 0.9737 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 1258: loss = 0.1438 (0.359 sec/step)\n",
            "I0205 13:26:35.741905 140689526667136 learning.py:507] global step 1258: loss = 0.1438 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 1259: loss = 0.2368 (0.361 sec/step)\n",
            "I0205 13:26:36.104786 140689526667136 learning.py:507] global step 1259: loss = 0.2368 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 1260: loss = 0.1632 (0.360 sec/step)\n",
            "I0205 13:26:36.466953 140689526667136 learning.py:507] global step 1260: loss = 0.1632 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 1261: loss = 0.7357 (0.354 sec/step)\n",
            "I0205 13:26:36.822202 140689526667136 learning.py:507] global step 1261: loss = 0.7357 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 1262: loss = 0.1606 (0.442 sec/step)\n",
            "I0205 13:26:37.265527 140689526667136 learning.py:507] global step 1262: loss = 0.1606 (0.442 sec/step)\n",
            "INFO:tensorflow:global step 1263: loss = 0.0386 (0.387 sec/step)\n",
            "I0205 13:26:37.653928 140689526667136 learning.py:507] global step 1263: loss = 0.0386 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 1264: loss = 0.1347 (0.354 sec/step)\n",
            "I0205 13:26:38.009398 140689526667136 learning.py:507] global step 1264: loss = 0.1347 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 1265: loss = 0.4226 (0.360 sec/step)\n",
            "I0205 13:26:38.371085 140689526667136 learning.py:507] global step 1265: loss = 0.4226 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 1266: loss = 0.1041 (0.375 sec/step)\n",
            "I0205 13:26:38.748043 140689526667136 learning.py:507] global step 1266: loss = 0.1041 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 1267: loss = 0.0947 (0.365 sec/step)\n",
            "I0205 13:26:39.114475 140689526667136 learning.py:507] global step 1267: loss = 0.0947 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 1268: loss = 0.1437 (0.388 sec/step)\n",
            "I0205 13:26:39.504678 140689526667136 learning.py:507] global step 1268: loss = 0.1437 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 1269: loss = 0.5709 (0.408 sec/step)\n",
            "I0205 13:26:39.914376 140689526667136 learning.py:507] global step 1269: loss = 0.5709 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 1270: loss = 0.0831 (0.359 sec/step)\n",
            "I0205 13:26:40.274862 140689526667136 learning.py:507] global step 1270: loss = 0.0831 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 1271: loss = 0.4203 (0.373 sec/step)\n",
            "I0205 13:26:40.649507 140689526667136 learning.py:507] global step 1271: loss = 0.4203 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 1272: loss = 0.2128 (0.368 sec/step)\n",
            "I0205 13:26:41.019227 140689526667136 learning.py:507] global step 1272: loss = 0.2128 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 1273: loss = 0.1421 (0.447 sec/step)\n",
            "I0205 13:26:41.467336 140689526667136 learning.py:507] global step 1273: loss = 0.1421 (0.447 sec/step)\n",
            "INFO:tensorflow:global step 1274: loss = 0.4279 (0.386 sec/step)\n",
            "I0205 13:26:41.854711 140689526667136 learning.py:507] global step 1274: loss = 0.4279 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 1275: loss = 0.4806 (0.379 sec/step)\n",
            "I0205 13:26:42.235262 140689526667136 learning.py:507] global step 1275: loss = 0.4806 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 1276: loss = 0.2989 (0.366 sec/step)\n",
            "I0205 13:26:42.603155 140689526667136 learning.py:507] global step 1276: loss = 0.2989 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 1277: loss = 0.1719 (0.386 sec/step)\n",
            "I0205 13:26:42.991074 140689526667136 learning.py:507] global step 1277: loss = 0.1719 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 1278: loss = 0.0691 (0.370 sec/step)\n",
            "I0205 13:26:43.362389 140689526667136 learning.py:507] global step 1278: loss = 0.0691 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 1279: loss = 0.1121 (0.383 sec/step)\n",
            "I0205 13:26:43.747189 140689526667136 learning.py:507] global step 1279: loss = 0.1121 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 1280: loss = 0.1839 (0.375 sec/step)\n",
            "I0205 13:26:44.124064 140689526667136 learning.py:507] global step 1280: loss = 0.1839 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 1281: loss = 0.1813 (0.445 sec/step)\n",
            "I0205 13:26:44.570465 140689526667136 learning.py:507] global step 1281: loss = 0.1813 (0.445 sec/step)\n",
            "INFO:tensorflow:global step 1282: loss = 0.1747 (0.375 sec/step)\n",
            "I0205 13:26:44.946608 140689526667136 learning.py:507] global step 1282: loss = 0.1747 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 1283: loss = 0.1922 (0.370 sec/step)\n",
            "I0205 13:26:45.318037 140689526667136 learning.py:507] global step 1283: loss = 0.1922 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 1284: loss = 0.3125 (0.403 sec/step)\n",
            "I0205 13:26:45.723347 140689526667136 learning.py:507] global step 1284: loss = 0.3125 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 1285: loss = 0.3227 (0.389 sec/step)\n",
            "I0205 13:26:46.113720 140689526667136 learning.py:507] global step 1285: loss = 0.3227 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 1286: loss = 0.2290 (0.412 sec/step)\n",
            "I0205 13:26:46.526907 140689526667136 learning.py:507] global step 1286: loss = 0.2290 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 1287: loss = 0.0813 (0.387 sec/step)\n",
            "I0205 13:26:46.915616 140689526667136 learning.py:507] global step 1287: loss = 0.0813 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 1288: loss = 0.4314 (0.385 sec/step)\n",
            "I0205 13:26:47.302001 140689526667136 learning.py:507] global step 1288: loss = 0.4314 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 1289: loss = 0.2803 (0.380 sec/step)\n",
            "I0205 13:26:47.683992 140689526667136 learning.py:507] global step 1289: loss = 0.2803 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1290: loss = 0.5581 (0.365 sec/step)\n",
            "I0205 13:26:48.050556 140689526667136 learning.py:507] global step 1290: loss = 0.5581 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 1291: loss = 0.1558 (0.381 sec/step)\n",
            "I0205 13:26:48.432778 140689526667136 learning.py:507] global step 1291: loss = 0.1558 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1292: loss = 0.7456 (0.342 sec/step)\n",
            "I0205 13:26:48.776909 140689526667136 learning.py:507] global step 1292: loss = 0.7456 (0.342 sec/step)\n",
            "INFO:tensorflow:global step 1293: loss = 0.3953 (1.581 sec/step)\n",
            "I0205 13:26:50.359235 140689526667136 learning.py:507] global step 1293: loss = 0.3953 (1.581 sec/step)\n",
            "INFO:tensorflow:global step 1294: loss = 0.2646 (0.377 sec/step)\n",
            "I0205 13:26:50.737490 140689526667136 learning.py:507] global step 1294: loss = 0.2646 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 1295: loss = 0.1240 (0.392 sec/step)\n",
            "I0205 13:26:51.130906 140689526667136 learning.py:507] global step 1295: loss = 0.1240 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 1296: loss = 0.3387 (0.391 sec/step)\n",
            "I0205 13:26:51.523577 140689526667136 learning.py:507] global step 1296: loss = 0.3387 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 1297: loss = 0.4739 (0.395 sec/step)\n",
            "I0205 13:26:51.920511 140689526667136 learning.py:507] global step 1297: loss = 0.4739 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 1298: loss = 0.1068 (0.392 sec/step)\n",
            "I0205 13:26:52.313970 140689526667136 learning.py:507] global step 1298: loss = 0.1068 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 1299: loss = 0.1107 (1.668 sec/step)\n",
            "I0205 13:26:53.983592 140689526667136 learning.py:507] global step 1299: loss = 0.1107 (1.668 sec/step)\n",
            "INFO:tensorflow:global step 1300: loss = 0.3134 (0.392 sec/step)\n",
            "I0205 13:26:54.377842 140689526667136 learning.py:507] global step 1300: loss = 0.3134 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 1301: loss = 0.1193 (0.404 sec/step)\n",
            "I0205 13:26:54.783675 140689526667136 learning.py:507] global step 1301: loss = 0.1193 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 1302: loss = 0.3570 (0.390 sec/step)\n",
            "I0205 13:26:55.174927 140689526667136 learning.py:507] global step 1302: loss = 0.3570 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 1303: loss = 0.1366 (0.404 sec/step)\n",
            "I0205 13:26:55.580790 140689526667136 learning.py:507] global step 1303: loss = 0.1366 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 1304: loss = 0.2874 (0.356 sec/step)\n",
            "I0205 13:26:55.938441 140689526667136 learning.py:507] global step 1304: loss = 0.2874 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 1305: loss = 0.2110 (0.381 sec/step)\n",
            "I0205 13:26:56.320921 140689526667136 learning.py:507] global step 1305: loss = 0.2110 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1306: loss = 0.2323 (0.399 sec/step)\n",
            "I0205 13:26:56.721712 140689526667136 learning.py:507] global step 1306: loss = 0.2323 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 1307: loss = 0.1397 (0.415 sec/step)\n",
            "I0205 13:26:57.139487 140689526667136 learning.py:507] global step 1307: loss = 0.1397 (0.415 sec/step)\n",
            "INFO:tensorflow:global step 1308: loss = 0.8867 (0.390 sec/step)\n",
            "I0205 13:26:57.531649 140689526667136 learning.py:507] global step 1308: loss = 0.8867 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 1309: loss = 0.0293 (0.355 sec/step)\n",
            "I0205 13:26:57.887704 140689526667136 learning.py:507] global step 1309: loss = 0.0293 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 1310: loss = 0.3967 (0.366 sec/step)\n",
            "I0205 13:26:58.255754 140689526667136 learning.py:507] global step 1310: loss = 0.3967 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 1311: loss = 0.1355 (0.398 sec/step)\n",
            "I0205 13:26:58.655254 140689526667136 learning.py:507] global step 1311: loss = 0.1355 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 1312: loss = 0.0770 (0.380 sec/step)\n",
            "I0205 13:26:59.037072 140689526667136 learning.py:507] global step 1312: loss = 0.0770 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1313: loss = 0.0464 (0.388 sec/step)\n",
            "I0205 13:26:59.427046 140689526667136 learning.py:507] global step 1313: loss = 0.0464 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 1314: loss = 0.1312 (0.394 sec/step)\n",
            "I0205 13:26:59.823078 140689526667136 learning.py:507] global step 1314: loss = 0.1312 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 1315: loss = 0.3254 (0.366 sec/step)\n",
            "I0205 13:27:00.190380 140689526667136 learning.py:507] global step 1315: loss = 0.3254 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 1316: loss = 0.1997 (0.372 sec/step)\n",
            "I0205 13:27:00.564059 140689526667136 learning.py:507] global step 1316: loss = 0.1997 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 1317: loss = 0.1888 (0.372 sec/step)\n",
            "I0205 13:27:00.937539 140689526667136 learning.py:507] global step 1317: loss = 0.1888 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 1318: loss = 0.1579 (0.380 sec/step)\n",
            "I0205 13:27:01.318950 140689526667136 learning.py:507] global step 1318: loss = 0.1579 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1319: loss = 0.4457 (0.367 sec/step)\n",
            "I0205 13:27:01.688154 140689526667136 learning.py:507] global step 1319: loss = 0.4457 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 1320: loss = 0.1178 (0.376 sec/step)\n",
            "I0205 13:27:02.066045 140689526667136 learning.py:507] global step 1320: loss = 0.1178 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 1321: loss = 0.1886 (0.365 sec/step)\n",
            "I0205 13:27:02.432771 140689526667136 learning.py:507] global step 1321: loss = 0.1886 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 1322: loss = 0.1375 (0.394 sec/step)\n",
            "I0205 13:27:02.828961 140689526667136 learning.py:507] global step 1322: loss = 0.1375 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 1323: loss = 0.1307 (0.385 sec/step)\n",
            "I0205 13:27:03.215356 140689526667136 learning.py:507] global step 1323: loss = 0.1307 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 1324: loss = 0.1400 (0.405 sec/step)\n",
            "I0205 13:27:03.623853 140689526667136 learning.py:507] global step 1324: loss = 0.1400 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 1325: loss = 0.0479 (1.034 sec/step)\n",
            "I0205 13:27:04.658929 140689526667136 learning.py:507] global step 1325: loss = 0.0479 (1.034 sec/step)\n",
            "INFO:tensorflow:global step 1326: loss = 0.1445 (0.388 sec/step)\n",
            "I0205 13:27:05.048138 140689526667136 learning.py:507] global step 1326: loss = 0.1445 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 1327: loss = 0.6557 (0.425 sec/step)\n",
            "I0205 13:27:05.475328 140689526667136 learning.py:507] global step 1327: loss = 0.6557 (0.425 sec/step)\n",
            "INFO:tensorflow:global step 1328: loss = 0.6131 (0.374 sec/step)\n",
            "I0205 13:27:05.851398 140689526667136 learning.py:507] global step 1328: loss = 0.6131 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 1329: loss = 0.2369 (0.385 sec/step)\n",
            "I0205 13:27:06.238482 140689526667136 learning.py:507] global step 1329: loss = 0.2369 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 1330: loss = 0.0204 (0.379 sec/step)\n",
            "I0205 13:27:06.618890 140689526667136 learning.py:507] global step 1330: loss = 0.0204 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 1331: loss = 0.2886 (0.386 sec/step)\n",
            "I0205 13:27:07.006796 140689526667136 learning.py:507] global step 1331: loss = 0.2886 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 1332: loss = 0.7600 (0.380 sec/step)\n",
            "I0205 13:27:07.388213 140689526667136 learning.py:507] global step 1332: loss = 0.7600 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1333: loss = 0.0668 (0.398 sec/step)\n",
            "I0205 13:27:07.789088 140689526667136 learning.py:507] global step 1333: loss = 0.0668 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 1334: loss = 0.0969 (0.415 sec/step)\n",
            "I0205 13:27:08.205816 140689526667136 learning.py:507] global step 1334: loss = 0.0969 (0.415 sec/step)\n",
            "INFO:tensorflow:global step 1335: loss = 0.4474 (0.364 sec/step)\n",
            "I0205 13:27:08.571390 140689526667136 learning.py:507] global step 1335: loss = 0.4474 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 1336: loss = 0.1058 (0.389 sec/step)\n",
            "I0205 13:27:08.962313 140689526667136 learning.py:507] global step 1336: loss = 0.1058 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 1337: loss = 1.0314 (0.378 sec/step)\n",
            "I0205 13:27:09.341603 140689526667136 learning.py:507] global step 1337: loss = 1.0314 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 1338: loss = 0.1161 (0.383 sec/step)\n",
            "I0205 13:27:09.726739 140689526667136 learning.py:507] global step 1338: loss = 0.1161 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 1339: loss = 0.2830 (0.469 sec/step)\n",
            "I0205 13:27:10.197138 140689526667136 learning.py:507] global step 1339: loss = 0.2830 (0.469 sec/step)\n",
            "INFO:tensorflow:global step 1340: loss = 0.2065 (0.367 sec/step)\n",
            "I0205 13:27:10.565410 140689526667136 learning.py:507] global step 1340: loss = 0.2065 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 1341: loss = 0.0612 (0.380 sec/step)\n",
            "I0205 13:27:10.947083 140689526667136 learning.py:507] global step 1341: loss = 0.0612 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1342: loss = 0.0382 (0.383 sec/step)\n",
            "I0205 13:27:11.331770 140689526667136 learning.py:507] global step 1342: loss = 0.0382 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 1343: loss = 0.0637 (0.375 sec/step)\n",
            "I0205 13:27:11.708748 140689526667136 learning.py:507] global step 1343: loss = 0.0637 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 1344: loss = 1.4192 (0.384 sec/step)\n",
            "I0205 13:27:12.094093 140689526667136 learning.py:507] global step 1344: loss = 1.4192 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 1345: loss = 0.3355 (0.378 sec/step)\n",
            "I0205 13:27:12.473897 140689526667136 learning.py:507] global step 1345: loss = 0.3355 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 1346: loss = 0.1743 (0.964 sec/step)\n",
            "I0205 13:27:13.439059 140689526667136 learning.py:507] global step 1346: loss = 0.1743 (0.964 sec/step)\n",
            "INFO:tensorflow:global step 1347: loss = 0.1114 (0.417 sec/step)\n",
            "I0205 13:27:13.858006 140689526667136 learning.py:507] global step 1347: loss = 0.1114 (0.417 sec/step)\n",
            "INFO:tensorflow:global step 1348: loss = 0.2820 (0.381 sec/step)\n",
            "I0205 13:27:14.240652 140689526667136 learning.py:507] global step 1348: loss = 0.2820 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1349: loss = 0.1828 (0.372 sec/step)\n",
            "I0205 13:27:14.614516 140689526667136 learning.py:507] global step 1349: loss = 0.1828 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 1350: loss = 0.2333 (0.393 sec/step)\n",
            "I0205 13:27:15.008841 140689526667136 learning.py:507] global step 1350: loss = 0.2333 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 1351: loss = 1.4485 (0.377 sec/step)\n",
            "I0205 13:27:15.387360 140689526667136 learning.py:507] global step 1351: loss = 1.4485 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 1352: loss = 0.1446 (0.365 sec/step)\n",
            "I0205 13:27:15.753930 140689526667136 learning.py:507] global step 1352: loss = 0.1446 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 1353: loss = 0.2893 (0.370 sec/step)\n",
            "I0205 13:27:16.125935 140689526667136 learning.py:507] global step 1353: loss = 0.2893 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 1354: loss = 0.3718 (2.155 sec/step)\n",
            "I0205 13:27:18.282670 140689526667136 learning.py:507] global step 1354: loss = 0.3718 (2.155 sec/step)\n",
            "INFO:tensorflow:global step 1355: loss = 0.0353 (0.383 sec/step)\n",
            "I0205 13:27:18.667351 140689526667136 learning.py:507] global step 1355: loss = 0.0353 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 1356: loss = 0.0849 (0.405 sec/step)\n",
            "I0205 13:27:19.073856 140689526667136 learning.py:507] global step 1356: loss = 0.0849 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 1357: loss = 1.2290 (0.392 sec/step)\n",
            "I0205 13:27:19.467569 140689526667136 learning.py:507] global step 1357: loss = 1.2290 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 1358: loss = 0.0883 (0.392 sec/step)\n",
            "I0205 13:27:19.861540 140689526667136 learning.py:507] global step 1358: loss = 0.0883 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 1359: loss = 0.1619 (0.381 sec/step)\n",
            "I0205 13:27:20.243907 140689526667136 learning.py:507] global step 1359: loss = 0.1619 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1360: loss = 0.1405 (0.367 sec/step)\n",
            "I0205 13:27:20.612408 140689526667136 learning.py:507] global step 1360: loss = 0.1405 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 1361: loss = 0.3354 (0.385 sec/step)\n",
            "I0205 13:27:20.998656 140689526667136 learning.py:507] global step 1361: loss = 0.3354 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 1362: loss = 0.1588 (0.364 sec/step)\n",
            "I0205 13:27:21.363904 140689526667136 learning.py:507] global step 1362: loss = 0.1588 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 1363: loss = 0.2002 (0.371 sec/step)\n",
            "I0205 13:27:21.736782 140689526667136 learning.py:507] global step 1363: loss = 0.2002 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 1364: loss = 0.5421 (0.399 sec/step)\n",
            "I0205 13:27:22.137710 140689526667136 learning.py:507] global step 1364: loss = 0.5421 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 1365: loss = 0.3217 (0.383 sec/step)\n",
            "I0205 13:27:22.522679 140689526667136 learning.py:507] global step 1365: loss = 0.3217 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 1366: loss = 0.2733 (0.378 sec/step)\n",
            "I0205 13:27:22.902327 140689526667136 learning.py:507] global step 1366: loss = 0.2733 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 1367: loss = 0.5939 (0.397 sec/step)\n",
            "I0205 13:27:23.301510 140689526667136 learning.py:507] global step 1367: loss = 0.5939 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 1368: loss = 0.1800 (0.373 sec/step)\n",
            "I0205 13:27:23.676074 140689526667136 learning.py:507] global step 1368: loss = 0.1800 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 1369: loss = 0.1709 (0.373 sec/step)\n",
            "I0205 13:27:24.050678 140689526667136 learning.py:507] global step 1369: loss = 0.1709 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 1370: loss = 0.1067 (0.463 sec/step)\n",
            "I0205 13:27:24.515986 140689526667136 learning.py:507] global step 1370: loss = 0.1067 (0.463 sec/step)\n",
            "INFO:tensorflow:global step 1371: loss = 0.2179 (0.381 sec/step)\n",
            "I0205 13:27:24.898724 140689526667136 learning.py:507] global step 1371: loss = 0.2179 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1372: loss = 0.1805 (0.385 sec/step)\n",
            "I0205 13:27:25.284919 140689526667136 learning.py:507] global step 1372: loss = 0.1805 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 1373: loss = 0.4205 (0.368 sec/step)\n",
            "I0205 13:27:25.654848 140689526667136 learning.py:507] global step 1373: loss = 0.4205 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 1374: loss = 0.4204 (0.366 sec/step)\n",
            "I0205 13:27:26.022513 140689526667136 learning.py:507] global step 1374: loss = 0.4204 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 1375: loss = 0.0819 (0.390 sec/step)\n",
            "I0205 13:27:26.414433 140689526667136 learning.py:507] global step 1375: loss = 0.0819 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 1376: loss = 1.1004 (0.418 sec/step)\n",
            "I0205 13:27:26.833869 140689526667136 learning.py:507] global step 1376: loss = 1.1004 (0.418 sec/step)\n",
            "INFO:tensorflow:global step 1377: loss = 0.1268 (0.361 sec/step)\n",
            "I0205 13:27:27.196679 140689526667136 learning.py:507] global step 1377: loss = 0.1268 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 1378: loss = 0.1512 (0.439 sec/step)\n",
            "I0205 13:27:27.637153 140689526667136 learning.py:507] global step 1378: loss = 0.1512 (0.439 sec/step)\n",
            "INFO:tensorflow:global step 1379: loss = 0.4461 (0.383 sec/step)\n",
            "I0205 13:27:28.021530 140689526667136 learning.py:507] global step 1379: loss = 0.4461 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 1380: loss = 0.1447 (0.388 sec/step)\n",
            "I0205 13:27:28.410988 140689526667136 learning.py:507] global step 1380: loss = 0.1447 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 1381: loss = 0.0796 (0.354 sec/step)\n",
            "I0205 13:27:28.767017 140689526667136 learning.py:507] global step 1381: loss = 0.0796 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 1382: loss = 0.4581 (0.370 sec/step)\n",
            "I0205 13:27:29.139191 140689526667136 learning.py:507] global step 1382: loss = 0.4581 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 1383: loss = 0.5065 (0.407 sec/step)\n",
            "I0205 13:27:29.548581 140689526667136 learning.py:507] global step 1383: loss = 0.5065 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 1384: loss = 0.0383 (0.410 sec/step)\n",
            "I0205 13:27:29.960152 140689526667136 learning.py:507] global step 1384: loss = 0.0383 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 1385: loss = 0.3049 (0.395 sec/step)\n",
            "I0205 13:27:30.357547 140689526667136 learning.py:507] global step 1385: loss = 0.3049 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 1386: loss = 0.3466 (0.374 sec/step)\n",
            "I0205 13:27:30.733480 140689526667136 learning.py:507] global step 1386: loss = 0.3466 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 1387: loss = 0.1633 (0.365 sec/step)\n",
            "I0205 13:27:31.099954 140689526667136 learning.py:507] global step 1387: loss = 0.1633 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 1388: loss = 0.2230 (0.375 sec/step)\n",
            "I0205 13:27:31.476823 140689526667136 learning.py:507] global step 1388: loss = 0.2230 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 1389: loss = 0.3476 (0.382 sec/step)\n",
            "I0205 13:27:31.861258 140689526667136 learning.py:507] global step 1389: loss = 0.3476 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 1390: loss = 0.1209 (0.378 sec/step)\n",
            "I0205 13:27:32.240668 140689526667136 learning.py:507] global step 1390: loss = 0.1209 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 1391: loss = 0.4633 (0.382 sec/step)\n",
            "I0205 13:27:32.624243 140689526667136 learning.py:507] global step 1391: loss = 0.4633 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 1392: loss = 0.1756 (0.386 sec/step)\n",
            "I0205 13:27:33.012117 140689526667136 learning.py:507] global step 1392: loss = 0.1756 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 1393: loss = 0.3534 (0.398 sec/step)\n",
            "I0205 13:27:33.412364 140689526667136 learning.py:507] global step 1393: loss = 0.3534 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 1394: loss = 0.1091 (0.387 sec/step)\n",
            "I0205 13:27:33.801270 140689526667136 learning.py:507] global step 1394: loss = 0.1091 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 1395: loss = 0.0605 (0.396 sec/step)\n",
            "I0205 13:27:34.199295 140689526667136 learning.py:507] global step 1395: loss = 0.0605 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 1396: loss = 0.2885 (0.398 sec/step)\n",
            "I0205 13:27:34.599348 140689526667136 learning.py:507] global step 1396: loss = 0.2885 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 1397: loss = 0.1489 (0.378 sec/step)\n",
            "I0205 13:27:34.979508 140689526667136 learning.py:507] global step 1397: loss = 0.1489 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 1398: loss = 0.0640 (0.387 sec/step)\n",
            "I0205 13:27:35.367666 140689526667136 learning.py:507] global step 1398: loss = 0.0640 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 1399: loss = 0.2488 (0.393 sec/step)\n",
            "I0205 13:27:35.762359 140689526667136 learning.py:507] global step 1399: loss = 0.2488 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 1400: loss = 0.4708 (0.396 sec/step)\n",
            "I0205 13:27:36.159696 140689526667136 learning.py:507] global step 1400: loss = 0.4708 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 1401: loss = 0.1581 (0.397 sec/step)\n",
            "I0205 13:27:36.558731 140689526667136 learning.py:507] global step 1401: loss = 0.1581 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 1402: loss = 0.2201 (0.372 sec/step)\n",
            "I0205 13:27:36.932427 140689526667136 learning.py:507] global step 1402: loss = 0.2201 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 1403: loss = 0.2728 (0.368 sec/step)\n",
            "I0205 13:27:37.301830 140689526667136 learning.py:507] global step 1403: loss = 0.2728 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 1404: loss = 0.2744 (0.373 sec/step)\n",
            "I0205 13:27:37.676784 140689526667136 learning.py:507] global step 1404: loss = 0.2744 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 1405: loss = 0.2903 (0.388 sec/step)\n",
            "I0205 13:27:38.066564 140689526667136 learning.py:507] global step 1405: loss = 0.2903 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 1406: loss = 0.1287 (0.384 sec/step)\n",
            "I0205 13:27:38.452713 140689526667136 learning.py:507] global step 1406: loss = 0.1287 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 1407: loss = 0.2745 (0.389 sec/step)\n",
            "I0205 13:27:38.843304 140689526667136 learning.py:507] global step 1407: loss = 0.2745 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 1408: loss = 0.1821 (0.357 sec/step)\n",
            "I0205 13:27:39.201969 140689526667136 learning.py:507] global step 1408: loss = 0.1821 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 1409: loss = 0.2359 (0.400 sec/step)\n",
            "I0205 13:27:39.603713 140689526667136 learning.py:507] global step 1409: loss = 0.2359 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 1410: loss = 0.1694 (0.390 sec/step)\n",
            "I0205 13:27:39.995467 140689526667136 learning.py:507] global step 1410: loss = 0.1694 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 1411: loss = 0.1664 (0.383 sec/step)\n",
            "I0205 13:27:40.380123 140689526667136 learning.py:507] global step 1411: loss = 0.1664 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 1412: loss = 0.3168 (0.389 sec/step)\n",
            "I0205 13:27:40.770649 140689526667136 learning.py:507] global step 1412: loss = 0.3168 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 1413: loss = 0.5514 (0.439 sec/step)\n",
            "I0205 13:27:41.211724 140689526667136 learning.py:507] global step 1413: loss = 0.5514 (0.439 sec/step)\n",
            "INFO:tensorflow:global step 1414: loss = 0.1894 (0.342 sec/step)\n",
            "I0205 13:27:41.555754 140689526667136 learning.py:507] global step 1414: loss = 0.1894 (0.342 sec/step)\n",
            "INFO:tensorflow:global step 1415: loss = 1.1866 (0.389 sec/step)\n",
            "I0205 13:27:41.946831 140689526667136 learning.py:507] global step 1415: loss = 1.1866 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 1416: loss = 0.2865 (0.381 sec/step)\n",
            "I0205 13:27:42.329491 140689526667136 learning.py:507] global step 1416: loss = 0.2865 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1417: loss = 0.0811 (0.357 sec/step)\n",
            "I0205 13:27:42.688029 140689526667136 learning.py:507] global step 1417: loss = 0.0811 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 1418: loss = 0.2215 (0.351 sec/step)\n",
            "I0205 13:27:43.040595 140689526667136 learning.py:507] global step 1418: loss = 0.2215 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 1419: loss = 0.1786 (0.380 sec/step)\n",
            "I0205 13:27:43.422531 140689526667136 learning.py:507] global step 1419: loss = 0.1786 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1420: loss = 0.0287 (0.393 sec/step)\n",
            "I0205 13:27:43.817475 140689526667136 learning.py:507] global step 1420: loss = 0.0287 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 1421: loss = 0.1505 (0.384 sec/step)\n",
            "I0205 13:27:44.203135 140689526667136 learning.py:507] global step 1421: loss = 0.1505 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 1422: loss = 0.4970 (0.368 sec/step)\n",
            "I0205 13:27:44.572298 140689526667136 learning.py:507] global step 1422: loss = 0.4970 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 1423: loss = 0.1825 (0.382 sec/step)\n",
            "I0205 13:27:44.955469 140689526667136 learning.py:507] global step 1423: loss = 0.1825 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 1424: loss = 0.2214 (0.392 sec/step)\n",
            "I0205 13:27:45.349688 140689526667136 learning.py:507] global step 1424: loss = 0.2214 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 1425: loss = 0.3097 (0.369 sec/step)\n",
            "I0205 13:27:45.720636 140689526667136 learning.py:507] global step 1425: loss = 0.3097 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 1426: loss = 0.2376 (0.381 sec/step)\n",
            "I0205 13:27:46.102757 140689526667136 learning.py:507] global step 1426: loss = 0.2376 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1427: loss = 0.0698 (0.375 sec/step)\n",
            "I0205 13:27:46.479333 140689526667136 learning.py:507] global step 1427: loss = 0.0698 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 1428: loss = 0.1352 (0.380 sec/step)\n",
            "I0205 13:27:46.860799 140689526667136 learning.py:507] global step 1428: loss = 0.1352 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1429: loss = 0.1610 (0.394 sec/step)\n",
            "I0205 13:27:47.256879 140689526667136 learning.py:507] global step 1429: loss = 0.1610 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 1430: loss = 0.0963 (0.388 sec/step)\n",
            "I0205 13:27:47.646327 140689526667136 learning.py:507] global step 1430: loss = 0.0963 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 1431: loss = 0.0446 (0.384 sec/step)\n",
            "I0205 13:27:48.032413 140689526667136 learning.py:507] global step 1431: loss = 0.0446 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 1432: loss = 1.1649 (0.396 sec/step)\n",
            "I0205 13:27:48.430229 140689526667136 learning.py:507] global step 1432: loss = 1.1649 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 1433: loss = 0.1082 (0.403 sec/step)\n",
            "I0205 13:27:48.834824 140689526667136 learning.py:507] global step 1433: loss = 0.1082 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 1434: loss = 0.1840 (0.380 sec/step)\n",
            "I0205 13:27:49.216519 140689526667136 learning.py:507] global step 1434: loss = 0.1840 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1435: loss = 1.6268 (0.390 sec/step)\n",
            "I0205 13:27:49.607681 140689526667136 learning.py:507] global step 1435: loss = 1.6268 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 1436: loss = 0.2257 (0.401 sec/step)\n",
            "I0205 13:27:50.010104 140689526667136 learning.py:507] global step 1436: loss = 0.2257 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 1437: loss = 0.1607 (0.360 sec/step)\n",
            "I0205 13:27:50.371647 140689526667136 learning.py:507] global step 1437: loss = 0.1607 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 1438: loss = 0.1107 (0.355 sec/step)\n",
            "I0205 13:27:50.728399 140689526667136 learning.py:507] global step 1438: loss = 0.1107 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 1439: loss = 1.2075 (0.359 sec/step)\n",
            "I0205 13:27:51.089252 140689526667136 learning.py:507] global step 1439: loss = 1.2075 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 1440: loss = 0.1069 (0.385 sec/step)\n",
            "I0205 13:27:51.476142 140689526667136 learning.py:507] global step 1440: loss = 0.1069 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 1441: loss = 0.1727 (0.365 sec/step)\n",
            "I0205 13:27:51.843011 140689526667136 learning.py:507] global step 1441: loss = 0.1727 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 1442: loss = 0.0708 (0.361 sec/step)\n",
            "I0205 13:27:52.205947 140689526667136 learning.py:507] global step 1442: loss = 0.0708 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 1443: loss = 0.2636 (0.439 sec/step)\n",
            "I0205 13:27:52.646914 140689526667136 learning.py:507] global step 1443: loss = 0.2636 (0.439 sec/step)\n",
            "INFO:tensorflow:global step 1444: loss = 0.1196 (0.412 sec/step)\n",
            "I0205 13:27:53.060366 140689526667136 learning.py:507] global step 1444: loss = 0.1196 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 1445: loss = 0.2179 (0.385 sec/step)\n",
            "I0205 13:27:53.446790 140689526667136 learning.py:507] global step 1445: loss = 0.2179 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 1446: loss = 0.1825 (0.381 sec/step)\n",
            "I0205 13:27:53.829216 140689526667136 learning.py:507] global step 1446: loss = 0.1825 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1447: loss = 0.1920 (0.399 sec/step)\n",
            "I0205 13:27:54.230280 140689526667136 learning.py:507] global step 1447: loss = 0.1920 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 1448: loss = 0.4288 (0.378 sec/step)\n",
            "I0205 13:27:54.609788 140689526667136 learning.py:507] global step 1448: loss = 0.4288 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 1449: loss = 0.0982 (0.389 sec/step)\n",
            "I0205 13:27:55.000952 140689526667136 learning.py:507] global step 1449: loss = 0.0982 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 1450: loss = 0.0711 (0.384 sec/step)\n",
            "I0205 13:27:55.386965 140689526667136 learning.py:507] global step 1450: loss = 0.0711 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 1451: loss = 0.3366 (0.397 sec/step)\n",
            "I0205 13:27:55.786031 140689526667136 learning.py:507] global step 1451: loss = 0.3366 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 1452: loss = 0.3502 (0.379 sec/step)\n",
            "I0205 13:27:56.167232 140689526667136 learning.py:507] global step 1452: loss = 0.3502 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 1453: loss = 0.4511 (0.370 sec/step)\n",
            "I0205 13:27:56.538922 140689526667136 learning.py:507] global step 1453: loss = 0.4511 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 1454: loss = 0.1831 (0.382 sec/step)\n",
            "I0205 13:27:56.922704 140689526667136 learning.py:507] global step 1454: loss = 0.1831 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 1455: loss = 0.1145 (0.413 sec/step)\n",
            "I0205 13:27:57.337240 140689526667136 learning.py:507] global step 1455: loss = 0.1145 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 1456: loss = 0.2802 (0.391 sec/step)\n",
            "I0205 13:27:57.729812 140689526667136 learning.py:507] global step 1456: loss = 0.2802 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 1457: loss = 0.1499 (0.369 sec/step)\n",
            "I0205 13:27:58.100153 140689526667136 learning.py:507] global step 1457: loss = 0.1499 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 1458: loss = 0.8417 (0.370 sec/step)\n",
            "I0205 13:27:58.471701 140689526667136 learning.py:507] global step 1458: loss = 0.8417 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 1459: loss = 0.0538 (0.407 sec/step)\n",
            "I0205 13:27:58.880497 140689526667136 learning.py:507] global step 1459: loss = 0.0538 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 1460: loss = 0.0595 (0.414 sec/step)\n",
            "I0205 13:27:59.295636 140689526667136 learning.py:507] global step 1460: loss = 0.0595 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 1461: loss = 0.5344 (0.383 sec/step)\n",
            "I0205 13:27:59.680357 140689526667136 learning.py:507] global step 1461: loss = 0.5344 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 1462: loss = 0.1928 (0.381 sec/step)\n",
            "I0205 13:28:00.062845 140689526667136 learning.py:507] global step 1462: loss = 0.1928 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1463: loss = 0.2562 (0.353 sec/step)\n",
            "I0205 13:28:00.418292 140689526667136 learning.py:507] global step 1463: loss = 0.2562 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 1464: loss = 0.1253 (0.380 sec/step)\n",
            "I0205 13:28:00.800281 140689526667136 learning.py:507] global step 1464: loss = 0.1253 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1465: loss = 0.2928 (0.397 sec/step)\n",
            "I0205 13:28:01.199100 140689526667136 learning.py:507] global step 1465: loss = 0.2928 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 1466: loss = 0.0821 (0.464 sec/step)\n",
            "I0205 13:28:01.664661 140689526667136 learning.py:507] global step 1466: loss = 0.0821 (0.464 sec/step)\n",
            "INFO:tensorflow:global step 1467: loss = 1.3205 (0.373 sec/step)\n",
            "I0205 13:28:02.039517 140689526667136 learning.py:507] global step 1467: loss = 1.3205 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 1468: loss = 0.1586 (0.349 sec/step)\n",
            "I0205 13:28:02.389869 140689526667136 learning.py:507] global step 1468: loss = 0.1586 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 1469: loss = 0.2355 (0.388 sec/step)\n",
            "I0205 13:28:02.779208 140689526667136 learning.py:507] global step 1469: loss = 0.2355 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 1470: loss = 0.0926 (0.380 sec/step)\n",
            "I0205 13:28:03.160656 140689526667136 learning.py:507] global step 1470: loss = 0.0926 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1471: loss = 0.1239 (1.636 sec/step)\n",
            "I0205 13:28:04.797747 140689526667136 learning.py:507] global step 1471: loss = 0.1239 (1.636 sec/step)\n",
            "INFO:tensorflow:global step 1472: loss = 0.2743 (0.379 sec/step)\n",
            "I0205 13:28:05.178423 140689526667136 learning.py:507] global step 1472: loss = 0.2743 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 1473: loss = 0.2517 (0.387 sec/step)\n",
            "I0205 13:28:05.567134 140689526667136 learning.py:507] global step 1473: loss = 0.2517 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 1474: loss = 0.1860 (0.351 sec/step)\n",
            "I0205 13:28:05.920013 140689526667136 learning.py:507] global step 1474: loss = 0.1860 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 1475: loss = 0.1846 (0.379 sec/step)\n",
            "I0205 13:28:06.300803 140689526667136 learning.py:507] global step 1475: loss = 0.1846 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 1476: loss = 0.1213 (0.364 sec/step)\n",
            "I0205 13:28:06.666805 140689526667136 learning.py:507] global step 1476: loss = 0.1213 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 1477: loss = 0.2764 (0.402 sec/step)\n",
            "I0205 13:28:07.070209 140689526667136 learning.py:507] global step 1477: loss = 0.2764 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 1478: loss = 0.2668 (0.394 sec/step)\n",
            "I0205 13:28:07.466176 140689526667136 learning.py:507] global step 1478: loss = 0.2668 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 1479: loss = 0.1249 (0.379 sec/step)\n",
            "I0205 13:28:07.846290 140689526667136 learning.py:507] global step 1479: loss = 0.1249 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 1480: loss = 0.1965 (0.366 sec/step)\n",
            "I0205 13:28:08.213502 140689526667136 learning.py:507] global step 1480: loss = 0.1965 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 1481: loss = 0.9683 (0.392 sec/step)\n",
            "I0205 13:28:08.607279 140689526667136 learning.py:507] global step 1481: loss = 0.9683 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 1482: loss = 0.0406 (0.381 sec/step)\n",
            "I0205 13:28:08.990279 140689526667136 learning.py:507] global step 1482: loss = 0.0406 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1483: loss = 0.4901 (0.372 sec/step)\n",
            "I0205 13:28:09.365645 140689526667136 learning.py:507] global step 1483: loss = 0.4901 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 1484: loss = 0.0465 (0.359 sec/step)\n",
            "I0205 13:28:09.726658 140689526667136 learning.py:507] global step 1484: loss = 0.0465 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 1485: loss = 0.1226 (0.365 sec/step)\n",
            "I0205 13:28:10.093231 140689526667136 learning.py:507] global step 1485: loss = 0.1226 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 1486: loss = 0.4606 (0.390 sec/step)\n",
            "I0205 13:28:10.485026 140689526667136 learning.py:507] global step 1486: loss = 0.4606 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 1487: loss = 0.1688 (0.369 sec/step)\n",
            "I0205 13:28:10.855700 140689526667136 learning.py:507] global step 1487: loss = 0.1688 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 1488: loss = 0.1332 (0.361 sec/step)\n",
            "I0205 13:28:11.219716 140689526667136 learning.py:507] global step 1488: loss = 0.1332 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 1489: loss = 0.1689 (0.372 sec/step)\n",
            "I0205 13:28:11.593005 140689526667136 learning.py:507] global step 1489: loss = 0.1689 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 1490: loss = 0.3162 (0.380 sec/step)\n",
            "I0205 13:28:11.974605 140689526667136 learning.py:507] global step 1490: loss = 0.3162 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1491: loss = 0.1351 (0.359 sec/step)\n",
            "I0205 13:28:12.335389 140689526667136 learning.py:507] global step 1491: loss = 0.1351 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 1492: loss = 0.3765 (0.391 sec/step)\n",
            "I0205 13:28:12.728151 140689526667136 learning.py:507] global step 1492: loss = 0.3765 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 1493: loss = 0.1655 (0.360 sec/step)\n",
            "I0205 13:28:13.089457 140689526667136 learning.py:507] global step 1493: loss = 0.1655 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 1494: loss = 0.0826 (0.438 sec/step)\n",
            "I0205 13:28:13.529199 140689526667136 learning.py:507] global step 1494: loss = 0.0826 (0.438 sec/step)\n",
            "INFO:tensorflow:global step 1495: loss = 0.5432 (0.460 sec/step)\n",
            "I0205 13:28:13.995897 140689526667136 learning.py:507] global step 1495: loss = 0.5432 (0.460 sec/step)\n",
            "INFO:tensorflow:global step 1496: loss = 0.1327 (0.877 sec/step)\n",
            "I0205 13:28:15.210340 140689526667136 learning.py:507] global step 1496: loss = 0.1327 (0.877 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 2.3993\n",
            "I0205 13:28:15.926387 140686034466560 supervisor.py:1099] global_step/sec: 2.3993\n",
            "INFO:tensorflow:global step 1497: loss = 0.2835 (0.616 sec/step)\n",
            "I0205 13:28:15.944621 140689526667136 learning.py:507] global step 1497: loss = 0.2835 (0.616 sec/step)\n",
            "INFO:tensorflow:global step 1498: loss = 1.5232 (0.583 sec/step)\n",
            "I0205 13:28:16.561664 140689526667136 learning.py:507] global step 1498: loss = 1.5232 (0.583 sec/step)\n",
            "INFO:tensorflow:global step 1499: loss = 0.0738 (0.663 sec/step)\n",
            "I0205 13:28:17.240303 140689526667136 learning.py:507] global step 1499: loss = 0.0738 (0.663 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 1499.\n",
            "I0205 13:28:17.346756 140686026073856 supervisor.py:1050] Recording summary at step 1499.\n",
            "INFO:tensorflow:global step 1500: loss = 0.0977 (0.453 sec/step)\n",
            "I0205 13:28:17.694915 140689526667136 learning.py:507] global step 1500: loss = 0.0977 (0.453 sec/step)\n",
            "INFO:tensorflow:global step 1501: loss = 0.4325 (0.349 sec/step)\n",
            "I0205 13:28:18.045767 140689526667136 learning.py:507] global step 1501: loss = 0.4325 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 1502: loss = 0.0974 (0.379 sec/step)\n",
            "I0205 13:28:18.425860 140689526667136 learning.py:507] global step 1502: loss = 0.0974 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 1503: loss = 0.2406 (0.983 sec/step)\n",
            "I0205 13:28:19.410017 140689526667136 learning.py:507] global step 1503: loss = 0.2406 (0.983 sec/step)\n",
            "INFO:tensorflow:global step 1504: loss = 1.0379 (0.396 sec/step)\n",
            "I0205 13:28:19.807195 140689526667136 learning.py:507] global step 1504: loss = 1.0379 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 1505: loss = 0.1399 (0.389 sec/step)\n",
            "I0205 13:28:20.197455 140689526667136 learning.py:507] global step 1505: loss = 0.1399 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 1506: loss = 0.5207 (0.391 sec/step)\n",
            "I0205 13:28:20.589990 140689526667136 learning.py:507] global step 1506: loss = 0.5207 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 1507: loss = 0.1055 (0.388 sec/step)\n",
            "I0205 13:28:20.979269 140689526667136 learning.py:507] global step 1507: loss = 0.1055 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 1508: loss = 0.2221 (0.404 sec/step)\n",
            "I0205 13:28:21.385149 140689526667136 learning.py:507] global step 1508: loss = 0.2221 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 1509: loss = 0.2322 (0.433 sec/step)\n",
            "I0205 13:28:21.819902 140689526667136 learning.py:507] global step 1509: loss = 0.2322 (0.433 sec/step)\n",
            "INFO:tensorflow:global step 1510: loss = 0.2279 (0.393 sec/step)\n",
            "I0205 13:28:22.214521 140689526667136 learning.py:507] global step 1510: loss = 0.2279 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 1511: loss = 0.2709 (0.367 sec/step)\n",
            "I0205 13:28:22.583334 140689526667136 learning.py:507] global step 1511: loss = 0.2709 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 1512: loss = 0.2441 (0.394 sec/step)\n",
            "I0205 13:28:22.978651 140689526667136 learning.py:507] global step 1512: loss = 0.2441 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 1513: loss = 0.1515 (0.360 sec/step)\n",
            "I0205 13:28:23.340235 140689526667136 learning.py:507] global step 1513: loss = 0.1515 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 1514: loss = 0.1537 (0.394 sec/step)\n",
            "I0205 13:28:23.735813 140689526667136 learning.py:507] global step 1514: loss = 0.1537 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 1515: loss = 0.1866 (1.643 sec/step)\n",
            "I0205 13:28:25.380133 140689526667136 learning.py:507] global step 1515: loss = 0.1866 (1.643 sec/step)\n",
            "INFO:tensorflow:global step 1516: loss = 0.0394 (0.458 sec/step)\n",
            "I0205 13:28:25.839266 140689526667136 learning.py:507] global step 1516: loss = 0.0394 (0.458 sec/step)\n",
            "INFO:tensorflow:global step 1517: loss = 0.4463 (0.360 sec/step)\n",
            "I0205 13:28:26.201011 140689526667136 learning.py:507] global step 1517: loss = 0.4463 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 1518: loss = 0.1621 (0.459 sec/step)\n",
            "I0205 13:28:26.661885 140689526667136 learning.py:507] global step 1518: loss = 0.1621 (0.459 sec/step)\n",
            "INFO:tensorflow:global step 1519: loss = 0.2582 (0.356 sec/step)\n",
            "I0205 13:28:27.019081 140689526667136 learning.py:507] global step 1519: loss = 0.2582 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 1520: loss = 0.2877 (0.389 sec/step)\n",
            "I0205 13:28:27.409138 140689526667136 learning.py:507] global step 1520: loss = 0.2877 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 1521: loss = 0.0909 (0.416 sec/step)\n",
            "I0205 13:28:27.826352 140689526667136 learning.py:507] global step 1521: loss = 0.0909 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 1522: loss = 0.2329 (0.380 sec/step)\n",
            "I0205 13:28:28.208433 140689526667136 learning.py:507] global step 1522: loss = 0.2329 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1523: loss = 0.1166 (0.395 sec/step)\n",
            "I0205 13:28:28.605013 140689526667136 learning.py:507] global step 1523: loss = 0.1166 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 1524: loss = 0.0668 (0.366 sec/step)\n",
            "I0205 13:28:28.972528 140689526667136 learning.py:507] global step 1524: loss = 0.0668 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 1525: loss = 0.0660 (0.362 sec/step)\n",
            "I0205 13:28:29.335785 140689526667136 learning.py:507] global step 1525: loss = 0.0660 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 1526: loss = 0.2951 (0.407 sec/step)\n",
            "I0205 13:28:29.744009 140689526667136 learning.py:507] global step 1526: loss = 0.2951 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 1527: loss = 0.4511 (0.415 sec/step)\n",
            "I0205 13:28:30.161425 140689526667136 learning.py:507] global step 1527: loss = 0.4511 (0.415 sec/step)\n",
            "INFO:tensorflow:global step 1528: loss = 0.5300 (0.373 sec/step)\n",
            "I0205 13:28:30.536025 140689526667136 learning.py:507] global step 1528: loss = 0.5300 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 1529: loss = 0.0720 (0.367 sec/step)\n",
            "I0205 13:28:30.904117 140689526667136 learning.py:507] global step 1529: loss = 0.0720 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 1530: loss = 0.1443 (0.343 sec/step)\n",
            "I0205 13:28:31.248681 140689526667136 learning.py:507] global step 1530: loss = 0.1443 (0.343 sec/step)\n",
            "INFO:tensorflow:global step 1531: loss = 0.0525 (0.374 sec/step)\n",
            "I0205 13:28:31.624492 140689526667136 learning.py:507] global step 1531: loss = 0.0525 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 1532: loss = 0.1837 (0.380 sec/step)\n",
            "I0205 13:28:32.006732 140689526667136 learning.py:507] global step 1532: loss = 0.1837 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1533: loss = 0.2428 (0.370 sec/step)\n",
            "I0205 13:28:32.377794 140689526667136 learning.py:507] global step 1533: loss = 0.2428 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 1534: loss = 0.2126 (0.475 sec/step)\n",
            "I0205 13:28:32.855075 140689526667136 learning.py:507] global step 1534: loss = 0.2126 (0.475 sec/step)\n",
            "INFO:tensorflow:global step 1535: loss = 0.9214 (0.390 sec/step)\n",
            "I0205 13:28:33.246928 140689526667136 learning.py:507] global step 1535: loss = 0.9214 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 1536: loss = 0.0388 (0.381 sec/step)\n",
            "I0205 13:28:33.629215 140689526667136 learning.py:507] global step 1536: loss = 0.0388 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1537: loss = 1.3899 (0.431 sec/step)\n",
            "I0205 13:28:34.062497 140689526667136 learning.py:507] global step 1537: loss = 1.3899 (0.431 sec/step)\n",
            "INFO:tensorflow:global step 1538: loss = 0.1024 (0.359 sec/step)\n",
            "I0205 13:28:34.423031 140689526667136 learning.py:507] global step 1538: loss = 0.1024 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 1539: loss = 0.0727 (0.368 sec/step)\n",
            "I0205 13:28:34.792861 140689526667136 learning.py:507] global step 1539: loss = 0.0727 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 1540: loss = 0.1776 (1.610 sec/step)\n",
            "I0205 13:28:36.404137 140689526667136 learning.py:507] global step 1540: loss = 0.1776 (1.610 sec/step)\n",
            "INFO:tensorflow:global step 1541: loss = 0.1155 (0.357 sec/step)\n",
            "I0205 13:28:36.762485 140689526667136 learning.py:507] global step 1541: loss = 0.1155 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 1542: loss = 0.1912 (0.373 sec/step)\n",
            "I0205 13:28:37.136990 140689526667136 learning.py:507] global step 1542: loss = 0.1912 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 1543: loss = 0.1859 (0.376 sec/step)\n",
            "I0205 13:28:37.513891 140689526667136 learning.py:507] global step 1543: loss = 0.1859 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 1544: loss = 0.2951 (0.395 sec/step)\n",
            "I0205 13:28:37.910047 140689526667136 learning.py:507] global step 1544: loss = 0.2951 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 1545: loss = 0.6830 (0.359 sec/step)\n",
            "I0205 13:28:38.270797 140689526667136 learning.py:507] global step 1545: loss = 0.6830 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 1546: loss = 1.4545 (0.375 sec/step)\n",
            "I0205 13:28:38.647979 140689526667136 learning.py:507] global step 1546: loss = 1.4545 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 1547: loss = 0.4585 (0.361 sec/step)\n",
            "I0205 13:28:39.010660 140689526667136 learning.py:507] global step 1547: loss = 0.4585 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 1548: loss = 0.2021 (0.377 sec/step)\n",
            "I0205 13:28:39.389461 140689526667136 learning.py:507] global step 1548: loss = 0.2021 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 1549: loss = 0.2796 (0.358 sec/step)\n",
            "I0205 13:28:39.748781 140689526667136 learning.py:507] global step 1549: loss = 0.2796 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 1550: loss = 0.4969 (0.386 sec/step)\n",
            "I0205 13:28:40.136070 140689526667136 learning.py:507] global step 1550: loss = 0.4969 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 1551: loss = 0.2442 (0.362 sec/step)\n",
            "I0205 13:28:40.499558 140689526667136 learning.py:507] global step 1551: loss = 0.2442 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 1552: loss = 0.0826 (0.365 sec/step)\n",
            "I0205 13:28:40.866138 140689526667136 learning.py:507] global step 1552: loss = 0.0826 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 1553: loss = 0.0912 (0.379 sec/step)\n",
            "I0205 13:28:41.246372 140689526667136 learning.py:507] global step 1553: loss = 0.0912 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 1554: loss = 0.1743 (0.414 sec/step)\n",
            "I0205 13:28:41.661758 140689526667136 learning.py:507] global step 1554: loss = 0.1743 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 1555: loss = 0.1667 (0.368 sec/step)\n",
            "I0205 13:28:42.031538 140689526667136 learning.py:507] global step 1555: loss = 0.1667 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 1556: loss = 0.0795 (1.931 sec/step)\n",
            "I0205 13:28:43.964292 140689526667136 learning.py:507] global step 1556: loss = 0.0795 (1.931 sec/step)\n",
            "INFO:tensorflow:global step 1557: loss = 0.3269 (0.378 sec/step)\n",
            "I0205 13:28:44.344054 140689526667136 learning.py:507] global step 1557: loss = 0.3269 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 1558: loss = 0.3720 (0.340 sec/step)\n",
            "I0205 13:28:44.685822 140689526667136 learning.py:507] global step 1558: loss = 0.3720 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 1559: loss = 0.6182 (0.365 sec/step)\n",
            "I0205 13:28:45.052942 140689526667136 learning.py:507] global step 1559: loss = 0.6182 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 1560: loss = 0.1752 (1.067 sec/step)\n",
            "I0205 13:28:46.121838 140689526667136 learning.py:507] global step 1560: loss = 0.1752 (1.067 sec/step)\n",
            "INFO:tensorflow:global step 1561: loss = 0.0399 (0.418 sec/step)\n",
            "I0205 13:28:46.542264 140689526667136 learning.py:507] global step 1561: loss = 0.0399 (0.418 sec/step)\n",
            "INFO:tensorflow:global step 1562: loss = 0.0324 (0.376 sec/step)\n",
            "I0205 13:28:46.919879 140689526667136 learning.py:507] global step 1562: loss = 0.0324 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 1563: loss = 0.4451 (0.364 sec/step)\n",
            "I0205 13:28:47.285679 140689526667136 learning.py:507] global step 1563: loss = 0.4451 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 1564: loss = 0.4549 (0.376 sec/step)\n",
            "I0205 13:28:47.663214 140689526667136 learning.py:507] global step 1564: loss = 0.4549 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 1565: loss = 0.2884 (0.366 sec/step)\n",
            "I0205 13:28:48.030231 140689526667136 learning.py:507] global step 1565: loss = 0.2884 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 1566: loss = 0.1235 (0.384 sec/step)\n",
            "I0205 13:28:48.415480 140689526667136 learning.py:507] global step 1566: loss = 0.1235 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 1567: loss = 0.2083 (0.416 sec/step)\n",
            "I0205 13:28:48.832852 140689526667136 learning.py:507] global step 1567: loss = 0.2083 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 1568: loss = 0.0402 (0.377 sec/step)\n",
            "I0205 13:28:49.211959 140689526667136 learning.py:507] global step 1568: loss = 0.0402 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 1569: loss = 0.1190 (0.391 sec/step)\n",
            "I0205 13:28:49.604069 140689526667136 learning.py:507] global step 1569: loss = 0.1190 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 1570: loss = 0.7282 (0.369 sec/step)\n",
            "I0205 13:28:49.974404 140689526667136 learning.py:507] global step 1570: loss = 0.7282 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 1571: loss = 0.1079 (0.387 sec/step)\n",
            "I0205 13:28:50.363509 140689526667136 learning.py:507] global step 1571: loss = 0.1079 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 1572: loss = 0.3787 (0.377 sec/step)\n",
            "I0205 13:28:50.742399 140689526667136 learning.py:507] global step 1572: loss = 0.3787 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 1573: loss = 1.2787 (0.382 sec/step)\n",
            "I0205 13:28:51.125832 140689526667136 learning.py:507] global step 1573: loss = 1.2787 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 1574: loss = 0.2082 (0.391 sec/step)\n",
            "I0205 13:28:51.518383 140689526667136 learning.py:507] global step 1574: loss = 0.2082 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 1575: loss = 0.2412 (0.390 sec/step)\n",
            "I0205 13:28:51.909706 140689526667136 learning.py:507] global step 1575: loss = 0.2412 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 1576: loss = 0.0255 (0.390 sec/step)\n",
            "I0205 13:28:52.301958 140689526667136 learning.py:507] global step 1576: loss = 0.0255 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 1577: loss = 0.1712 (0.431 sec/step)\n",
            "I0205 13:28:52.734477 140689526667136 learning.py:507] global step 1577: loss = 0.1712 (0.431 sec/step)\n",
            "INFO:tensorflow:global step 1578: loss = 0.1322 (0.376 sec/step)\n",
            "I0205 13:28:53.112051 140689526667136 learning.py:507] global step 1578: loss = 0.1322 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 1579: loss = 0.1601 (0.377 sec/step)\n",
            "I0205 13:28:53.490889 140689526667136 learning.py:507] global step 1579: loss = 0.1601 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 1580: loss = 0.1656 (0.376 sec/step)\n",
            "I0205 13:28:53.868607 140689526667136 learning.py:507] global step 1580: loss = 0.1656 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 1581: loss = 0.1208 (0.367 sec/step)\n",
            "I0205 13:28:54.236876 140689526667136 learning.py:507] global step 1581: loss = 0.1208 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 1582: loss = 0.1236 (0.350 sec/step)\n",
            "I0205 13:28:54.588730 140689526667136 learning.py:507] global step 1582: loss = 0.1236 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 1583: loss = 0.3510 (0.367 sec/step)\n",
            "I0205 13:28:54.957940 140689526667136 learning.py:507] global step 1583: loss = 0.3510 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 1584: loss = 0.2966 (0.378 sec/step)\n",
            "I0205 13:28:55.337843 140689526667136 learning.py:507] global step 1584: loss = 0.2966 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 1585: loss = 0.4038 (0.374 sec/step)\n",
            "I0205 13:28:55.712985 140689526667136 learning.py:507] global step 1585: loss = 0.4038 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 1586: loss = 0.5992 (0.360 sec/step)\n",
            "I0205 13:28:56.074795 140689526667136 learning.py:507] global step 1586: loss = 0.5992 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 1587: loss = 0.1196 (0.347 sec/step)\n",
            "I0205 13:28:56.423019 140689526667136 learning.py:507] global step 1587: loss = 0.1196 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 1588: loss = 0.2464 (0.388 sec/step)\n",
            "I0205 13:28:56.812711 140689526667136 learning.py:507] global step 1588: loss = 0.2464 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 1589: loss = 0.2912 (0.377 sec/step)\n",
            "I0205 13:28:57.191289 140689526667136 learning.py:507] global step 1589: loss = 0.2912 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 1590: loss = 0.0569 (0.399 sec/step)\n",
            "I0205 13:28:57.591991 140689526667136 learning.py:507] global step 1590: loss = 0.0569 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 1591: loss = 0.1863 (0.389 sec/step)\n",
            "I0205 13:28:57.982886 140689526667136 learning.py:507] global step 1591: loss = 0.1863 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 1592: loss = 0.4462 (0.378 sec/step)\n",
            "I0205 13:28:58.362224 140689526667136 learning.py:507] global step 1592: loss = 0.4462 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 1593: loss = 0.1660 (0.404 sec/step)\n",
            "I0205 13:28:58.767092 140689526667136 learning.py:507] global step 1593: loss = 0.1660 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 1594: loss = 0.2169 (1.118 sec/step)\n",
            "I0205 13:28:59.886844 140689526667136 learning.py:507] global step 1594: loss = 0.2169 (1.118 sec/step)\n",
            "INFO:tensorflow:global step 1595: loss = 0.3052 (0.390 sec/step)\n",
            "I0205 13:29:00.278877 140689526667136 learning.py:507] global step 1595: loss = 0.3052 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 1596: loss = 0.4209 (0.369 sec/step)\n",
            "I0205 13:29:00.649143 140689526667136 learning.py:507] global step 1596: loss = 0.4209 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 1597: loss = 0.1843 (0.390 sec/step)\n",
            "I0205 13:29:01.040385 140689526667136 learning.py:507] global step 1597: loss = 0.1843 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 1598: loss = 0.3808 (0.367 sec/step)\n",
            "I0205 13:29:01.408926 140689526667136 learning.py:507] global step 1598: loss = 0.3808 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 1599: loss = 0.6512 (0.348 sec/step)\n",
            "I0205 13:29:01.758826 140689526667136 learning.py:507] global step 1599: loss = 0.6512 (0.348 sec/step)\n",
            "INFO:tensorflow:global step 1600: loss = 0.3653 (0.412 sec/step)\n",
            "I0205 13:29:02.173046 140689526667136 learning.py:507] global step 1600: loss = 0.3653 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 1601: loss = 0.3727 (0.381 sec/step)\n",
            "I0205 13:29:02.555662 140689526667136 learning.py:507] global step 1601: loss = 0.3727 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1602: loss = 0.5189 (0.372 sec/step)\n",
            "I0205 13:29:02.929001 140689526667136 learning.py:507] global step 1602: loss = 0.5189 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 1603: loss = 0.1642 (0.388 sec/step)\n",
            "I0205 13:29:03.318569 140689526667136 learning.py:507] global step 1603: loss = 0.1642 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 1604: loss = 0.0263 (0.383 sec/step)\n",
            "I0205 13:29:03.703300 140689526667136 learning.py:507] global step 1604: loss = 0.0263 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 1605: loss = 0.0746 (0.364 sec/step)\n",
            "I0205 13:29:04.068938 140689526667136 learning.py:507] global step 1605: loss = 0.0746 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 1606: loss = 0.1349 (0.375 sec/step)\n",
            "I0205 13:29:04.445760 140689526667136 learning.py:507] global step 1606: loss = 0.1349 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 1607: loss = 0.3267 (0.460 sec/step)\n",
            "I0205 13:29:04.907374 140689526667136 learning.py:507] global step 1607: loss = 0.3267 (0.460 sec/step)\n",
            "INFO:tensorflow:global step 1608: loss = 0.1439 (0.374 sec/step)\n",
            "I0205 13:29:05.282694 140689526667136 learning.py:507] global step 1608: loss = 0.1439 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 1609: loss = 0.4853 (0.378 sec/step)\n",
            "I0205 13:29:05.661993 140689526667136 learning.py:507] global step 1609: loss = 0.4853 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 1610: loss = 0.1103 (0.383 sec/step)\n",
            "I0205 13:29:06.046671 140689526667136 learning.py:507] global step 1610: loss = 0.1103 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 1611: loss = 0.1690 (0.380 sec/step)\n",
            "I0205 13:29:06.428433 140689526667136 learning.py:507] global step 1611: loss = 0.1690 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1612: loss = 0.2720 (0.381 sec/step)\n",
            "I0205 13:29:06.810553 140689526667136 learning.py:507] global step 1612: loss = 0.2720 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1613: loss = 0.1148 (0.388 sec/step)\n",
            "I0205 13:29:07.200128 140689526667136 learning.py:507] global step 1613: loss = 0.1148 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 1614: loss = 0.0889 (0.403 sec/step)\n",
            "I0205 13:29:07.605095 140689526667136 learning.py:507] global step 1614: loss = 0.0889 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 1615: loss = 0.1307 (0.409 sec/step)\n",
            "I0205 13:29:08.016060 140689526667136 learning.py:507] global step 1615: loss = 0.1307 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 1616: loss = 0.3335 (0.380 sec/step)\n",
            "I0205 13:29:08.397765 140689526667136 learning.py:507] global step 1616: loss = 0.3335 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1617: loss = 0.0677 (0.374 sec/step)\n",
            "I0205 13:29:08.773710 140689526667136 learning.py:507] global step 1617: loss = 0.0677 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 1618: loss = 0.0402 (0.380 sec/step)\n",
            "I0205 13:29:09.155062 140689526667136 learning.py:507] global step 1618: loss = 0.0402 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1619: loss = 0.0798 (0.404 sec/step)\n",
            "I0205 13:29:09.560944 140689526667136 learning.py:507] global step 1619: loss = 0.0798 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 1620: loss = 0.1952 (0.366 sec/step)\n",
            "I0205 13:29:09.928281 140689526667136 learning.py:507] global step 1620: loss = 0.1952 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 1621: loss = 0.1526 (0.383 sec/step)\n",
            "I0205 13:29:10.312463 140689526667136 learning.py:507] global step 1621: loss = 0.1526 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 1622: loss = 0.2101 (0.381 sec/step)\n",
            "I0205 13:29:10.694686 140689526667136 learning.py:507] global step 1622: loss = 0.2101 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1623: loss = 0.1948 (0.390 sec/step)\n",
            "I0205 13:29:11.086906 140689526667136 learning.py:507] global step 1623: loss = 0.1948 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 1624: loss = 0.2020 (0.391 sec/step)\n",
            "I0205 13:29:11.479704 140689526667136 learning.py:507] global step 1624: loss = 0.2020 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 1625: loss = 0.2791 (0.359 sec/step)\n",
            "I0205 13:29:11.839943 140689526667136 learning.py:507] global step 1625: loss = 0.2791 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 1626: loss = 0.1370 (0.392 sec/step)\n",
            "I0205 13:29:12.233562 140689526667136 learning.py:507] global step 1626: loss = 0.1370 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 1627: loss = 0.1140 (0.398 sec/step)\n",
            "I0205 13:29:12.633003 140689526667136 learning.py:507] global step 1627: loss = 0.1140 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 1628: loss = 0.6519 (0.392 sec/step)\n",
            "I0205 13:29:13.026161 140689526667136 learning.py:507] global step 1628: loss = 0.6519 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 1629: loss = 0.7654 (0.369 sec/step)\n",
            "I0205 13:29:13.396759 140689526667136 learning.py:507] global step 1629: loss = 0.7654 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 1630: loss = 0.0508 (0.389 sec/step)\n",
            "I0205 13:29:13.786866 140689526667136 learning.py:507] global step 1630: loss = 0.0508 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 1631: loss = 0.2056 (0.389 sec/step)\n",
            "I0205 13:29:14.179186 140689526667136 learning.py:507] global step 1631: loss = 0.2056 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 1632: loss = 0.1052 (0.363 sec/step)\n",
            "I0205 13:29:14.543521 140689526667136 learning.py:507] global step 1632: loss = 0.1052 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 1633: loss = 0.1102 (0.401 sec/step)\n",
            "I0205 13:29:14.946041 140689526667136 learning.py:507] global step 1633: loss = 0.1102 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 1634: loss = 0.3864 (0.394 sec/step)\n",
            "I0205 13:29:15.341797 140689526667136 learning.py:507] global step 1634: loss = 0.3864 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 1635: loss = 0.3000 (0.369 sec/step)\n",
            "I0205 13:29:15.712496 140689526667136 learning.py:507] global step 1635: loss = 0.3000 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 1636: loss = 0.2939 (0.389 sec/step)\n",
            "I0205 13:29:16.103099 140689526667136 learning.py:507] global step 1636: loss = 0.2939 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 1637: loss = 0.2709 (0.381 sec/step)\n",
            "I0205 13:29:16.485571 140689526667136 learning.py:507] global step 1637: loss = 0.2709 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1638: loss = 0.2613 (0.358 sec/step)\n",
            "I0205 13:29:16.844872 140689526667136 learning.py:507] global step 1638: loss = 0.2613 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 1639: loss = 0.1871 (0.364 sec/step)\n",
            "I0205 13:29:17.210404 140689526667136 learning.py:507] global step 1639: loss = 0.1871 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 1640: loss = 0.3066 (0.374 sec/step)\n",
            "I0205 13:29:17.586242 140689526667136 learning.py:507] global step 1640: loss = 0.3066 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 1641: loss = 0.1796 (0.365 sec/step)\n",
            "I0205 13:29:17.952862 140689526667136 learning.py:507] global step 1641: loss = 0.1796 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 1642: loss = 0.1972 (0.395 sec/step)\n",
            "I0205 13:29:18.349797 140689526667136 learning.py:507] global step 1642: loss = 0.1972 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 1643: loss = 0.0413 (0.373 sec/step)\n",
            "I0205 13:29:18.724291 140689526667136 learning.py:507] global step 1643: loss = 0.0413 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 1644: loss = 0.3727 (0.386 sec/step)\n",
            "I0205 13:29:19.112258 140689526667136 learning.py:507] global step 1644: loss = 0.3727 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 1645: loss = 0.3729 (0.394 sec/step)\n",
            "I0205 13:29:19.508241 140689526667136 learning.py:507] global step 1645: loss = 0.3729 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 1646: loss = 0.2109 (0.388 sec/step)\n",
            "I0205 13:29:19.898150 140689526667136 learning.py:507] global step 1646: loss = 0.2109 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 1647: loss = 0.3165 (0.344 sec/step)\n",
            "I0205 13:29:20.244060 140689526667136 learning.py:507] global step 1647: loss = 0.3165 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 1648: loss = 0.3205 (0.372 sec/step)\n",
            "I0205 13:29:20.618100 140689526667136 learning.py:507] global step 1648: loss = 0.3205 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 1649: loss = 0.0786 (0.386 sec/step)\n",
            "I0205 13:29:21.005817 140689526667136 learning.py:507] global step 1649: loss = 0.0786 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 1650: loss = 0.3870 (0.379 sec/step)\n",
            "I0205 13:29:21.386343 140689526667136 learning.py:507] global step 1650: loss = 0.3870 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 1651: loss = 0.0636 (0.342 sec/step)\n",
            "I0205 13:29:21.729992 140689526667136 learning.py:507] global step 1651: loss = 0.0636 (0.342 sec/step)\n",
            "INFO:tensorflow:global step 1652: loss = 0.2120 (0.400 sec/step)\n",
            "I0205 13:29:22.131775 140689526667136 learning.py:507] global step 1652: loss = 0.2120 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 1653: loss = 0.2054 (0.403 sec/step)\n",
            "I0205 13:29:22.536377 140689526667136 learning.py:507] global step 1653: loss = 0.2054 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 1654: loss = 0.2521 (0.379 sec/step)\n",
            "I0205 13:29:22.917575 140689526667136 learning.py:507] global step 1654: loss = 0.2521 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 1655: loss = 0.6452 (0.379 sec/step)\n",
            "I0205 13:29:23.298298 140689526667136 learning.py:507] global step 1655: loss = 0.6452 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 1656: loss = 0.2269 (0.352 sec/step)\n",
            "I0205 13:29:23.652046 140689526667136 learning.py:507] global step 1656: loss = 0.2269 (0.352 sec/step)\n",
            "INFO:tensorflow:global step 1657: loss = 0.0547 (0.382 sec/step)\n",
            "I0205 13:29:24.035832 140689526667136 learning.py:507] global step 1657: loss = 0.0547 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 1658: loss = 0.1448 (0.468 sec/step)\n",
            "I0205 13:29:24.505679 140689526667136 learning.py:507] global step 1658: loss = 0.1448 (0.468 sec/step)\n",
            "INFO:tensorflow:global step 1659: loss = 0.2006 (0.372 sec/step)\n",
            "I0205 13:29:24.878717 140689526667136 learning.py:507] global step 1659: loss = 0.2006 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 1660: loss = 0.2730 (0.381 sec/step)\n",
            "I0205 13:29:25.261108 140689526667136 learning.py:507] global step 1660: loss = 0.2730 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1661: loss = 0.0630 (0.374 sec/step)\n",
            "I0205 13:29:25.637007 140689526667136 learning.py:507] global step 1661: loss = 0.0630 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 1662: loss = 0.0653 (1.566 sec/step)\n",
            "I0205 13:29:27.203826 140689526667136 learning.py:507] global step 1662: loss = 0.0653 (1.566 sec/step)\n",
            "INFO:tensorflow:global step 1663: loss = 0.1005 (0.386 sec/step)\n",
            "I0205 13:29:27.590900 140689526667136 learning.py:507] global step 1663: loss = 0.1005 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 1664: loss = 0.0583 (0.379 sec/step)\n",
            "I0205 13:29:27.971972 140689526667136 learning.py:507] global step 1664: loss = 0.0583 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 1665: loss = 0.2126 (0.362 sec/step)\n",
            "I0205 13:29:28.335566 140689526667136 learning.py:507] global step 1665: loss = 0.2126 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 1666: loss = 0.0709 (0.390 sec/step)\n",
            "I0205 13:29:28.727621 140689526667136 learning.py:507] global step 1666: loss = 0.0709 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 1667: loss = 0.5022 (0.367 sec/step)\n",
            "I0205 13:29:29.096536 140689526667136 learning.py:507] global step 1667: loss = 0.5022 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 1668: loss = 0.2479 (0.415 sec/step)\n",
            "I0205 13:29:29.513785 140689526667136 learning.py:507] global step 1668: loss = 0.2479 (0.415 sec/step)\n",
            "INFO:tensorflow:global step 1669: loss = 0.3346 (0.408 sec/step)\n",
            "I0205 13:29:29.923185 140689526667136 learning.py:507] global step 1669: loss = 0.3346 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 1670: loss = 0.1104 (0.479 sec/step)\n",
            "I0205 13:29:30.403831 140689526667136 learning.py:507] global step 1670: loss = 0.1104 (0.479 sec/step)\n",
            "INFO:tensorflow:global step 1671: loss = 0.1448 (0.376 sec/step)\n",
            "I0205 13:29:30.781240 140689526667136 learning.py:507] global step 1671: loss = 0.1448 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 1672: loss = 0.1593 (0.361 sec/step)\n",
            "I0205 13:29:31.143788 140689526667136 learning.py:507] global step 1672: loss = 0.1593 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 1673: loss = 0.1706 (0.396 sec/step)\n",
            "I0205 13:29:31.541676 140689526667136 learning.py:507] global step 1673: loss = 0.1706 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 1674: loss = 0.1260 (0.337 sec/step)\n",
            "I0205 13:29:31.880317 140689526667136 learning.py:507] global step 1674: loss = 0.1260 (0.337 sec/step)\n",
            "INFO:tensorflow:global step 1675: loss = 0.0954 (0.374 sec/step)\n",
            "I0205 13:29:32.255587 140689526667136 learning.py:507] global step 1675: loss = 0.0954 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 1676: loss = 0.0787 (0.344 sec/step)\n",
            "I0205 13:29:32.605101 140689526667136 learning.py:507] global step 1676: loss = 0.0787 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 1677: loss = 0.2201 (0.382 sec/step)\n",
            "I0205 13:29:32.988437 140689526667136 learning.py:507] global step 1677: loss = 0.2201 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 1678: loss = 0.0306 (0.358 sec/step)\n",
            "I0205 13:29:33.347660 140689526667136 learning.py:507] global step 1678: loss = 0.0306 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 1679: loss = 0.0733 (0.407 sec/step)\n",
            "I0205 13:29:33.758331 140689526667136 learning.py:507] global step 1679: loss = 0.0733 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 1680: loss = 0.2295 (0.400 sec/step)\n",
            "I0205 13:29:34.159726 140689526667136 learning.py:507] global step 1680: loss = 0.2295 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 1681: loss = 0.0457 (0.364 sec/step)\n",
            "I0205 13:29:34.525676 140689526667136 learning.py:507] global step 1681: loss = 0.0457 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 1682: loss = 0.3848 (0.379 sec/step)\n",
            "I0205 13:29:34.906055 140689526667136 learning.py:507] global step 1682: loss = 0.3848 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 1683: loss = 0.1409 (0.360 sec/step)\n",
            "I0205 13:29:35.267919 140689526667136 learning.py:507] global step 1683: loss = 0.1409 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 1684: loss = 0.2381 (0.405 sec/step)\n",
            "I0205 13:29:35.674748 140689526667136 learning.py:507] global step 1684: loss = 0.2381 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 1685: loss = 0.0931 (0.394 sec/step)\n",
            "I0205 13:29:36.071104 140689526667136 learning.py:507] global step 1685: loss = 0.0931 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 1686: loss = 0.3876 (0.371 sec/step)\n",
            "I0205 13:29:36.443544 140689526667136 learning.py:507] global step 1686: loss = 0.3876 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 1687: loss = 0.4504 (0.814 sec/step)\n",
            "I0205 13:29:37.258996 140689526667136 learning.py:507] global step 1687: loss = 0.4504 (0.814 sec/step)\n",
            "INFO:tensorflow:global step 1688: loss = 0.2051 (0.370 sec/step)\n",
            "I0205 13:29:37.631192 140689526667136 learning.py:507] global step 1688: loss = 0.2051 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 1689: loss = 0.1622 (0.380 sec/step)\n",
            "I0205 13:29:38.013094 140689526667136 learning.py:507] global step 1689: loss = 0.1622 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1690: loss = 0.1284 (0.341 sec/step)\n",
            "I0205 13:29:38.356076 140689526667136 learning.py:507] global step 1690: loss = 0.1284 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 1691: loss = 0.1455 (0.346 sec/step)\n",
            "I0205 13:29:38.703770 140689526667136 learning.py:507] global step 1691: loss = 0.1455 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 1692: loss = 0.1476 (0.393 sec/step)\n",
            "I0205 13:29:39.098183 140689526667136 learning.py:507] global step 1692: loss = 0.1476 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 1693: loss = 0.4101 (0.382 sec/step)\n",
            "I0205 13:29:39.481608 140689526667136 learning.py:507] global step 1693: loss = 0.4101 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 1694: loss = 0.1743 (0.391 sec/step)\n",
            "I0205 13:29:39.873693 140689526667136 learning.py:507] global step 1694: loss = 0.1743 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 1695: loss = 0.0640 (0.392 sec/step)\n",
            "I0205 13:29:40.267282 140689526667136 learning.py:507] global step 1695: loss = 0.0640 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 1696: loss = 0.0526 (0.356 sec/step)\n",
            "I0205 13:29:40.625191 140689526667136 learning.py:507] global step 1696: loss = 0.0526 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 1697: loss = 0.0723 (0.382 sec/step)\n",
            "I0205 13:29:41.008735 140689526667136 learning.py:507] global step 1697: loss = 0.0723 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 1698: loss = 0.0194 (0.374 sec/step)\n",
            "I0205 13:29:41.384497 140689526667136 learning.py:507] global step 1698: loss = 0.0194 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 1699: loss = 0.2329 (0.374 sec/step)\n",
            "I0205 13:29:41.760363 140689526667136 learning.py:507] global step 1699: loss = 0.2329 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 1700: loss = 0.0649 (0.370 sec/step)\n",
            "I0205 13:29:42.131733 140689526667136 learning.py:507] global step 1700: loss = 0.0649 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 1701: loss = 0.0663 (0.379 sec/step)\n",
            "I0205 13:29:42.512155 140689526667136 learning.py:507] global step 1701: loss = 0.0663 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 1702: loss = 0.2387 (0.371 sec/step)\n",
            "I0205 13:29:42.885119 140689526667136 learning.py:507] global step 1702: loss = 0.2387 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 1703: loss = 0.1986 (0.380 sec/step)\n",
            "I0205 13:29:43.267001 140689526667136 learning.py:507] global step 1703: loss = 0.1986 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1704: loss = 0.3680 (0.357 sec/step)\n",
            "I0205 13:29:43.625966 140689526667136 learning.py:507] global step 1704: loss = 0.3680 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 1705: loss = 0.0942 (0.392 sec/step)\n",
            "I0205 13:29:44.019641 140689526667136 learning.py:507] global step 1705: loss = 0.0942 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 1706: loss = 0.2882 (0.370 sec/step)\n",
            "I0205 13:29:44.392091 140689526667136 learning.py:507] global step 1706: loss = 0.2882 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 1707: loss = 0.2763 (0.391 sec/step)\n",
            "I0205 13:29:44.784609 140689526667136 learning.py:507] global step 1707: loss = 0.2763 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 1708: loss = 0.1136 (1.055 sec/step)\n",
            "I0205 13:29:45.841290 140689526667136 learning.py:507] global step 1708: loss = 0.1136 (1.055 sec/step)\n",
            "INFO:tensorflow:global step 1709: loss = 0.1683 (0.349 sec/step)\n",
            "I0205 13:29:46.191856 140689526667136 learning.py:507] global step 1709: loss = 0.1683 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 1710: loss = 0.4202 (0.375 sec/step)\n",
            "I0205 13:29:46.568615 140689526667136 learning.py:507] global step 1710: loss = 0.4202 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 1711: loss = 0.4214 (0.358 sec/step)\n",
            "I0205 13:29:46.928062 140689526667136 learning.py:507] global step 1711: loss = 0.4214 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 1712: loss = 0.2422 (0.370 sec/step)\n",
            "I0205 13:29:47.299347 140689526667136 learning.py:507] global step 1712: loss = 0.2422 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 1713: loss = 0.3161 (0.338 sec/step)\n",
            "I0205 13:29:47.638319 140689526667136 learning.py:507] global step 1713: loss = 0.3161 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 1714: loss = 0.1591 (0.348 sec/step)\n",
            "I0205 13:29:47.988262 140689526667136 learning.py:507] global step 1714: loss = 0.1591 (0.348 sec/step)\n",
            "INFO:tensorflow:global step 1715: loss = 0.2074 (0.409 sec/step)\n",
            "I0205 13:29:48.399046 140689526667136 learning.py:507] global step 1715: loss = 0.2074 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 1716: loss = 0.0599 (0.394 sec/step)\n",
            "I0205 13:29:48.795132 140689526667136 learning.py:507] global step 1716: loss = 0.0599 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 1717: loss = 0.1132 (0.384 sec/step)\n",
            "I0205 13:29:49.180576 140689526667136 learning.py:507] global step 1717: loss = 0.1132 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 1718: loss = 0.0793 (0.377 sec/step)\n",
            "I0205 13:29:49.559499 140689526667136 learning.py:507] global step 1718: loss = 0.0793 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 1719: loss = 0.1068 (0.392 sec/step)\n",
            "I0205 13:29:49.952852 140689526667136 learning.py:507] global step 1719: loss = 0.1068 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 1720: loss = 0.1731 (0.399 sec/step)\n",
            "I0205 13:29:50.353596 140689526667136 learning.py:507] global step 1720: loss = 0.1731 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 1721: loss = 0.1266 (0.361 sec/step)\n",
            "I0205 13:29:50.715632 140689526667136 learning.py:507] global step 1721: loss = 0.1266 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 1722: loss = 0.1057 (0.382 sec/step)\n",
            "I0205 13:29:51.098765 140689526667136 learning.py:507] global step 1722: loss = 0.1057 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 1723: loss = 0.1574 (0.396 sec/step)\n",
            "I0205 13:29:51.496315 140689526667136 learning.py:507] global step 1723: loss = 0.1574 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 1724: loss = 0.3906 (0.414 sec/step)\n",
            "I0205 13:29:51.911531 140689526667136 learning.py:507] global step 1724: loss = 0.3906 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 1725: loss = 0.3438 (0.389 sec/step)\n",
            "I0205 13:29:52.301662 140689526667136 learning.py:507] global step 1725: loss = 0.3438 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 1726: loss = 0.1041 (0.416 sec/step)\n",
            "I0205 13:29:52.719690 140689526667136 learning.py:507] global step 1726: loss = 0.1041 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 1727: loss = 0.0808 (0.389 sec/step)\n",
            "I0205 13:29:53.110424 140689526667136 learning.py:507] global step 1727: loss = 0.0808 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 1728: loss = 0.2248 (0.361 sec/step)\n",
            "I0205 13:29:53.473336 140689526667136 learning.py:507] global step 1728: loss = 0.2248 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 1729: loss = 0.2679 (0.375 sec/step)\n",
            "I0205 13:29:53.849708 140689526667136 learning.py:507] global step 1729: loss = 0.2679 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 1730: loss = 0.1017 (0.377 sec/step)\n",
            "I0205 13:29:54.227992 140689526667136 learning.py:507] global step 1730: loss = 0.1017 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 1731: loss = 0.1335 (0.353 sec/step)\n",
            "I0205 13:29:54.583108 140689526667136 learning.py:507] global step 1731: loss = 0.1335 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 1732: loss = 0.2069 (2.328 sec/step)\n",
            "I0205 13:29:56.912810 140689526667136 learning.py:507] global step 1732: loss = 0.2069 (2.328 sec/step)\n",
            "INFO:tensorflow:global step 1733: loss = 0.1469 (0.361 sec/step)\n",
            "I0205 13:29:57.275378 140689526667136 learning.py:507] global step 1733: loss = 0.1469 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 1734: loss = 0.0613 (0.368 sec/step)\n",
            "I0205 13:29:57.645427 140689526667136 learning.py:507] global step 1734: loss = 0.0613 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 1735: loss = 0.0849 (0.386 sec/step)\n",
            "I0205 13:29:58.032542 140689526667136 learning.py:507] global step 1735: loss = 0.0849 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 1736: loss = 0.1708 (0.401 sec/step)\n",
            "I0205 13:29:58.435137 140689526667136 learning.py:507] global step 1736: loss = 0.1708 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 1737: loss = 0.2159 (0.369 sec/step)\n",
            "I0205 13:29:58.806174 140689526667136 learning.py:507] global step 1737: loss = 0.2159 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 1738: loss = 0.0316 (0.387 sec/step)\n",
            "I0205 13:29:59.194789 140689526667136 learning.py:507] global step 1738: loss = 0.0316 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 1739: loss = 0.5372 (0.376 sec/step)\n",
            "I0205 13:29:59.571961 140689526667136 learning.py:507] global step 1739: loss = 0.5372 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 1740: loss = 0.1767 (0.373 sec/step)\n",
            "I0205 13:29:59.946002 140689526667136 learning.py:507] global step 1740: loss = 0.1767 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 1741: loss = 0.2333 (0.365 sec/step)\n",
            "I0205 13:30:00.312160 140689526667136 learning.py:507] global step 1741: loss = 0.2333 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 1742: loss = 0.2524 (0.849 sec/step)\n",
            "I0205 13:30:01.162997 140689526667136 learning.py:507] global step 1742: loss = 0.2524 (0.849 sec/step)\n",
            "INFO:tensorflow:global step 1743: loss = 0.5529 (0.381 sec/step)\n",
            "I0205 13:30:01.545994 140689526667136 learning.py:507] global step 1743: loss = 0.5529 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1744: loss = 0.0946 (0.361 sec/step)\n",
            "I0205 13:30:01.908195 140689526667136 learning.py:507] global step 1744: loss = 0.0946 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 1745: loss = 0.3932 (0.391 sec/step)\n",
            "I0205 13:30:02.300909 140689526667136 learning.py:507] global step 1745: loss = 0.3932 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 1746: loss = 0.1250 (0.360 sec/step)\n",
            "I0205 13:30:02.662123 140689526667136 learning.py:507] global step 1746: loss = 0.1250 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 1747: loss = 0.2485 (0.361 sec/step)\n",
            "I0205 13:30:03.024938 140689526667136 learning.py:507] global step 1747: loss = 0.2485 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 1748: loss = 0.3105 (0.387 sec/step)\n",
            "I0205 13:30:03.413268 140689526667136 learning.py:507] global step 1748: loss = 0.3105 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 1749: loss = 0.1567 (0.367 sec/step)\n",
            "I0205 13:30:03.782148 140689526667136 learning.py:507] global step 1749: loss = 0.1567 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 1750: loss = 0.8621 (0.374 sec/step)\n",
            "I0205 13:30:04.159230 140689526667136 learning.py:507] global step 1750: loss = 0.8621 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 1751: loss = 0.1675 (0.402 sec/step)\n",
            "I0205 13:30:04.563297 140689526667136 learning.py:507] global step 1751: loss = 0.1675 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 1752: loss = 0.2269 (0.390 sec/step)\n",
            "I0205 13:30:04.954742 140689526667136 learning.py:507] global step 1752: loss = 0.2269 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 1753: loss = 0.1748 (0.397 sec/step)\n",
            "I0205 13:30:05.353802 140689526667136 learning.py:507] global step 1753: loss = 0.1748 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 1754: loss = 0.1237 (0.372 sec/step)\n",
            "I0205 13:30:05.727659 140689526667136 learning.py:507] global step 1754: loss = 0.1237 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 1755: loss = 0.1438 (0.394 sec/step)\n",
            "I0205 13:30:06.123256 140689526667136 learning.py:507] global step 1755: loss = 0.1438 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 1756: loss = 0.1609 (0.348 sec/step)\n",
            "I0205 13:30:06.472755 140689526667136 learning.py:507] global step 1756: loss = 0.1609 (0.348 sec/step)\n",
            "INFO:tensorflow:global step 1757: loss = 0.2129 (0.372 sec/step)\n",
            "I0205 13:30:06.846442 140689526667136 learning.py:507] global step 1757: loss = 0.2129 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 1758: loss = 0.1749 (0.374 sec/step)\n",
            "I0205 13:30:07.222091 140689526667136 learning.py:507] global step 1758: loss = 0.1749 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 1759: loss = 0.4217 (0.376 sec/step)\n",
            "I0205 13:30:07.599887 140689526667136 learning.py:507] global step 1759: loss = 0.4217 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 1760: loss = 0.0976 (0.395 sec/step)\n",
            "I0205 13:30:07.996464 140689526667136 learning.py:507] global step 1760: loss = 0.0976 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 1761: loss = 0.0864 (0.397 sec/step)\n",
            "I0205 13:30:08.395610 140689526667136 learning.py:507] global step 1761: loss = 0.0864 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 1762: loss = 0.3145 (0.394 sec/step)\n",
            "I0205 13:30:08.791419 140689526667136 learning.py:507] global step 1762: loss = 0.3145 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 1763: loss = 0.1702 (0.394 sec/step)\n",
            "I0205 13:30:09.187160 140689526667136 learning.py:507] global step 1763: loss = 0.1702 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 1764: loss = 0.1265 (0.392 sec/step)\n",
            "I0205 13:30:09.580919 140689526667136 learning.py:507] global step 1764: loss = 0.1265 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 1765: loss = 0.1094 (0.407 sec/step)\n",
            "I0205 13:30:09.989017 140689526667136 learning.py:507] global step 1765: loss = 0.1094 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 1766: loss = 0.0828 (0.401 sec/step)\n",
            "I0205 13:30:10.391556 140689526667136 learning.py:507] global step 1766: loss = 0.0828 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 1767: loss = 0.1076 (0.378 sec/step)\n",
            "I0205 13:30:10.771371 140689526667136 learning.py:507] global step 1767: loss = 0.1076 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 1768: loss = 0.1400 (0.396 sec/step)\n",
            "I0205 13:30:11.168725 140689526667136 learning.py:507] global step 1768: loss = 0.1400 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 1769: loss = 0.1605 (0.396 sec/step)\n",
            "I0205 13:30:11.566404 140689526667136 learning.py:507] global step 1769: loss = 0.1605 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 1770: loss = 0.5145 (0.381 sec/step)\n",
            "I0205 13:30:11.948513 140689526667136 learning.py:507] global step 1770: loss = 0.5145 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1771: loss = 0.1092 (0.359 sec/step)\n",
            "I0205 13:30:12.308783 140689526667136 learning.py:507] global step 1771: loss = 0.1092 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 1772: loss = 0.1537 (0.405 sec/step)\n",
            "I0205 13:30:12.715442 140689526667136 learning.py:507] global step 1772: loss = 0.1537 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 1773: loss = 0.3288 (0.390 sec/step)\n",
            "I0205 13:30:13.107491 140689526667136 learning.py:507] global step 1773: loss = 0.3288 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 1774: loss = 0.0606 (0.411 sec/step)\n",
            "I0205 13:30:13.520204 140689526667136 learning.py:507] global step 1774: loss = 0.0606 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 1775: loss = 0.1708 (1.334 sec/step)\n",
            "I0205 13:30:14.921347 140689526667136 learning.py:507] global step 1775: loss = 0.1708 (1.334 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 2.31732\n",
            "I0205 13:30:15.892506 140686034466560 supervisor.py:1099] global_step/sec: 2.31732\n",
            "INFO:tensorflow:global step 1776: loss = 0.2239 (0.915 sec/step)\n",
            "I0205 13:30:15.970394 140689526667136 learning.py:507] global step 1776: loss = 0.2239 (0.915 sec/step)\n",
            "INFO:tensorflow:global step 1777: loss = 0.2401 (0.652 sec/step)\n",
            "I0205 13:30:16.782786 140689526667136 learning.py:507] global step 1777: loss = 0.2401 (0.652 sec/step)\n",
            "INFO:tensorflow:global step 1778: loss = 0.0647 (0.519 sec/step)\n",
            "I0205 13:30:17.304440 140689526667136 learning.py:507] global step 1778: loss = 0.0647 (0.519 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 1778.\n",
            "I0205 13:30:17.342998 140686026073856 supervisor.py:1050] Recording summary at step 1778.\n",
            "INFO:tensorflow:global step 1779: loss = 0.3282 (0.421 sec/step)\n",
            "I0205 13:30:17.728922 140689526667136 learning.py:507] global step 1779: loss = 0.3282 (0.421 sec/step)\n",
            "INFO:tensorflow:global step 1780: loss = 0.3636 (0.395 sec/step)\n",
            "I0205 13:30:18.125705 140689526667136 learning.py:507] global step 1780: loss = 0.3636 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 1781: loss = 1.1345 (0.351 sec/step)\n",
            "I0205 13:30:18.478483 140689526667136 learning.py:507] global step 1781: loss = 1.1345 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 1782: loss = 0.0971 (0.375 sec/step)\n",
            "I0205 13:30:18.855367 140689526667136 learning.py:507] global step 1782: loss = 0.0971 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 1783: loss = 0.2619 (0.410 sec/step)\n",
            "I0205 13:30:19.267447 140689526667136 learning.py:507] global step 1783: loss = 0.2619 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 1784: loss = 0.5660 (0.404 sec/step)\n",
            "I0205 13:30:19.673135 140689526667136 learning.py:507] global step 1784: loss = 0.5660 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 1785: loss = 0.2370 (0.348 sec/step)\n",
            "I0205 13:30:20.022258 140689526667136 learning.py:507] global step 1785: loss = 0.2370 (0.348 sec/step)\n",
            "INFO:tensorflow:global step 1786: loss = 0.1600 (0.395 sec/step)\n",
            "I0205 13:30:20.418670 140689526667136 learning.py:507] global step 1786: loss = 0.1600 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 1787: loss = 0.1534 (0.374 sec/step)\n",
            "I0205 13:30:20.793786 140689526667136 learning.py:507] global step 1787: loss = 0.1534 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 1788: loss = 0.0674 (0.399 sec/step)\n",
            "I0205 13:30:21.194626 140689526667136 learning.py:507] global step 1788: loss = 0.0674 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 1789: loss = 0.1068 (0.401 sec/step)\n",
            "I0205 13:30:21.597104 140689526667136 learning.py:507] global step 1789: loss = 0.1068 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 1790: loss = 0.3417 (0.396 sec/step)\n",
            "I0205 13:30:21.994206 140689526667136 learning.py:507] global step 1790: loss = 0.3417 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 1791: loss = 0.2763 (0.369 sec/step)\n",
            "I0205 13:30:22.364836 140689526667136 learning.py:507] global step 1791: loss = 0.2763 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 1792: loss = 0.7554 (0.391 sec/step)\n",
            "I0205 13:30:22.756872 140689526667136 learning.py:507] global step 1792: loss = 0.7554 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 1793: loss = 0.5046 (0.385 sec/step)\n",
            "I0205 13:30:23.143536 140689526667136 learning.py:507] global step 1793: loss = 0.5046 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 1794: loss = 0.6006 (0.445 sec/step)\n",
            "I0205 13:30:23.590149 140689526667136 learning.py:507] global step 1794: loss = 0.6006 (0.445 sec/step)\n",
            "INFO:tensorflow:global step 1795: loss = 0.2963 (0.380 sec/step)\n",
            "I0205 13:30:23.971571 140689526667136 learning.py:507] global step 1795: loss = 0.2963 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1796: loss = 0.2272 (0.396 sec/step)\n",
            "I0205 13:30:24.369922 140689526667136 learning.py:507] global step 1796: loss = 0.2272 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 1797: loss = 0.0255 (0.944 sec/step)\n",
            "I0205 13:30:25.315569 140689526667136 learning.py:507] global step 1797: loss = 0.0255 (0.944 sec/step)\n",
            "INFO:tensorflow:global step 1798: loss = 0.1181 (0.385 sec/step)\n",
            "I0205 13:30:25.702148 140689526667136 learning.py:507] global step 1798: loss = 0.1181 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 1799: loss = 0.1733 (0.379 sec/step)\n",
            "I0205 13:30:26.083689 140689526667136 learning.py:507] global step 1799: loss = 0.1733 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 1800: loss = 0.1499 (0.408 sec/step)\n",
            "I0205 13:30:26.493352 140689526667136 learning.py:507] global step 1800: loss = 0.1499 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 1801: loss = 0.1671 (0.381 sec/step)\n",
            "I0205 13:30:26.875839 140689526667136 learning.py:507] global step 1801: loss = 0.1671 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1802: loss = 0.3696 (0.394 sec/step)\n",
            "I0205 13:30:27.271194 140689526667136 learning.py:507] global step 1802: loss = 0.3696 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 1803: loss = 0.2176 (0.979 sec/step)\n",
            "I0205 13:30:28.251909 140689526667136 learning.py:507] global step 1803: loss = 0.2176 (0.979 sec/step)\n",
            "INFO:tensorflow:global step 1804: loss = 0.0953 (0.376 sec/step)\n",
            "I0205 13:30:28.629946 140689526667136 learning.py:507] global step 1804: loss = 0.0953 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 1805: loss = 0.0481 (0.383 sec/step)\n",
            "I0205 13:30:29.015062 140689526667136 learning.py:507] global step 1805: loss = 0.0481 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 1806: loss = 0.1050 (0.376 sec/step)\n",
            "I0205 13:30:29.392890 140689526667136 learning.py:507] global step 1806: loss = 0.1050 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 1807: loss = 0.4274 (0.434 sec/step)\n",
            "I0205 13:30:29.829128 140689526667136 learning.py:507] global step 1807: loss = 0.4274 (0.434 sec/step)\n",
            "INFO:tensorflow:global step 1808: loss = 0.1970 (0.402 sec/step)\n",
            "I0205 13:30:30.233057 140689526667136 learning.py:507] global step 1808: loss = 0.1970 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 1809: loss = 0.1921 (0.367 sec/step)\n",
            "I0205 13:30:30.601871 140689526667136 learning.py:507] global step 1809: loss = 0.1921 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 1810: loss = 0.3656 (0.384 sec/step)\n",
            "I0205 13:30:30.987659 140689526667136 learning.py:507] global step 1810: loss = 0.3656 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 1811: loss = 0.0560 (0.449 sec/step)\n",
            "I0205 13:30:31.438072 140689526667136 learning.py:507] global step 1811: loss = 0.0560 (0.449 sec/step)\n",
            "INFO:tensorflow:global step 1812: loss = 0.1475 (0.402 sec/step)\n",
            "I0205 13:30:31.841605 140689526667136 learning.py:507] global step 1812: loss = 0.1475 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 1813: loss = 0.2430 (0.398 sec/step)\n",
            "I0205 13:30:32.240688 140689526667136 learning.py:507] global step 1813: loss = 0.2430 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 1814: loss = 0.1443 (0.368 sec/step)\n",
            "I0205 13:30:32.610784 140689526667136 learning.py:507] global step 1814: loss = 0.1443 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 1815: loss = 0.2680 (0.400 sec/step)\n",
            "I0205 13:30:33.012648 140689526667136 learning.py:507] global step 1815: loss = 0.2680 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 1816: loss = 0.4373 (0.394 sec/step)\n",
            "I0205 13:30:33.407955 140689526667136 learning.py:507] global step 1816: loss = 0.4373 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 1817: loss = 0.2842 (0.387 sec/step)\n",
            "I0205 13:30:33.796129 140689526667136 learning.py:507] global step 1817: loss = 0.2842 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 1818: loss = 0.1076 (0.414 sec/step)\n",
            "I0205 13:30:34.212263 140689526667136 learning.py:507] global step 1818: loss = 0.1076 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 1819: loss = 0.0932 (0.431 sec/step)\n",
            "I0205 13:30:34.644777 140689526667136 learning.py:507] global step 1819: loss = 0.0932 (0.431 sec/step)\n",
            "INFO:tensorflow:global step 1820: loss = 0.5659 (0.872 sec/step)\n",
            "I0205 13:30:35.518507 140689526667136 learning.py:507] global step 1820: loss = 0.5659 (0.872 sec/step)\n",
            "INFO:tensorflow:global step 1821: loss = 0.5395 (0.356 sec/step)\n",
            "I0205 13:30:35.876116 140689526667136 learning.py:507] global step 1821: loss = 0.5395 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 1822: loss = 0.1153 (0.362 sec/step)\n",
            "I0205 13:30:36.240073 140689526667136 learning.py:507] global step 1822: loss = 0.1153 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 1823: loss = 0.0355 (0.385 sec/step)\n",
            "I0205 13:30:36.625961 140689526667136 learning.py:507] global step 1823: loss = 0.0355 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 1824: loss = 0.8265 (0.387 sec/step)\n",
            "I0205 13:30:37.014500 140689526667136 learning.py:507] global step 1824: loss = 0.8265 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 1825: loss = 0.5156 (0.385 sec/step)\n",
            "I0205 13:30:37.401597 140689526667136 learning.py:507] global step 1825: loss = 0.5156 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 1826: loss = 0.1522 (0.391 sec/step)\n",
            "I0205 13:30:37.794917 140689526667136 learning.py:507] global step 1826: loss = 0.1522 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 1827: loss = 0.1931 (0.404 sec/step)\n",
            "I0205 13:30:38.200147 140689526667136 learning.py:507] global step 1827: loss = 0.1931 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 1828: loss = 0.1040 (0.371 sec/step)\n",
            "I0205 13:30:38.572662 140689526667136 learning.py:507] global step 1828: loss = 0.1040 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 1829: loss = 0.1484 (0.399 sec/step)\n",
            "I0205 13:30:38.973068 140689526667136 learning.py:507] global step 1829: loss = 0.1484 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 1830: loss = 1.0148 (0.365 sec/step)\n",
            "I0205 13:30:39.339876 140689526667136 learning.py:507] global step 1830: loss = 1.0148 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 1831: loss = 0.2348 (0.366 sec/step)\n",
            "I0205 13:30:39.707695 140689526667136 learning.py:507] global step 1831: loss = 0.2348 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 1832: loss = 0.1319 (0.380 sec/step)\n",
            "I0205 13:30:40.089050 140689526667136 learning.py:507] global step 1832: loss = 0.1319 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1833: loss = 0.1471 (0.349 sec/step)\n",
            "I0205 13:30:40.439635 140689526667136 learning.py:507] global step 1833: loss = 0.1471 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 1834: loss = 0.0678 (0.371 sec/step)\n",
            "I0205 13:30:40.812285 140689526667136 learning.py:507] global step 1834: loss = 0.0678 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 1835: loss = 0.7777 (0.381 sec/step)\n",
            "I0205 13:30:41.195361 140689526667136 learning.py:507] global step 1835: loss = 0.7777 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1836: loss = 0.0224 (0.385 sec/step)\n",
            "I0205 13:30:41.581757 140689526667136 learning.py:507] global step 1836: loss = 0.0224 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 1837: loss = 0.0534 (0.342 sec/step)\n",
            "I0205 13:30:41.925577 140689526667136 learning.py:507] global step 1837: loss = 0.0534 (0.342 sec/step)\n",
            "INFO:tensorflow:global step 1838: loss = 0.1316 (0.444 sec/step)\n",
            "I0205 13:30:42.371465 140689526667136 learning.py:507] global step 1838: loss = 0.1316 (0.444 sec/step)\n",
            "INFO:tensorflow:global step 1839: loss = 0.1397 (0.968 sec/step)\n",
            "I0205 13:30:43.340526 140689526667136 learning.py:507] global step 1839: loss = 0.1397 (0.968 sec/step)\n",
            "INFO:tensorflow:global step 1840: loss = 0.1925 (0.376 sec/step)\n",
            "I0205 13:30:43.718354 140689526667136 learning.py:507] global step 1840: loss = 0.1925 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 1841: loss = 0.2146 (0.375 sec/step)\n",
            "I0205 13:30:44.094263 140689526667136 learning.py:507] global step 1841: loss = 0.2146 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 1842: loss = 0.2943 (0.374 sec/step)\n",
            "I0205 13:30:44.469683 140689526667136 learning.py:507] global step 1842: loss = 0.2943 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 1843: loss = 0.5575 (0.358 sec/step)\n",
            "I0205 13:30:44.829914 140689526667136 learning.py:507] global step 1843: loss = 0.5575 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 1844: loss = 0.3811 (0.346 sec/step)\n",
            "I0205 13:30:45.177489 140689526667136 learning.py:507] global step 1844: loss = 0.3811 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 1845: loss = 0.1902 (0.380 sec/step)\n",
            "I0205 13:30:45.558921 140689526667136 learning.py:507] global step 1845: loss = 0.1902 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1846: loss = 0.1712 (0.372 sec/step)\n",
            "I0205 13:30:45.932877 140689526667136 learning.py:507] global step 1846: loss = 0.1712 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 1847: loss = 0.0951 (0.388 sec/step)\n",
            "I0205 13:30:46.322003 140689526667136 learning.py:507] global step 1847: loss = 0.0951 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 1848: loss = 0.1096 (0.374 sec/step)\n",
            "I0205 13:30:46.697229 140689526667136 learning.py:507] global step 1848: loss = 0.1096 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 1849: loss = 0.1212 (0.376 sec/step)\n",
            "I0205 13:30:47.074438 140689526667136 learning.py:507] global step 1849: loss = 0.1212 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 1850: loss = 0.0786 (0.385 sec/step)\n",
            "I0205 13:30:47.460906 140689526667136 learning.py:507] global step 1850: loss = 0.0786 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 1851: loss = 0.0334 (0.392 sec/step)\n",
            "I0205 13:30:47.854381 140689526667136 learning.py:507] global step 1851: loss = 0.0334 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 1852: loss = 0.0288 (0.349 sec/step)\n",
            "I0205 13:30:48.204562 140689526667136 learning.py:507] global step 1852: loss = 0.0288 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 1853: loss = 0.4070 (0.354 sec/step)\n",
            "I0205 13:30:48.559971 140689526667136 learning.py:507] global step 1853: loss = 0.4070 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 1854: loss = 0.1301 (0.394 sec/step)\n",
            "I0205 13:30:48.955441 140689526667136 learning.py:507] global step 1854: loss = 0.1301 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 1855: loss = 0.1003 (0.382 sec/step)\n",
            "I0205 13:30:49.339107 140689526667136 learning.py:507] global step 1855: loss = 0.1003 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 1856: loss = 0.6199 (0.348 sec/step)\n",
            "I0205 13:30:49.689275 140689526667136 learning.py:507] global step 1856: loss = 0.6199 (0.348 sec/step)\n",
            "INFO:tensorflow:global step 1857: loss = 0.2089 (0.371 sec/step)\n",
            "I0205 13:30:50.061637 140689526667136 learning.py:507] global step 1857: loss = 0.2089 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 1858: loss = 0.0483 (0.380 sec/step)\n",
            "I0205 13:30:50.443350 140689526667136 learning.py:507] global step 1858: loss = 0.0483 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1859: loss = 0.1411 (0.361 sec/step)\n",
            "I0205 13:30:50.806151 140689526667136 learning.py:507] global step 1859: loss = 0.1411 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 1860: loss = 0.2356 (0.383 sec/step)\n",
            "I0205 13:30:51.191154 140689526667136 learning.py:507] global step 1860: loss = 0.2356 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 1861: loss = 0.1418 (0.399 sec/step)\n",
            "I0205 13:30:51.592148 140689526667136 learning.py:507] global step 1861: loss = 0.1418 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 1862: loss = 0.0809 (0.374 sec/step)\n",
            "I0205 13:30:51.968061 140689526667136 learning.py:507] global step 1862: loss = 0.0809 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 1863: loss = 0.3295 (0.420 sec/step)\n",
            "I0205 13:30:52.389980 140689526667136 learning.py:507] global step 1863: loss = 0.3295 (0.420 sec/step)\n",
            "INFO:tensorflow:global step 1864: loss = 0.1639 (0.422 sec/step)\n",
            "I0205 13:30:52.813818 140689526667136 learning.py:507] global step 1864: loss = 0.1639 (0.422 sec/step)\n",
            "INFO:tensorflow:global step 1865: loss = 0.1768 (0.429 sec/step)\n",
            "I0205 13:30:53.244096 140689526667136 learning.py:507] global step 1865: loss = 0.1768 (0.429 sec/step)\n",
            "INFO:tensorflow:global step 1866: loss = 0.6273 (0.360 sec/step)\n",
            "I0205 13:30:53.605465 140689526667136 learning.py:507] global step 1866: loss = 0.6273 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 1867: loss = 0.9840 (0.389 sec/step)\n",
            "I0205 13:30:53.995756 140689526667136 learning.py:507] global step 1867: loss = 0.9840 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 1868: loss = 0.4968 (0.361 sec/step)\n",
            "I0205 13:30:54.360244 140689526667136 learning.py:507] global step 1868: loss = 0.4968 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 1869: loss = 0.0728 (0.391 sec/step)\n",
            "I0205 13:30:54.752846 140689526667136 learning.py:507] global step 1869: loss = 0.0728 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 1870: loss = 0.2427 (0.355 sec/step)\n",
            "I0205 13:30:55.109034 140689526667136 learning.py:507] global step 1870: loss = 0.2427 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 1871: loss = 0.1531 (0.384 sec/step)\n",
            "I0205 13:30:55.495206 140689526667136 learning.py:507] global step 1871: loss = 0.1531 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 1872: loss = 0.1580 (0.349 sec/step)\n",
            "I0205 13:30:55.845294 140689526667136 learning.py:507] global step 1872: loss = 0.1580 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 1873: loss = 0.1300 (0.394 sec/step)\n",
            "I0205 13:30:56.240754 140689526667136 learning.py:507] global step 1873: loss = 0.1300 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 1874: loss = 0.0872 (1.982 sec/step)\n",
            "I0205 13:30:58.224585 140689526667136 learning.py:507] global step 1874: loss = 0.0872 (1.982 sec/step)\n",
            "INFO:tensorflow:global step 1875: loss = 0.3502 (0.398 sec/step)\n",
            "I0205 13:30:58.624589 140689526667136 learning.py:507] global step 1875: loss = 0.3502 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 1876: loss = 0.1232 (0.385 sec/step)\n",
            "I0205 13:30:59.011623 140689526667136 learning.py:507] global step 1876: loss = 0.1232 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 1877: loss = 0.1027 (0.394 sec/step)\n",
            "I0205 13:30:59.407665 140689526667136 learning.py:507] global step 1877: loss = 0.1027 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 1878: loss = 0.6264 (0.389 sec/step)\n",
            "I0205 13:30:59.798551 140689526667136 learning.py:507] global step 1878: loss = 0.6264 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 1879: loss = 0.0499 (0.361 sec/step)\n",
            "I0205 13:31:00.161523 140689526667136 learning.py:507] global step 1879: loss = 0.0499 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 1880: loss = 0.1233 (0.366 sec/step)\n",
            "I0205 13:31:00.529731 140689526667136 learning.py:507] global step 1880: loss = 0.1233 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 1881: loss = 0.0710 (0.365 sec/step)\n",
            "I0205 13:31:00.896737 140689526667136 learning.py:507] global step 1881: loss = 0.0710 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 1882: loss = 0.1640 (0.362 sec/step)\n",
            "I0205 13:31:01.261613 140689526667136 learning.py:507] global step 1882: loss = 0.1640 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 1883: loss = 0.0772 (0.370 sec/step)\n",
            "I0205 13:31:01.633599 140689526667136 learning.py:507] global step 1883: loss = 0.0772 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 1884: loss = 0.3150 (0.380 sec/step)\n",
            "I0205 13:31:02.015188 140689526667136 learning.py:507] global step 1884: loss = 0.3150 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1885: loss = 0.0769 (0.393 sec/step)\n",
            "I0205 13:31:02.410338 140689526667136 learning.py:507] global step 1885: loss = 0.0769 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 1886: loss = 0.0508 (0.425 sec/step)\n",
            "I0205 13:31:02.837154 140689526667136 learning.py:507] global step 1886: loss = 0.0508 (0.425 sec/step)\n",
            "INFO:tensorflow:global step 1887: loss = 0.0629 (0.389 sec/step)\n",
            "I0205 13:31:03.228237 140689526667136 learning.py:507] global step 1887: loss = 0.0629 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 1888: loss = 0.1541 (0.359 sec/step)\n",
            "I0205 13:31:03.589251 140689526667136 learning.py:507] global step 1888: loss = 0.1541 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 1889: loss = 0.1116 (0.363 sec/step)\n",
            "I0205 13:31:03.954221 140689526667136 learning.py:507] global step 1889: loss = 0.1116 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 1890: loss = 0.2447 (0.354 sec/step)\n",
            "I0205 13:31:04.309219 140689526667136 learning.py:507] global step 1890: loss = 0.2447 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 1891: loss = 0.1077 (0.359 sec/step)\n",
            "I0205 13:31:04.669909 140689526667136 learning.py:507] global step 1891: loss = 0.1077 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 1892: loss = 0.0217 (0.387 sec/step)\n",
            "I0205 13:31:05.058889 140689526667136 learning.py:507] global step 1892: loss = 0.0217 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 1893: loss = 0.0951 (0.377 sec/step)\n",
            "I0205 13:31:05.437052 140689526667136 learning.py:507] global step 1893: loss = 0.0951 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 1894: loss = 0.1017 (0.368 sec/step)\n",
            "I0205 13:31:05.806873 140689526667136 learning.py:507] global step 1894: loss = 0.1017 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 1895: loss = 0.4836 (0.393 sec/step)\n",
            "I0205 13:31:06.201205 140689526667136 learning.py:507] global step 1895: loss = 0.4836 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 1896: loss = 0.0356 (0.403 sec/step)\n",
            "I0205 13:31:06.605899 140689526667136 learning.py:507] global step 1896: loss = 0.0356 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 1897: loss = 0.3275 (0.384 sec/step)\n",
            "I0205 13:31:06.992247 140689526667136 learning.py:507] global step 1897: loss = 0.3275 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 1898: loss = 0.1294 (0.383 sec/step)\n",
            "I0205 13:31:07.377358 140689526667136 learning.py:507] global step 1898: loss = 0.1294 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 1899: loss = 0.6579 (0.367 sec/step)\n",
            "I0205 13:31:07.746711 140689526667136 learning.py:507] global step 1899: loss = 0.6579 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 1900: loss = 0.2521 (0.414 sec/step)\n",
            "I0205 13:31:08.162288 140689526667136 learning.py:507] global step 1900: loss = 0.2521 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 1901: loss = 0.4757 (0.383 sec/step)\n",
            "I0205 13:31:08.547198 140689526667136 learning.py:507] global step 1901: loss = 0.4757 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 1902: loss = 0.5323 (0.434 sec/step)\n",
            "I0205 13:31:08.982868 140689526667136 learning.py:507] global step 1902: loss = 0.5323 (0.434 sec/step)\n",
            "INFO:tensorflow:global step 1903: loss = 0.3739 (0.371 sec/step)\n",
            "I0205 13:31:09.355354 140689526667136 learning.py:507] global step 1903: loss = 0.3739 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 1904: loss = 0.2444 (0.344 sec/step)\n",
            "I0205 13:31:09.701292 140689526667136 learning.py:507] global step 1904: loss = 0.2444 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 1905: loss = 0.0215 (0.375 sec/step)\n",
            "I0205 13:31:10.078670 140689526667136 learning.py:507] global step 1905: loss = 0.0215 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 1906: loss = 0.0660 (0.370 sec/step)\n",
            "I0205 13:31:10.450523 140689526667136 learning.py:507] global step 1906: loss = 0.0660 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 1907: loss = 0.5188 (0.394 sec/step)\n",
            "I0205 13:31:10.848075 140689526667136 learning.py:507] global step 1907: loss = 0.5188 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 1908: loss = 0.2674 (0.362 sec/step)\n",
            "I0205 13:31:11.212285 140689526667136 learning.py:507] global step 1908: loss = 0.2674 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 1909: loss = 0.5179 (0.386 sec/step)\n",
            "I0205 13:31:11.599767 140689526667136 learning.py:507] global step 1909: loss = 0.5179 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 1910: loss = 0.1530 (0.373 sec/step)\n",
            "I0205 13:31:11.974184 140689526667136 learning.py:507] global step 1910: loss = 0.1530 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 1911: loss = 0.2236 (0.407 sec/step)\n",
            "I0205 13:31:12.382550 140689526667136 learning.py:507] global step 1911: loss = 0.2236 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 1912: loss = 0.1105 (0.354 sec/step)\n",
            "I0205 13:31:12.738070 140689526667136 learning.py:507] global step 1912: loss = 0.1105 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 1913: loss = 0.2063 (0.341 sec/step)\n",
            "I0205 13:31:13.080573 140689526667136 learning.py:507] global step 1913: loss = 0.2063 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 1914: loss = 0.1479 (0.372 sec/step)\n",
            "I0205 13:31:13.454486 140689526667136 learning.py:507] global step 1914: loss = 0.1479 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 1915: loss = 0.0868 (0.349 sec/step)\n",
            "I0205 13:31:13.805209 140689526667136 learning.py:507] global step 1915: loss = 0.0868 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 1916: loss = 0.0449 (0.374 sec/step)\n",
            "I0205 13:31:14.180840 140689526667136 learning.py:507] global step 1916: loss = 0.0449 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 1917: loss = 0.1083 (0.367 sec/step)\n",
            "I0205 13:31:14.549185 140689526667136 learning.py:507] global step 1917: loss = 0.1083 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 1918: loss = 0.0950 (0.388 sec/step)\n",
            "I0205 13:31:14.938953 140689526667136 learning.py:507] global step 1918: loss = 0.0950 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 1919: loss = 1.2619 (0.389 sec/step)\n",
            "I0205 13:31:15.329482 140689526667136 learning.py:507] global step 1919: loss = 1.2619 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 1920: loss = 0.1570 (0.397 sec/step)\n",
            "I0205 13:31:15.727927 140689526667136 learning.py:507] global step 1920: loss = 0.1570 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 1921: loss = 0.1502 (0.359 sec/step)\n",
            "I0205 13:31:16.088128 140689526667136 learning.py:507] global step 1921: loss = 0.1502 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 1922: loss = 0.1635 (0.393 sec/step)\n",
            "I0205 13:31:16.483251 140689526667136 learning.py:507] global step 1922: loss = 0.1635 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 1923: loss = 0.1242 (0.361 sec/step)\n",
            "I0205 13:31:16.845564 140689526667136 learning.py:507] global step 1923: loss = 0.1242 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 1924: loss = 0.0357 (0.361 sec/step)\n",
            "I0205 13:31:17.207609 140689526667136 learning.py:507] global step 1924: loss = 0.0357 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 1925: loss = 0.2503 (0.399 sec/step)\n",
            "I0205 13:31:17.608450 140689526667136 learning.py:507] global step 1925: loss = 0.2503 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 1926: loss = 0.1730 (0.368 sec/step)\n",
            "I0205 13:31:17.978331 140689526667136 learning.py:507] global step 1926: loss = 0.1730 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 1927: loss = 0.1192 (0.385 sec/step)\n",
            "I0205 13:31:18.364696 140689526667136 learning.py:507] global step 1927: loss = 0.1192 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 1928: loss = 0.1181 (0.350 sec/step)\n",
            "I0205 13:31:18.716711 140689526667136 learning.py:507] global step 1928: loss = 0.1181 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 1929: loss = 0.1852 (0.389 sec/step)\n",
            "I0205 13:31:19.107049 140689526667136 learning.py:507] global step 1929: loss = 0.1852 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 1930: loss = 0.2969 (0.461 sec/step)\n",
            "I0205 13:31:19.569715 140689526667136 learning.py:507] global step 1930: loss = 0.2969 (0.461 sec/step)\n",
            "INFO:tensorflow:global step 1931: loss = 0.0651 (0.353 sec/step)\n",
            "I0205 13:31:19.924555 140689526667136 learning.py:507] global step 1931: loss = 0.0651 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 1932: loss = 0.1818 (0.373 sec/step)\n",
            "I0205 13:31:20.299462 140689526667136 learning.py:507] global step 1932: loss = 0.1818 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 1933: loss = 0.0703 (0.391 sec/step)\n",
            "I0205 13:31:20.692418 140689526667136 learning.py:507] global step 1933: loss = 0.0703 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 1934: loss = 0.1232 (0.371 sec/step)\n",
            "I0205 13:31:21.064508 140689526667136 learning.py:507] global step 1934: loss = 0.1232 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 1935: loss = 0.1047 (0.387 sec/step)\n",
            "I0205 13:31:21.453598 140689526667136 learning.py:507] global step 1935: loss = 0.1047 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 1936: loss = 0.1270 (0.371 sec/step)\n",
            "I0205 13:31:21.826485 140689526667136 learning.py:507] global step 1936: loss = 0.1270 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 1937: loss = 0.1369 (0.386 sec/step)\n",
            "I0205 13:31:22.214142 140689526667136 learning.py:507] global step 1937: loss = 0.1369 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 1938: loss = 0.1270 (0.364 sec/step)\n",
            "I0205 13:31:22.580381 140689526667136 learning.py:507] global step 1938: loss = 0.1270 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 1939: loss = 0.1160 (0.448 sec/step)\n",
            "I0205 13:31:23.030195 140689526667136 learning.py:507] global step 1939: loss = 0.1160 (0.448 sec/step)\n",
            "INFO:tensorflow:global step 1940: loss = 0.0620 (0.365 sec/step)\n",
            "I0205 13:31:23.396453 140689526667136 learning.py:507] global step 1940: loss = 0.0620 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 1941: loss = 0.0640 (2.476 sec/step)\n",
            "I0205 13:31:25.874379 140689526667136 learning.py:507] global step 1941: loss = 0.0640 (2.476 sec/step)\n",
            "INFO:tensorflow:global step 1942: loss = 0.7561 (0.354 sec/step)\n",
            "I0205 13:31:26.229974 140689526667136 learning.py:507] global step 1942: loss = 0.7561 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 1943: loss = 0.3878 (0.373 sec/step)\n",
            "I0205 13:31:26.604128 140689526667136 learning.py:507] global step 1943: loss = 0.3878 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 1944: loss = 0.0696 (0.387 sec/step)\n",
            "I0205 13:31:26.993123 140689526667136 learning.py:507] global step 1944: loss = 0.0696 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 1945: loss = 0.0808 (0.378 sec/step)\n",
            "I0205 13:31:27.373040 140689526667136 learning.py:507] global step 1945: loss = 0.0808 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 1946: loss = 0.1430 (0.409 sec/step)\n",
            "I0205 13:31:27.783461 140689526667136 learning.py:507] global step 1946: loss = 0.1430 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 1947: loss = 0.2693 (0.368 sec/step)\n",
            "I0205 13:31:28.153159 140689526667136 learning.py:507] global step 1947: loss = 0.2693 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 1948: loss = 0.1203 (0.379 sec/step)\n",
            "I0205 13:31:28.533317 140689526667136 learning.py:507] global step 1948: loss = 0.1203 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 1949: loss = 0.3189 (0.378 sec/step)\n",
            "I0205 13:31:28.912928 140689526667136 learning.py:507] global step 1949: loss = 0.3189 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 1950: loss = 0.2334 (1.081 sec/step)\n",
            "I0205 13:31:29.995754 140689526667136 learning.py:507] global step 1950: loss = 0.2334 (1.081 sec/step)\n",
            "INFO:tensorflow:global step 1951: loss = 0.0882 (0.409 sec/step)\n",
            "I0205 13:31:30.406081 140689526667136 learning.py:507] global step 1951: loss = 0.0882 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 1952: loss = 0.1294 (0.388 sec/step)\n",
            "I0205 13:31:30.796135 140689526667136 learning.py:507] global step 1952: loss = 0.1294 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 1953: loss = 0.0812 (0.381 sec/step)\n",
            "I0205 13:31:31.178092 140689526667136 learning.py:507] global step 1953: loss = 0.0812 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1954: loss = 0.2002 (0.388 sec/step)\n",
            "I0205 13:31:31.567429 140689526667136 learning.py:507] global step 1954: loss = 0.2002 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 1955: loss = 0.1037 (0.363 sec/step)\n",
            "I0205 13:31:31.932333 140689526667136 learning.py:507] global step 1955: loss = 0.1037 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 1956: loss = 0.2740 (0.388 sec/step)\n",
            "I0205 13:31:32.322440 140689526667136 learning.py:507] global step 1956: loss = 0.2740 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 1957: loss = 0.1404 (0.391 sec/step)\n",
            "I0205 13:31:32.714783 140689526667136 learning.py:507] global step 1957: loss = 0.1404 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 1958: loss = 0.0537 (0.381 sec/step)\n",
            "I0205 13:31:33.096901 140689526667136 learning.py:507] global step 1958: loss = 0.0537 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1959: loss = 0.2746 (0.397 sec/step)\n",
            "I0205 13:31:33.495752 140689526667136 learning.py:507] global step 1959: loss = 0.2746 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 1960: loss = 0.0627 (1.571 sec/step)\n",
            "I0205 13:31:35.068269 140689526667136 learning.py:507] global step 1960: loss = 0.0627 (1.571 sec/step)\n",
            "INFO:tensorflow:global step 1961: loss = 0.1610 (0.390 sec/step)\n",
            "I0205 13:31:35.459434 140689526667136 learning.py:507] global step 1961: loss = 0.1610 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 1962: loss = 0.3772 (0.377 sec/step)\n",
            "I0205 13:31:35.837977 140689526667136 learning.py:507] global step 1962: loss = 0.3772 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 1963: loss = 0.2339 (0.366 sec/step)\n",
            "I0205 13:31:36.205534 140689526667136 learning.py:507] global step 1963: loss = 0.2339 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 1964: loss = 0.0853 (0.385 sec/step)\n",
            "I0205 13:31:36.591767 140689526667136 learning.py:507] global step 1964: loss = 0.0853 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 1965: loss = 0.0777 (0.366 sec/step)\n",
            "I0205 13:31:36.958951 140689526667136 learning.py:507] global step 1965: loss = 0.0777 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 1966: loss = 0.1563 (0.367 sec/step)\n",
            "I0205 13:31:37.327722 140689526667136 learning.py:507] global step 1966: loss = 0.1563 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 1967: loss = 0.2533 (0.381 sec/step)\n",
            "I0205 13:31:37.710405 140689526667136 learning.py:507] global step 1967: loss = 0.2533 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 1968: loss = 0.2601 (0.388 sec/step)\n",
            "I0205 13:31:38.099567 140689526667136 learning.py:507] global step 1968: loss = 0.2601 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 1969: loss = 0.0470 (0.434 sec/step)\n",
            "I0205 13:31:38.535514 140689526667136 learning.py:507] global step 1969: loss = 0.0470 (0.434 sec/step)\n",
            "INFO:tensorflow:global step 1970: loss = 0.1569 (0.359 sec/step)\n",
            "I0205 13:31:38.896272 140689526667136 learning.py:507] global step 1970: loss = 0.1569 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 1971: loss = 0.0400 (0.385 sec/step)\n",
            "I0205 13:31:39.283128 140689526667136 learning.py:507] global step 1971: loss = 0.0400 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 1972: loss = 0.0833 (0.388 sec/step)\n",
            "I0205 13:31:39.672438 140689526667136 learning.py:507] global step 1972: loss = 0.0833 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 1973: loss = 0.0685 (0.372 sec/step)\n",
            "I0205 13:31:40.045991 140689526667136 learning.py:507] global step 1973: loss = 0.0685 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 1974: loss = 0.1181 (0.380 sec/step)\n",
            "I0205 13:31:40.428102 140689526667136 learning.py:507] global step 1974: loss = 0.1181 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 1975: loss = 0.2896 (0.391 sec/step)\n",
            "I0205 13:31:40.820437 140689526667136 learning.py:507] global step 1975: loss = 0.2896 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 1976: loss = 0.0983 (0.361 sec/step)\n",
            "I0205 13:31:41.183063 140689526667136 learning.py:507] global step 1976: loss = 0.0983 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 1977: loss = 0.0636 (0.403 sec/step)\n",
            "I0205 13:31:41.588052 140689526667136 learning.py:507] global step 1977: loss = 0.0636 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 1978: loss = 0.2315 (0.389 sec/step)\n",
            "I0205 13:31:41.979088 140689526667136 learning.py:507] global step 1978: loss = 0.2315 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 1979: loss = 0.0573 (0.396 sec/step)\n",
            "I0205 13:31:42.376611 140689526667136 learning.py:507] global step 1979: loss = 0.0573 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 1980: loss = 0.0693 (0.388 sec/step)\n",
            "I0205 13:31:42.766063 140689526667136 learning.py:507] global step 1980: loss = 0.0693 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 1981: loss = 0.1126 (0.397 sec/step)\n",
            "I0205 13:31:43.165227 140689526667136 learning.py:507] global step 1981: loss = 0.1126 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 1982: loss = 0.0679 (0.371 sec/step)\n",
            "I0205 13:31:43.538049 140689526667136 learning.py:507] global step 1982: loss = 0.0679 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 1983: loss = 0.1215 (0.374 sec/step)\n",
            "I0205 13:31:43.914008 140689526667136 learning.py:507] global step 1983: loss = 0.1215 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 1984: loss = 0.0946 (0.446 sec/step)\n",
            "I0205 13:31:44.361147 140689526667136 learning.py:507] global step 1984: loss = 0.0946 (0.446 sec/step)\n",
            "INFO:tensorflow:global step 1985: loss = 1.4350 (0.416 sec/step)\n",
            "I0205 13:31:44.779327 140689526667136 learning.py:507] global step 1985: loss = 1.4350 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 1986: loss = 1.0968 (0.372 sec/step)\n",
            "I0205 13:31:45.153123 140689526667136 learning.py:507] global step 1986: loss = 1.0968 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 1987: loss = 0.0447 (0.382 sec/step)\n",
            "I0205 13:31:45.536870 140689526667136 learning.py:507] global step 1987: loss = 0.0447 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 1988: loss = 0.3319 (2.268 sec/step)\n",
            "I0205 13:31:47.805930 140689526667136 learning.py:507] global step 1988: loss = 0.3319 (2.268 sec/step)\n",
            "INFO:tensorflow:global step 1989: loss = 0.0996 (0.363 sec/step)\n",
            "I0205 13:31:48.170463 140689526667136 learning.py:507] global step 1989: loss = 0.0996 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 1990: loss = 0.1095 (0.337 sec/step)\n",
            "I0205 13:31:48.508458 140689526667136 learning.py:507] global step 1990: loss = 0.1095 (0.337 sec/step)\n",
            "INFO:tensorflow:global step 1991: loss = 0.3369 (0.425 sec/step)\n",
            "I0205 13:31:48.935525 140689526667136 learning.py:507] global step 1991: loss = 0.3369 (0.425 sec/step)\n",
            "INFO:tensorflow:global step 1992: loss = 0.0220 (0.378 sec/step)\n",
            "I0205 13:31:49.315552 140689526667136 learning.py:507] global step 1992: loss = 0.0220 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 1993: loss = 0.1271 (0.390 sec/step)\n",
            "I0205 13:31:49.707159 140689526667136 learning.py:507] global step 1993: loss = 0.1271 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 1994: loss = 0.1009 (0.394 sec/step)\n",
            "I0205 13:31:50.102530 140689526667136 learning.py:507] global step 1994: loss = 0.1009 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 1995: loss = 0.2477 (0.385 sec/step)\n",
            "I0205 13:31:50.488831 140689526667136 learning.py:507] global step 1995: loss = 0.2477 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 1996: loss = 0.1433 (0.379 sec/step)\n",
            "I0205 13:31:50.869129 140689526667136 learning.py:507] global step 1996: loss = 0.1433 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 1997: loss = 1.0313 (0.382 sec/step)\n",
            "I0205 13:31:51.252265 140689526667136 learning.py:507] global step 1997: loss = 1.0313 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 1998: loss = 0.5449 (0.366 sec/step)\n",
            "I0205 13:31:51.619925 140689526667136 learning.py:507] global step 1998: loss = 0.5449 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 1999: loss = 0.2833 (0.376 sec/step)\n",
            "I0205 13:31:51.997122 140689526667136 learning.py:507] global step 1999: loss = 0.2833 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 2000: loss = 0.3233 (0.391 sec/step)\n",
            "I0205 13:31:52.390690 140689526667136 learning.py:507] global step 2000: loss = 0.3233 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2001: loss = 0.1547 (0.433 sec/step)\n",
            "I0205 13:31:52.825504 140689526667136 learning.py:507] global step 2001: loss = 0.1547 (0.433 sec/step)\n",
            "INFO:tensorflow:global step 2002: loss = 0.4401 (0.395 sec/step)\n",
            "I0205 13:31:53.221980 140689526667136 learning.py:507] global step 2002: loss = 0.4401 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 2003: loss = 0.1182 (0.387 sec/step)\n",
            "I0205 13:31:53.610431 140689526667136 learning.py:507] global step 2003: loss = 0.1182 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 2004: loss = 0.0989 (0.379 sec/step)\n",
            "I0205 13:31:53.991460 140689526667136 learning.py:507] global step 2004: loss = 0.0989 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2005: loss = 0.1843 (0.381 sec/step)\n",
            "I0205 13:31:54.374236 140689526667136 learning.py:507] global step 2005: loss = 0.1843 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 2006: loss = 0.1003 (0.954 sec/step)\n",
            "I0205 13:31:55.329913 140689526667136 learning.py:507] global step 2006: loss = 0.1003 (0.954 sec/step)\n",
            "INFO:tensorflow:global step 2007: loss = 0.0861 (0.367 sec/step)\n",
            "I0205 13:31:55.697934 140689526667136 learning.py:507] global step 2007: loss = 0.0861 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 2008: loss = 0.2398 (0.430 sec/step)\n",
            "I0205 13:31:56.129117 140689526667136 learning.py:507] global step 2008: loss = 0.2398 (0.430 sec/step)\n",
            "INFO:tensorflow:global step 2009: loss = 0.1429 (0.384 sec/step)\n",
            "I0205 13:31:56.514695 140689526667136 learning.py:507] global step 2009: loss = 0.1429 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 2010: loss = 0.1269 (0.376 sec/step)\n",
            "I0205 13:31:56.892287 140689526667136 learning.py:507] global step 2010: loss = 0.1269 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 2011: loss = 0.3379 (0.378 sec/step)\n",
            "I0205 13:31:57.271931 140689526667136 learning.py:507] global step 2011: loss = 0.3379 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 2012: loss = 0.2197 (0.384 sec/step)\n",
            "I0205 13:31:57.657352 140689526667136 learning.py:507] global step 2012: loss = 0.2197 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 2013: loss = 0.1618 (0.445 sec/step)\n",
            "I0205 13:31:58.104241 140689526667136 learning.py:507] global step 2013: loss = 0.1618 (0.445 sec/step)\n",
            "INFO:tensorflow:global step 2014: loss = 1.0408 (0.401 sec/step)\n",
            "I0205 13:31:58.507147 140689526667136 learning.py:507] global step 2014: loss = 1.0408 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 2015: loss = 0.1004 (0.352 sec/step)\n",
            "I0205 13:31:58.860429 140689526667136 learning.py:507] global step 2015: loss = 0.1004 (0.352 sec/step)\n",
            "INFO:tensorflow:global step 2016: loss = 0.2692 (0.355 sec/step)\n",
            "I0205 13:31:59.217549 140689526667136 learning.py:507] global step 2016: loss = 0.2692 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 2017: loss = 0.4916 (0.392 sec/step)\n",
            "I0205 13:31:59.611154 140689526667136 learning.py:507] global step 2017: loss = 0.4916 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 2018: loss = 0.0867 (0.378 sec/step)\n",
            "I0205 13:31:59.991117 140689526667136 learning.py:507] global step 2018: loss = 0.0867 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 2019: loss = 0.0438 (0.356 sec/step)\n",
            "I0205 13:32:00.348704 140689526667136 learning.py:507] global step 2019: loss = 0.0438 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 2020: loss = 0.1946 (1.689 sec/step)\n",
            "I0205 13:32:02.038915 140689526667136 learning.py:507] global step 2020: loss = 0.1946 (1.689 sec/step)\n",
            "INFO:tensorflow:global step 2021: loss = 0.1874 (0.379 sec/step)\n",
            "I0205 13:32:02.419890 140689526667136 learning.py:507] global step 2021: loss = 0.1874 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2022: loss = 0.0593 (0.374 sec/step)\n",
            "I0205 13:32:02.795283 140689526667136 learning.py:507] global step 2022: loss = 0.0593 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 2023: loss = 0.2716 (0.482 sec/step)\n",
            "I0205 13:32:03.278918 140689526667136 learning.py:507] global step 2023: loss = 0.2716 (0.482 sec/step)\n",
            "INFO:tensorflow:global step 2024: loss = 0.0686 (0.392 sec/step)\n",
            "I0205 13:32:03.672720 140689526667136 learning.py:507] global step 2024: loss = 0.0686 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 2025: loss = 0.0763 (0.367 sec/step)\n",
            "I0205 13:32:04.041770 140689526667136 learning.py:507] global step 2025: loss = 0.0763 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 2026: loss = 0.1926 (0.369 sec/step)\n",
            "I0205 13:32:04.412215 140689526667136 learning.py:507] global step 2026: loss = 0.1926 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 2027: loss = 0.4026 (0.373 sec/step)\n",
            "I0205 13:32:04.786950 140689526667136 learning.py:507] global step 2027: loss = 0.4026 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 2028: loss = 0.0476 (0.367 sec/step)\n",
            "I0205 13:32:05.156003 140689526667136 learning.py:507] global step 2028: loss = 0.0476 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 2029: loss = 0.0938 (0.377 sec/step)\n",
            "I0205 13:32:05.534473 140689526667136 learning.py:507] global step 2029: loss = 0.0938 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 2030: loss = 0.1464 (0.368 sec/step)\n",
            "I0205 13:32:05.904472 140689526667136 learning.py:507] global step 2030: loss = 0.1464 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 2031: loss = 0.0616 (0.394 sec/step)\n",
            "I0205 13:32:06.300655 140689526667136 learning.py:507] global step 2031: loss = 0.0616 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 2032: loss = 0.2001 (0.364 sec/step)\n",
            "I0205 13:32:06.666475 140689526667136 learning.py:507] global step 2032: loss = 0.2001 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 2033: loss = 0.1748 (0.384 sec/step)\n",
            "I0205 13:32:07.052847 140689526667136 learning.py:507] global step 2033: loss = 0.1748 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 2034: loss = 0.5195 (0.416 sec/step)\n",
            "I0205 13:32:07.470200 140689526667136 learning.py:507] global step 2034: loss = 0.5195 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 2035: loss = 0.1408 (0.386 sec/step)\n",
            "I0205 13:32:07.858095 140689526667136 learning.py:507] global step 2035: loss = 0.1408 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 2036: loss = 0.3972 (0.387 sec/step)\n",
            "I0205 13:32:08.246685 140689526667136 learning.py:507] global step 2036: loss = 0.3972 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 2037: loss = 0.0761 (0.392 sec/step)\n",
            "I0205 13:32:08.640593 140689526667136 learning.py:507] global step 2037: loss = 0.0761 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 2038: loss = 0.0993 (0.388 sec/step)\n",
            "I0205 13:32:09.030025 140689526667136 learning.py:507] global step 2038: loss = 0.0993 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 2039: loss = 0.2130 (0.403 sec/step)\n",
            "I0205 13:32:09.434131 140689526667136 learning.py:507] global step 2039: loss = 0.2130 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 2040: loss = 0.0931 (0.383 sec/step)\n",
            "I0205 13:32:09.818749 140689526667136 learning.py:507] global step 2040: loss = 0.0931 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2041: loss = 0.3652 (0.391 sec/step)\n",
            "I0205 13:32:10.211207 140689526667136 learning.py:507] global step 2041: loss = 0.3652 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2042: loss = 0.1325 (0.380 sec/step)\n",
            "I0205 13:32:10.592555 140689526667136 learning.py:507] global step 2042: loss = 0.1325 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2043: loss = 0.5545 (0.378 sec/step)\n",
            "I0205 13:32:10.972720 140689526667136 learning.py:507] global step 2043: loss = 0.5545 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 2044: loss = 0.2758 (0.407 sec/step)\n",
            "I0205 13:32:11.382251 140689526667136 learning.py:507] global step 2044: loss = 0.2758 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 2045: loss = 0.4020 (0.361 sec/step)\n",
            "I0205 13:32:11.744731 140689526667136 learning.py:507] global step 2045: loss = 0.4020 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 2046: loss = 0.1238 (0.388 sec/step)\n",
            "I0205 13:32:12.134585 140689526667136 learning.py:507] global step 2046: loss = 0.1238 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 2047: loss = 0.0405 (0.388 sec/step)\n",
            "I0205 13:32:12.524421 140689526667136 learning.py:507] global step 2047: loss = 0.0405 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 2048: loss = 0.1063 (0.404 sec/step)\n",
            "I0205 13:32:12.929756 140689526667136 learning.py:507] global step 2048: loss = 0.1063 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 2049: loss = 0.1261 (0.354 sec/step)\n",
            "I0205 13:32:13.284926 140689526667136 learning.py:507] global step 2049: loss = 0.1261 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 2050: loss = 0.1347 (0.383 sec/step)\n",
            "I0205 13:32:13.669462 140689526667136 learning.py:507] global step 2050: loss = 0.1347 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2051: loss = 0.9337 (0.864 sec/step)\n",
            "I0205 13:32:14.676614 140689526667136 learning.py:507] global step 2051: loss = 0.9337 (0.864 sec/step)\n",
            "INFO:tensorflow:global step 2052: loss = 0.1269 (0.808 sec/step)\n",
            "I0205 13:32:15.581505 140689526667136 learning.py:507] global step 2052: loss = 0.1269 (0.808 sec/step)\n",
            "INFO:tensorflow:global_step/sec: 2.30742\n",
            "I0205 13:32:15.940005 140686034466560 supervisor.py:1099] global_step/sec: 2.30742\n",
            "INFO:tensorflow:global step 2053: loss = 0.0330 (0.667 sec/step)\n",
            "I0205 13:32:16.269696 140689526667136 learning.py:507] global step 2053: loss = 0.0330 (0.667 sec/step)\n",
            "INFO:tensorflow:global step 2054: loss = 0.1463 (0.575 sec/step)\n",
            "I0205 13:32:16.846462 140689526667136 learning.py:507] global step 2054: loss = 0.1463 (0.575 sec/step)\n",
            "INFO:tensorflow:global step 2055: loss = 0.1033 (0.476 sec/step)\n",
            "I0205 13:32:17.327989 140689526667136 learning.py:507] global step 2055: loss = 0.1033 (0.476 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 2055.\n",
            "I0205 13:32:17.360534 140686026073856 supervisor.py:1050] Recording summary at step 2055.\n",
            "INFO:tensorflow:global step 2056: loss = 0.1858 (0.416 sec/step)\n",
            "I0205 13:32:17.745745 140689526667136 learning.py:507] global step 2056: loss = 0.1858 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 2057: loss = 0.5118 (0.389 sec/step)\n",
            "I0205 13:32:18.136331 140689526667136 learning.py:507] global step 2057: loss = 0.5118 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 2058: loss = 0.1299 (0.349 sec/step)\n",
            "I0205 13:32:18.486999 140689526667136 learning.py:507] global step 2058: loss = 0.1299 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 2059: loss = 0.1948 (0.394 sec/step)\n",
            "I0205 13:32:18.882953 140689526667136 learning.py:507] global step 2059: loss = 0.1948 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 2060: loss = 0.1217 (0.450 sec/step)\n",
            "I0205 13:32:19.334855 140689526667136 learning.py:507] global step 2060: loss = 0.1217 (0.450 sec/step)\n",
            "INFO:tensorflow:global step 2061: loss = 0.0405 (0.388 sec/step)\n",
            "I0205 13:32:19.724575 140689526667136 learning.py:507] global step 2061: loss = 0.0405 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 2062: loss = 0.0251 (0.380 sec/step)\n",
            "I0205 13:32:20.106359 140689526667136 learning.py:507] global step 2062: loss = 0.0251 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2063: loss = 0.0706 (0.355 sec/step)\n",
            "I0205 13:32:20.462540 140689526667136 learning.py:507] global step 2063: loss = 0.0706 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 2064: loss = 0.4685 (0.375 sec/step)\n",
            "I0205 13:32:20.838898 140689526667136 learning.py:507] global step 2064: loss = 0.4685 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2065: loss = 0.1000 (0.400 sec/step)\n",
            "I0205 13:32:21.240638 140689526667136 learning.py:507] global step 2065: loss = 0.1000 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 2066: loss = 0.6619 (0.405 sec/step)\n",
            "I0205 13:32:21.647054 140689526667136 learning.py:507] global step 2066: loss = 0.6619 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 2067: loss = 0.1744 (0.374 sec/step)\n",
            "I0205 13:32:22.022567 140689526667136 learning.py:507] global step 2067: loss = 0.1744 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 2068: loss = 0.3294 (0.368 sec/step)\n",
            "I0205 13:32:22.392387 140689526667136 learning.py:507] global step 2068: loss = 0.3294 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 2069: loss = 0.0755 (0.383 sec/step)\n",
            "I0205 13:32:22.776674 140689526667136 learning.py:507] global step 2069: loss = 0.0755 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2070: loss = 0.0942 (0.365 sec/step)\n",
            "I0205 13:32:23.143236 140689526667136 learning.py:507] global step 2070: loss = 0.0942 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 2071: loss = 0.6586 (0.384 sec/step)\n",
            "I0205 13:32:23.528835 140689526667136 learning.py:507] global step 2071: loss = 0.6586 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 2072: loss = 0.0870 (0.380 sec/step)\n",
            "I0205 13:32:23.910542 140689526667136 learning.py:507] global step 2072: loss = 0.0870 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2073: loss = 0.4323 (0.362 sec/step)\n",
            "I0205 13:32:24.274372 140689526667136 learning.py:507] global step 2073: loss = 0.4323 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 2074: loss = 0.1298 (0.367 sec/step)\n",
            "I0205 13:32:24.642650 140689526667136 learning.py:507] global step 2074: loss = 0.1298 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 2075: loss = 0.0950 (0.383 sec/step)\n",
            "I0205 13:32:25.027158 140689526667136 learning.py:507] global step 2075: loss = 0.0950 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2076: loss = 0.2288 (0.379 sec/step)\n",
            "I0205 13:32:25.407312 140689526667136 learning.py:507] global step 2076: loss = 0.2288 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2077: loss = 0.0363 (0.380 sec/step)\n",
            "I0205 13:32:25.788823 140689526667136 learning.py:507] global step 2077: loss = 0.0363 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2078: loss = 0.1491 (0.379 sec/step)\n",
            "I0205 13:32:26.169138 140689526667136 learning.py:507] global step 2078: loss = 0.1491 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2079: loss = 0.0347 (0.381 sec/step)\n",
            "I0205 13:32:26.551625 140689526667136 learning.py:507] global step 2079: loss = 0.0347 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 2080: loss = 0.1834 (0.379 sec/step)\n",
            "I0205 13:32:26.931636 140689526667136 learning.py:507] global step 2080: loss = 0.1834 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2081: loss = 0.0399 (0.388 sec/step)\n",
            "I0205 13:32:27.321589 140689526667136 learning.py:507] global step 2081: loss = 0.0399 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 2082: loss = 0.4605 (0.402 sec/step)\n",
            "I0205 13:32:27.725631 140689526667136 learning.py:507] global step 2082: loss = 0.4605 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 2083: loss = 0.1427 (0.402 sec/step)\n",
            "I0205 13:32:28.129463 140689526667136 learning.py:507] global step 2083: loss = 0.1427 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 2084: loss = 0.2851 (0.383 sec/step)\n",
            "I0205 13:32:28.513660 140689526667136 learning.py:507] global step 2084: loss = 0.2851 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2085: loss = 0.0661 (0.375 sec/step)\n",
            "I0205 13:32:28.889904 140689526667136 learning.py:507] global step 2085: loss = 0.0661 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2086: loss = 0.1927 (0.363 sec/step)\n",
            "I0205 13:32:29.254313 140689526667136 learning.py:507] global step 2086: loss = 0.1927 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 2087: loss = 0.2888 (0.388 sec/step)\n",
            "I0205 13:32:29.643783 140689526667136 learning.py:507] global step 2087: loss = 0.2888 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 2088: loss = 0.2902 (0.400 sec/step)\n",
            "I0205 13:32:30.046132 140689526667136 learning.py:507] global step 2088: loss = 0.2902 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 2089: loss = 0.0559 (0.394 sec/step)\n",
            "I0205 13:32:30.441508 140689526667136 learning.py:507] global step 2089: loss = 0.0559 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 2090: loss = 0.1721 (0.379 sec/step)\n",
            "I0205 13:32:30.821894 140689526667136 learning.py:507] global step 2090: loss = 0.1721 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2091: loss = 0.2562 (0.380 sec/step)\n",
            "I0205 13:32:31.203027 140689526667136 learning.py:507] global step 2091: loss = 0.2562 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2092: loss = 0.2074 (0.383 sec/step)\n",
            "I0205 13:32:31.587453 140689526667136 learning.py:507] global step 2092: loss = 0.2074 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2093: loss = 0.2619 (0.395 sec/step)\n",
            "I0205 13:32:31.983535 140689526667136 learning.py:507] global step 2093: loss = 0.2619 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 2094: loss = 0.1991 (0.453 sec/step)\n",
            "I0205 13:32:32.437676 140689526667136 learning.py:507] global step 2094: loss = 0.1991 (0.453 sec/step)\n",
            "INFO:tensorflow:global step 2095: loss = 0.1723 (0.409 sec/step)\n",
            "I0205 13:32:32.848626 140689526667136 learning.py:507] global step 2095: loss = 0.1723 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 2096: loss = 0.2472 (0.367 sec/step)\n",
            "I0205 13:32:33.216770 140689526667136 learning.py:507] global step 2096: loss = 0.2472 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 2097: loss = 0.2646 (0.359 sec/step)\n",
            "I0205 13:32:33.577395 140689526667136 learning.py:507] global step 2097: loss = 0.2646 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 2098: loss = 0.1944 (0.415 sec/step)\n",
            "I0205 13:32:33.993642 140689526667136 learning.py:507] global step 2098: loss = 0.1944 (0.415 sec/step)\n",
            "INFO:tensorflow:global step 2099: loss = 0.1262 (0.406 sec/step)\n",
            "I0205 13:32:34.401603 140689526667136 learning.py:507] global step 2099: loss = 0.1262 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 2100: loss = 0.4152 (0.378 sec/step)\n",
            "I0205 13:32:34.781346 140689526667136 learning.py:507] global step 2100: loss = 0.4152 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 2101: loss = 0.2907 (0.377 sec/step)\n",
            "I0205 13:32:35.160037 140689526667136 learning.py:507] global step 2101: loss = 0.2907 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 2102: loss = 0.6071 (0.353 sec/step)\n",
            "I0205 13:32:35.515184 140689526667136 learning.py:507] global step 2102: loss = 0.6071 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 2103: loss = 0.1519 (0.381 sec/step)\n",
            "I0205 13:32:35.897712 140689526667136 learning.py:507] global step 2103: loss = 0.1519 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 2104: loss = 0.3667 (0.388 sec/step)\n",
            "I0205 13:32:36.287130 140689526667136 learning.py:507] global step 2104: loss = 0.3667 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 2105: loss = 0.1295 (0.370 sec/step)\n",
            "I0205 13:32:36.658230 140689526667136 learning.py:507] global step 2105: loss = 0.1295 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 2106: loss = 0.0870 (0.380 sec/step)\n",
            "I0205 13:32:37.039714 140689526667136 learning.py:507] global step 2106: loss = 0.0870 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2107: loss = 0.1260 (0.370 sec/step)\n",
            "I0205 13:32:37.411128 140689526667136 learning.py:507] global step 2107: loss = 0.1260 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 2108: loss = 0.1180 (0.394 sec/step)\n",
            "I0205 13:32:37.807036 140689526667136 learning.py:507] global step 2108: loss = 0.1180 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 2109: loss = 0.2893 (0.403 sec/step)\n",
            "I0205 13:32:38.211632 140689526667136 learning.py:507] global step 2109: loss = 0.2893 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 2110: loss = 0.4391 (0.385 sec/step)\n",
            "I0205 13:32:38.598258 140689526667136 learning.py:507] global step 2110: loss = 0.4391 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 2111: loss = 0.0861 (0.383 sec/step)\n",
            "I0205 13:32:38.982510 140689526667136 learning.py:507] global step 2111: loss = 0.0861 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2112: loss = 0.2013 (0.369 sec/step)\n",
            "I0205 13:32:39.353178 140689526667136 learning.py:507] global step 2112: loss = 0.2013 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 2113: loss = 0.0790 (0.392 sec/step)\n",
            "I0205 13:32:39.746624 140689526667136 learning.py:507] global step 2113: loss = 0.0790 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 2114: loss = 0.1151 (0.393 sec/step)\n",
            "I0205 13:32:40.141552 140689526667136 learning.py:507] global step 2114: loss = 0.1151 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 2115: loss = 0.0565 (0.386 sec/step)\n",
            "I0205 13:32:40.528874 140689526667136 learning.py:507] global step 2115: loss = 0.0565 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 2116: loss = 0.9675 (0.373 sec/step)\n",
            "I0205 13:32:40.903225 140689526667136 learning.py:507] global step 2116: loss = 0.9675 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 2117: loss = 0.1610 (0.375 sec/step)\n",
            "I0205 13:32:41.279605 140689526667136 learning.py:507] global step 2117: loss = 0.1610 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2118: loss = 0.0900 (0.387 sec/step)\n",
            "I0205 13:32:41.668293 140689526667136 learning.py:507] global step 2118: loss = 0.0900 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 2119: loss = 0.3377 (0.375 sec/step)\n",
            "I0205 13:32:42.044617 140689526667136 learning.py:507] global step 2119: loss = 0.3377 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2120: loss = 0.3906 (0.396 sec/step)\n",
            "I0205 13:32:42.441816 140689526667136 learning.py:507] global step 2120: loss = 0.3906 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 2121: loss = 0.1965 (0.386 sec/step)\n",
            "I0205 13:32:42.829255 140689526667136 learning.py:507] global step 2121: loss = 0.1965 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 2122: loss = 0.1342 (0.389 sec/step)\n",
            "I0205 13:32:43.219987 140689526667136 learning.py:507] global step 2122: loss = 0.1342 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 2123: loss = 0.2502 (0.387 sec/step)\n",
            "I0205 13:32:43.608491 140689526667136 learning.py:507] global step 2123: loss = 0.2502 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 2124: loss = 0.1118 (0.385 sec/step)\n",
            "I0205 13:32:43.995513 140689526667136 learning.py:507] global step 2124: loss = 0.1118 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 2125: loss = 0.0984 (0.392 sec/step)\n",
            "I0205 13:32:44.389783 140689526667136 learning.py:507] global step 2125: loss = 0.0984 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 2126: loss = 0.0418 (0.365 sec/step)\n",
            "I0205 13:32:44.756007 140689526667136 learning.py:507] global step 2126: loss = 0.0418 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 2127: loss = 0.1564 (0.370 sec/step)\n",
            "I0205 13:32:45.127822 140689526667136 learning.py:507] global step 2127: loss = 0.1564 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 2128: loss = 0.1607 (0.346 sec/step)\n",
            "I0205 13:32:45.475185 140689526667136 learning.py:507] global step 2128: loss = 0.1607 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 2129: loss = 0.0768 (0.376 sec/step)\n",
            "I0205 13:32:45.853180 140689526667136 learning.py:507] global step 2129: loss = 0.0768 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 2130: loss = 0.1218 (0.379 sec/step)\n",
            "I0205 13:32:46.236251 140689526667136 learning.py:507] global step 2130: loss = 0.1218 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2131: loss = 0.0581 (0.382 sec/step)\n",
            "I0205 13:32:46.620659 140689526667136 learning.py:507] global step 2131: loss = 0.0581 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 2132: loss = 0.5495 (0.337 sec/step)\n",
            "I0205 13:32:46.959437 140689526667136 learning.py:507] global step 2132: loss = 0.5495 (0.337 sec/step)\n",
            "INFO:tensorflow:global step 2133: loss = 0.0593 (0.393 sec/step)\n",
            "I0205 13:32:47.354224 140689526667136 learning.py:507] global step 2133: loss = 0.0593 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 2134: loss = 0.0598 (0.401 sec/step)\n",
            "I0205 13:32:47.756809 140689526667136 learning.py:507] global step 2134: loss = 0.0598 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 2135: loss = 0.2715 (0.382 sec/step)\n",
            "I0205 13:32:48.140600 140689526667136 learning.py:507] global step 2135: loss = 0.2715 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 2136: loss = 0.0739 (0.375 sec/step)\n",
            "I0205 13:32:48.517596 140689526667136 learning.py:507] global step 2136: loss = 0.0739 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2137: loss = 0.1698 (0.407 sec/step)\n",
            "I0205 13:32:48.925739 140689526667136 learning.py:507] global step 2137: loss = 0.1698 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 2138: loss = 0.5139 (0.401 sec/step)\n",
            "I0205 13:32:49.328935 140689526667136 learning.py:507] global step 2138: loss = 0.5139 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 2139: loss = 0.0748 (0.393 sec/step)\n",
            "I0205 13:32:49.724024 140689526667136 learning.py:507] global step 2139: loss = 0.0748 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 2140: loss = 0.1934 (0.395 sec/step)\n",
            "I0205 13:32:50.120379 140689526667136 learning.py:507] global step 2140: loss = 0.1934 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 2141: loss = 0.1563 (0.380 sec/step)\n",
            "I0205 13:32:50.502138 140689526667136 learning.py:507] global step 2141: loss = 0.1563 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2142: loss = 0.4554 (0.360 sec/step)\n",
            "I0205 13:32:50.863599 140689526667136 learning.py:507] global step 2142: loss = 0.4554 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 2143: loss = 0.2452 (0.368 sec/step)\n",
            "I0205 13:32:51.232842 140689526667136 learning.py:507] global step 2143: loss = 0.2452 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 2144: loss = 0.1900 (0.394 sec/step)\n",
            "I0205 13:32:51.628208 140689526667136 learning.py:507] global step 2144: loss = 0.1900 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 2145: loss = 0.0393 (0.376 sec/step)\n",
            "I0205 13:32:52.006255 140689526667136 learning.py:507] global step 2145: loss = 0.0393 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 2146: loss = 0.3362 (0.416 sec/step)\n",
            "I0205 13:32:52.425239 140689526667136 learning.py:507] global step 2146: loss = 0.3362 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 2147: loss = 0.2223 (0.416 sec/step)\n",
            "I0205 13:32:52.843612 140689526667136 learning.py:507] global step 2147: loss = 0.2223 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 2148: loss = 0.2776 (0.380 sec/step)\n",
            "I0205 13:32:53.225080 140689526667136 learning.py:507] global step 2148: loss = 0.2776 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2149: loss = 0.1099 (0.404 sec/step)\n",
            "I0205 13:32:53.630225 140689526667136 learning.py:507] global step 2149: loss = 0.1099 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 2150: loss = 0.2659 (0.372 sec/step)\n",
            "I0205 13:32:54.004298 140689526667136 learning.py:507] global step 2150: loss = 0.2659 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 2151: loss = 0.1189 (0.342 sec/step)\n",
            "I0205 13:32:54.347776 140689526667136 learning.py:507] global step 2151: loss = 0.1189 (0.342 sec/step)\n",
            "INFO:tensorflow:global step 2152: loss = 0.2407 (0.403 sec/step)\n",
            "I0205 13:32:54.752445 140689526667136 learning.py:507] global step 2152: loss = 0.2407 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 2153: loss = 0.1235 (0.383 sec/step)\n",
            "I0205 13:32:55.138289 140689526667136 learning.py:507] global step 2153: loss = 0.1235 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2154: loss = 0.1064 (0.392 sec/step)\n",
            "I0205 13:32:55.532212 140689526667136 learning.py:507] global step 2154: loss = 0.1064 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 2155: loss = 0.1569 (0.405 sec/step)\n",
            "I0205 13:32:55.939195 140689526667136 learning.py:507] global step 2155: loss = 0.1569 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 2156: loss = 0.1341 (0.385 sec/step)\n",
            "I0205 13:32:56.325734 140689526667136 learning.py:507] global step 2156: loss = 0.1341 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 2157: loss = 0.0565 (0.447 sec/step)\n",
            "I0205 13:32:56.774153 140689526667136 learning.py:507] global step 2157: loss = 0.0565 (0.447 sec/step)\n",
            "INFO:tensorflow:global step 2158: loss = 0.1826 (0.378 sec/step)\n",
            "I0205 13:32:57.153469 140689526667136 learning.py:507] global step 2158: loss = 0.1826 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 2159: loss = 0.0651 (0.405 sec/step)\n",
            "I0205 13:32:57.560745 140689526667136 learning.py:507] global step 2159: loss = 0.0651 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 2160: loss = 0.1191 (0.371 sec/step)\n",
            "I0205 13:32:57.934370 140689526667136 learning.py:507] global step 2160: loss = 0.1191 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 2161: loss = 1.3173 (0.350 sec/step)\n",
            "I0205 13:32:58.285689 140689526667136 learning.py:507] global step 2161: loss = 1.3173 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 2162: loss = 0.1180 (0.369 sec/step)\n",
            "I0205 13:32:58.656802 140689526667136 learning.py:507] global step 2162: loss = 0.1180 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 2163: loss = 0.0261 (0.385 sec/step)\n",
            "I0205 13:32:59.042975 140689526667136 learning.py:507] global step 2163: loss = 0.0261 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 2164: loss = 0.5661 (0.379 sec/step)\n",
            "I0205 13:32:59.423069 140689526667136 learning.py:507] global step 2164: loss = 0.5661 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2165: loss = 0.2498 (0.391 sec/step)\n",
            "I0205 13:32:59.815592 140689526667136 learning.py:507] global step 2165: loss = 0.2498 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2166: loss = 0.0605 (0.388 sec/step)\n",
            "I0205 13:33:00.205215 140689526667136 learning.py:507] global step 2166: loss = 0.0605 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 2167: loss = 0.1460 (0.391 sec/step)\n",
            "I0205 13:33:00.598120 140689526667136 learning.py:507] global step 2167: loss = 0.1460 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2168: loss = 0.1568 (0.391 sec/step)\n",
            "I0205 13:33:00.991045 140689526667136 learning.py:507] global step 2168: loss = 0.1568 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2169: loss = 1.0021 (1.993 sec/step)\n",
            "I0205 13:33:02.986070 140689526667136 learning.py:507] global step 2169: loss = 1.0021 (1.993 sec/step)\n",
            "INFO:tensorflow:global step 2170: loss = 0.1385 (0.371 sec/step)\n",
            "I0205 13:33:03.358644 140689526667136 learning.py:507] global step 2170: loss = 0.1385 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 2171: loss = 0.1065 (0.391 sec/step)\n",
            "I0205 13:33:03.751751 140689526667136 learning.py:507] global step 2171: loss = 0.1065 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2172: loss = 0.2118 (0.389 sec/step)\n",
            "I0205 13:33:04.142312 140689526667136 learning.py:507] global step 2172: loss = 0.2118 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 2173: loss = 0.5158 (0.367 sec/step)\n",
            "I0205 13:33:04.510878 140689526667136 learning.py:507] global step 2173: loss = 0.5158 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 2174: loss = 0.3234 (0.372 sec/step)\n",
            "I0205 13:33:04.884604 140689526667136 learning.py:507] global step 2174: loss = 0.3234 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 2175: loss = 0.1059 (0.384 sec/step)\n",
            "I0205 13:33:05.270387 140689526667136 learning.py:507] global step 2175: loss = 0.1059 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 2176: loss = 0.0600 (0.373 sec/step)\n",
            "I0205 13:33:05.644757 140689526667136 learning.py:507] global step 2176: loss = 0.0600 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 2177: loss = 0.1133 (0.436 sec/step)\n",
            "I0205 13:33:06.082586 140689526667136 learning.py:507] global step 2177: loss = 0.1133 (0.436 sec/step)\n",
            "INFO:tensorflow:global step 2178: loss = 0.1099 (0.414 sec/step)\n",
            "I0205 13:33:06.497802 140689526667136 learning.py:507] global step 2178: loss = 0.1099 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 2179: loss = 0.1529 (0.371 sec/step)\n",
            "I0205 13:33:06.870141 140689526667136 learning.py:507] global step 2179: loss = 0.1529 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 2180: loss = 0.0573 (0.376 sec/step)\n",
            "I0205 13:33:07.247956 140689526667136 learning.py:507] global step 2180: loss = 0.0573 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 2181: loss = 0.1259 (0.410 sec/step)\n",
            "I0205 13:33:07.659749 140689526667136 learning.py:507] global step 2181: loss = 0.1259 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 2182: loss = 0.1609 (0.375 sec/step)\n",
            "I0205 13:33:08.036705 140689526667136 learning.py:507] global step 2182: loss = 0.1609 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2183: loss = 0.1309 (0.394 sec/step)\n",
            "I0205 13:33:08.431992 140689526667136 learning.py:507] global step 2183: loss = 0.1309 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 2184: loss = 0.3369 (0.396 sec/step)\n",
            "I0205 13:33:08.829740 140689526667136 learning.py:507] global step 2184: loss = 0.3369 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 2185: loss = 0.4131 (0.378 sec/step)\n",
            "I0205 13:33:09.209746 140689526667136 learning.py:507] global step 2185: loss = 0.4131 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 2186: loss = 0.1483 (0.364 sec/step)\n",
            "I0205 13:33:09.575419 140689526667136 learning.py:507] global step 2186: loss = 0.1483 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 2187: loss = 0.1805 (0.358 sec/step)\n",
            "I0205 13:33:09.934538 140689526667136 learning.py:507] global step 2187: loss = 0.1805 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 2188: loss = 0.5786 (0.401 sec/step)\n",
            "I0205 13:33:10.337678 140689526667136 learning.py:507] global step 2188: loss = 0.5786 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 2189: loss = 0.2712 (0.362 sec/step)\n",
            "I0205 13:33:10.700990 140689526667136 learning.py:507] global step 2189: loss = 0.2712 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 2190: loss = 0.3270 (0.366 sec/step)\n",
            "I0205 13:33:11.069028 140689526667136 learning.py:507] global step 2190: loss = 0.3270 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 2191: loss = 0.2752 (0.382 sec/step)\n",
            "I0205 13:33:11.452581 140689526667136 learning.py:507] global step 2191: loss = 0.2752 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 2192: loss = 0.1957 (0.370 sec/step)\n",
            "I0205 13:33:11.824942 140689526667136 learning.py:507] global step 2192: loss = 0.1957 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 2193: loss = 0.1415 (0.382 sec/step)\n",
            "I0205 13:33:12.208815 140689526667136 learning.py:507] global step 2193: loss = 0.1415 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 2194: loss = 0.2582 (0.385 sec/step)\n",
            "I0205 13:33:12.595191 140689526667136 learning.py:507] global step 2194: loss = 0.2582 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 2195: loss = 0.0719 (0.394 sec/step)\n",
            "I0205 13:33:12.991046 140689526667136 learning.py:507] global step 2195: loss = 0.0719 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 2196: loss = 0.6265 (0.369 sec/step)\n",
            "I0205 13:33:13.361726 140689526667136 learning.py:507] global step 2196: loss = 0.6265 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 2197: loss = 0.5844 (0.380 sec/step)\n",
            "I0205 13:33:13.743923 140689526667136 learning.py:507] global step 2197: loss = 0.5844 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2198: loss = 0.1732 (0.389 sec/step)\n",
            "I0205 13:33:14.134977 140689526667136 learning.py:507] global step 2198: loss = 0.1732 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 2199: loss = 0.3859 (0.383 sec/step)\n",
            "I0205 13:33:14.520092 140689526667136 learning.py:507] global step 2199: loss = 0.3859 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2200: loss = 0.0446 (0.358 sec/step)\n",
            "I0205 13:33:14.879571 140689526667136 learning.py:507] global step 2200: loss = 0.0446 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 2201: loss = 0.1082 (0.403 sec/step)\n",
            "I0205 13:33:15.284673 140689526667136 learning.py:507] global step 2201: loss = 0.1082 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 2202: loss = 0.1580 (0.386 sec/step)\n",
            "I0205 13:33:15.672385 140689526667136 learning.py:507] global step 2202: loss = 0.1580 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 2203: loss = 0.2461 (0.372 sec/step)\n",
            "I0205 13:33:16.046193 140689526667136 learning.py:507] global step 2203: loss = 0.2461 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 2204: loss = 0.3716 (0.364 sec/step)\n",
            "I0205 13:33:16.411142 140689526667136 learning.py:507] global step 2204: loss = 0.3716 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 2205: loss = 0.5519 (0.962 sec/step)\n",
            "I0205 13:33:17.374412 140689526667136 learning.py:507] global step 2205: loss = 0.5519 (0.962 sec/step)\n",
            "INFO:tensorflow:global step 2206: loss = 0.5632 (0.351 sec/step)\n",
            "I0205 13:33:17.727207 140689526667136 learning.py:507] global step 2206: loss = 0.5632 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 2207: loss = 0.3118 (0.360 sec/step)\n",
            "I0205 13:33:18.088688 140689526667136 learning.py:507] global step 2207: loss = 0.3118 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 2208: loss = 0.0893 (0.381 sec/step)\n",
            "I0205 13:33:18.471558 140689526667136 learning.py:507] global step 2208: loss = 0.0893 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 2209: loss = 0.1985 (0.355 sec/step)\n",
            "I0205 13:33:18.827911 140689526667136 learning.py:507] global step 2209: loss = 0.1985 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 2210: loss = 0.1999 (0.423 sec/step)\n",
            "I0205 13:33:19.252908 140689526667136 learning.py:507] global step 2210: loss = 0.1999 (0.423 sec/step)\n",
            "INFO:tensorflow:global step 2211: loss = 0.4974 (0.376 sec/step)\n",
            "I0205 13:33:19.630814 140689526667136 learning.py:507] global step 2211: loss = 0.4974 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 2212: loss = 0.0685 (0.370 sec/step)\n",
            "I0205 13:33:20.002847 140689526667136 learning.py:507] global step 2212: loss = 0.0685 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 2213: loss = 0.2424 (0.380 sec/step)\n",
            "I0205 13:33:20.384118 140689526667136 learning.py:507] global step 2213: loss = 0.2424 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2214: loss = 0.3115 (0.354 sec/step)\n",
            "I0205 13:33:20.740478 140689526667136 learning.py:507] global step 2214: loss = 0.3115 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 2215: loss = 0.1738 (0.416 sec/step)\n",
            "I0205 13:33:21.158041 140689526667136 learning.py:507] global step 2215: loss = 0.1738 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 2216: loss = 0.3466 (0.366 sec/step)\n",
            "I0205 13:33:21.525907 140689526667136 learning.py:507] global step 2216: loss = 0.3466 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 2217: loss = 0.2727 (0.392 sec/step)\n",
            "I0205 13:33:21.919065 140689526667136 learning.py:507] global step 2217: loss = 0.2727 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 2218: loss = 0.8385 (0.365 sec/step)\n",
            "I0205 13:33:22.285800 140689526667136 learning.py:507] global step 2218: loss = 0.8385 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 2219: loss = 0.3974 (0.359 sec/step)\n",
            "I0205 13:33:22.646473 140689526667136 learning.py:507] global step 2219: loss = 0.3974 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 2220: loss = 0.0232 (0.358 sec/step)\n",
            "I0205 13:33:23.006312 140689526667136 learning.py:507] global step 2220: loss = 0.0232 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 2221: loss = 0.1692 (0.369 sec/step)\n",
            "I0205 13:33:23.376764 140689526667136 learning.py:507] global step 2221: loss = 0.1692 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 2222: loss = 0.1761 (0.364 sec/step)\n",
            "I0205 13:33:23.742598 140689526667136 learning.py:507] global step 2222: loss = 0.1761 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 2223: loss = 0.0865 (0.378 sec/step)\n",
            "I0205 13:33:24.123384 140689526667136 learning.py:507] global step 2223: loss = 0.0865 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 2224: loss = 0.1837 (0.386 sec/step)\n",
            "I0205 13:33:24.511706 140689526667136 learning.py:507] global step 2224: loss = 0.1837 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 2225: loss = 0.1217 (0.356 sec/step)\n",
            "I0205 13:33:24.869499 140689526667136 learning.py:507] global step 2225: loss = 0.1217 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 2226: loss = 0.3841 (0.379 sec/step)\n",
            "I0205 13:33:25.250506 140689526667136 learning.py:507] global step 2226: loss = 0.3841 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2227: loss = 0.1203 (0.393 sec/step)\n",
            "I0205 13:33:25.645301 140689526667136 learning.py:507] global step 2227: loss = 0.1203 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 2228: loss = 0.0412 (0.378 sec/step)\n",
            "I0205 13:33:26.025497 140689526667136 learning.py:507] global step 2228: loss = 0.0412 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 2229: loss = 0.4172 (0.381 sec/step)\n",
            "I0205 13:33:26.407990 140689526667136 learning.py:507] global step 2229: loss = 0.4172 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 2230: loss = 0.2697 (0.393 sec/step)\n",
            "I0205 13:33:26.802950 140689526667136 learning.py:507] global step 2230: loss = 0.2697 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 2231: loss = 1.4942 (0.381 sec/step)\n",
            "I0205 13:33:27.185667 140689526667136 learning.py:507] global step 2231: loss = 1.4942 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 2232: loss = 0.1211 (0.389 sec/step)\n",
            "I0205 13:33:27.576287 140689526667136 learning.py:507] global step 2232: loss = 0.1211 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 2233: loss = 0.5281 (0.389 sec/step)\n",
            "I0205 13:33:27.967102 140689526667136 learning.py:507] global step 2233: loss = 0.5281 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 2234: loss = 0.1850 (0.391 sec/step)\n",
            "I0205 13:33:28.359877 140689526667136 learning.py:507] global step 2234: loss = 0.1850 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2235: loss = 0.1546 (0.378 sec/step)\n",
            "I0205 13:33:28.740274 140689526667136 learning.py:507] global step 2235: loss = 0.1546 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 2236: loss = 0.3300 (0.388 sec/step)\n",
            "I0205 13:33:29.130092 140689526667136 learning.py:507] global step 2236: loss = 0.3300 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 2237: loss = 0.1053 (0.408 sec/step)\n",
            "I0205 13:33:29.539877 140689526667136 learning.py:507] global step 2237: loss = 0.1053 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 2238: loss = 0.0874 (0.408 sec/step)\n",
            "I0205 13:33:29.949823 140689526667136 learning.py:507] global step 2238: loss = 0.0874 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 2239: loss = 0.2082 (0.386 sec/step)\n",
            "I0205 13:33:30.337745 140689526667136 learning.py:507] global step 2239: loss = 0.2082 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 2240: loss = 0.2638 (0.389 sec/step)\n",
            "I0205 13:33:30.728371 140689526667136 learning.py:507] global step 2240: loss = 0.2638 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 2241: loss = 0.0257 (0.382 sec/step)\n",
            "I0205 13:33:31.112194 140689526667136 learning.py:507] global step 2241: loss = 0.0257 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 2242: loss = 0.0695 (0.397 sec/step)\n",
            "I0205 13:33:31.511488 140689526667136 learning.py:507] global step 2242: loss = 0.0695 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 2243: loss = 0.2679 (0.375 sec/step)\n",
            "I0205 13:33:31.888289 140689526667136 learning.py:507] global step 2243: loss = 0.2679 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2244: loss = 0.2762 (0.387 sec/step)\n",
            "I0205 13:33:32.276589 140689526667136 learning.py:507] global step 2244: loss = 0.2762 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 2245: loss = 0.1113 (0.400 sec/step)\n",
            "I0205 13:33:32.678314 140689526667136 learning.py:507] global step 2245: loss = 0.1113 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 2246: loss = 0.1306 (0.400 sec/step)\n",
            "I0205 13:33:33.079824 140689526667136 learning.py:507] global step 2246: loss = 0.1306 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 2247: loss = 0.1010 (0.426 sec/step)\n",
            "I0205 13:33:33.507407 140689526667136 learning.py:507] global step 2247: loss = 0.1010 (0.426 sec/step)\n",
            "INFO:tensorflow:global step 2248: loss = 0.1089 (0.376 sec/step)\n",
            "I0205 13:33:33.884631 140689526667136 learning.py:507] global step 2248: loss = 0.1089 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 2249: loss = 0.0933 (0.412 sec/step)\n",
            "I0205 13:33:34.298613 140689526667136 learning.py:507] global step 2249: loss = 0.0933 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 2250: loss = 0.0507 (0.386 sec/step)\n",
            "I0205 13:33:34.686226 140689526667136 learning.py:507] global step 2250: loss = 0.0507 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 2251: loss = 0.1995 (0.395 sec/step)\n",
            "I0205 13:33:35.083231 140689526667136 learning.py:507] global step 2251: loss = 0.1995 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 2252: loss = 0.4137 (0.357 sec/step)\n",
            "I0205 13:33:35.441562 140689526667136 learning.py:507] global step 2252: loss = 0.4137 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 2253: loss = 0.0620 (0.373 sec/step)\n",
            "I0205 13:33:35.816715 140689526667136 learning.py:507] global step 2253: loss = 0.0620 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 2254: loss = 0.2064 (0.371 sec/step)\n",
            "I0205 13:33:36.189075 140689526667136 learning.py:507] global step 2254: loss = 0.2064 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 2255: loss = 0.0683 (0.381 sec/step)\n",
            "I0205 13:33:36.571889 140689526667136 learning.py:507] global step 2255: loss = 0.0683 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 2256: loss = 0.2645 (0.378 sec/step)\n",
            "I0205 13:33:36.951252 140689526667136 learning.py:507] global step 2256: loss = 0.2645 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 2257: loss = 0.0639 (0.379 sec/step)\n",
            "I0205 13:33:37.331857 140689526667136 learning.py:507] global step 2257: loss = 0.0639 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2258: loss = 1.3611 (0.384 sec/step)\n",
            "I0205 13:33:37.717681 140689526667136 learning.py:507] global step 2258: loss = 1.3611 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 2259: loss = 0.2098 (0.374 sec/step)\n",
            "I0205 13:33:38.093923 140689526667136 learning.py:507] global step 2259: loss = 0.2098 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 2260: loss = 0.1372 (0.383 sec/step)\n",
            "I0205 13:33:38.478749 140689526667136 learning.py:507] global step 2260: loss = 0.1372 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2261: loss = 0.5037 (0.349 sec/step)\n",
            "I0205 13:33:38.830259 140689526667136 learning.py:507] global step 2261: loss = 0.5037 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 2262: loss = 0.3966 (0.349 sec/step)\n",
            "I0205 13:33:39.181365 140689526667136 learning.py:507] global step 2262: loss = 0.3966 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 2263: loss = 0.3913 (0.364 sec/step)\n",
            "I0205 13:33:39.546496 140689526667136 learning.py:507] global step 2263: loss = 0.3913 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 2264: loss = 0.3706 (0.373 sec/step)\n",
            "I0205 13:33:39.920949 140689526667136 learning.py:507] global step 2264: loss = 0.3706 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 2265: loss = 0.0574 (0.370 sec/step)\n",
            "I0205 13:33:40.292897 140689526667136 learning.py:507] global step 2265: loss = 0.0574 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 2266: loss = 0.1233 (0.363 sec/step)\n",
            "I0205 13:33:40.658810 140689526667136 learning.py:507] global step 2266: loss = 0.1233 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 2267: loss = 0.1483 (0.383 sec/step)\n",
            "I0205 13:33:41.044285 140689526667136 learning.py:507] global step 2267: loss = 0.1483 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2268: loss = 0.2198 (0.371 sec/step)\n",
            "I0205 13:33:41.416759 140689526667136 learning.py:507] global step 2268: loss = 0.2198 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 2269: loss = 0.1672 (0.391 sec/step)\n",
            "I0205 13:33:41.809118 140689526667136 learning.py:507] global step 2269: loss = 0.1672 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2270: loss = 0.0519 (0.389 sec/step)\n",
            "I0205 13:33:42.199331 140689526667136 learning.py:507] global step 2270: loss = 0.0519 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 2271: loss = 0.0468 (0.370 sec/step)\n",
            "I0205 13:33:42.573095 140689526667136 learning.py:507] global step 2271: loss = 0.0468 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 2272: loss = 0.3047 (0.468 sec/step)\n",
            "I0205 13:33:43.043138 140689526667136 learning.py:507] global step 2272: loss = 0.3047 (0.468 sec/step)\n",
            "INFO:tensorflow:global step 2273: loss = 0.1356 (0.366 sec/step)\n",
            "I0205 13:33:43.410395 140689526667136 learning.py:507] global step 2273: loss = 0.1356 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 2274: loss = 0.1378 (0.385 sec/step)\n",
            "I0205 13:33:43.798516 140689526667136 learning.py:507] global step 2274: loss = 0.1378 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 2275: loss = 0.8011 (0.371 sec/step)\n",
            "I0205 13:33:44.171147 140689526667136 learning.py:507] global step 2275: loss = 0.8011 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 2276: loss = 0.2592 (0.396 sec/step)\n",
            "I0205 13:33:44.568935 140689526667136 learning.py:507] global step 2276: loss = 0.2592 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 2277: loss = 0.1793 (0.384 sec/step)\n",
            "I0205 13:33:44.954997 140689526667136 learning.py:507] global step 2277: loss = 0.1793 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 2278: loss = 0.0858 (0.376 sec/step)\n",
            "I0205 13:33:45.332956 140689526667136 learning.py:507] global step 2278: loss = 0.0858 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 2279: loss = 0.1109 (0.392 sec/step)\n",
            "I0205 13:33:45.726537 140689526667136 learning.py:507] global step 2279: loss = 0.1109 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 2280: loss = 0.1129 (0.398 sec/step)\n",
            "I0205 13:33:46.126691 140689526667136 learning.py:507] global step 2280: loss = 0.1129 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 2281: loss = 0.0742 (0.360 sec/step)\n",
            "I0205 13:33:46.488093 140689526667136 learning.py:507] global step 2281: loss = 0.0742 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 2282: loss = 0.2087 (0.404 sec/step)\n",
            "I0205 13:33:46.893327 140689526667136 learning.py:507] global step 2282: loss = 0.2087 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 2283: loss = 0.6950 (0.367 sec/step)\n",
            "I0205 13:33:47.261813 140689526667136 learning.py:507] global step 2283: loss = 0.6950 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 2284: loss = 0.0923 (0.388 sec/step)\n",
            "I0205 13:33:47.651807 140689526667136 learning.py:507] global step 2284: loss = 0.0923 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 2285: loss = 0.0438 (0.395 sec/step)\n",
            "I0205 13:33:48.048781 140689526667136 learning.py:507] global step 2285: loss = 0.0438 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 2286: loss = 0.0877 (0.378 sec/step)\n",
            "I0205 13:33:48.428324 140689526667136 learning.py:507] global step 2286: loss = 0.0877 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 2287: loss = 0.1576 (0.399 sec/step)\n",
            "I0205 13:33:48.828544 140689526667136 learning.py:507] global step 2287: loss = 0.1576 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 2288: loss = 0.2218 (0.406 sec/step)\n",
            "I0205 13:33:49.235836 140689526667136 learning.py:507] global step 2288: loss = 0.2218 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 2289: loss = 0.2387 (0.380 sec/step)\n",
            "I0205 13:33:49.617658 140689526667136 learning.py:507] global step 2289: loss = 0.2387 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2290: loss = 0.2034 (0.375 sec/step)\n",
            "I0205 13:33:49.993993 140689526667136 learning.py:507] global step 2290: loss = 0.2034 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2291: loss = 0.3264 (0.371 sec/step)\n",
            "I0205 13:33:50.366698 140689526667136 learning.py:507] global step 2291: loss = 0.3264 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 2292: loss = 0.1655 (0.397 sec/step)\n",
            "I0205 13:33:50.765697 140689526667136 learning.py:507] global step 2292: loss = 0.1655 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 2293: loss = 0.0469 (0.399 sec/step)\n",
            "I0205 13:33:51.166834 140689526667136 learning.py:507] global step 2293: loss = 0.0469 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 2294: loss = 0.5388 (0.366 sec/step)\n",
            "I0205 13:33:51.534772 140689526667136 learning.py:507] global step 2294: loss = 0.5388 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 2295: loss = 0.1473 (0.364 sec/step)\n",
            "I0205 13:33:51.900859 140689526667136 learning.py:507] global step 2295: loss = 0.1473 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 2296: loss = 0.4548 (0.402 sec/step)\n",
            "I0205 13:33:52.304811 140689526667136 learning.py:507] global step 2296: loss = 0.4548 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 2297: loss = 0.0806 (0.433 sec/step)\n",
            "I0205 13:33:52.739737 140689526667136 learning.py:507] global step 2297: loss = 0.0806 (0.433 sec/step)\n",
            "INFO:tensorflow:global step 2298: loss = 0.5682 (0.379 sec/step)\n",
            "I0205 13:33:53.120660 140689526667136 learning.py:507] global step 2298: loss = 0.5682 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2299: loss = 0.0487 (0.385 sec/step)\n",
            "I0205 13:33:53.507560 140689526667136 learning.py:507] global step 2299: loss = 0.0487 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 2300: loss = 0.2064 (0.377 sec/step)\n",
            "I0205 13:33:53.886785 140689526667136 learning.py:507] global step 2300: loss = 0.2064 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 2301: loss = 0.4887 (0.363 sec/step)\n",
            "I0205 13:33:54.251399 140689526667136 learning.py:507] global step 2301: loss = 0.4887 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 2302: loss = 0.1201 (0.400 sec/step)\n",
            "I0205 13:33:54.652647 140689526667136 learning.py:507] global step 2302: loss = 0.1201 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 2303: loss = 0.2970 (0.372 sec/step)\n",
            "I0205 13:33:55.026039 140689526667136 learning.py:507] global step 2303: loss = 0.2970 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 2304: loss = 0.1954 (0.389 sec/step)\n",
            "I0205 13:33:55.417218 140689526667136 learning.py:507] global step 2304: loss = 0.1954 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 2305: loss = 0.2089 (0.362 sec/step)\n",
            "I0205 13:33:55.781019 140689526667136 learning.py:507] global step 2305: loss = 0.2089 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 2306: loss = 0.5083 (0.353 sec/step)\n",
            "I0205 13:33:56.135547 140689526667136 learning.py:507] global step 2306: loss = 0.5083 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 2307: loss = 0.3208 (0.367 sec/step)\n",
            "I0205 13:33:56.503985 140689526667136 learning.py:507] global step 2307: loss = 0.3208 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 2308: loss = 0.2249 (0.392 sec/step)\n",
            "I0205 13:33:56.897327 140689526667136 learning.py:507] global step 2308: loss = 0.2249 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 2309: loss = 0.2080 (0.376 sec/step)\n",
            "I0205 13:33:57.274642 140689526667136 learning.py:507] global step 2309: loss = 0.2080 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 2310: loss = 0.0229 (0.376 sec/step)\n",
            "I0205 13:33:57.652737 140689526667136 learning.py:507] global step 2310: loss = 0.0229 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 2311: loss = 0.1996 (0.382 sec/step)\n",
            "I0205 13:33:58.036252 140689526667136 learning.py:507] global step 2311: loss = 0.1996 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 2312: loss = 0.0890 (0.373 sec/step)\n",
            "I0205 13:33:58.410637 140689526667136 learning.py:507] global step 2312: loss = 0.0890 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 2313: loss = 0.1747 (0.391 sec/step)\n",
            "I0205 13:33:58.803445 140689526667136 learning.py:507] global step 2313: loss = 0.1747 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2314: loss = 0.2310 (0.382 sec/step)\n",
            "I0205 13:33:59.186927 140689526667136 learning.py:507] global step 2314: loss = 0.2310 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 2315: loss = 0.1335 (0.392 sec/step)\n",
            "I0205 13:33:59.580402 140689526667136 learning.py:507] global step 2315: loss = 0.1335 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 2316: loss = 0.1268 (0.394 sec/step)\n",
            "I0205 13:33:59.976331 140689526667136 learning.py:507] global step 2316: loss = 0.1268 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 2317: loss = 0.1109 (0.387 sec/step)\n",
            "I0205 13:34:00.365058 140689526667136 learning.py:507] global step 2317: loss = 0.1109 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 2318: loss = 0.0882 (0.380 sec/step)\n",
            "I0205 13:34:00.747093 140689526667136 learning.py:507] global step 2318: loss = 0.0882 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2319: loss = 0.6284 (0.389 sec/step)\n",
            "I0205 13:34:01.137570 140689526667136 learning.py:507] global step 2319: loss = 0.6284 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 2320: loss = 0.0835 (0.374 sec/step)\n",
            "I0205 13:34:01.512950 140689526667136 learning.py:507] global step 2320: loss = 0.0835 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 2321: loss = 0.6935 (0.407 sec/step)\n",
            "I0205 13:34:01.921415 140689526667136 learning.py:507] global step 2321: loss = 0.6935 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 2322: loss = 0.2352 (0.399 sec/step)\n",
            "I0205 13:34:02.322301 140689526667136 learning.py:507] global step 2322: loss = 0.2352 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 2323: loss = 0.2131 (0.368 sec/step)\n",
            "I0205 13:34:02.692158 140689526667136 learning.py:507] global step 2323: loss = 0.2131 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 2324: loss = 0.1038 (0.396 sec/step)\n",
            "I0205 13:34:03.089807 140689526667136 learning.py:507] global step 2324: loss = 0.1038 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 2325: loss = 0.0838 (0.350 sec/step)\n",
            "I0205 13:34:03.441139 140689526667136 learning.py:507] global step 2325: loss = 0.0838 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 2326: loss = 0.0875 (0.369 sec/step)\n",
            "I0205 13:34:03.811208 140689526667136 learning.py:507] global step 2326: loss = 0.0875 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 2327: loss = 0.1500 (0.372 sec/step)\n",
            "I0205 13:34:04.184861 140689526667136 learning.py:507] global step 2327: loss = 0.1500 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 2328: loss = 0.1121 (0.375 sec/step)\n",
            "I0205 13:34:04.561790 140689526667136 learning.py:507] global step 2328: loss = 0.1121 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2329: loss = 0.1733 (0.365 sec/step)\n",
            "I0205 13:34:04.928498 140689526667136 learning.py:507] global step 2329: loss = 0.1733 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 2330: loss = 0.1774 (0.371 sec/step)\n",
            "I0205 13:34:05.300738 140689526667136 learning.py:507] global step 2330: loss = 0.1774 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 2331: loss = 0.0471 (0.396 sec/step)\n",
            "I0205 13:34:05.698833 140689526667136 learning.py:507] global step 2331: loss = 0.0471 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 2332: loss = 0.1263 (0.369 sec/step)\n",
            "I0205 13:34:06.069953 140689526667136 learning.py:507] global step 2332: loss = 0.1263 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 2333: loss = 0.1544 (0.407 sec/step)\n",
            "I0205 13:34:06.478831 140689526667136 learning.py:507] global step 2333: loss = 0.1544 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 2334: loss = 0.0258 (0.375 sec/step)\n",
            "I0205 13:34:06.855835 140689526667136 learning.py:507] global step 2334: loss = 0.0258 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2335: loss = 0.4327 (0.363 sec/step)\n",
            "I0205 13:34:07.220847 140689526667136 learning.py:507] global step 2335: loss = 0.4327 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 2336: loss = 0.3022 (0.368 sec/step)\n",
            "I0205 13:34:07.590614 140689526667136 learning.py:507] global step 2336: loss = 0.3022 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 2337: loss = 0.0739 (0.376 sec/step)\n",
            "I0205 13:34:07.968224 140689526667136 learning.py:507] global step 2337: loss = 0.0739 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 2338: loss = 0.1740 (0.417 sec/step)\n",
            "I0205 13:34:08.386593 140689526667136 learning.py:507] global step 2338: loss = 0.1740 (0.417 sec/step)\n",
            "INFO:tensorflow:global step 2339: loss = 0.3678 (0.373 sec/step)\n",
            "I0205 13:34:08.761706 140689526667136 learning.py:507] global step 2339: loss = 0.3678 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 2340: loss = 0.2769 (0.382 sec/step)\n",
            "I0205 13:34:09.144904 140689526667136 learning.py:507] global step 2340: loss = 0.2769 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 2341: loss = 0.1524 (0.423 sec/step)\n",
            "I0205 13:34:09.568885 140689526667136 learning.py:507] global step 2341: loss = 0.1524 (0.423 sec/step)\n",
            "INFO:tensorflow:global step 2342: loss = 0.5307 (0.379 sec/step)\n",
            "I0205 13:34:09.949441 140689526667136 learning.py:507] global step 2342: loss = 0.5307 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2343: loss = 0.1012 (0.356 sec/step)\n",
            "I0205 13:34:10.306715 140689526667136 learning.py:507] global step 2343: loss = 0.1012 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 2344: loss = 0.0547 (0.378 sec/step)\n",
            "I0205 13:34:10.686714 140689526667136 learning.py:507] global step 2344: loss = 0.0547 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 2345: loss = 0.0610 (0.371 sec/step)\n",
            "I0205 13:34:11.059366 140689526667136 learning.py:507] global step 2345: loss = 0.0610 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 2346: loss = 0.2527 (0.398 sec/step)\n",
            "I0205 13:34:11.458994 140689526667136 learning.py:507] global step 2346: loss = 0.2527 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 2347: loss = 0.1819 (0.349 sec/step)\n",
            "I0205 13:34:11.809345 140689526667136 learning.py:507] global step 2347: loss = 0.1819 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 2348: loss = 0.1068 (0.998 sec/step)\n",
            "I0205 13:34:12.808852 140689526667136 learning.py:507] global step 2348: loss = 0.1068 (0.998 sec/step)\n",
            "INFO:tensorflow:global step 2349: loss = 0.4824 (0.372 sec/step)\n",
            "I0205 13:34:13.182344 140689526667136 learning.py:507] global step 2349: loss = 0.4824 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 2350: loss = 0.1374 (0.377 sec/step)\n",
            "I0205 13:34:13.560736 140689526667136 learning.py:507] global step 2350: loss = 0.1374 (0.377 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path ../training/model.ckpt\n",
            "I0205 13:34:13.745407 140686000895744 supervisor.py:1117] Saving checkpoint to path ../training/model.ckpt\n",
            "INFO:tensorflow:global step 2351: loss = 1.0079 (1.845 sec/step)\n",
            "I0205 13:34:15.445149 140689526667136 learning.py:507] global step 2351: loss = 1.0079 (1.845 sec/step)\n",
            "INFO:tensorflow:global step 2352: loss = 0.5797 (2.381 sec/step)\n",
            "I0205 13:34:17.923999 140689526667136 learning.py:507] global step 2352: loss = 0.5797 (2.381 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 2352.\n",
            "I0205 13:34:17.991772 140686026073856 supervisor.py:1050] Recording summary at step 2352.\n",
            "INFO:tensorflow:global step 2353: loss = 0.2213 (0.383 sec/step)\n",
            "I0205 13:34:18.383704 140689526667136 learning.py:507] global step 2353: loss = 0.2213 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2354: loss = 0.3067 (0.394 sec/step)\n",
            "I0205 13:34:18.779594 140689526667136 learning.py:507] global step 2354: loss = 0.3067 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 2355: loss = 0.0414 (0.390 sec/step)\n",
            "I0205 13:34:19.171356 140689526667136 learning.py:507] global step 2355: loss = 0.0414 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 2356: loss = 0.1448 (0.398 sec/step)\n",
            "I0205 13:34:19.571529 140689526667136 learning.py:507] global step 2356: loss = 0.1448 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 2357: loss = 0.0802 (0.372 sec/step)\n",
            "I0205 13:34:19.944808 140689526667136 learning.py:507] global step 2357: loss = 0.0802 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 2358: loss = 0.1129 (0.378 sec/step)\n",
            "I0205 13:34:20.324305 140689526667136 learning.py:507] global step 2358: loss = 0.1129 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 2359: loss = 0.3036 (0.344 sec/step)\n",
            "I0205 13:34:20.669474 140689526667136 learning.py:507] global step 2359: loss = 0.3036 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 2360: loss = 0.2019 (0.376 sec/step)\n",
            "I0205 13:34:21.047039 140689526667136 learning.py:507] global step 2360: loss = 0.2019 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 2361: loss = 0.0131 (0.459 sec/step)\n",
            "I0205 13:34:21.507337 140689526667136 learning.py:507] global step 2361: loss = 0.0131 (0.459 sec/step)\n",
            "INFO:tensorflow:global step 2362: loss = 0.0523 (0.402 sec/step)\n",
            "I0205 13:34:21.910730 140689526667136 learning.py:507] global step 2362: loss = 0.0523 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 2363: loss = 0.1715 (0.384 sec/step)\n",
            "I0205 13:34:22.296229 140689526667136 learning.py:507] global step 2363: loss = 0.1715 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 2364: loss = 0.2945 (0.387 sec/step)\n",
            "I0205 13:34:22.684910 140689526667136 learning.py:507] global step 2364: loss = 0.2945 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 2365: loss = 0.3088 (0.399 sec/step)\n",
            "I0205 13:34:23.085531 140689526667136 learning.py:507] global step 2365: loss = 0.3088 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 2366: loss = 0.1864 (0.368 sec/step)\n",
            "I0205 13:34:23.455260 140689526667136 learning.py:507] global step 2366: loss = 0.1864 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 2367: loss = 0.2030 (0.372 sec/step)\n",
            "I0205 13:34:23.828893 140689526667136 learning.py:507] global step 2367: loss = 0.2030 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 2368: loss = 0.2067 (0.381 sec/step)\n",
            "I0205 13:34:24.211539 140689526667136 learning.py:507] global step 2368: loss = 0.2067 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 2369: loss = 0.5306 (0.398 sec/step)\n",
            "I0205 13:34:24.611244 140689526667136 learning.py:507] global step 2369: loss = 0.5306 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 2370: loss = 0.1028 (0.362 sec/step)\n",
            "I0205 13:34:24.974685 140689526667136 learning.py:507] global step 2370: loss = 0.1028 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 2371: loss = 0.2391 (0.366 sec/step)\n",
            "I0205 13:34:25.342705 140689526667136 learning.py:507] global step 2371: loss = 0.2391 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 2372: loss = 0.2233 (0.398 sec/step)\n",
            "I0205 13:34:25.742782 140689526667136 learning.py:507] global step 2372: loss = 0.2233 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 2373: loss = 0.0704 (0.368 sec/step)\n",
            "I0205 13:34:26.112602 140689526667136 learning.py:507] global step 2373: loss = 0.0704 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 2374: loss = 0.0696 (0.391 sec/step)\n",
            "I0205 13:34:26.505225 140689526667136 learning.py:507] global step 2374: loss = 0.0696 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2375: loss = 0.1760 (0.351 sec/step)\n",
            "I0205 13:34:26.860362 140689526667136 learning.py:507] global step 2375: loss = 0.1760 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 2376: loss = 0.0743 (0.377 sec/step)\n",
            "I0205 13:34:27.241438 140689526667136 learning.py:507] global step 2376: loss = 0.0743 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 2377: loss = 0.5041 (0.365 sec/step)\n",
            "I0205 13:34:27.607888 140689526667136 learning.py:507] global step 2377: loss = 0.5041 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 2378: loss = 0.2034 (0.403 sec/step)\n",
            "I0205 13:34:28.011874 140689526667136 learning.py:507] global step 2378: loss = 0.2034 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 2379: loss = 0.1998 (0.369 sec/step)\n",
            "I0205 13:34:28.382321 140689526667136 learning.py:507] global step 2379: loss = 0.1998 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 2380: loss = 0.3374 (0.386 sec/step)\n",
            "I0205 13:34:28.769694 140689526667136 learning.py:507] global step 2380: loss = 0.3374 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 2381: loss = 0.5125 (0.380 sec/step)\n",
            "I0205 13:34:29.151176 140689526667136 learning.py:507] global step 2381: loss = 0.5125 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2382: loss = 0.1032 (0.387 sec/step)\n",
            "I0205 13:34:29.539318 140689526667136 learning.py:507] global step 2382: loss = 0.1032 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 2383: loss = 0.2601 (0.432 sec/step)\n",
            "I0205 13:34:29.972433 140689526667136 learning.py:507] global step 2383: loss = 0.2601 (0.432 sec/step)\n",
            "INFO:tensorflow:global step 2384: loss = 0.1562 (0.382 sec/step)\n",
            "I0205 13:34:30.356480 140689526667136 learning.py:507] global step 2384: loss = 0.1562 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 2385: loss = 0.5919 (0.350 sec/step)\n",
            "I0205 13:34:30.707816 140689526667136 learning.py:507] global step 2385: loss = 0.5919 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 2386: loss = 0.1403 (0.365 sec/step)\n",
            "I0205 13:34:31.074514 140689526667136 learning.py:507] global step 2386: loss = 0.1403 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 2387: loss = 0.2053 (0.399 sec/step)\n",
            "I0205 13:34:31.474988 140689526667136 learning.py:507] global step 2387: loss = 0.2053 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 2388: loss = 0.2855 (0.367 sec/step)\n",
            "I0205 13:34:31.843975 140689526667136 learning.py:507] global step 2388: loss = 0.2855 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 2389: loss = 0.0922 (0.400 sec/step)\n",
            "I0205 13:34:32.245669 140689526667136 learning.py:507] global step 2389: loss = 0.0922 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 2390: loss = 0.1883 (0.391 sec/step)\n",
            "I0205 13:34:32.637986 140689526667136 learning.py:507] global step 2390: loss = 0.1883 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2391: loss = 0.1063 (0.410 sec/step)\n",
            "I0205 13:34:33.049729 140689526667136 learning.py:507] global step 2391: loss = 0.1063 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 2392: loss = 0.2273 (0.385 sec/step)\n",
            "I0205 13:34:33.436954 140689526667136 learning.py:507] global step 2392: loss = 0.2273 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 2393: loss = 0.0589 (0.369 sec/step)\n",
            "I0205 13:34:33.807924 140689526667136 learning.py:507] global step 2393: loss = 0.0589 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 2394: loss = 0.2807 (0.417 sec/step)\n",
            "I0205 13:34:34.226743 140689526667136 learning.py:507] global step 2394: loss = 0.2807 (0.417 sec/step)\n",
            "INFO:tensorflow:global step 2395: loss = 0.4819 (0.375 sec/step)\n",
            "I0205 13:34:34.603445 140689526667136 learning.py:507] global step 2395: loss = 0.4819 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2396: loss = 0.0765 (0.379 sec/step)\n",
            "I0205 13:34:34.984070 140689526667136 learning.py:507] global step 2396: loss = 0.0765 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2397: loss = 0.9819 (0.359 sec/step)\n",
            "I0205 13:34:35.344820 140689526667136 learning.py:507] global step 2397: loss = 0.9819 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 2398: loss = 0.3678 (0.379 sec/step)\n",
            "I0205 13:34:35.725394 140689526667136 learning.py:507] global step 2398: loss = 0.3678 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2399: loss = 0.2321 (0.377 sec/step)\n",
            "I0205 13:34:36.103602 140689526667136 learning.py:507] global step 2399: loss = 0.2321 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 2400: loss = 0.2068 (0.390 sec/step)\n",
            "I0205 13:34:36.495187 140689526667136 learning.py:507] global step 2400: loss = 0.2068 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 2401: loss = 0.2857 (0.389 sec/step)\n",
            "I0205 13:34:36.886152 140689526667136 learning.py:507] global step 2401: loss = 0.2857 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 2402: loss = 0.0971 (0.371 sec/step)\n",
            "I0205 13:34:37.259110 140689526667136 learning.py:507] global step 2402: loss = 0.0971 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 2403: loss = 0.0616 (0.365 sec/step)\n",
            "I0205 13:34:37.625495 140689526667136 learning.py:507] global step 2403: loss = 0.0616 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 2404: loss = 0.6191 (0.367 sec/step)\n",
            "I0205 13:34:37.994628 140689526667136 learning.py:507] global step 2404: loss = 0.6191 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 2405: loss = 0.1410 (0.382 sec/step)\n",
            "I0205 13:34:38.378798 140689526667136 learning.py:507] global step 2405: loss = 0.1410 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 2406: loss = 0.0586 (0.408 sec/step)\n",
            "I0205 13:34:38.788242 140689526667136 learning.py:507] global step 2406: loss = 0.0586 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 2407: loss = 0.0698 (0.376 sec/step)\n",
            "I0205 13:34:39.165393 140689526667136 learning.py:507] global step 2407: loss = 0.0698 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 2408: loss = 0.1352 (0.348 sec/step)\n",
            "I0205 13:34:39.515224 140689526667136 learning.py:507] global step 2408: loss = 0.1352 (0.348 sec/step)\n",
            "INFO:tensorflow:global step 2409: loss = 0.2039 (0.372 sec/step)\n",
            "I0205 13:34:39.889266 140689526667136 learning.py:507] global step 2409: loss = 0.2039 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 2410: loss = 0.2301 (0.361 sec/step)\n",
            "I0205 13:34:40.253077 140689526667136 learning.py:507] global step 2410: loss = 0.2301 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 2411: loss = 0.1676 (0.375 sec/step)\n",
            "I0205 13:34:40.629343 140689526667136 learning.py:507] global step 2411: loss = 0.1676 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2412: loss = 0.1544 (0.354 sec/step)\n",
            "I0205 13:34:40.984907 140689526667136 learning.py:507] global step 2412: loss = 0.1544 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 2413: loss = 0.3704 (0.405 sec/step)\n",
            "I0205 13:34:41.393794 140689526667136 learning.py:507] global step 2413: loss = 0.3704 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 2414: loss = 0.1953 (0.387 sec/step)\n",
            "I0205 13:34:41.782757 140689526667136 learning.py:507] global step 2414: loss = 0.1953 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 2415: loss = 0.2662 (0.389 sec/step)\n",
            "I0205 13:34:42.172991 140689526667136 learning.py:507] global step 2415: loss = 0.2662 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 2416: loss = 0.1750 (0.387 sec/step)\n",
            "I0205 13:34:42.561383 140689526667136 learning.py:507] global step 2416: loss = 0.1750 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 2417: loss = 0.3122 (0.370 sec/step)\n",
            "I0205 13:34:42.933186 140689526667136 learning.py:507] global step 2417: loss = 0.3122 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 2418: loss = 0.4483 (0.357 sec/step)\n",
            "I0205 13:34:43.291857 140689526667136 learning.py:507] global step 2418: loss = 0.4483 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 2419: loss = 0.2396 (0.405 sec/step)\n",
            "I0205 13:34:43.698379 140689526667136 learning.py:507] global step 2419: loss = 0.2396 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 2420: loss = 0.1316 (0.392 sec/step)\n",
            "I0205 13:34:44.092842 140689526667136 learning.py:507] global step 2420: loss = 0.1316 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 2421: loss = 0.1488 (0.384 sec/step)\n",
            "I0205 13:34:44.478548 140689526667136 learning.py:507] global step 2421: loss = 0.1488 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 2422: loss = 0.1099 (0.466 sec/step)\n",
            "I0205 13:34:44.945710 140689526667136 learning.py:507] global step 2422: loss = 0.1099 (0.466 sec/step)\n",
            "INFO:tensorflow:global step 2423: loss = 0.1767 (0.386 sec/step)\n",
            "I0205 13:34:45.333439 140689526667136 learning.py:507] global step 2423: loss = 0.1767 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 2424: loss = 0.1507 (0.382 sec/step)\n",
            "I0205 13:34:45.716689 140689526667136 learning.py:507] global step 2424: loss = 0.1507 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 2425: loss = 0.2469 (0.366 sec/step)\n",
            "I0205 13:34:46.084469 140689526667136 learning.py:507] global step 2425: loss = 0.2469 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 2426: loss = 0.1346 (0.374 sec/step)\n",
            "I0205 13:34:46.459639 140689526667136 learning.py:507] global step 2426: loss = 0.1346 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 2427: loss = 0.2409 (0.383 sec/step)\n",
            "I0205 13:34:46.845370 140689526667136 learning.py:507] global step 2427: loss = 0.2409 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2428: loss = 0.2364 (0.383 sec/step)\n",
            "I0205 13:34:47.230792 140689526667136 learning.py:507] global step 2428: loss = 0.2364 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2429: loss = 0.2931 (0.380 sec/step)\n",
            "I0205 13:34:47.612545 140689526667136 learning.py:507] global step 2429: loss = 0.2931 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2430: loss = 0.1066 (0.385 sec/step)\n",
            "I0205 13:34:47.998870 140689526667136 learning.py:507] global step 2430: loss = 0.1066 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 2431: loss = 0.1998 (0.369 sec/step)\n",
            "I0205 13:34:48.369503 140689526667136 learning.py:507] global step 2431: loss = 0.1998 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 2432: loss = 0.1619 (0.387 sec/step)\n",
            "I0205 13:34:48.758038 140689526667136 learning.py:507] global step 2432: loss = 0.1619 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 2433: loss = 0.2549 (0.374 sec/step)\n",
            "I0205 13:34:49.133437 140689526667136 learning.py:507] global step 2433: loss = 0.2549 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 2434: loss = 0.1708 (0.414 sec/step)\n",
            "I0205 13:34:49.548853 140689526667136 learning.py:507] global step 2434: loss = 0.1708 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 2435: loss = 0.1531 (0.383 sec/step)\n",
            "I0205 13:34:49.933651 140689526667136 learning.py:507] global step 2435: loss = 0.1531 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2436: loss = 0.1935 (0.390 sec/step)\n",
            "I0205 13:34:50.325421 140689526667136 learning.py:507] global step 2436: loss = 0.1935 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 2437: loss = 0.0918 (0.350 sec/step)\n",
            "I0205 13:34:50.678283 140689526667136 learning.py:507] global step 2437: loss = 0.0918 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 2438: loss = 0.6369 (0.402 sec/step)\n",
            "I0205 13:34:51.082775 140689526667136 learning.py:507] global step 2438: loss = 0.6369 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 2439: loss = 0.0281 (0.407 sec/step)\n",
            "I0205 13:34:51.491538 140689526667136 learning.py:507] global step 2439: loss = 0.0281 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 2440: loss = 0.1360 (0.397 sec/step)\n",
            "I0205 13:34:51.889837 140689526667136 learning.py:507] global step 2440: loss = 0.1360 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 2441: loss = 0.0556 (0.373 sec/step)\n",
            "I0205 13:34:52.265352 140689526667136 learning.py:507] global step 2441: loss = 0.0556 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 2442: loss = 0.0717 (0.455 sec/step)\n",
            "I0205 13:34:52.722757 140689526667136 learning.py:507] global step 2442: loss = 0.0717 (0.455 sec/step)\n",
            "INFO:tensorflow:global step 2443: loss = 0.0783 (0.396 sec/step)\n",
            "I0205 13:34:53.120902 140689526667136 learning.py:507] global step 2443: loss = 0.0783 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 2444: loss = 0.3914 (0.375 sec/step)\n",
            "I0205 13:34:53.497869 140689526667136 learning.py:507] global step 2444: loss = 0.3914 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2445: loss = 0.1776 (0.375 sec/step)\n",
            "I0205 13:34:53.874233 140689526667136 learning.py:507] global step 2445: loss = 0.1776 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2446: loss = 0.1299 (0.390 sec/step)\n",
            "I0205 13:34:54.265759 140689526667136 learning.py:507] global step 2446: loss = 0.1299 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 2447: loss = 0.1719 (0.385 sec/step)\n",
            "I0205 13:34:54.652445 140689526667136 learning.py:507] global step 2447: loss = 0.1719 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 2448: loss = 0.1091 (0.998 sec/step)\n",
            "I0205 13:34:55.652214 140689526667136 learning.py:507] global step 2448: loss = 0.1091 (0.998 sec/step)\n",
            "INFO:tensorflow:global step 2449: loss = 0.0490 (0.391 sec/step)\n",
            "I0205 13:34:56.045010 140689526667136 learning.py:507] global step 2449: loss = 0.0490 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2450: loss = 0.1974 (0.374 sec/step)\n",
            "I0205 13:34:56.421010 140689526667136 learning.py:507] global step 2450: loss = 0.1974 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 2451: loss = 0.2116 (0.411 sec/step)\n",
            "I0205 13:34:56.834098 140689526667136 learning.py:507] global step 2451: loss = 0.2116 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 2452: loss = 0.1454 (0.395 sec/step)\n",
            "I0205 13:34:57.231159 140689526667136 learning.py:507] global step 2452: loss = 0.1454 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 2453: loss = 0.0754 (0.370 sec/step)\n",
            "I0205 13:34:57.602775 140689526667136 learning.py:507] global step 2453: loss = 0.0754 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 2454: loss = 0.3135 (0.373 sec/step)\n",
            "I0205 13:34:57.977303 140689526667136 learning.py:507] global step 2454: loss = 0.3135 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 2455: loss = 0.1522 (0.392 sec/step)\n",
            "I0205 13:34:58.372594 140689526667136 learning.py:507] global step 2455: loss = 0.1522 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 2456: loss = 0.2928 (0.380 sec/step)\n",
            "I0205 13:34:58.753862 140689526667136 learning.py:507] global step 2456: loss = 0.2928 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2457: loss = 0.1784 (0.382 sec/step)\n",
            "I0205 13:34:59.137553 140689526667136 learning.py:507] global step 2457: loss = 0.1784 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 2458: loss = 0.2633 (0.375 sec/step)\n",
            "I0205 13:34:59.514402 140689526667136 learning.py:507] global step 2458: loss = 0.2633 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2459: loss = 0.2517 (0.389 sec/step)\n",
            "I0205 13:34:59.905534 140689526667136 learning.py:507] global step 2459: loss = 0.2517 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 2460: loss = 0.1685 (0.376 sec/step)\n",
            "I0205 13:35:00.283557 140689526667136 learning.py:507] global step 2460: loss = 0.1685 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 2461: loss = 0.1249 (0.382 sec/step)\n",
            "I0205 13:35:00.667306 140689526667136 learning.py:507] global step 2461: loss = 0.1249 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 2462: loss = 0.3966 (0.365 sec/step)\n",
            "I0205 13:35:01.034472 140689526667136 learning.py:507] global step 2462: loss = 0.3966 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 2463: loss = 0.2059 (0.387 sec/step)\n",
            "I0205 13:35:01.423710 140689526667136 learning.py:507] global step 2463: loss = 0.2059 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 2464: loss = 0.2018 (0.408 sec/step)\n",
            "I0205 13:35:01.832851 140689526667136 learning.py:507] global step 2464: loss = 0.2018 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 2465: loss = 0.1576 (0.391 sec/step)\n",
            "I0205 13:35:02.226084 140689526667136 learning.py:507] global step 2465: loss = 0.1576 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2466: loss = 0.0690 (0.365 sec/step)\n",
            "I0205 13:35:02.592550 140689526667136 learning.py:507] global step 2466: loss = 0.0690 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 2467: loss = 0.0624 (0.382 sec/step)\n",
            "I0205 13:35:02.975812 140689526667136 learning.py:507] global step 2467: loss = 0.0624 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 2468: loss = 0.2895 (0.342 sec/step)\n",
            "I0205 13:35:03.319640 140689526667136 learning.py:507] global step 2468: loss = 0.2895 (0.342 sec/step)\n",
            "INFO:tensorflow:global step 2469: loss = 0.1687 (1.024 sec/step)\n",
            "I0205 13:35:04.345199 140689526667136 learning.py:507] global step 2469: loss = 0.1687 (1.024 sec/step)\n",
            "INFO:tensorflow:global step 2470: loss = 0.1035 (0.368 sec/step)\n",
            "I0205 13:35:04.714457 140689526667136 learning.py:507] global step 2470: loss = 0.1035 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 2471: loss = 0.0856 (0.361 sec/step)\n",
            "I0205 13:35:05.077370 140689526667136 learning.py:507] global step 2471: loss = 0.0856 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 2472: loss = 0.0656 (0.386 sec/step)\n",
            "I0205 13:35:05.465276 140689526667136 learning.py:507] global step 2472: loss = 0.0656 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 2473: loss = 0.1948 (0.406 sec/step)\n",
            "I0205 13:35:05.872938 140689526667136 learning.py:507] global step 2473: loss = 0.1948 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 2474: loss = 0.1691 (0.388 sec/step)\n",
            "I0205 13:35:06.262222 140689526667136 learning.py:507] global step 2474: loss = 0.1691 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 2475: loss = 0.2537 (0.361 sec/step)\n",
            "I0205 13:35:06.625291 140689526667136 learning.py:507] global step 2475: loss = 0.2537 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 2476: loss = 0.3357 (0.373 sec/step)\n",
            "I0205 13:35:07.000070 140689526667136 learning.py:507] global step 2476: loss = 0.3357 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 2477: loss = 0.0426 (0.358 sec/step)\n",
            "I0205 13:35:07.359573 140689526667136 learning.py:507] global step 2477: loss = 0.0426 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 2478: loss = 0.2542 (0.355 sec/step)\n",
            "I0205 13:35:07.716101 140689526667136 learning.py:507] global step 2478: loss = 0.2542 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 2479: loss = 0.1078 (0.388 sec/step)\n",
            "I0205 13:35:08.106061 140689526667136 learning.py:507] global step 2479: loss = 0.1078 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 2480: loss = 0.1875 (0.399 sec/step)\n",
            "I0205 13:35:08.506851 140689526667136 learning.py:507] global step 2480: loss = 0.1875 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 2481: loss = 0.0264 (0.410 sec/step)\n",
            "I0205 13:35:08.918598 140689526667136 learning.py:507] global step 2481: loss = 0.0264 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 2482: loss = 0.0491 (0.398 sec/step)\n",
            "I0205 13:35:09.318256 140689526667136 learning.py:507] global step 2482: loss = 0.0491 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 2483: loss = 0.2251 (0.446 sec/step)\n",
            "I0205 13:35:09.765337 140689526667136 learning.py:507] global step 2483: loss = 0.2251 (0.446 sec/step)\n",
            "INFO:tensorflow:global step 2484: loss = 0.0626 (0.363 sec/step)\n",
            "I0205 13:35:10.130031 140689526667136 learning.py:507] global step 2484: loss = 0.0626 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 2485: loss = 0.0575 (0.380 sec/step)\n",
            "I0205 13:35:10.511724 140689526667136 learning.py:507] global step 2485: loss = 0.0575 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2486: loss = 0.0827 (0.365 sec/step)\n",
            "I0205 13:35:10.878250 140689526667136 learning.py:507] global step 2486: loss = 0.0827 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 2487: loss = 0.2908 (0.387 sec/step)\n",
            "I0205 13:35:11.266942 140689526667136 learning.py:507] global step 2487: loss = 0.2908 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 2488: loss = 0.6400 (0.384 sec/step)\n",
            "I0205 13:35:11.652902 140689526667136 learning.py:507] global step 2488: loss = 0.6400 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 2489: loss = 0.5006 (0.368 sec/step)\n",
            "I0205 13:35:12.022203 140689526667136 learning.py:507] global step 2489: loss = 0.5006 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 2490: loss = 0.1431 (0.379 sec/step)\n",
            "I0205 13:35:12.403284 140689526667136 learning.py:507] global step 2490: loss = 0.1431 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2491: loss = 0.2172 (0.368 sec/step)\n",
            "I0205 13:35:12.772470 140689526667136 learning.py:507] global step 2491: loss = 0.2172 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 2492: loss = 0.1227 (0.396 sec/step)\n",
            "I0205 13:35:13.170186 140689526667136 learning.py:507] global step 2492: loss = 0.1227 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 2493: loss = 0.0447 (0.390 sec/step)\n",
            "I0205 13:35:13.561812 140689526667136 learning.py:507] global step 2493: loss = 0.0447 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 2494: loss = 0.0767 (0.377 sec/step)\n",
            "I0205 13:35:13.940332 140689526667136 learning.py:507] global step 2494: loss = 0.0767 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 2495: loss = 0.0446 (0.375 sec/step)\n",
            "I0205 13:35:14.318863 140689526667136 learning.py:507] global step 2495: loss = 0.0446 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2496: loss = 0.0573 (0.380 sec/step)\n",
            "I0205 13:35:14.700326 140689526667136 learning.py:507] global step 2496: loss = 0.0573 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2497: loss = 0.0782 (0.374 sec/step)\n",
            "I0205 13:35:15.075912 140689526667136 learning.py:507] global step 2497: loss = 0.0782 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 2498: loss = 0.0696 (0.368 sec/step)\n",
            "I0205 13:35:15.445485 140689526667136 learning.py:507] global step 2498: loss = 0.0696 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 2499: loss = 0.1853 (0.375 sec/step)\n",
            "I0205 13:35:15.821951 140689526667136 learning.py:507] global step 2499: loss = 0.1853 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2500: loss = 0.0638 (0.388 sec/step)\n",
            "I0205 13:35:16.211723 140689526667136 learning.py:507] global step 2500: loss = 0.0638 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 2501: loss = 1.5290 (0.384 sec/step)\n",
            "I0205 13:35:16.597694 140689526667136 learning.py:507] global step 2501: loss = 1.5290 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 2502: loss = 0.6516 (0.361 sec/step)\n",
            "I0205 13:35:16.959959 140689526667136 learning.py:507] global step 2502: loss = 0.6516 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 2503: loss = 0.3165 (0.371 sec/step)\n",
            "I0205 13:35:17.332277 140689526667136 learning.py:507] global step 2503: loss = 0.3165 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 2504: loss = 0.1906 (0.379 sec/step)\n",
            "I0205 13:35:17.712974 140689526667136 learning.py:507] global step 2504: loss = 0.1906 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2505: loss = 0.1483 (0.351 sec/step)\n",
            "I0205 13:35:18.066035 140689526667136 learning.py:507] global step 2505: loss = 0.1483 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 2506: loss = 0.1138 (0.356 sec/step)\n",
            "I0205 13:35:18.423369 140689526667136 learning.py:507] global step 2506: loss = 0.1138 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 2507: loss = 0.1418 (0.356 sec/step)\n",
            "I0205 13:35:18.781244 140689526667136 learning.py:507] global step 2507: loss = 0.1418 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 2508: loss = 0.0853 (0.408 sec/step)\n",
            "I0205 13:35:19.190900 140689526667136 learning.py:507] global step 2508: loss = 0.0853 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 2509: loss = 0.1014 (0.374 sec/step)\n",
            "I0205 13:35:19.566925 140689526667136 learning.py:507] global step 2509: loss = 0.1014 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 2510: loss = 0.0728 (0.377 sec/step)\n",
            "I0205 13:35:19.945649 140689526667136 learning.py:507] global step 2510: loss = 0.0728 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 2511: loss = 0.0767 (0.391 sec/step)\n",
            "I0205 13:35:20.338657 140689526667136 learning.py:507] global step 2511: loss = 0.0767 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2512: loss = 0.2046 (0.357 sec/step)\n",
            "I0205 13:35:20.697635 140689526667136 learning.py:507] global step 2512: loss = 0.2046 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 2513: loss = 0.1912 (0.405 sec/step)\n",
            "I0205 13:35:21.104465 140689526667136 learning.py:507] global step 2513: loss = 0.1912 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 2514: loss = 0.5519 (0.404 sec/step)\n",
            "I0205 13:35:21.510365 140689526667136 learning.py:507] global step 2514: loss = 0.5519 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 2515: loss = 0.2137 (0.383 sec/step)\n",
            "I0205 13:35:21.895131 140689526667136 learning.py:507] global step 2515: loss = 0.2137 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2516: loss = 0.0761 (0.380 sec/step)\n",
            "I0205 13:35:22.276823 140689526667136 learning.py:507] global step 2516: loss = 0.0761 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2517: loss = 0.1103 (0.407 sec/step)\n",
            "I0205 13:35:22.685665 140689526667136 learning.py:507] global step 2517: loss = 0.1103 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 2518: loss = 0.6446 (0.393 sec/step)\n",
            "I0205 13:35:23.081085 140689526667136 learning.py:507] global step 2518: loss = 0.6446 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 2519: loss = 0.1106 (0.375 sec/step)\n",
            "I0205 13:35:23.458031 140689526667136 learning.py:507] global step 2519: loss = 0.1106 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2520: loss = 0.0812 (0.383 sec/step)\n",
            "I0205 13:35:23.842873 140689526667136 learning.py:507] global step 2520: loss = 0.0812 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2521: loss = 0.1507 (0.377 sec/step)\n",
            "I0205 13:35:24.221243 140689526667136 learning.py:507] global step 2521: loss = 0.1507 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 2522: loss = 0.3321 (0.422 sec/step)\n",
            "I0205 13:35:24.644807 140689526667136 learning.py:507] global step 2522: loss = 0.3321 (0.422 sec/step)\n",
            "INFO:tensorflow:global step 2523: loss = 0.3127 (0.377 sec/step)\n",
            "I0205 13:35:25.024012 140689526667136 learning.py:507] global step 2523: loss = 0.3127 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 2524: loss = 0.1673 (0.395 sec/step)\n",
            "I0205 13:35:25.420731 140689526667136 learning.py:507] global step 2524: loss = 0.1673 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 2525: loss = 0.2598 (0.368 sec/step)\n",
            "I0205 13:35:25.789985 140689526667136 learning.py:507] global step 2525: loss = 0.2598 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 2526: loss = 0.2443 (0.372 sec/step)\n",
            "I0205 13:35:26.163492 140689526667136 learning.py:507] global step 2526: loss = 0.2443 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 2527: loss = 0.2915 (0.398 sec/step)\n",
            "I0205 13:35:26.562827 140689526667136 learning.py:507] global step 2527: loss = 0.2915 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 2528: loss = 0.1617 (0.362 sec/step)\n",
            "I0205 13:35:26.926599 140689526667136 learning.py:507] global step 2528: loss = 0.1617 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 2529: loss = 0.0406 (0.375 sec/step)\n",
            "I0205 13:35:27.303026 140689526667136 learning.py:507] global step 2529: loss = 0.0406 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2530: loss = 0.0713 (0.378 sec/step)\n",
            "I0205 13:35:27.682825 140689526667136 learning.py:507] global step 2530: loss = 0.0713 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 2531: loss = 0.1389 (0.380 sec/step)\n",
            "I0205 13:35:28.064431 140689526667136 learning.py:507] global step 2531: loss = 0.1389 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2532: loss = 0.0282 (0.351 sec/step)\n",
            "I0205 13:35:28.417324 140689526667136 learning.py:507] global step 2532: loss = 0.0282 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 2533: loss = 0.1452 (0.387 sec/step)\n",
            "I0205 13:35:28.806644 140689526667136 learning.py:507] global step 2533: loss = 0.1452 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 2534: loss = 0.0352 (0.391 sec/step)\n",
            "I0205 13:35:29.199663 140689526667136 learning.py:507] global step 2534: loss = 0.0352 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2535: loss = 0.1655 (0.407 sec/step)\n",
            "I0205 13:35:29.608923 140689526667136 learning.py:507] global step 2535: loss = 0.1655 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 2536: loss = 0.1443 (0.411 sec/step)\n",
            "I0205 13:35:30.021846 140689526667136 learning.py:507] global step 2536: loss = 0.1443 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 2537: loss = 0.1538 (0.413 sec/step)\n",
            "I0205 13:35:30.437129 140689526667136 learning.py:507] global step 2537: loss = 0.1538 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 2538: loss = 0.0724 (0.359 sec/step)\n",
            "I0205 13:35:30.798288 140689526667136 learning.py:507] global step 2538: loss = 0.0724 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 2539: loss = 0.0860 (0.378 sec/step)\n",
            "I0205 13:35:31.177642 140689526667136 learning.py:507] global step 2539: loss = 0.0860 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 2540: loss = 0.1107 (0.362 sec/step)\n",
            "I0205 13:35:31.541516 140689526667136 learning.py:507] global step 2540: loss = 0.1107 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 2541: loss = 0.1417 (0.433 sec/step)\n",
            "I0205 13:35:31.976298 140689526667136 learning.py:507] global step 2541: loss = 0.1417 (0.433 sec/step)\n",
            "INFO:tensorflow:global step 2542: loss = 0.1797 (0.376 sec/step)\n",
            "I0205 13:35:32.353705 140689526667136 learning.py:507] global step 2542: loss = 0.1797 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 2543: loss = 0.0401 (0.403 sec/step)\n",
            "I0205 13:35:32.758123 140689526667136 learning.py:507] global step 2543: loss = 0.0401 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 2544: loss = 0.4864 (0.406 sec/step)\n",
            "I0205 13:35:33.165635 140689526667136 learning.py:507] global step 2544: loss = 0.4864 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 2545: loss = 0.2681 (0.366 sec/step)\n",
            "I0205 13:35:33.533756 140689526667136 learning.py:507] global step 2545: loss = 0.2681 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 2546: loss = 0.3058 (0.398 sec/step)\n",
            "I0205 13:35:33.933809 140689526667136 learning.py:507] global step 2546: loss = 0.3058 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 2547: loss = 0.1007 (0.399 sec/step)\n",
            "I0205 13:35:34.334844 140689526667136 learning.py:507] global step 2547: loss = 0.1007 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 2548: loss = 0.7813 (0.368 sec/step)\n",
            "I0205 13:35:34.705011 140689526667136 learning.py:507] global step 2548: loss = 0.7813 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 2549: loss = 0.1131 (0.373 sec/step)\n",
            "I0205 13:35:35.079242 140689526667136 learning.py:507] global step 2549: loss = 0.1131 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 2550: loss = 0.0289 (0.373 sec/step)\n",
            "I0205 13:35:35.453961 140689526667136 learning.py:507] global step 2550: loss = 0.0289 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 2551: loss = 0.2305 (0.377 sec/step)\n",
            "I0205 13:35:35.832791 140689526667136 learning.py:507] global step 2551: loss = 0.2305 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 2552: loss = 0.1393 (0.369 sec/step)\n",
            "I0205 13:35:36.203557 140689526667136 learning.py:507] global step 2552: loss = 0.1393 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 2553: loss = 0.1276 (0.372 sec/step)\n",
            "I0205 13:35:36.576640 140689526667136 learning.py:507] global step 2553: loss = 0.1276 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 2554: loss = 0.2415 (0.394 sec/step)\n",
            "I0205 13:35:36.972689 140689526667136 learning.py:507] global step 2554: loss = 0.2415 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 2555: loss = 0.2919 (0.391 sec/step)\n",
            "I0205 13:35:37.365406 140689526667136 learning.py:507] global step 2555: loss = 0.2919 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2556: loss = 0.1555 (0.393 sec/step)\n",
            "I0205 13:35:37.759718 140689526667136 learning.py:507] global step 2556: loss = 0.1555 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 2557: loss = 0.3064 (0.385 sec/step)\n",
            "I0205 13:35:38.146369 140689526667136 learning.py:507] global step 2557: loss = 0.3064 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 2558: loss = 0.2921 (0.403 sec/step)\n",
            "I0205 13:35:38.550559 140689526667136 learning.py:507] global step 2558: loss = 0.2921 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 2559: loss = 0.4935 (0.384 sec/step)\n",
            "I0205 13:35:38.935906 140689526667136 learning.py:507] global step 2559: loss = 0.4935 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 2560: loss = 0.2993 (0.377 sec/step)\n",
            "I0205 13:35:39.314839 140689526667136 learning.py:507] global step 2560: loss = 0.2993 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 2561: loss = 0.0920 (0.368 sec/step)\n",
            "I0205 13:35:39.684048 140689526667136 learning.py:507] global step 2561: loss = 0.0920 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 2562: loss = 0.1128 (0.388 sec/step)\n",
            "I0205 13:35:40.073072 140689526667136 learning.py:507] global step 2562: loss = 0.1128 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 2563: loss = 0.1735 (0.371 sec/step)\n",
            "I0205 13:35:40.445339 140689526667136 learning.py:507] global step 2563: loss = 0.1735 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 2564: loss = 0.9332 (0.404 sec/step)\n",
            "I0205 13:35:40.851687 140689526667136 learning.py:507] global step 2564: loss = 0.9332 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 2565: loss = 0.2678 (0.375 sec/step)\n",
            "I0205 13:35:41.228153 140689526667136 learning.py:507] global step 2565: loss = 0.2678 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2566: loss = 0.0455 (0.368 sec/step)\n",
            "I0205 13:35:41.598148 140689526667136 learning.py:507] global step 2566: loss = 0.0455 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 2567: loss = 0.1519 (0.381 sec/step)\n",
            "I0205 13:35:41.980678 140689526667136 learning.py:507] global step 2567: loss = 0.1519 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 2568: loss = 0.1235 (0.394 sec/step)\n",
            "I0205 13:35:42.375911 140689526667136 learning.py:507] global step 2568: loss = 0.1235 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 2569: loss = 0.4171 (0.406 sec/step)\n",
            "I0205 13:35:42.783360 140689526667136 learning.py:507] global step 2569: loss = 0.4171 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 2570: loss = 0.1468 (0.397 sec/step)\n",
            "I0205 13:35:43.181538 140689526667136 learning.py:507] global step 2570: loss = 0.1468 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 2571: loss = 0.1331 (0.368 sec/step)\n",
            "I0205 13:35:43.551460 140689526667136 learning.py:507] global step 2571: loss = 0.1331 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 2572: loss = 0.5965 (0.407 sec/step)\n",
            "I0205 13:35:43.959980 140689526667136 learning.py:507] global step 2572: loss = 0.5965 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 2573: loss = 0.2976 (0.391 sec/step)\n",
            "I0205 13:35:44.352919 140689526667136 learning.py:507] global step 2573: loss = 0.2976 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2574: loss = 0.1760 (0.388 sec/step)\n",
            "I0205 13:35:44.742408 140689526667136 learning.py:507] global step 2574: loss = 0.1760 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 2575: loss = 0.0523 (0.396 sec/step)\n",
            "I0205 13:35:45.139846 140689526667136 learning.py:507] global step 2575: loss = 0.0523 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 2576: loss = 0.0616 (0.361 sec/step)\n",
            "I0205 13:35:45.503205 140689526667136 learning.py:507] global step 2576: loss = 0.0616 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 2577: loss = 0.3203 (0.386 sec/step)\n",
            "I0205 13:35:45.892148 140689526667136 learning.py:507] global step 2577: loss = 0.3203 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 2578: loss = 0.2356 (0.386 sec/step)\n",
            "I0205 13:35:46.280560 140689526667136 learning.py:507] global step 2578: loss = 0.2356 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 2579: loss = 0.1194 (0.391 sec/step)\n",
            "I0205 13:35:46.673729 140689526667136 learning.py:507] global step 2579: loss = 0.1194 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2580: loss = 0.2266 (0.383 sec/step)\n",
            "I0205 13:35:47.058590 140689526667136 learning.py:507] global step 2580: loss = 0.2266 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2581: loss = 0.1577 (0.366 sec/step)\n",
            "I0205 13:35:47.426021 140689526667136 learning.py:507] global step 2581: loss = 0.1577 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 2582: loss = 0.1016 (0.373 sec/step)\n",
            "I0205 13:35:47.800269 140689526667136 learning.py:507] global step 2582: loss = 0.1016 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 2583: loss = 0.1219 (0.349 sec/step)\n",
            "I0205 13:35:48.150889 140689526667136 learning.py:507] global step 2583: loss = 0.1219 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 2584: loss = 0.1849 (0.387 sec/step)\n",
            "I0205 13:35:48.541121 140689526667136 learning.py:507] global step 2584: loss = 0.1849 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 2585: loss = 0.6850 (0.382 sec/step)\n",
            "I0205 13:35:48.924611 140689526667136 learning.py:507] global step 2585: loss = 0.6850 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 2586: loss = 0.0907 (0.364 sec/step)\n",
            "I0205 13:35:49.289835 140689526667136 learning.py:507] global step 2586: loss = 0.0907 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 2587: loss = 0.2257 (0.376 sec/step)\n",
            "I0205 13:35:49.667369 140689526667136 learning.py:507] global step 2587: loss = 0.2257 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 2588: loss = 0.7740 (0.387 sec/step)\n",
            "I0205 13:35:50.057005 140689526667136 learning.py:507] global step 2588: loss = 0.7740 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 2589: loss = 0.1233 (0.383 sec/step)\n",
            "I0205 13:35:50.441749 140689526667136 learning.py:507] global step 2589: loss = 0.1233 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2590: loss = 0.7274 (0.379 sec/step)\n",
            "I0205 13:35:50.822877 140689526667136 learning.py:507] global step 2590: loss = 0.7274 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2591: loss = 0.0822 (0.370 sec/step)\n",
            "I0205 13:35:51.194401 140689526667136 learning.py:507] global step 2591: loss = 0.0822 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 2592: loss = 0.1025 (0.374 sec/step)\n",
            "I0205 13:35:51.570174 140689526667136 learning.py:507] global step 2592: loss = 0.1025 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 2593: loss = 0.2160 (0.376 sec/step)\n",
            "I0205 13:35:51.947873 140689526667136 learning.py:507] global step 2593: loss = 0.2160 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 2594: loss = 0.1909 (0.389 sec/step)\n",
            "I0205 13:35:52.338216 140689526667136 learning.py:507] global step 2594: loss = 0.1909 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 2595: loss = 0.1204 (0.435 sec/step)\n",
            "I0205 13:35:52.774904 140689526667136 learning.py:507] global step 2595: loss = 0.1204 (0.435 sec/step)\n",
            "INFO:tensorflow:global step 2596: loss = 0.0896 (0.398 sec/step)\n",
            "I0205 13:35:53.174436 140689526667136 learning.py:507] global step 2596: loss = 0.0896 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 2597: loss = 0.2489 (0.380 sec/step)\n",
            "I0205 13:35:53.556073 140689526667136 learning.py:507] global step 2597: loss = 0.2489 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2598: loss = 0.1271 (0.354 sec/step)\n",
            "I0205 13:35:53.911684 140689526667136 learning.py:507] global step 2598: loss = 0.1271 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 2599: loss = 0.0471 (0.390 sec/step)\n",
            "I0205 13:35:54.302993 140689526667136 learning.py:507] global step 2599: loss = 0.0471 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 2600: loss = 0.3854 (0.375 sec/step)\n",
            "I0205 13:35:54.679796 140689526667136 learning.py:507] global step 2600: loss = 0.3854 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2601: loss = 0.2163 (0.384 sec/step)\n",
            "I0205 13:35:55.065407 140689526667136 learning.py:507] global step 2601: loss = 0.2163 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 2602: loss = 0.1237 (0.372 sec/step)\n",
            "I0205 13:35:55.438878 140689526667136 learning.py:507] global step 2602: loss = 0.1237 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 2603: loss = 0.5109 (0.412 sec/step)\n",
            "I0205 13:35:55.852788 140689526667136 learning.py:507] global step 2603: loss = 0.5109 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 2604: loss = 0.1563 (0.390 sec/step)\n",
            "I0205 13:35:56.244707 140689526667136 learning.py:507] global step 2604: loss = 0.1563 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 2605: loss = 0.1580 (0.365 sec/step)\n",
            "I0205 13:35:56.611681 140689526667136 learning.py:507] global step 2605: loss = 0.1580 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 2606: loss = 0.0498 (0.370 sec/step)\n",
            "I0205 13:35:56.983094 140689526667136 learning.py:507] global step 2606: loss = 0.0498 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 2607: loss = 0.1395 (0.384 sec/step)\n",
            "I0205 13:35:57.368655 140689526667136 learning.py:507] global step 2607: loss = 0.1395 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 2608: loss = 0.0499 (0.360 sec/step)\n",
            "I0205 13:35:57.730763 140689526667136 learning.py:507] global step 2608: loss = 0.0499 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 2609: loss = 0.6858 (0.376 sec/step)\n",
            "I0205 13:35:58.107944 140689526667136 learning.py:507] global step 2609: loss = 0.6858 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 2610: loss = 0.0890 (0.382 sec/step)\n",
            "I0205 13:35:58.491479 140689526667136 learning.py:507] global step 2610: loss = 0.0890 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 2611: loss = 0.1550 (0.369 sec/step)\n",
            "I0205 13:35:58.862838 140689526667136 learning.py:507] global step 2611: loss = 0.1550 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 2612: loss = 0.0831 (0.383 sec/step)\n",
            "I0205 13:35:59.247635 140689526667136 learning.py:507] global step 2612: loss = 0.0831 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2613: loss = 0.4000 (0.370 sec/step)\n",
            "I0205 13:35:59.619041 140689526667136 learning.py:507] global step 2613: loss = 0.4000 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 2614: loss = 0.1348 (0.380 sec/step)\n",
            "I0205 13:36:00.000985 140689526667136 learning.py:507] global step 2614: loss = 0.1348 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2615: loss = 0.1102 (0.377 sec/step)\n",
            "I0205 13:36:00.379364 140689526667136 learning.py:507] global step 2615: loss = 0.1102 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 2616: loss = 0.1865 (0.390 sec/step)\n",
            "I0205 13:36:00.770880 140689526667136 learning.py:507] global step 2616: loss = 0.1865 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 2617: loss = 0.2006 (0.392 sec/step)\n",
            "I0205 13:36:01.163909 140689526667136 learning.py:507] global step 2617: loss = 0.2006 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 2618: loss = 0.8005 (0.407 sec/step)\n",
            "I0205 13:36:01.572126 140689526667136 learning.py:507] global step 2618: loss = 0.8005 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 2619: loss = 0.5564 (0.390 sec/step)\n",
            "I0205 13:36:01.964229 140689526667136 learning.py:507] global step 2619: loss = 0.5564 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 2620: loss = 0.1910 (0.383 sec/step)\n",
            "I0205 13:36:02.349400 140689526667136 learning.py:507] global step 2620: loss = 0.1910 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2621: loss = 0.1545 (0.406 sec/step)\n",
            "I0205 13:36:02.756942 140689526667136 learning.py:507] global step 2621: loss = 0.1545 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 2622: loss = 0.1001 (0.393 sec/step)\n",
            "I0205 13:36:03.153658 140689526667136 learning.py:507] global step 2622: loss = 0.1001 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 2623: loss = 0.1737 (0.393 sec/step)\n",
            "I0205 13:36:03.548297 140689526667136 learning.py:507] global step 2623: loss = 0.1737 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 2624: loss = 0.0944 (0.388 sec/step)\n",
            "I0205 13:36:03.937754 140689526667136 learning.py:507] global step 2624: loss = 0.0944 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 2625: loss = 0.1499 (0.376 sec/step)\n",
            "I0205 13:36:04.315439 140689526667136 learning.py:507] global step 2625: loss = 0.1499 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 2626: loss = 0.0635 (0.380 sec/step)\n",
            "I0205 13:36:04.696578 140689526667136 learning.py:507] global step 2626: loss = 0.0635 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2627: loss = 0.0853 (0.344 sec/step)\n",
            "I0205 13:36:05.042317 140689526667136 learning.py:507] global step 2627: loss = 0.0853 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 2628: loss = 0.1033 (0.339 sec/step)\n",
            "I0205 13:36:05.383029 140689526667136 learning.py:507] global step 2628: loss = 0.1033 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 2629: loss = 0.1737 (0.375 sec/step)\n",
            "I0205 13:36:05.759832 140689526667136 learning.py:507] global step 2629: loss = 0.1737 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2630: loss = 0.1234 (0.384 sec/step)\n",
            "I0205 13:36:06.145658 140689526667136 learning.py:507] global step 2630: loss = 0.1234 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 2631: loss = 0.1280 (0.376 sec/step)\n",
            "I0205 13:36:06.522975 140689526667136 learning.py:507] global step 2631: loss = 0.1280 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 2632: loss = 0.8843 (0.356 sec/step)\n",
            "I0205 13:36:06.881210 140689526667136 learning.py:507] global step 2632: loss = 0.8843 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 2633: loss = 0.1443 (0.356 sec/step)\n",
            "I0205 13:36:07.238723 140689526667136 learning.py:507] global step 2633: loss = 0.1443 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 2634: loss = 0.1659 (0.375 sec/step)\n",
            "I0205 13:36:07.614950 140689526667136 learning.py:507] global step 2634: loss = 0.1659 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2635: loss = 0.4477 (0.404 sec/step)\n",
            "I0205 13:36:08.020376 140689526667136 learning.py:507] global step 2635: loss = 0.4477 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 2636: loss = 0.1696 (0.366 sec/step)\n",
            "I0205 13:36:08.387975 140689526667136 learning.py:507] global step 2636: loss = 0.1696 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 2637: loss = 0.1522 (0.387 sec/step)\n",
            "I0205 13:36:08.776592 140689526667136 learning.py:507] global step 2637: loss = 0.1522 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 2638: loss = 0.0752 (0.380 sec/step)\n",
            "I0205 13:36:09.158196 140689526667136 learning.py:507] global step 2638: loss = 0.0752 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2639: loss = 0.5264 (0.372 sec/step)\n",
            "I0205 13:36:09.531416 140689526667136 learning.py:507] global step 2639: loss = 0.5264 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 2640: loss = 0.1139 (0.380 sec/step)\n",
            "I0205 13:36:09.912672 140689526667136 learning.py:507] global step 2640: loss = 0.1139 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2641: loss = 0.1189 (0.367 sec/step)\n",
            "I0205 13:36:10.281056 140689526667136 learning.py:507] global step 2641: loss = 0.1189 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 2642: loss = 0.3474 (0.354 sec/step)\n",
            "I0205 13:36:10.636784 140689526667136 learning.py:507] global step 2642: loss = 0.3474 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 2643: loss = 0.2129 (0.363 sec/step)\n",
            "I0205 13:36:11.001276 140689526667136 learning.py:507] global step 2643: loss = 0.2129 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 2644: loss = 0.5988 (0.347 sec/step)\n",
            "I0205 13:36:11.349965 140689526667136 learning.py:507] global step 2644: loss = 0.5988 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 2645: loss = 0.2828 (0.374 sec/step)\n",
            "I0205 13:36:11.726076 140689526667136 learning.py:507] global step 2645: loss = 0.2828 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 2646: loss = 0.1005 (0.374 sec/step)\n",
            "I0205 13:36:12.101548 140689526667136 learning.py:507] global step 2646: loss = 0.1005 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 2647: loss = 0.0336 (0.388 sec/step)\n",
            "I0205 13:36:12.491069 140689526667136 learning.py:507] global step 2647: loss = 0.0336 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 2648: loss = 0.3906 (0.381 sec/step)\n",
            "I0205 13:36:12.873561 140689526667136 learning.py:507] global step 2648: loss = 0.3906 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 2649: loss = 0.1386 (0.442 sec/step)\n",
            "I0205 13:36:13.316839 140689526667136 learning.py:507] global step 2649: loss = 0.1386 (0.442 sec/step)\n",
            "INFO:tensorflow:global step 2650: loss = 0.1099 (0.402 sec/step)\n",
            "I0205 13:36:13.720086 140689526667136 learning.py:507] global step 2650: loss = 0.1099 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 2651: loss = 0.2334 (0.625 sec/step)\n",
            "I0205 13:36:14.409529 140689526667136 learning.py:507] global step 2651: loss = 0.2334 (0.625 sec/step)\n",
            "INFO:tensorflow:global step 2652: loss = 0.9687 (0.811 sec/step)\n",
            "I0205 13:36:15.506140 140689526667136 learning.py:507] global step 2652: loss = 0.9687 (0.811 sec/step)\n",
            "INFO:tensorflow:global step 2653: loss = 0.8141 (0.666 sec/step)\n",
            "I0205 13:36:16.189536 140689526667136 learning.py:507] global step 2653: loss = 0.8141 (0.666 sec/step)\n",
            "INFO:tensorflow:global step 2654: loss = 0.0367 (0.623 sec/step)\n",
            "I0205 13:36:16.860992 140689526667136 learning.py:507] global step 2654: loss = 0.0367 (0.623 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 2654.\n",
            "I0205 13:36:17.137813 140686026073856 supervisor.py:1050] Recording summary at step 2654.\n",
            "INFO:tensorflow:global step 2655: loss = 0.0895 (0.473 sec/step)\n",
            "I0205 13:36:17.335516 140689526667136 learning.py:507] global step 2655: loss = 0.0895 (0.473 sec/step)\n",
            "INFO:tensorflow:global step 2656: loss = 0.1414 (0.366 sec/step)\n",
            "I0205 13:36:17.703572 140689526667136 learning.py:507] global step 2656: loss = 0.1414 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 2657: loss = 0.0902 (0.393 sec/step)\n",
            "I0205 13:36:18.097988 140689526667136 learning.py:507] global step 2657: loss = 0.0902 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 2658: loss = 0.1988 (0.365 sec/step)\n",
            "I0205 13:36:18.464336 140689526667136 learning.py:507] global step 2658: loss = 0.1988 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 2659: loss = 0.1082 (0.396 sec/step)\n",
            "I0205 13:36:18.862467 140689526667136 learning.py:507] global step 2659: loss = 0.1082 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 2660: loss = 0.1580 (0.436 sec/step)\n",
            "I0205 13:36:19.300395 140689526667136 learning.py:507] global step 2660: loss = 0.1580 (0.436 sec/step)\n",
            "INFO:tensorflow:global step 2661: loss = 0.2355 (0.431 sec/step)\n",
            "I0205 13:36:19.732662 140689526667136 learning.py:507] global step 2661: loss = 0.2355 (0.431 sec/step)\n",
            "INFO:tensorflow:global step 2662: loss = 0.2377 (0.377 sec/step)\n",
            "I0205 13:36:20.111571 140689526667136 learning.py:507] global step 2662: loss = 0.2377 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 2663: loss = 0.1483 (0.393 sec/step)\n",
            "I0205 13:36:20.505893 140689526667136 learning.py:507] global step 2663: loss = 0.1483 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 2664: loss = 0.2317 (0.375 sec/step)\n",
            "I0205 13:36:20.883076 140689526667136 learning.py:507] global step 2664: loss = 0.2317 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2665: loss = 0.1459 (0.366 sec/step)\n",
            "I0205 13:36:21.250695 140689526667136 learning.py:507] global step 2665: loss = 0.1459 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 2666: loss = 0.0929 (0.374 sec/step)\n",
            "I0205 13:36:21.625931 140689526667136 learning.py:507] global step 2666: loss = 0.0929 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 2667: loss = 0.2462 (0.380 sec/step)\n",
            "I0205 13:36:22.007548 140689526667136 learning.py:507] global step 2667: loss = 0.2462 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2668: loss = 0.6934 (0.412 sec/step)\n",
            "I0205 13:36:22.421036 140689526667136 learning.py:507] global step 2668: loss = 0.6934 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 2669: loss = 0.2801 (0.391 sec/step)\n",
            "I0205 13:36:22.814104 140689526667136 learning.py:507] global step 2669: loss = 0.2801 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2670: loss = 0.1674 (0.384 sec/step)\n",
            "I0205 13:36:23.199611 140689526667136 learning.py:507] global step 2670: loss = 0.1674 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 2671: loss = 0.1491 (0.366 sec/step)\n",
            "I0205 13:36:23.567119 140689526667136 learning.py:507] global step 2671: loss = 0.1491 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 2672: loss = 0.2914 (0.381 sec/step)\n",
            "I0205 13:36:23.949863 140689526667136 learning.py:507] global step 2672: loss = 0.2914 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 2673: loss = 0.0833 (0.371 sec/step)\n",
            "I0205 13:36:24.322530 140689526667136 learning.py:507] global step 2673: loss = 0.0833 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 2674: loss = 0.3318 (0.399 sec/step)\n",
            "I0205 13:36:24.723804 140689526667136 learning.py:507] global step 2674: loss = 0.3318 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 2675: loss = 0.1205 (0.382 sec/step)\n",
            "I0205 13:36:25.107032 140689526667136 learning.py:507] global step 2675: loss = 0.1205 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 2676: loss = 0.2440 (0.368 sec/step)\n",
            "I0205 13:36:25.477061 140689526667136 learning.py:507] global step 2676: loss = 0.2440 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 2677: loss = 0.0923 (0.370 sec/step)\n",
            "I0205 13:36:25.849186 140689526667136 learning.py:507] global step 2677: loss = 0.0923 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 2678: loss = 0.4893 (0.381 sec/step)\n",
            "I0205 13:36:26.232244 140689526667136 learning.py:507] global step 2678: loss = 0.4893 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 2679: loss = 0.2754 (0.392 sec/step)\n",
            "I0205 13:36:26.626080 140689526667136 learning.py:507] global step 2679: loss = 0.2754 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 2680: loss = 0.0801 (0.374 sec/step)\n",
            "I0205 13:36:27.001432 140689526667136 learning.py:507] global step 2680: loss = 0.0801 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 2681: loss = 0.1656 (0.401 sec/step)\n",
            "I0205 13:36:27.403480 140689526667136 learning.py:507] global step 2681: loss = 0.1656 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 2682: loss = 0.1621 (0.417 sec/step)\n",
            "I0205 13:36:27.822964 140689526667136 learning.py:507] global step 2682: loss = 0.1621 (0.417 sec/step)\n",
            "INFO:tensorflow:global step 2683: loss = 0.0998 (0.381 sec/step)\n",
            "I0205 13:36:28.205594 140689526667136 learning.py:507] global step 2683: loss = 0.0998 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 2684: loss = 0.2426 (0.384 sec/step)\n",
            "I0205 13:36:28.591609 140689526667136 learning.py:507] global step 2684: loss = 0.2426 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 2685: loss = 0.1481 (0.379 sec/step)\n",
            "I0205 13:36:28.971888 140689526667136 learning.py:507] global step 2685: loss = 0.1481 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2686: loss = 0.1859 (0.397 sec/step)\n",
            "I0205 13:36:29.370962 140689526667136 learning.py:507] global step 2686: loss = 0.1859 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 2687: loss = 0.1573 (0.523 sec/step)\n",
            "I0205 13:36:29.895530 140689526667136 learning.py:507] global step 2687: loss = 0.1573 (0.523 sec/step)\n",
            "INFO:tensorflow:global step 2688: loss = 0.5844 (0.338 sec/step)\n",
            "I0205 13:36:30.235224 140689526667136 learning.py:507] global step 2688: loss = 0.5844 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 2689: loss = 0.1222 (0.410 sec/step)\n",
            "I0205 13:36:30.646977 140689526667136 learning.py:507] global step 2689: loss = 0.1222 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 2690: loss = 0.0701 (0.381 sec/step)\n",
            "I0205 13:36:31.030135 140689526667136 learning.py:507] global step 2690: loss = 0.0701 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 2691: loss = 0.1081 (0.408 sec/step)\n",
            "I0205 13:36:31.439450 140689526667136 learning.py:507] global step 2691: loss = 0.1081 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 2692: loss = 0.2066 (0.391 sec/step)\n",
            "I0205 13:36:31.832421 140689526667136 learning.py:507] global step 2692: loss = 0.2066 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2693: loss = 0.4413 (0.383 sec/step)\n",
            "I0205 13:36:32.217101 140689526667136 learning.py:507] global step 2693: loss = 0.4413 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2694: loss = 0.0797 (0.377 sec/step)\n",
            "I0205 13:36:32.595310 140689526667136 learning.py:507] global step 2694: loss = 0.0797 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 2695: loss = 0.1055 (0.396 sec/step)\n",
            "I0205 13:36:32.992753 140689526667136 learning.py:507] global step 2695: loss = 0.1055 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 2696: loss = 0.0720 (0.404 sec/step)\n",
            "I0205 13:36:33.398406 140689526667136 learning.py:507] global step 2696: loss = 0.0720 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 2697: loss = 0.2773 (0.393 sec/step)\n",
            "I0205 13:36:33.793334 140689526667136 learning.py:507] global step 2697: loss = 0.2773 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 2698: loss = 1.4252 (0.391 sec/step)\n",
            "I0205 13:36:34.185683 140689526667136 learning.py:507] global step 2698: loss = 1.4252 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2699: loss = 0.2889 (0.391 sec/step)\n",
            "I0205 13:36:34.578002 140689526667136 learning.py:507] global step 2699: loss = 0.2889 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2700: loss = 0.2010 (0.368 sec/step)\n",
            "I0205 13:36:34.948201 140689526667136 learning.py:507] global step 2700: loss = 0.2010 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 2701: loss = 0.3669 (0.387 sec/step)\n",
            "I0205 13:36:35.336532 140689526667136 learning.py:507] global step 2701: loss = 0.3669 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 2702: loss = 0.1041 (0.377 sec/step)\n",
            "I0205 13:36:35.715472 140689526667136 learning.py:507] global step 2702: loss = 0.1041 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 2703: loss = 0.1146 (0.410 sec/step)\n",
            "I0205 13:36:36.127052 140689526667136 learning.py:507] global step 2703: loss = 0.1146 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 2704: loss = 0.0431 (0.380 sec/step)\n",
            "I0205 13:36:36.508645 140689526667136 learning.py:507] global step 2704: loss = 0.0431 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2705: loss = 0.0666 (0.375 sec/step)\n",
            "I0205 13:36:36.885043 140689526667136 learning.py:507] global step 2705: loss = 0.0666 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2706: loss = 0.3050 (0.363 sec/step)\n",
            "I0205 13:36:37.249248 140689526667136 learning.py:507] global step 2706: loss = 0.3050 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 2707: loss = 0.2680 (0.378 sec/step)\n",
            "I0205 13:36:37.628329 140689526667136 learning.py:507] global step 2707: loss = 0.2680 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 2708: loss = 0.1587 (0.364 sec/step)\n",
            "I0205 13:36:37.994230 140689526667136 learning.py:507] global step 2708: loss = 0.1587 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 2709: loss = 0.1571 (0.397 sec/step)\n",
            "I0205 13:36:38.393158 140689526667136 learning.py:507] global step 2709: loss = 0.1571 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 2710: loss = 0.1783 (0.357 sec/step)\n",
            "I0205 13:36:38.751916 140689526667136 learning.py:507] global step 2710: loss = 0.1783 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 2711: loss = 0.1590 (0.374 sec/step)\n",
            "I0205 13:36:39.127803 140689526667136 learning.py:507] global step 2711: loss = 0.1590 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 2712: loss = 0.0528 (0.373 sec/step)\n",
            "I0205 13:36:39.502844 140689526667136 learning.py:507] global step 2712: loss = 0.0528 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 2713: loss = 0.1864 (0.368 sec/step)\n",
            "I0205 13:36:39.872308 140689526667136 learning.py:507] global step 2713: loss = 0.1864 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 2714: loss = 0.1174 (0.384 sec/step)\n",
            "I0205 13:36:40.257496 140689526667136 learning.py:507] global step 2714: loss = 0.1174 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 2715: loss = 0.1785 (0.374 sec/step)\n",
            "I0205 13:36:40.633629 140689526667136 learning.py:507] global step 2715: loss = 0.1785 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 2716: loss = 0.0818 (0.389 sec/step)\n",
            "I0205 13:36:41.024008 140689526667136 learning.py:507] global step 2716: loss = 0.0818 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 2717: loss = 0.2291 (0.390 sec/step)\n",
            "I0205 13:36:41.416145 140689526667136 learning.py:507] global step 2717: loss = 0.2291 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 2718: loss = 0.1550 (0.393 sec/step)\n",
            "I0205 13:36:41.811218 140689526667136 learning.py:507] global step 2718: loss = 0.1550 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 2719: loss = 0.1059 (0.378 sec/step)\n",
            "I0205 13:36:42.191565 140689526667136 learning.py:507] global step 2719: loss = 0.1059 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 2720: loss = 0.6237 (0.408 sec/step)\n",
            "I0205 13:36:42.600863 140689526667136 learning.py:507] global step 2720: loss = 0.6237 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 2721: loss = 0.1373 (0.373 sec/step)\n",
            "I0205 13:36:42.975684 140689526667136 learning.py:507] global step 2721: loss = 0.1373 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 2722: loss = 0.0855 (0.409 sec/step)\n",
            "I0205 13:36:43.386205 140689526667136 learning.py:507] global step 2722: loss = 0.0855 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 2723: loss = 0.1189 (0.379 sec/step)\n",
            "I0205 13:36:43.767219 140689526667136 learning.py:507] global step 2723: loss = 0.1189 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2724: loss = 0.2663 (0.394 sec/step)\n",
            "I0205 13:36:44.162301 140689526667136 learning.py:507] global step 2724: loss = 0.2663 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 2725: loss = 0.2039 (0.387 sec/step)\n",
            "I0205 13:36:44.551146 140689526667136 learning.py:507] global step 2725: loss = 0.2039 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 2726: loss = 0.0270 (0.365 sec/step)\n",
            "I0205 13:36:44.917988 140689526667136 learning.py:507] global step 2726: loss = 0.0270 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 2727: loss = 0.0981 (0.386 sec/step)\n",
            "I0205 13:36:45.305277 140689526667136 learning.py:507] global step 2727: loss = 0.0981 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 2728: loss = 0.1280 (0.430 sec/step)\n",
            "I0205 13:36:45.736984 140689526667136 learning.py:507] global step 2728: loss = 0.1280 (0.430 sec/step)\n",
            "INFO:tensorflow:global step 2729: loss = 0.2286 (0.376 sec/step)\n",
            "I0205 13:36:46.114975 140689526667136 learning.py:507] global step 2729: loss = 0.2286 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 2730: loss = 0.3000 (0.384 sec/step)\n",
            "I0205 13:36:46.500999 140689526667136 learning.py:507] global step 2730: loss = 0.3000 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 2731: loss = 0.1430 (0.367 sec/step)\n",
            "I0205 13:36:46.869748 140689526667136 learning.py:507] global step 2731: loss = 0.1430 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 2732: loss = 0.0978 (0.394 sec/step)\n",
            "I0205 13:36:47.265540 140689526667136 learning.py:507] global step 2732: loss = 0.0978 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 2733: loss = 0.0560 (0.362 sec/step)\n",
            "I0205 13:36:47.629101 140689526667136 learning.py:507] global step 2733: loss = 0.0560 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 2734: loss = 0.0866 (0.368 sec/step)\n",
            "I0205 13:36:47.998250 140689526667136 learning.py:507] global step 2734: loss = 0.0866 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 2735: loss = 0.1046 (0.388 sec/step)\n",
            "I0205 13:36:48.387420 140689526667136 learning.py:507] global step 2735: loss = 0.1046 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 2736: loss = 0.0361 (0.444 sec/step)\n",
            "I0205 13:36:48.832994 140689526667136 learning.py:507] global step 2736: loss = 0.0361 (0.444 sec/step)\n",
            "INFO:tensorflow:global step 2737: loss = 0.1186 (0.356 sec/step)\n",
            "I0205 13:36:49.190969 140689526667136 learning.py:507] global step 2737: loss = 0.1186 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 2738: loss = 0.5345 (0.358 sec/step)\n",
            "I0205 13:36:49.550460 140689526667136 learning.py:507] global step 2738: loss = 0.5345 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 2739: loss = 1.0034 (0.379 sec/step)\n",
            "I0205 13:36:49.931137 140689526667136 learning.py:507] global step 2739: loss = 1.0034 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2740: loss = 0.1464 (0.388 sec/step)\n",
            "I0205 13:36:50.320995 140689526667136 learning.py:507] global step 2740: loss = 0.1464 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 2741: loss = 0.5325 (0.351 sec/step)\n",
            "I0205 13:36:50.673219 140689526667136 learning.py:507] global step 2741: loss = 0.5325 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 2742: loss = 0.0856 (0.396 sec/step)\n",
            "I0205 13:36:51.070642 140689526667136 learning.py:507] global step 2742: loss = 0.0856 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 2743: loss = 0.1323 (0.395 sec/step)\n",
            "I0205 13:36:51.467023 140689526667136 learning.py:507] global step 2743: loss = 0.1323 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 2744: loss = 0.1119 (0.375 sec/step)\n",
            "I0205 13:36:51.843807 140689526667136 learning.py:507] global step 2744: loss = 0.1119 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2745: loss = 0.2088 (0.413 sec/step)\n",
            "I0205 13:36:52.259292 140689526667136 learning.py:507] global step 2745: loss = 0.2088 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 2746: loss = 0.2236 (0.416 sec/step)\n",
            "I0205 13:36:52.676680 140689526667136 learning.py:507] global step 2746: loss = 0.2236 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 2747: loss = 0.1040 (0.393 sec/step)\n",
            "I0205 13:36:53.071380 140689526667136 learning.py:507] global step 2747: loss = 0.1040 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 2748: loss = 0.1355 (0.375 sec/step)\n",
            "I0205 13:36:53.448283 140689526667136 learning.py:507] global step 2748: loss = 0.1355 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2749: loss = 0.3091 (0.380 sec/step)\n",
            "I0205 13:36:53.830334 140689526667136 learning.py:507] global step 2749: loss = 0.3091 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2750: loss = 0.3278 (0.391 sec/step)\n",
            "I0205 13:36:54.222882 140689526667136 learning.py:507] global step 2750: loss = 0.3278 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2751: loss = 0.4933 (0.397 sec/step)\n",
            "I0205 13:36:54.621493 140689526667136 learning.py:507] global step 2751: loss = 0.4933 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 2752: loss = 0.1351 (0.400 sec/step)\n",
            "I0205 13:36:55.024012 140689526667136 learning.py:507] global step 2752: loss = 0.1351 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 2753: loss = 0.2051 (0.396 sec/step)\n",
            "I0205 13:36:55.421184 140689526667136 learning.py:507] global step 2753: loss = 0.2051 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 2754: loss = 0.1543 (0.391 sec/step)\n",
            "I0205 13:36:55.814090 140689526667136 learning.py:507] global step 2754: loss = 0.1543 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2755: loss = 0.3364 (0.361 sec/step)\n",
            "I0205 13:36:56.177351 140689526667136 learning.py:507] global step 2755: loss = 0.3364 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 2756: loss = 0.3966 (0.382 sec/step)\n",
            "I0205 13:36:56.561453 140689526667136 learning.py:507] global step 2756: loss = 0.3966 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 2757: loss = 0.0510 (0.357 sec/step)\n",
            "I0205 13:36:56.919959 140689526667136 learning.py:507] global step 2757: loss = 0.0510 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 2758: loss = 0.0669 (0.387 sec/step)\n",
            "I0205 13:36:57.308971 140689526667136 learning.py:507] global step 2758: loss = 0.0669 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 2759: loss = 0.8292 (0.418 sec/step)\n",
            "I0205 13:36:57.728142 140689526667136 learning.py:507] global step 2759: loss = 0.8292 (0.418 sec/step)\n",
            "INFO:tensorflow:global step 2760: loss = 0.2809 (0.375 sec/step)\n",
            "I0205 13:36:58.104623 140689526667136 learning.py:507] global step 2760: loss = 0.2809 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2761: loss = 0.0690 (0.403 sec/step)\n",
            "I0205 13:36:58.509556 140689526667136 learning.py:507] global step 2761: loss = 0.0690 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 2762: loss = 0.0738 (0.390 sec/step)\n",
            "I0205 13:36:58.901565 140689526667136 learning.py:507] global step 2762: loss = 0.0738 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 2763: loss = 0.0842 (0.392 sec/step)\n",
            "I0205 13:36:59.294986 140689526667136 learning.py:507] global step 2763: loss = 0.0842 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 2764: loss = 0.2758 (0.377 sec/step)\n",
            "I0205 13:36:59.673808 140689526667136 learning.py:507] global step 2764: loss = 0.2758 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 2765: loss = 0.1243 (0.369 sec/step)\n",
            "I0205 13:37:00.044804 140689526667136 learning.py:507] global step 2765: loss = 0.1243 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 2766: loss = 0.4986 (0.379 sec/step)\n",
            "I0205 13:37:00.425410 140689526667136 learning.py:507] global step 2766: loss = 0.4986 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2767: loss = 0.1502 (0.372 sec/step)\n",
            "I0205 13:37:00.799328 140689526667136 learning.py:507] global step 2767: loss = 0.1502 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 2768: loss = 0.1234 (0.391 sec/step)\n",
            "I0205 13:37:01.192329 140689526667136 learning.py:507] global step 2768: loss = 0.1234 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2769: loss = 0.1305 (0.376 sec/step)\n",
            "I0205 13:37:01.569565 140689526667136 learning.py:507] global step 2769: loss = 0.1305 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 2770: loss = 0.1611 (0.398 sec/step)\n",
            "I0205 13:37:01.969582 140689526667136 learning.py:507] global step 2770: loss = 0.1611 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 2771: loss = 0.0970 (0.385 sec/step)\n",
            "I0205 13:37:02.356405 140689526667136 learning.py:507] global step 2771: loss = 0.0970 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 2772: loss = 0.1163 (0.369 sec/step)\n",
            "I0205 13:37:02.727035 140689526667136 learning.py:507] global step 2772: loss = 0.1163 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 2773: loss = 0.2647 (0.403 sec/step)\n",
            "I0205 13:37:03.132137 140689526667136 learning.py:507] global step 2773: loss = 0.2647 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 2774: loss = 0.2775 (0.383 sec/step)\n",
            "I0205 13:37:03.516639 140689526667136 learning.py:507] global step 2774: loss = 0.2775 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2775: loss = 0.1557 (0.381 sec/step)\n",
            "I0205 13:37:03.899736 140689526667136 learning.py:507] global step 2775: loss = 0.1557 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 2776: loss = 0.2504 (0.373 sec/step)\n",
            "I0205 13:37:04.274489 140689526667136 learning.py:507] global step 2776: loss = 0.2504 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 2777: loss = 0.0500 (0.392 sec/step)\n",
            "I0205 13:37:04.668179 140689526667136 learning.py:507] global step 2777: loss = 0.0500 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 2778: loss = 0.1828 (0.384 sec/step)\n",
            "I0205 13:37:05.053869 140689526667136 learning.py:507] global step 2778: loss = 0.1828 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 2779: loss = 0.1095 (0.387 sec/step)\n",
            "I0205 13:37:05.442053 140689526667136 learning.py:507] global step 2779: loss = 0.1095 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 2780: loss = 0.6330 (0.397 sec/step)\n",
            "I0205 13:37:05.841566 140689526667136 learning.py:507] global step 2780: loss = 0.6330 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 2781: loss = 0.3559 (0.393 sec/step)\n",
            "I0205 13:37:06.236046 140689526667136 learning.py:507] global step 2781: loss = 0.3559 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 2782: loss = 0.2755 (0.398 sec/step)\n",
            "I0205 13:37:06.636016 140689526667136 learning.py:507] global step 2782: loss = 0.2755 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 2783: loss = 0.3243 (0.405 sec/step)\n",
            "I0205 13:37:07.042412 140689526667136 learning.py:507] global step 2783: loss = 0.3243 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 2784: loss = 0.4244 (0.380 sec/step)\n",
            "I0205 13:37:07.423851 140689526667136 learning.py:507] global step 2784: loss = 0.4244 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2785: loss = 0.0608 (0.379 sec/step)\n",
            "I0205 13:37:07.804761 140689526667136 learning.py:507] global step 2785: loss = 0.0608 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2786: loss = 0.5339 (0.403 sec/step)\n",
            "I0205 13:37:08.208981 140689526667136 learning.py:507] global step 2786: loss = 0.5339 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 2787: loss = 0.2221 (0.379 sec/step)\n",
            "I0205 13:37:08.589848 140689526667136 learning.py:507] global step 2787: loss = 0.2221 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2788: loss = 0.2304 (0.384 sec/step)\n",
            "I0205 13:37:08.975014 140689526667136 learning.py:507] global step 2788: loss = 0.2304 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 2789: loss = 0.1199 (0.402 sec/step)\n",
            "I0205 13:37:09.378297 140689526667136 learning.py:507] global step 2789: loss = 0.1199 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 2790: loss = 0.1309 (0.357 sec/step)\n",
            "I0205 13:37:09.737695 140689526667136 learning.py:507] global step 2790: loss = 0.1309 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 2791: loss = 0.5523 (0.362 sec/step)\n",
            "I0205 13:37:10.101770 140689526667136 learning.py:507] global step 2791: loss = 0.5523 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 2792: loss = 0.0103 (0.364 sec/step)\n",
            "I0205 13:37:10.466844 140689526667136 learning.py:507] global step 2792: loss = 0.0103 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 2793: loss = 0.6820 (0.345 sec/step)\n",
            "I0205 13:37:10.813787 140689526667136 learning.py:507] global step 2793: loss = 0.6820 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 2794: loss = 0.0450 (0.391 sec/step)\n",
            "I0205 13:37:11.206359 140689526667136 learning.py:507] global step 2794: loss = 0.0450 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2795: loss = 0.0999 (0.372 sec/step)\n",
            "I0205 13:37:11.579755 140689526667136 learning.py:507] global step 2795: loss = 0.0999 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 2796: loss = 0.1070 (0.367 sec/step)\n",
            "I0205 13:37:11.948465 140689526667136 learning.py:507] global step 2796: loss = 0.1070 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 2797: loss = 0.1251 (0.374 sec/step)\n",
            "I0205 13:37:12.323667 140689526667136 learning.py:507] global step 2797: loss = 0.1251 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 2798: loss = 0.0680 (0.360 sec/step)\n",
            "I0205 13:37:12.685527 140689526667136 learning.py:507] global step 2798: loss = 0.0680 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 2799: loss = 0.1927 (0.381 sec/step)\n",
            "I0205 13:37:13.068081 140689526667136 learning.py:507] global step 2799: loss = 0.1927 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 2800: loss = 0.0517 (0.381 sec/step)\n",
            "I0205 13:37:13.451196 140689526667136 learning.py:507] global step 2800: loss = 0.0517 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 2801: loss = 0.1253 (0.357 sec/step)\n",
            "I0205 13:37:13.810453 140689526667136 learning.py:507] global step 2801: loss = 0.1253 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 2802: loss = 0.3021 (0.391 sec/step)\n",
            "I0205 13:37:14.203377 140689526667136 learning.py:507] global step 2802: loss = 0.3021 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2803: loss = 0.3624 (0.361 sec/step)\n",
            "I0205 13:37:14.566012 140689526667136 learning.py:507] global step 2803: loss = 0.3624 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 2804: loss = 0.1669 (0.362 sec/step)\n",
            "I0205 13:37:14.930009 140689526667136 learning.py:507] global step 2804: loss = 0.1669 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 2805: loss = 0.0882 (0.367 sec/step)\n",
            "I0205 13:37:15.298610 140689526667136 learning.py:507] global step 2805: loss = 0.0882 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 2806: loss = 0.3581 (0.380 sec/step)\n",
            "I0205 13:37:15.679996 140689526667136 learning.py:507] global step 2806: loss = 0.3581 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2807: loss = 0.3698 (0.357 sec/step)\n",
            "I0205 13:37:16.038826 140689526667136 learning.py:507] global step 2807: loss = 0.3698 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 2808: loss = 0.2207 (0.390 sec/step)\n",
            "I0205 13:37:16.430832 140689526667136 learning.py:507] global step 2808: loss = 0.2207 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 2809: loss = 0.1486 (0.383 sec/step)\n",
            "I0205 13:37:16.815046 140689526667136 learning.py:507] global step 2809: loss = 0.1486 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2810: loss = 0.1295 (0.374 sec/step)\n",
            "I0205 13:37:17.191633 140689526667136 learning.py:507] global step 2810: loss = 0.1295 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 2811: loss = 0.0631 (0.365 sec/step)\n",
            "I0205 13:37:17.558639 140689526667136 learning.py:507] global step 2811: loss = 0.0631 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 2812: loss = 0.3909 (0.385 sec/step)\n",
            "I0205 13:37:17.945464 140689526667136 learning.py:507] global step 2812: loss = 0.3909 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 2813: loss = 0.2789 (0.389 sec/step)\n",
            "I0205 13:37:18.336614 140689526667136 learning.py:507] global step 2813: loss = 0.2789 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 2814: loss = 0.2838 (0.383 sec/step)\n",
            "I0205 13:37:18.721202 140689526667136 learning.py:507] global step 2814: loss = 0.2838 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2815: loss = 0.0999 (0.393 sec/step)\n",
            "I0205 13:37:19.116049 140689526667136 learning.py:507] global step 2815: loss = 0.0999 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 2816: loss = 0.2346 (0.401 sec/step)\n",
            "I0205 13:37:19.519278 140689526667136 learning.py:507] global step 2816: loss = 0.2346 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 2817: loss = 0.2417 (0.397 sec/step)\n",
            "I0205 13:37:19.918294 140689526667136 learning.py:507] global step 2817: loss = 0.2417 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 2818: loss = 0.2174 (0.387 sec/step)\n",
            "I0205 13:37:20.306379 140689526667136 learning.py:507] global step 2818: loss = 0.2174 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 2819: loss = 1.3698 (0.395 sec/step)\n",
            "I0205 13:37:20.703146 140689526667136 learning.py:507] global step 2819: loss = 1.3698 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 2820: loss = 0.6129 (0.358 sec/step)\n",
            "I0205 13:37:21.062223 140689526667136 learning.py:507] global step 2820: loss = 0.6129 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 2821: loss = 0.2369 (0.381 sec/step)\n",
            "I0205 13:37:21.444778 140689526667136 learning.py:507] global step 2821: loss = 0.2369 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 2822: loss = 0.1849 (0.365 sec/step)\n",
            "I0205 13:37:21.810854 140689526667136 learning.py:507] global step 2822: loss = 0.1849 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 2823: loss = 0.0959 (0.357 sec/step)\n",
            "I0205 13:37:22.169958 140689526667136 learning.py:507] global step 2823: loss = 0.0959 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 2824: loss = 0.2889 (0.376 sec/step)\n",
            "I0205 13:37:22.547354 140689526667136 learning.py:507] global step 2824: loss = 0.2889 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 2825: loss = 0.2797 (0.344 sec/step)\n",
            "I0205 13:37:22.893526 140689526667136 learning.py:507] global step 2825: loss = 0.2797 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 2826: loss = 0.2071 (0.381 sec/step)\n",
            "I0205 13:37:23.276230 140689526667136 learning.py:507] global step 2826: loss = 0.2071 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 2827: loss = 0.6115 (0.385 sec/step)\n",
            "I0205 13:37:23.663187 140689526667136 learning.py:507] global step 2827: loss = 0.6115 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 2828: loss = 0.0202 (0.381 sec/step)\n",
            "I0205 13:37:24.045848 140689526667136 learning.py:507] global step 2828: loss = 0.0202 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 2829: loss = 0.0468 (0.397 sec/step)\n",
            "I0205 13:37:24.444592 140689526667136 learning.py:507] global step 2829: loss = 0.0468 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 2830: loss = 0.2249 (0.381 sec/step)\n",
            "I0205 13:37:24.827487 140689526667136 learning.py:507] global step 2830: loss = 0.2249 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 2831: loss = 0.1449 (0.377 sec/step)\n",
            "I0205 13:37:25.205663 140689526667136 learning.py:507] global step 2831: loss = 0.1449 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 2832: loss = 0.2999 (0.346 sec/step)\n",
            "I0205 13:37:25.553385 140689526667136 learning.py:507] global step 2832: loss = 0.2999 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 2833: loss = 0.1753 (0.371 sec/step)\n",
            "I0205 13:37:25.925780 140689526667136 learning.py:507] global step 2833: loss = 0.1753 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 2834: loss = 0.2128 (0.363 sec/step)\n",
            "I0205 13:37:26.290670 140689526667136 learning.py:507] global step 2834: loss = 0.2128 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 2835: loss = 0.1009 (0.376 sec/step)\n",
            "I0205 13:37:26.668621 140689526667136 learning.py:507] global step 2835: loss = 0.1009 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 2836: loss = 0.4899 (0.373 sec/step)\n",
            "I0205 13:37:27.042779 140689526667136 learning.py:507] global step 2836: loss = 0.4899 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 2837: loss = 0.2891 (0.412 sec/step)\n",
            "I0205 13:37:27.456233 140689526667136 learning.py:507] global step 2837: loss = 0.2891 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 2838: loss = 0.2334 (0.396 sec/step)\n",
            "I0205 13:37:27.855725 140689526667136 learning.py:507] global step 2838: loss = 0.2334 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 2839: loss = 0.1371 (0.344 sec/step)\n",
            "I0205 13:37:28.201595 140689526667136 learning.py:507] global step 2839: loss = 0.1371 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 2840: loss = 0.1037 (0.384 sec/step)\n",
            "I0205 13:37:28.587497 140689526667136 learning.py:507] global step 2840: loss = 0.1037 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 2841: loss = 0.9546 (0.379 sec/step)\n",
            "I0205 13:37:28.967839 140689526667136 learning.py:507] global step 2841: loss = 0.9546 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2842: loss = 0.4292 (0.403 sec/step)\n",
            "I0205 13:37:29.372306 140689526667136 learning.py:507] global step 2842: loss = 0.4292 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 2843: loss = 0.1568 (0.437 sec/step)\n",
            "I0205 13:37:29.811141 140689526667136 learning.py:507] global step 2843: loss = 0.1568 (0.437 sec/step)\n",
            "INFO:tensorflow:global step 2844: loss = 0.0898 (0.374 sec/step)\n",
            "I0205 13:37:30.187021 140689526667136 learning.py:507] global step 2844: loss = 0.0898 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 2845: loss = 0.2819 (0.397 sec/step)\n",
            "I0205 13:37:30.585015 140689526667136 learning.py:507] global step 2845: loss = 0.2819 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 2846: loss = 0.1336 (0.384 sec/step)\n",
            "I0205 13:37:30.970427 140689526667136 learning.py:507] global step 2846: loss = 0.1336 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 2847: loss = 0.2787 (0.357 sec/step)\n",
            "I0205 13:37:31.329245 140689526667136 learning.py:507] global step 2847: loss = 0.2787 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 2848: loss = 0.1489 (0.382 sec/step)\n",
            "I0205 13:37:31.713040 140689526667136 learning.py:507] global step 2848: loss = 0.1489 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 2849: loss = 0.1090 (0.369 sec/step)\n",
            "I0205 13:37:32.083720 140689526667136 learning.py:507] global step 2849: loss = 0.1090 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 2850: loss = 0.0889 (0.402 sec/step)\n",
            "I0205 13:37:32.487864 140689526667136 learning.py:507] global step 2850: loss = 0.0889 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 2851: loss = 0.1231 (0.358 sec/step)\n",
            "I0205 13:37:32.847640 140689526667136 learning.py:507] global step 2851: loss = 0.1231 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 2852: loss = 0.2182 (0.384 sec/step)\n",
            "I0205 13:37:33.233725 140689526667136 learning.py:507] global step 2852: loss = 0.2182 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 2853: loss = 0.3216 (0.382 sec/step)\n",
            "I0205 13:37:33.617267 140689526667136 learning.py:507] global step 2853: loss = 0.3216 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 2854: loss = 0.1201 (0.361 sec/step)\n",
            "I0205 13:37:33.980429 140689526667136 learning.py:507] global step 2854: loss = 0.1201 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 2855: loss = 0.1965 (0.383 sec/step)\n",
            "I0205 13:37:34.365222 140689526667136 learning.py:507] global step 2855: loss = 0.1965 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2856: loss = 0.2960 (0.383 sec/step)\n",
            "I0205 13:37:34.749713 140689526667136 learning.py:507] global step 2856: loss = 0.2960 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2857: loss = 0.0242 (0.372 sec/step)\n",
            "I0205 13:37:35.123596 140689526667136 learning.py:507] global step 2857: loss = 0.0242 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 2858: loss = 0.4389 (0.382 sec/step)\n",
            "I0205 13:37:35.507378 140689526667136 learning.py:507] global step 2858: loss = 0.4389 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 2859: loss = 0.0804 (0.389 sec/step)\n",
            "I0205 13:37:35.898099 140689526667136 learning.py:507] global step 2859: loss = 0.0804 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 2860: loss = 0.0723 (0.366 sec/step)\n",
            "I0205 13:37:36.267370 140689526667136 learning.py:507] global step 2860: loss = 0.0723 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 2861: loss = 0.1197 (0.367 sec/step)\n",
            "I0205 13:37:36.635612 140689526667136 learning.py:507] global step 2861: loss = 0.1197 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 2862: loss = 0.0857 (0.374 sec/step)\n",
            "I0205 13:37:37.011270 140689526667136 learning.py:507] global step 2862: loss = 0.0857 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 2863: loss = 0.0491 (0.372 sec/step)\n",
            "I0205 13:37:37.385191 140689526667136 learning.py:507] global step 2863: loss = 0.0491 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 2864: loss = 0.4972 (0.394 sec/step)\n",
            "I0205 13:37:37.780934 140689526667136 learning.py:507] global step 2864: loss = 0.4972 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 2865: loss = 0.0894 (0.372 sec/step)\n",
            "I0205 13:37:38.154289 140689526667136 learning.py:507] global step 2865: loss = 0.0894 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 2866: loss = 0.0879 (0.379 sec/step)\n",
            "I0205 13:37:38.534441 140689526667136 learning.py:507] global step 2866: loss = 0.0879 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2867: loss = 0.1847 (0.369 sec/step)\n",
            "I0205 13:37:38.905244 140689526667136 learning.py:507] global step 2867: loss = 0.1847 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 2868: loss = 0.2425 (0.351 sec/step)\n",
            "I0205 13:37:39.258198 140689526667136 learning.py:507] global step 2868: loss = 0.2425 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 2869: loss = 0.0819 (0.386 sec/step)\n",
            "I0205 13:37:39.645661 140689526667136 learning.py:507] global step 2869: loss = 0.0819 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 2870: loss = 0.0604 (0.364 sec/step)\n",
            "I0205 13:37:40.011362 140689526667136 learning.py:507] global step 2870: loss = 0.0604 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 2871: loss = 0.6252 (0.357 sec/step)\n",
            "I0205 13:37:40.370219 140689526667136 learning.py:507] global step 2871: loss = 0.6252 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 2872: loss = 0.2060 (0.399 sec/step)\n",
            "I0205 13:37:40.771244 140689526667136 learning.py:507] global step 2872: loss = 0.2060 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 2873: loss = 0.0805 (0.372 sec/step)\n",
            "I0205 13:37:41.145823 140689526667136 learning.py:507] global step 2873: loss = 0.0805 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 2874: loss = 0.3117 (0.379 sec/step)\n",
            "I0205 13:37:41.526480 140689526667136 learning.py:507] global step 2874: loss = 0.3117 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2875: loss = 0.1292 (0.377 sec/step)\n",
            "I0205 13:37:41.905244 140689526667136 learning.py:507] global step 2875: loss = 0.1292 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 2876: loss = 0.5371 (0.382 sec/step)\n",
            "I0205 13:37:42.288908 140689526667136 learning.py:507] global step 2876: loss = 0.5371 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 2877: loss = 0.2264 (0.370 sec/step)\n",
            "I0205 13:37:42.660430 140689526667136 learning.py:507] global step 2877: loss = 0.2264 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 2878: loss = 0.0657 (0.371 sec/step)\n",
            "I0205 13:37:43.032921 140689526667136 learning.py:507] global step 2878: loss = 0.0657 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 2879: loss = 0.1700 (0.389 sec/step)\n",
            "I0205 13:37:43.423612 140689526667136 learning.py:507] global step 2879: loss = 0.1700 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 2880: loss = 0.1144 (0.383 sec/step)\n",
            "I0205 13:37:43.808372 140689526667136 learning.py:507] global step 2880: loss = 0.1144 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2881: loss = 0.0629 (0.405 sec/step)\n",
            "I0205 13:37:44.215466 140689526667136 learning.py:507] global step 2881: loss = 0.0629 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 2882: loss = 0.2400 (0.392 sec/step)\n",
            "I0205 13:37:44.608604 140689526667136 learning.py:507] global step 2882: loss = 0.2400 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 2883: loss = 0.4843 (0.378 sec/step)\n",
            "I0205 13:37:44.987962 140689526667136 learning.py:507] global step 2883: loss = 0.4843 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 2884: loss = 0.0880 (0.370 sec/step)\n",
            "I0205 13:37:45.359823 140689526667136 learning.py:507] global step 2884: loss = 0.0880 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 2885: loss = 0.2394 (0.358 sec/step)\n",
            "I0205 13:37:45.718989 140689526667136 learning.py:507] global step 2885: loss = 0.2394 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 2886: loss = 0.1741 (0.368 sec/step)\n",
            "I0205 13:37:46.088893 140689526667136 learning.py:507] global step 2886: loss = 0.1741 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 2887: loss = 0.0700 (0.339 sec/step)\n",
            "I0205 13:37:46.429139 140689526667136 learning.py:507] global step 2887: loss = 0.0700 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 2888: loss = 0.3539 (0.394 sec/step)\n",
            "I0205 13:37:46.825602 140689526667136 learning.py:507] global step 2888: loss = 0.3539 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 2889: loss = 0.0509 (0.385 sec/step)\n",
            "I0205 13:37:47.213375 140689526667136 learning.py:507] global step 2889: loss = 0.0509 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 2890: loss = 0.1384 (0.378 sec/step)\n",
            "I0205 13:37:47.593018 140689526667136 learning.py:507] global step 2890: loss = 0.1384 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 2891: loss = 0.1784 (0.370 sec/step)\n",
            "I0205 13:37:47.964848 140689526667136 learning.py:507] global step 2891: loss = 0.1784 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 2892: loss = 0.0882 (0.377 sec/step)\n",
            "I0205 13:37:48.343661 140689526667136 learning.py:507] global step 2892: loss = 0.0882 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 2893: loss = 0.1474 (0.400 sec/step)\n",
            "I0205 13:37:48.744995 140689526667136 learning.py:507] global step 2893: loss = 0.1474 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 2894: loss = 0.0096 (0.384 sec/step)\n",
            "I0205 13:37:49.130736 140689526667136 learning.py:507] global step 2894: loss = 0.0096 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 2895: loss = 0.2352 (0.379 sec/step)\n",
            "I0205 13:37:49.510860 140689526667136 learning.py:507] global step 2895: loss = 0.2352 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2896: loss = 0.2266 (0.368 sec/step)\n",
            "I0205 13:37:49.880337 140689526667136 learning.py:507] global step 2896: loss = 0.2266 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 2897: loss = 0.2841 (0.399 sec/step)\n",
            "I0205 13:37:50.281293 140689526667136 learning.py:507] global step 2897: loss = 0.2841 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 2898: loss = 0.1071 (0.371 sec/step)\n",
            "I0205 13:37:50.653793 140689526667136 learning.py:507] global step 2898: loss = 0.1071 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 2899: loss = 0.1082 (0.412 sec/step)\n",
            "I0205 13:37:51.066980 140689526667136 learning.py:507] global step 2899: loss = 0.1082 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 2900: loss = 0.1458 (0.407 sec/step)\n",
            "I0205 13:37:51.476053 140689526667136 learning.py:507] global step 2900: loss = 0.1458 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 2901: loss = 0.1070 (0.375 sec/step)\n",
            "I0205 13:37:51.853040 140689526667136 learning.py:507] global step 2901: loss = 0.1070 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2902: loss = 1.0503 (0.404 sec/step)\n",
            "I0205 13:37:52.258740 140689526667136 learning.py:507] global step 2902: loss = 1.0503 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 2903: loss = 0.0845 (0.408 sec/step)\n",
            "I0205 13:37:52.668269 140689526667136 learning.py:507] global step 2903: loss = 0.0845 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 2904: loss = 0.1289 (0.403 sec/step)\n",
            "I0205 13:37:53.073154 140689526667136 learning.py:507] global step 2904: loss = 0.1289 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 2905: loss = 0.0943 (0.375 sec/step)\n",
            "I0205 13:37:53.449729 140689526667136 learning.py:507] global step 2905: loss = 0.0943 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2906: loss = 0.2293 (0.359 sec/step)\n",
            "I0205 13:37:53.810781 140689526667136 learning.py:507] global step 2906: loss = 0.2293 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 2907: loss = 0.1749 (0.424 sec/step)\n",
            "I0205 13:37:54.236309 140689526667136 learning.py:507] global step 2907: loss = 0.1749 (0.424 sec/step)\n",
            "INFO:tensorflow:global step 2908: loss = 0.2072 (0.364 sec/step)\n",
            "I0205 13:37:54.602258 140689526667136 learning.py:507] global step 2908: loss = 0.2072 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 2909: loss = 0.3203 (0.350 sec/step)\n",
            "I0205 13:37:54.953553 140689526667136 learning.py:507] global step 2909: loss = 0.3203 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 2910: loss = 0.2040 (0.356 sec/step)\n",
            "I0205 13:37:55.311587 140689526667136 learning.py:507] global step 2910: loss = 0.2040 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 2911: loss = 0.3874 (0.362 sec/step)\n",
            "I0205 13:37:55.674921 140689526667136 learning.py:507] global step 2911: loss = 0.3874 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 2912: loss = 0.1993 (0.401 sec/step)\n",
            "I0205 13:37:56.077505 140689526667136 learning.py:507] global step 2912: loss = 0.1993 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 2913: loss = 0.1156 (0.366 sec/step)\n",
            "I0205 13:37:56.444960 140689526667136 learning.py:507] global step 2913: loss = 0.1156 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 2914: loss = 0.4049 (0.383 sec/step)\n",
            "I0205 13:37:56.829793 140689526667136 learning.py:507] global step 2914: loss = 0.4049 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2915: loss = 0.4413 (0.398 sec/step)\n",
            "I0205 13:37:57.229255 140689526667136 learning.py:507] global step 2915: loss = 0.4413 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 2916: loss = 0.1510 (0.379 sec/step)\n",
            "I0205 13:37:57.610280 140689526667136 learning.py:507] global step 2916: loss = 0.1510 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2917: loss = 0.0517 (0.362 sec/step)\n",
            "I0205 13:37:57.973635 140689526667136 learning.py:507] global step 2917: loss = 0.0517 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 2918: loss = 0.0510 (0.388 sec/step)\n",
            "I0205 13:37:58.363607 140689526667136 learning.py:507] global step 2918: loss = 0.0510 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 2919: loss = 0.1468 (0.382 sec/step)\n",
            "I0205 13:37:58.747231 140689526667136 learning.py:507] global step 2919: loss = 0.1468 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 2920: loss = 0.3656 (0.380 sec/step)\n",
            "I0205 13:37:59.129236 140689526667136 learning.py:507] global step 2920: loss = 0.3656 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2921: loss = 0.2146 (0.367 sec/step)\n",
            "I0205 13:37:59.497724 140689526667136 learning.py:507] global step 2921: loss = 0.2146 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 2922: loss = 0.0438 (0.354 sec/step)\n",
            "I0205 13:37:59.853294 140689526667136 learning.py:507] global step 2922: loss = 0.0438 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 2923: loss = 0.0709 (0.354 sec/step)\n",
            "I0205 13:38:00.209222 140689526667136 learning.py:507] global step 2923: loss = 0.0709 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 2924: loss = 0.0868 (0.392 sec/step)\n",
            "I0205 13:38:00.602476 140689526667136 learning.py:507] global step 2924: loss = 0.0868 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 2925: loss = 0.1190 (0.390 sec/step)\n",
            "I0205 13:38:00.994595 140689526667136 learning.py:507] global step 2925: loss = 0.1190 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 2926: loss = 0.0853 (0.390 sec/step)\n",
            "I0205 13:38:01.386038 140689526667136 learning.py:507] global step 2926: loss = 0.0853 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 2927: loss = 0.1463 (0.381 sec/step)\n",
            "I0205 13:38:01.768562 140689526667136 learning.py:507] global step 2927: loss = 0.1463 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 2928: loss = 0.2878 (0.385 sec/step)\n",
            "I0205 13:38:02.155623 140689526667136 learning.py:507] global step 2928: loss = 0.2878 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 2929: loss = 0.3293 (0.368 sec/step)\n",
            "I0205 13:38:02.524641 140689526667136 learning.py:507] global step 2929: loss = 0.3293 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 2930: loss = 0.0606 (0.375 sec/step)\n",
            "I0205 13:38:02.901381 140689526667136 learning.py:507] global step 2930: loss = 0.0606 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2931: loss = 0.0539 (0.380 sec/step)\n",
            "I0205 13:38:03.283544 140689526667136 learning.py:507] global step 2931: loss = 0.0539 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2932: loss = 0.6722 (0.377 sec/step)\n",
            "I0205 13:38:03.661829 140689526667136 learning.py:507] global step 2932: loss = 0.6722 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 2933: loss = 0.6770 (0.402 sec/step)\n",
            "I0205 13:38:04.065404 140689526667136 learning.py:507] global step 2933: loss = 0.6770 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 2934: loss = 0.1969 (0.375 sec/step)\n",
            "I0205 13:38:04.442518 140689526667136 learning.py:507] global step 2934: loss = 0.1969 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2935: loss = 0.1352 (0.373 sec/step)\n",
            "I0205 13:38:04.817020 140689526667136 learning.py:507] global step 2935: loss = 0.1352 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 2936: loss = 0.1700 (0.409 sec/step)\n",
            "I0205 13:38:05.227828 140689526667136 learning.py:507] global step 2936: loss = 0.1700 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 2937: loss = 0.0986 (2.035 sec/step)\n",
            "I0205 13:38:07.264412 140689526667136 learning.py:507] global step 2937: loss = 0.0986 (2.035 sec/step)\n",
            "INFO:tensorflow:global step 2938: loss = 0.1609 (0.369 sec/step)\n",
            "I0205 13:38:07.635082 140689526667136 learning.py:507] global step 2938: loss = 0.1609 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 2939: loss = 0.3168 (0.382 sec/step)\n",
            "I0205 13:38:08.018288 140689526667136 learning.py:507] global step 2939: loss = 0.3168 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 2940: loss = 0.1782 (0.406 sec/step)\n",
            "I0205 13:38:08.425666 140689526667136 learning.py:507] global step 2940: loss = 0.1782 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 2941: loss = 0.1040 (0.413 sec/step)\n",
            "I0205 13:38:08.840016 140689526667136 learning.py:507] global step 2941: loss = 0.1040 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 2942: loss = 0.1223 (0.349 sec/step)\n",
            "I0205 13:38:09.191064 140689526667136 learning.py:507] global step 2942: loss = 0.1223 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 2943: loss = 0.0732 (0.389 sec/step)\n",
            "I0205 13:38:09.581246 140689526667136 learning.py:507] global step 2943: loss = 0.0732 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 2944: loss = 0.1077 (0.376 sec/step)\n",
            "I0205 13:38:09.958752 140689526667136 learning.py:507] global step 2944: loss = 0.1077 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 2945: loss = 0.0655 (0.369 sec/step)\n",
            "I0205 13:38:10.328918 140689526667136 learning.py:507] global step 2945: loss = 0.0655 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 2946: loss = 0.1494 (0.378 sec/step)\n",
            "I0205 13:38:10.708086 140689526667136 learning.py:507] global step 2946: loss = 0.1494 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 2947: loss = 0.1408 (0.378 sec/step)\n",
            "I0205 13:38:11.087384 140689526667136 learning.py:507] global step 2947: loss = 0.1408 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 2948: loss = 0.5709 (0.379 sec/step)\n",
            "I0205 13:38:11.467818 140689526667136 learning.py:507] global step 2948: loss = 0.5709 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2949: loss = 0.1171 (0.387 sec/step)\n",
            "I0205 13:38:11.855979 140689526667136 learning.py:507] global step 2949: loss = 0.1171 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 2950: loss = 0.3106 (0.381 sec/step)\n",
            "I0205 13:38:12.239231 140689526667136 learning.py:507] global step 2950: loss = 0.3106 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 2951: loss = 0.5806 (0.378 sec/step)\n",
            "I0205 13:38:12.618457 140689526667136 learning.py:507] global step 2951: loss = 0.5806 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 2952: loss = 0.2353 (0.391 sec/step)\n",
            "I0205 13:38:13.011030 140689526667136 learning.py:507] global step 2952: loss = 0.2353 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2953: loss = 0.1113 (0.431 sec/step)\n",
            "I0205 13:38:13.443683 140689526667136 learning.py:507] global step 2953: loss = 0.1113 (0.431 sec/step)\n",
            "INFO:tensorflow:global step 2954: loss = 0.1797 (0.418 sec/step)\n",
            "I0205 13:38:13.874021 140689526667136 learning.py:507] global step 2954: loss = 0.1797 (0.418 sec/step)\n",
            "INFO:tensorflow:global step 2955: loss = 0.6212 (1.211 sec/step)\n",
            "I0205 13:38:15.096038 140689526667136 learning.py:507] global step 2955: loss = 0.6212 (1.211 sec/step)\n",
            "INFO:tensorflow:global step 2956: loss = 0.0940 (0.561 sec/step)\n",
            "I0205 13:38:15.758076 140689526667136 learning.py:507] global step 2956: loss = 0.0940 (0.561 sec/step)\n",
            "INFO:tensorflow:global step 2957: loss = 0.2659 (0.608 sec/step)\n",
            "I0205 13:38:16.382609 140689526667136 learning.py:507] global step 2957: loss = 0.2659 (0.608 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 2957.\n",
            "I0205 13:38:17.111940 140686026073856 supervisor.py:1050] Recording summary at step 2957.\n",
            "INFO:tensorflow:global step 2958: loss = 0.7075 (0.744 sec/step)\n",
            "I0205 13:38:17.133212 140689526667136 learning.py:507] global step 2958: loss = 0.7075 (0.744 sec/step)\n",
            "INFO:tensorflow:global step 2959: loss = 0.1801 (0.375 sec/step)\n",
            "I0205 13:38:17.509426 140689526667136 learning.py:507] global step 2959: loss = 0.1801 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 2960: loss = 0.0338 (0.388 sec/step)\n",
            "I0205 13:38:17.898767 140689526667136 learning.py:507] global step 2960: loss = 0.0338 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 2961: loss = 0.2506 (0.379 sec/step)\n",
            "I0205 13:38:18.278686 140689526667136 learning.py:507] global step 2961: loss = 0.2506 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2962: loss = 0.1448 (0.388 sec/step)\n",
            "I0205 13:38:18.668671 140689526667136 learning.py:507] global step 2962: loss = 0.1448 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 2963: loss = 0.6120 (0.397 sec/step)\n",
            "I0205 13:38:19.067954 140689526667136 learning.py:507] global step 2963: loss = 0.6120 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 2964: loss = 0.3277 (0.407 sec/step)\n",
            "I0205 13:38:19.476980 140689526667136 learning.py:507] global step 2964: loss = 0.3277 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 2965: loss = 0.0525 (0.381 sec/step)\n",
            "I0205 13:38:19.859860 140689526667136 learning.py:507] global step 2965: loss = 0.0525 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 2966: loss = 0.4087 (0.379 sec/step)\n",
            "I0205 13:38:20.240757 140689526667136 learning.py:507] global step 2966: loss = 0.4087 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2967: loss = 0.1501 (0.380 sec/step)\n",
            "I0205 13:38:20.622822 140689526667136 learning.py:507] global step 2967: loss = 0.1501 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2968: loss = 0.2574 (0.374 sec/step)\n",
            "I0205 13:38:20.998891 140689526667136 learning.py:507] global step 2968: loss = 0.2574 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 2969: loss = 0.0440 (0.384 sec/step)\n",
            "I0205 13:38:21.384955 140689526667136 learning.py:507] global step 2969: loss = 0.0440 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 2970: loss = 0.3606 (0.385 sec/step)\n",
            "I0205 13:38:21.771588 140689526667136 learning.py:507] global step 2970: loss = 0.3606 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 2971: loss = 0.2613 (0.379 sec/step)\n",
            "I0205 13:38:22.152496 140689526667136 learning.py:507] global step 2971: loss = 0.2613 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 2972: loss = 0.6404 (0.446 sec/step)\n",
            "I0205 13:38:22.600305 140689526667136 learning.py:507] global step 2972: loss = 0.6404 (0.446 sec/step)\n",
            "INFO:tensorflow:global step 2973: loss = 0.1191 (0.398 sec/step)\n",
            "I0205 13:38:23.000329 140689526667136 learning.py:507] global step 2973: loss = 0.1191 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 2974: loss = 0.2136 (0.373 sec/step)\n",
            "I0205 13:38:23.375397 140689526667136 learning.py:507] global step 2974: loss = 0.2136 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 2975: loss = 0.2745 (0.372 sec/step)\n",
            "I0205 13:38:23.749178 140689526667136 learning.py:507] global step 2975: loss = 0.2745 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 2976: loss = 0.1299 (0.404 sec/step)\n",
            "I0205 13:38:24.154593 140689526667136 learning.py:507] global step 2976: loss = 0.1299 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 2977: loss = 0.0606 (0.383 sec/step)\n",
            "I0205 13:38:24.538751 140689526667136 learning.py:507] global step 2977: loss = 0.0606 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2978: loss = 0.3759 (0.400 sec/step)\n",
            "I0205 13:38:24.939845 140689526667136 learning.py:507] global step 2978: loss = 0.3759 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 2979: loss = 0.1205 (0.361 sec/step)\n",
            "I0205 13:38:25.302197 140689526667136 learning.py:507] global step 2979: loss = 0.1205 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 2980: loss = 0.2973 (0.400 sec/step)\n",
            "I0205 13:38:25.704086 140689526667136 learning.py:507] global step 2980: loss = 0.2973 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 2981: loss = 0.1885 (0.361 sec/step)\n",
            "I0205 13:38:26.066779 140689526667136 learning.py:507] global step 2981: loss = 0.1885 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 2982: loss = 0.1043 (0.368 sec/step)\n",
            "I0205 13:38:26.436926 140689526667136 learning.py:507] global step 2982: loss = 0.1043 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 2983: loss = 0.1193 (0.355 sec/step)\n",
            "I0205 13:38:26.793961 140689526667136 learning.py:507] global step 2983: loss = 0.1193 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 2984: loss = 0.2113 (0.382 sec/step)\n",
            "I0205 13:38:27.177650 140689526667136 learning.py:507] global step 2984: loss = 0.2113 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 2985: loss = 0.1114 (0.391 sec/step)\n",
            "I0205 13:38:27.570048 140689526667136 learning.py:507] global step 2985: loss = 0.1114 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 2986: loss = 0.2913 (0.388 sec/step)\n",
            "I0205 13:38:27.959821 140689526667136 learning.py:507] global step 2986: loss = 0.2913 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 2987: loss = 0.0702 (0.382 sec/step)\n",
            "I0205 13:38:28.343695 140689526667136 learning.py:507] global step 2987: loss = 0.0702 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 2988: loss = 0.0830 (0.383 sec/step)\n",
            "I0205 13:38:28.727941 140689526667136 learning.py:507] global step 2988: loss = 0.0830 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 2989: loss = 0.2281 (0.384 sec/step)\n",
            "I0205 13:38:29.113874 140689526667136 learning.py:507] global step 2989: loss = 0.2281 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 2990: loss = 0.1099 (0.403 sec/step)\n",
            "I0205 13:38:29.519048 140689526667136 learning.py:507] global step 2990: loss = 0.1099 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 2991: loss = 0.0610 (0.420 sec/step)\n",
            "I0205 13:38:29.941037 140689526667136 learning.py:507] global step 2991: loss = 0.0610 (0.420 sec/step)\n",
            "INFO:tensorflow:global step 2992: loss = 0.0680 (0.396 sec/step)\n",
            "I0205 13:38:30.338810 140689526667136 learning.py:507] global step 2992: loss = 0.0680 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 2993: loss = 0.2267 (0.373 sec/step)\n",
            "I0205 13:38:30.713268 140689526667136 learning.py:507] global step 2993: loss = 0.2267 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 2994: loss = 0.0289 (0.380 sec/step)\n",
            "I0205 13:38:31.094776 140689526667136 learning.py:507] global step 2994: loss = 0.0289 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 2995: loss = 0.0267 (0.370 sec/step)\n",
            "I0205 13:38:31.466342 140689526667136 learning.py:507] global step 2995: loss = 0.0267 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 2996: loss = 0.1480 (0.352 sec/step)\n",
            "I0205 13:38:31.820443 140689526667136 learning.py:507] global step 2996: loss = 0.1480 (0.352 sec/step)\n",
            "INFO:tensorflow:global step 2997: loss = 0.0704 (0.394 sec/step)\n",
            "I0205 13:38:32.215945 140689526667136 learning.py:507] global step 2997: loss = 0.0704 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 2998: loss = 0.0706 (0.374 sec/step)\n",
            "I0205 13:38:32.591569 140689526667136 learning.py:507] global step 2998: loss = 0.0706 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 2999: loss = 0.0691 (0.378 sec/step)\n",
            "I0205 13:38:32.971418 140689526667136 learning.py:507] global step 2999: loss = 0.0691 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 3000: loss = 0.1108 (0.426 sec/step)\n",
            "I0205 13:38:33.399375 140689526667136 learning.py:507] global step 3000: loss = 0.1108 (0.426 sec/step)\n",
            "INFO:tensorflow:global step 3001: loss = 0.2086 (0.397 sec/step)\n",
            "I0205 13:38:33.798417 140689526667136 learning.py:507] global step 3001: loss = 0.2086 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 3002: loss = 0.2146 (0.354 sec/step)\n",
            "I0205 13:38:34.153461 140689526667136 learning.py:507] global step 3002: loss = 0.2146 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 3003: loss = 0.0562 (0.396 sec/step)\n",
            "I0205 13:38:34.550699 140689526667136 learning.py:507] global step 3003: loss = 0.0562 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 3004: loss = 0.0481 (0.390 sec/step)\n",
            "I0205 13:38:34.942465 140689526667136 learning.py:507] global step 3004: loss = 0.0481 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3005: loss = 0.1818 (0.360 sec/step)\n",
            "I0205 13:38:35.303796 140689526667136 learning.py:507] global step 3005: loss = 0.1818 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 3006: loss = 0.3905 (0.367 sec/step)\n",
            "I0205 13:38:35.671798 140689526667136 learning.py:507] global step 3006: loss = 0.3905 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 3007: loss = 0.3320 (0.389 sec/step)\n",
            "I0205 13:38:36.062524 140689526667136 learning.py:507] global step 3007: loss = 0.3320 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 3008: loss = 0.0439 (0.373 sec/step)\n",
            "I0205 13:38:36.436854 140689526667136 learning.py:507] global step 3008: loss = 0.0439 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 3009: loss = 0.2350 (0.392 sec/step)\n",
            "I0205 13:38:36.830180 140689526667136 learning.py:507] global step 3009: loss = 0.2350 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 3010: loss = 0.3094 (0.363 sec/step)\n",
            "I0205 13:38:37.195081 140689526667136 learning.py:507] global step 3010: loss = 0.3094 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 3011: loss = 0.1488 (0.351 sec/step)\n",
            "I0205 13:38:37.547913 140689526667136 learning.py:507] global step 3011: loss = 0.1488 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 3012: loss = 0.1588 (0.362 sec/step)\n",
            "I0205 13:38:37.911742 140689526667136 learning.py:507] global step 3012: loss = 0.1588 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 3013: loss = 0.0979 (0.416 sec/step)\n",
            "I0205 13:38:38.329564 140689526667136 learning.py:507] global step 3013: loss = 0.0979 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 3014: loss = 0.0993 (0.372 sec/step)\n",
            "I0205 13:38:38.703092 140689526667136 learning.py:507] global step 3014: loss = 0.0993 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 3015: loss = 0.1001 (0.374 sec/step)\n",
            "I0205 13:38:39.078445 140689526667136 learning.py:507] global step 3015: loss = 0.1001 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 3016: loss = 0.8224 (0.373 sec/step)\n",
            "I0205 13:38:39.453032 140689526667136 learning.py:507] global step 3016: loss = 0.8224 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 3017: loss = 0.1746 (0.383 sec/step)\n",
            "I0205 13:38:39.838058 140689526667136 learning.py:507] global step 3017: loss = 0.1746 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 3018: loss = 0.0130 (0.383 sec/step)\n",
            "I0205 13:38:40.222805 140689526667136 learning.py:507] global step 3018: loss = 0.0130 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 3019: loss = 0.2424 (0.390 sec/step)\n",
            "I0205 13:38:40.614203 140689526667136 learning.py:507] global step 3019: loss = 0.2424 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3020: loss = 0.8883 (0.387 sec/step)\n",
            "I0205 13:38:41.002246 140689526667136 learning.py:507] global step 3020: loss = 0.8883 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 3021: loss = 0.4242 (0.361 sec/step)\n",
            "I0205 13:38:41.365049 140689526667136 learning.py:507] global step 3021: loss = 0.4242 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 3022: loss = 0.0450 (0.397 sec/step)\n",
            "I0205 13:38:41.763567 140689526667136 learning.py:507] global step 3022: loss = 0.0450 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 3023: loss = 0.1172 (0.384 sec/step)\n",
            "I0205 13:38:42.148923 140689526667136 learning.py:507] global step 3023: loss = 0.1172 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 3024: loss = 0.3872 (0.373 sec/step)\n",
            "I0205 13:38:42.523951 140689526667136 learning.py:507] global step 3024: loss = 0.3872 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 3025: loss = 0.2135 (0.377 sec/step)\n",
            "I0205 13:38:42.902941 140689526667136 learning.py:507] global step 3025: loss = 0.2135 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 3026: loss = 0.1219 (0.392 sec/step)\n",
            "I0205 13:38:43.296712 140689526667136 learning.py:507] global step 3026: loss = 0.1219 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 3027: loss = 0.1412 (0.380 sec/step)\n",
            "I0205 13:38:43.678521 140689526667136 learning.py:507] global step 3027: loss = 0.1412 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 3028: loss = 0.1826 (0.385 sec/step)\n",
            "I0205 13:38:44.065537 140689526667136 learning.py:507] global step 3028: loss = 0.1826 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3029: loss = 0.1064 (0.352 sec/step)\n",
            "I0205 13:38:44.418970 140689526667136 learning.py:507] global step 3029: loss = 0.1064 (0.352 sec/step)\n",
            "INFO:tensorflow:global step 3030: loss = 0.1834 (0.358 sec/step)\n",
            "I0205 13:38:44.778443 140689526667136 learning.py:507] global step 3030: loss = 0.1834 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 3031: loss = 0.2345 (0.369 sec/step)\n",
            "I0205 13:38:45.148702 140689526667136 learning.py:507] global step 3031: loss = 0.2345 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 3032: loss = 0.1751 (0.365 sec/step)\n",
            "I0205 13:38:45.515552 140689526667136 learning.py:507] global step 3032: loss = 0.1751 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 3033: loss = 0.1442 (0.368 sec/step)\n",
            "I0205 13:38:45.884800 140689526667136 learning.py:507] global step 3033: loss = 0.1442 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 3034: loss = 0.2907 (0.394 sec/step)\n",
            "I0205 13:38:46.280651 140689526667136 learning.py:507] global step 3034: loss = 0.2907 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 3035: loss = 0.0893 (0.367 sec/step)\n",
            "I0205 13:38:46.649766 140689526667136 learning.py:507] global step 3035: loss = 0.0893 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 3036: loss = 0.0492 (0.391 sec/step)\n",
            "I0205 13:38:47.042587 140689526667136 learning.py:507] global step 3036: loss = 0.0492 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 3037: loss = 0.2561 (0.369 sec/step)\n",
            "I0205 13:38:47.413339 140689526667136 learning.py:507] global step 3037: loss = 0.2561 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 3038: loss = 0.0664 (0.384 sec/step)\n",
            "I0205 13:38:47.798847 140689526667136 learning.py:507] global step 3038: loss = 0.0664 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 3039: loss = 0.0577 (0.413 sec/step)\n",
            "I0205 13:38:48.213092 140689526667136 learning.py:507] global step 3039: loss = 0.0577 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 3040: loss = 0.5963 (0.370 sec/step)\n",
            "I0205 13:38:48.586816 140689526667136 learning.py:507] global step 3040: loss = 0.5963 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 3041: loss = 0.2014 (0.417 sec/step)\n",
            "I0205 13:38:49.005064 140689526667136 learning.py:507] global step 3041: loss = 0.2014 (0.417 sec/step)\n",
            "INFO:tensorflow:global step 3042: loss = 0.5078 (0.366 sec/step)\n",
            "I0205 13:38:49.373297 140689526667136 learning.py:507] global step 3042: loss = 0.5078 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 3043: loss = 0.2094 (0.385 sec/step)\n",
            "I0205 13:38:49.759662 140689526667136 learning.py:507] global step 3043: loss = 0.2094 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3044: loss = 0.2057 (0.390 sec/step)\n",
            "I0205 13:38:50.151622 140689526667136 learning.py:507] global step 3044: loss = 0.2057 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3045: loss = 0.0998 (0.383 sec/step)\n",
            "I0205 13:38:50.536967 140689526667136 learning.py:507] global step 3045: loss = 0.0998 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 3046: loss = 0.2007 (0.358 sec/step)\n",
            "I0205 13:38:50.896716 140689526667136 learning.py:507] global step 3046: loss = 0.2007 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 3047: loss = 0.0666 (0.379 sec/step)\n",
            "I0205 13:38:51.277117 140689526667136 learning.py:507] global step 3047: loss = 0.0666 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 3048: loss = 0.3027 (0.369 sec/step)\n",
            "I0205 13:38:51.647727 140689526667136 learning.py:507] global step 3048: loss = 0.3027 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 3049: loss = 0.1628 (0.390 sec/step)\n",
            "I0205 13:38:52.039181 140689526667136 learning.py:507] global step 3049: loss = 0.1628 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3050: loss = 0.0983 (0.399 sec/step)\n",
            "I0205 13:38:52.440268 140689526667136 learning.py:507] global step 3050: loss = 0.0983 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 3051: loss = 0.0599 (0.401 sec/step)\n",
            "I0205 13:38:52.843452 140689526667136 learning.py:507] global step 3051: loss = 0.0599 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 3052: loss = 0.5023 (0.390 sec/step)\n",
            "I0205 13:38:53.235644 140689526667136 learning.py:507] global step 3052: loss = 0.5023 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3053: loss = 0.3307 (0.393 sec/step)\n",
            "I0205 13:38:53.630573 140689526667136 learning.py:507] global step 3053: loss = 0.3307 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 3054: loss = 0.5629 (0.360 sec/step)\n",
            "I0205 13:38:53.991786 140689526667136 learning.py:507] global step 3054: loss = 0.5629 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 3055: loss = 0.1285 (0.382 sec/step)\n",
            "I0205 13:38:54.375387 140689526667136 learning.py:507] global step 3055: loss = 0.1285 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 3056: loss = 0.0587 (0.378 sec/step)\n",
            "I0205 13:38:54.754548 140689526667136 learning.py:507] global step 3056: loss = 0.0587 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 3057: loss = 0.0468 (0.385 sec/step)\n",
            "I0205 13:38:55.141072 140689526667136 learning.py:507] global step 3057: loss = 0.0468 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3058: loss = 0.1999 (0.387 sec/step)\n",
            "I0205 13:38:55.529219 140689526667136 learning.py:507] global step 3058: loss = 0.1999 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 3059: loss = 0.4078 (0.378 sec/step)\n",
            "I0205 13:38:55.908565 140689526667136 learning.py:507] global step 3059: loss = 0.4078 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 3060: loss = 0.3042 (0.364 sec/step)\n",
            "I0205 13:38:56.274755 140689526667136 learning.py:507] global step 3060: loss = 0.3042 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 3061: loss = 0.0648 (0.383 sec/step)\n",
            "I0205 13:38:56.661415 140689526667136 learning.py:507] global step 3061: loss = 0.0648 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 3062: loss = 0.2430 (0.382 sec/step)\n",
            "I0205 13:38:57.045152 140689526667136 learning.py:507] global step 3062: loss = 0.2430 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 3063: loss = 0.2975 (0.334 sec/step)\n",
            "I0205 13:38:57.380452 140689526667136 learning.py:507] global step 3063: loss = 0.2975 (0.334 sec/step)\n",
            "INFO:tensorflow:global step 3064: loss = 0.0757 (1.061 sec/step)\n",
            "I0205 13:38:58.442610 140689526667136 learning.py:507] global step 3064: loss = 0.0757 (1.061 sec/step)\n",
            "INFO:tensorflow:global step 3065: loss = 0.3128 (0.388 sec/step)\n",
            "I0205 13:38:58.832004 140689526667136 learning.py:507] global step 3065: loss = 0.3128 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 3066: loss = 0.6139 (0.401 sec/step)\n",
            "I0205 13:38:59.234181 140689526667136 learning.py:507] global step 3066: loss = 0.6139 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 3067: loss = 0.6154 (0.376 sec/step)\n",
            "I0205 13:38:59.611422 140689526667136 learning.py:507] global step 3067: loss = 0.6154 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 3068: loss = 0.0589 (0.384 sec/step)\n",
            "I0205 13:38:59.997248 140689526667136 learning.py:507] global step 3068: loss = 0.0589 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 3069: loss = 0.5135 (0.388 sec/step)\n",
            "I0205 13:39:00.387150 140689526667136 learning.py:507] global step 3069: loss = 0.5135 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 3070: loss = 0.0733 (0.386 sec/step)\n",
            "I0205 13:39:00.775378 140689526667136 learning.py:507] global step 3070: loss = 0.0733 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 3071: loss = 0.0296 (0.373 sec/step)\n",
            "I0205 13:39:01.150220 140689526667136 learning.py:507] global step 3071: loss = 0.0296 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 3072: loss = 1.4133 (0.370 sec/step)\n",
            "I0205 13:39:01.521985 140689526667136 learning.py:507] global step 3072: loss = 1.4133 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 3073: loss = 0.2319 (0.403 sec/step)\n",
            "I0205 13:39:01.926673 140689526667136 learning.py:507] global step 3073: loss = 0.2319 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 3074: loss = 0.1181 (0.359 sec/step)\n",
            "I0205 13:39:02.287795 140689526667136 learning.py:507] global step 3074: loss = 0.1181 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 3075: loss = 0.0695 (0.377 sec/step)\n",
            "I0205 13:39:02.666338 140689526667136 learning.py:507] global step 3075: loss = 0.0695 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 3076: loss = 0.2624 (0.406 sec/step)\n",
            "I0205 13:39:03.076133 140689526667136 learning.py:507] global step 3076: loss = 0.2624 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 3077: loss = 0.2930 (0.371 sec/step)\n",
            "I0205 13:39:03.448984 140689526667136 learning.py:507] global step 3077: loss = 0.2930 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 3078: loss = 0.0836 (0.380 sec/step)\n",
            "I0205 13:39:03.831017 140689526667136 learning.py:507] global step 3078: loss = 0.0836 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 3079: loss = 0.2199 (0.375 sec/step)\n",
            "I0205 13:39:04.207659 140689526667136 learning.py:507] global step 3079: loss = 0.2199 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 3080: loss = 0.1882 (0.342 sec/step)\n",
            "I0205 13:39:04.550843 140689526667136 learning.py:507] global step 3080: loss = 0.1882 (0.342 sec/step)\n",
            "INFO:tensorflow:global step 3081: loss = 0.1208 (0.363 sec/step)\n",
            "I0205 13:39:04.915968 140689526667136 learning.py:507] global step 3081: loss = 0.1208 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 3082: loss = 0.4642 (0.367 sec/step)\n",
            "I0205 13:39:05.284714 140689526667136 learning.py:507] global step 3082: loss = 0.4642 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 3083: loss = 0.1351 (0.378 sec/step)\n",
            "I0205 13:39:05.664599 140689526667136 learning.py:507] global step 3083: loss = 0.1351 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 3084: loss = 0.0679 (0.391 sec/step)\n",
            "I0205 13:39:06.057379 140689526667136 learning.py:507] global step 3084: loss = 0.0679 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 3085: loss = 0.2308 (0.375 sec/step)\n",
            "I0205 13:39:06.434000 140689526667136 learning.py:507] global step 3085: loss = 0.2308 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 3086: loss = 0.1448 (0.380 sec/step)\n",
            "I0205 13:39:06.815835 140689526667136 learning.py:507] global step 3086: loss = 0.1448 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 3087: loss = 0.2532 (0.370 sec/step)\n",
            "I0205 13:39:07.187887 140689526667136 learning.py:507] global step 3087: loss = 0.2532 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 3088: loss = 0.1381 (0.388 sec/step)\n",
            "I0205 13:39:07.578015 140689526667136 learning.py:507] global step 3088: loss = 0.1381 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 3089: loss = 0.0992 (0.383 sec/step)\n",
            "I0205 13:39:07.962393 140689526667136 learning.py:507] global step 3089: loss = 0.0992 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 3090: loss = 0.2761 (0.376 sec/step)\n",
            "I0205 13:39:08.339737 140689526667136 learning.py:507] global step 3090: loss = 0.2761 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 3091: loss = 0.3438 (0.371 sec/step)\n",
            "I0205 13:39:08.712820 140689526667136 learning.py:507] global step 3091: loss = 0.3438 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 3092: loss = 0.1480 (0.389 sec/step)\n",
            "I0205 13:39:09.103359 140689526667136 learning.py:507] global step 3092: loss = 0.1480 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 3093: loss = 0.2247 (0.384 sec/step)\n",
            "I0205 13:39:09.488999 140689526667136 learning.py:507] global step 3093: loss = 0.2247 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 3094: loss = 0.3508 (0.382 sec/step)\n",
            "I0205 13:39:09.872600 140689526667136 learning.py:507] global step 3094: loss = 0.3508 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 3095: loss = 0.0969 (0.387 sec/step)\n",
            "I0205 13:39:10.261471 140689526667136 learning.py:507] global step 3095: loss = 0.0969 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 3096: loss = 0.0556 (0.380 sec/step)\n",
            "I0205 13:39:10.643797 140689526667136 learning.py:507] global step 3096: loss = 0.0556 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 3097: loss = 0.3178 (0.361 sec/step)\n",
            "I0205 13:39:11.007239 140689526667136 learning.py:507] global step 3097: loss = 0.3178 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 3098: loss = 0.2759 (0.377 sec/step)\n",
            "I0205 13:39:11.385878 140689526667136 learning.py:507] global step 3098: loss = 0.2759 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 3099: loss = 0.1140 (0.359 sec/step)\n",
            "I0205 13:39:11.746466 140689526667136 learning.py:507] global step 3099: loss = 0.1140 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 3100: loss = 0.1105 (0.369 sec/step)\n",
            "I0205 13:39:12.117422 140689526667136 learning.py:507] global step 3100: loss = 0.1105 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 3101: loss = 0.0336 (0.384 sec/step)\n",
            "I0205 13:39:12.503056 140689526667136 learning.py:507] global step 3101: loss = 0.0336 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 3102: loss = 0.0894 (0.385 sec/step)\n",
            "I0205 13:39:12.889916 140689526667136 learning.py:507] global step 3102: loss = 0.0894 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3103: loss = 0.1261 (0.429 sec/step)\n",
            "I0205 13:39:13.320790 140689526667136 learning.py:507] global step 3103: loss = 0.1261 (0.429 sec/step)\n",
            "INFO:tensorflow:global step 3104: loss = 0.3055 (0.378 sec/step)\n",
            "I0205 13:39:13.700899 140689526667136 learning.py:507] global step 3104: loss = 0.3055 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 3105: loss = 0.1417 (0.385 sec/step)\n",
            "I0205 13:39:14.088981 140689526667136 learning.py:507] global step 3105: loss = 0.1417 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3106: loss = 0.2314 (0.396 sec/step)\n",
            "I0205 13:39:14.488266 140689526667136 learning.py:507] global step 3106: loss = 0.2314 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 3107: loss = 0.1320 (0.380 sec/step)\n",
            "I0205 13:39:14.870303 140689526667136 learning.py:507] global step 3107: loss = 0.1320 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 3108: loss = 0.2087 (0.365 sec/step)\n",
            "I0205 13:39:15.237870 140689526667136 learning.py:507] global step 3108: loss = 0.2087 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 3109: loss = 0.0874 (0.361 sec/step)\n",
            "I0205 13:39:15.600124 140689526667136 learning.py:507] global step 3109: loss = 0.0874 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 3110: loss = 0.0430 (0.348 sec/step)\n",
            "I0205 13:39:15.949928 140689526667136 learning.py:507] global step 3110: loss = 0.0430 (0.348 sec/step)\n",
            "INFO:tensorflow:global step 3111: loss = 0.1901 (0.387 sec/step)\n",
            "I0205 13:39:16.338188 140689526667136 learning.py:507] global step 3111: loss = 0.1901 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 3112: loss = 0.1781 (0.392 sec/step)\n",
            "I0205 13:39:16.731827 140689526667136 learning.py:507] global step 3112: loss = 0.1781 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 3113: loss = 0.1231 (0.383 sec/step)\n",
            "I0205 13:39:17.115982 140689526667136 learning.py:507] global step 3113: loss = 0.1231 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 3114: loss = 0.5151 (0.372 sec/step)\n",
            "I0205 13:39:17.489147 140689526667136 learning.py:507] global step 3114: loss = 0.5151 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 3115: loss = 0.0982 (0.355 sec/step)\n",
            "I0205 13:39:17.845988 140689526667136 learning.py:507] global step 3115: loss = 0.0982 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 3116: loss = 0.1338 (0.360 sec/step)\n",
            "I0205 13:39:18.207265 140689526667136 learning.py:507] global step 3116: loss = 0.1338 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 3117: loss = 0.3222 (0.391 sec/step)\n",
            "I0205 13:39:18.599680 140689526667136 learning.py:507] global step 3117: loss = 0.3222 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 3118: loss = 0.0280 (0.369 sec/step)\n",
            "I0205 13:39:18.970454 140689526667136 learning.py:507] global step 3118: loss = 0.0280 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 3119: loss = 0.1812 (0.403 sec/step)\n",
            "I0205 13:39:19.374846 140689526667136 learning.py:507] global step 3119: loss = 0.1812 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 3120: loss = 0.1131 (0.374 sec/step)\n",
            "I0205 13:39:19.750378 140689526667136 learning.py:507] global step 3120: loss = 0.1131 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 3121: loss = 0.4471 (0.375 sec/step)\n",
            "I0205 13:39:20.128813 140689526667136 learning.py:507] global step 3121: loss = 0.4471 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 3122: loss = 0.1206 (0.350 sec/step)\n",
            "I0205 13:39:20.480004 140689526667136 learning.py:507] global step 3122: loss = 0.1206 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 3123: loss = 0.2971 (0.394 sec/step)\n",
            "I0205 13:39:20.875745 140689526667136 learning.py:507] global step 3123: loss = 0.2971 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 3124: loss = 0.4946 (0.403 sec/step)\n",
            "I0205 13:39:21.282441 140689526667136 learning.py:507] global step 3124: loss = 0.4946 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 3125: loss = 0.2692 (0.366 sec/step)\n",
            "I0205 13:39:21.652035 140689526667136 learning.py:507] global step 3125: loss = 0.2692 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 3126: loss = 0.0967 (0.373 sec/step)\n",
            "I0205 13:39:22.026636 140689526667136 learning.py:507] global step 3126: loss = 0.0967 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 3127: loss = 0.1265 (0.374 sec/step)\n",
            "I0205 13:39:22.402293 140689526667136 learning.py:507] global step 3127: loss = 0.1265 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 3128: loss = 0.0988 (0.366 sec/step)\n",
            "I0205 13:39:22.770051 140689526667136 learning.py:507] global step 3128: loss = 0.0988 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 3129: loss = 0.0799 (0.397 sec/step)\n",
            "I0205 13:39:23.169190 140689526667136 learning.py:507] global step 3129: loss = 0.0799 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 3130: loss = 0.0357 (0.426 sec/step)\n",
            "I0205 13:39:23.596151 140689526667136 learning.py:507] global step 3130: loss = 0.0357 (0.426 sec/step)\n",
            "INFO:tensorflow:global step 3131: loss = 0.1829 (0.379 sec/step)\n",
            "I0205 13:39:23.976312 140689526667136 learning.py:507] global step 3131: loss = 0.1829 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 3132: loss = 0.1316 (0.399 sec/step)\n",
            "I0205 13:39:24.377338 140689526667136 learning.py:507] global step 3132: loss = 0.1316 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 3133: loss = 0.2566 (0.353 sec/step)\n",
            "I0205 13:39:24.731584 140689526667136 learning.py:507] global step 3133: loss = 0.2566 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 3134: loss = 0.0481 (0.379 sec/step)\n",
            "I0205 13:39:25.112218 140689526667136 learning.py:507] global step 3134: loss = 0.0481 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 3135: loss = 0.0998 (0.393 sec/step)\n",
            "I0205 13:39:25.506922 140689526667136 learning.py:507] global step 3135: loss = 0.0998 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 3136: loss = 0.0498 (0.378 sec/step)\n",
            "I0205 13:39:25.886895 140689526667136 learning.py:507] global step 3136: loss = 0.0498 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 3137: loss = 0.1068 (0.355 sec/step)\n",
            "I0205 13:39:26.243760 140689526667136 learning.py:507] global step 3137: loss = 0.1068 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 3138: loss = 0.0728 (0.395 sec/step)\n",
            "I0205 13:39:26.640665 140689526667136 learning.py:507] global step 3138: loss = 0.0728 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 3139: loss = 0.1475 (0.362 sec/step)\n",
            "I0205 13:39:27.004250 140689526667136 learning.py:507] global step 3139: loss = 0.1475 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 3140: loss = 0.0172 (0.362 sec/step)\n",
            "I0205 13:39:27.368027 140689526667136 learning.py:507] global step 3140: loss = 0.0172 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 3141: loss = 0.1435 (0.362 sec/step)\n",
            "I0205 13:39:27.731832 140689526667136 learning.py:507] global step 3141: loss = 0.1435 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 3142: loss = 0.2852 (0.394 sec/step)\n",
            "I0205 13:39:28.126989 140689526667136 learning.py:507] global step 3142: loss = 0.2852 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 3143: loss = 0.0528 (0.366 sec/step)\n",
            "I0205 13:39:28.494486 140689526667136 learning.py:507] global step 3143: loss = 0.0528 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 3144: loss = 0.0399 (0.409 sec/step)\n",
            "I0205 13:39:28.904837 140689526667136 learning.py:507] global step 3144: loss = 0.0399 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 3145: loss = 0.2501 (0.384 sec/step)\n",
            "I0205 13:39:29.290111 140689526667136 learning.py:507] global step 3145: loss = 0.2501 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 3146: loss = 0.1256 (0.442 sec/step)\n",
            "I0205 13:39:29.734098 140689526667136 learning.py:507] global step 3146: loss = 0.1256 (0.442 sec/step)\n",
            "INFO:tensorflow:global step 3147: loss = 0.1483 (0.389 sec/step)\n",
            "I0205 13:39:30.125263 140689526667136 learning.py:507] global step 3147: loss = 0.1483 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 3148: loss = 0.4296 (0.385 sec/step)\n",
            "I0205 13:39:30.512551 140689526667136 learning.py:507] global step 3148: loss = 0.4296 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3149: loss = 0.6173 (0.397 sec/step)\n",
            "I0205 13:39:30.910999 140689526667136 learning.py:507] global step 3149: loss = 0.6173 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 3150: loss = 0.1958 (0.372 sec/step)\n",
            "I0205 13:39:31.284468 140689526667136 learning.py:507] global step 3150: loss = 0.1958 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 3151: loss = 0.3711 (0.376 sec/step)\n",
            "I0205 13:39:31.662066 140689526667136 learning.py:507] global step 3151: loss = 0.3711 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 3152: loss = 0.0747 (0.353 sec/step)\n",
            "I0205 13:39:32.016978 140689526667136 learning.py:507] global step 3152: loss = 0.0747 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 3153: loss = 0.0588 (0.358 sec/step)\n",
            "I0205 13:39:32.377122 140689526667136 learning.py:507] global step 3153: loss = 0.0588 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 3154: loss = 0.1276 (0.357 sec/step)\n",
            "I0205 13:39:32.735699 140689526667136 learning.py:507] global step 3154: loss = 0.1276 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 3155: loss = 0.0546 (0.405 sec/step)\n",
            "I0205 13:39:33.142823 140689526667136 learning.py:507] global step 3155: loss = 0.0546 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 3156: loss = 0.4515 (0.365 sec/step)\n",
            "I0205 13:39:33.509672 140689526667136 learning.py:507] global step 3156: loss = 0.4515 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 3157: loss = 0.0521 (0.378 sec/step)\n",
            "I0205 13:39:33.889291 140689526667136 learning.py:507] global step 3157: loss = 0.0521 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 3158: loss = 0.0725 (0.376 sec/step)\n",
            "I0205 13:39:34.266771 140689526667136 learning.py:507] global step 3158: loss = 0.0725 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 3159: loss = 0.1400 (0.379 sec/step)\n",
            "I0205 13:39:34.646691 140689526667136 learning.py:507] global step 3159: loss = 0.1400 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 3160: loss = 0.1101 (0.353 sec/step)\n",
            "I0205 13:39:35.001198 140689526667136 learning.py:507] global step 3160: loss = 0.1101 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 3161: loss = 0.0965 (0.375 sec/step)\n",
            "I0205 13:39:35.378345 140689526667136 learning.py:507] global step 3161: loss = 0.0965 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 3162: loss = 0.6038 (0.394 sec/step)\n",
            "I0205 13:39:35.773624 140689526667136 learning.py:507] global step 3162: loss = 0.6038 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 3163: loss = 0.1517 (0.390 sec/step)\n",
            "I0205 13:39:36.165741 140689526667136 learning.py:507] global step 3163: loss = 0.1517 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3164: loss = 0.2292 (0.386 sec/step)\n",
            "I0205 13:39:36.553793 140689526667136 learning.py:507] global step 3164: loss = 0.2292 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 3165: loss = 0.1128 (0.372 sec/step)\n",
            "I0205 13:39:36.927615 140689526667136 learning.py:507] global step 3165: loss = 0.1128 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 3166: loss = 0.2216 (0.377 sec/step)\n",
            "I0205 13:39:37.306113 140689526667136 learning.py:507] global step 3166: loss = 0.2216 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 3167: loss = 0.0451 (0.402 sec/step)\n",
            "I0205 13:39:37.709786 140689526667136 learning.py:507] global step 3167: loss = 0.0451 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 3168: loss = 0.2851 (0.386 sec/step)\n",
            "I0205 13:39:38.097218 140689526667136 learning.py:507] global step 3168: loss = 0.2851 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 3169: loss = 0.0776 (0.360 sec/step)\n",
            "I0205 13:39:38.458216 140689526667136 learning.py:507] global step 3169: loss = 0.0776 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 3170: loss = 0.0962 (0.387 sec/step)\n",
            "I0205 13:39:38.847112 140689526667136 learning.py:507] global step 3170: loss = 0.0962 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 3171: loss = 0.2043 (0.384 sec/step)\n",
            "I0205 13:39:39.233318 140689526667136 learning.py:507] global step 3171: loss = 0.2043 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 3172: loss = 0.1175 (0.390 sec/step)\n",
            "I0205 13:39:39.625149 140689526667136 learning.py:507] global step 3172: loss = 0.1175 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3173: loss = 0.0514 (0.369 sec/step)\n",
            "I0205 13:39:39.995996 140689526667136 learning.py:507] global step 3173: loss = 0.0514 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 3174: loss = 0.0495 (0.388 sec/step)\n",
            "I0205 13:39:40.385230 140689526667136 learning.py:507] global step 3174: loss = 0.0495 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 3175: loss = 0.0827 (0.386 sec/step)\n",
            "I0205 13:39:40.773565 140689526667136 learning.py:507] global step 3175: loss = 0.0827 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 3176: loss = 0.7949 (0.461 sec/step)\n",
            "I0205 13:39:41.236239 140689526667136 learning.py:507] global step 3176: loss = 0.7949 (0.461 sec/step)\n",
            "INFO:tensorflow:global step 3177: loss = 0.2534 (0.379 sec/step)\n",
            "I0205 13:39:41.616831 140689526667136 learning.py:507] global step 3177: loss = 0.2534 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 3178: loss = 0.2531 (0.387 sec/step)\n",
            "I0205 13:39:42.005459 140689526667136 learning.py:507] global step 3178: loss = 0.2531 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 3179: loss = 0.1221 (0.399 sec/step)\n",
            "I0205 13:39:42.405377 140689526667136 learning.py:507] global step 3179: loss = 0.1221 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 3180: loss = 0.0994 (0.368 sec/step)\n",
            "I0205 13:39:42.775130 140689526667136 learning.py:507] global step 3180: loss = 0.0994 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 3181: loss = 0.1528 (0.404 sec/step)\n",
            "I0205 13:39:43.180383 140689526667136 learning.py:507] global step 3181: loss = 0.1528 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 3182: loss = 0.1181 (0.385 sec/step)\n",
            "I0205 13:39:43.566600 140689526667136 learning.py:507] global step 3182: loss = 0.1181 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3183: loss = 0.0794 (0.378 sec/step)\n",
            "I0205 13:39:43.946568 140689526667136 learning.py:507] global step 3183: loss = 0.0794 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 3184: loss = 0.1050 (0.383 sec/step)\n",
            "I0205 13:39:44.331408 140689526667136 learning.py:507] global step 3184: loss = 0.1050 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 3185: loss = 0.1055 (0.393 sec/step)\n",
            "I0205 13:39:44.726003 140689526667136 learning.py:507] global step 3185: loss = 0.1055 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 3186: loss = 0.2453 (0.379 sec/step)\n",
            "I0205 13:39:45.106367 140689526667136 learning.py:507] global step 3186: loss = 0.2453 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 3187: loss = 0.1262 (0.385 sec/step)\n",
            "I0205 13:39:45.493010 140689526667136 learning.py:507] global step 3187: loss = 0.1262 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3188: loss = 0.0651 (0.390 sec/step)\n",
            "I0205 13:39:45.885093 140689526667136 learning.py:507] global step 3188: loss = 0.0651 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3189: loss = 0.0915 (0.386 sec/step)\n",
            "I0205 13:39:46.272495 140689526667136 learning.py:507] global step 3189: loss = 0.0915 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 3190: loss = 0.5519 (0.380 sec/step)\n",
            "I0205 13:39:46.654608 140689526667136 learning.py:507] global step 3190: loss = 0.5519 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 3191: loss = 0.1738 (0.411 sec/step)\n",
            "I0205 13:39:47.067343 140689526667136 learning.py:507] global step 3191: loss = 0.1738 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 3192: loss = 0.0664 (0.364 sec/step)\n",
            "I0205 13:39:47.432995 140689526667136 learning.py:507] global step 3192: loss = 0.0664 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 3193: loss = 0.4359 (0.371 sec/step)\n",
            "I0205 13:39:47.805931 140689526667136 learning.py:507] global step 3193: loss = 0.4359 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 3194: loss = 0.1164 (0.379 sec/step)\n",
            "I0205 13:39:48.186053 140689526667136 learning.py:507] global step 3194: loss = 0.1164 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 3195: loss = 0.2149 (0.380 sec/step)\n",
            "I0205 13:39:48.567532 140689526667136 learning.py:507] global step 3195: loss = 0.2149 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 3196: loss = 0.1188 (0.415 sec/step)\n",
            "I0205 13:39:48.985425 140689526667136 learning.py:507] global step 3196: loss = 0.1188 (0.415 sec/step)\n",
            "INFO:tensorflow:global step 3197: loss = 0.0376 (0.406 sec/step)\n",
            "I0205 13:39:49.395532 140689526667136 learning.py:507] global step 3197: loss = 0.0376 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 3198: loss = 0.0618 (0.372 sec/step)\n",
            "I0205 13:39:49.769440 140689526667136 learning.py:507] global step 3198: loss = 0.0618 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 3199: loss = 0.3221 (0.393 sec/step)\n",
            "I0205 13:39:50.163897 140689526667136 learning.py:507] global step 3199: loss = 0.3221 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 3200: loss = 0.1042 (0.373 sec/step)\n",
            "I0205 13:39:50.538888 140689526667136 learning.py:507] global step 3200: loss = 0.1042 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 3201: loss = 0.1591 (0.383 sec/step)\n",
            "I0205 13:39:50.923856 140689526667136 learning.py:507] global step 3201: loss = 0.1591 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 3202: loss = 0.3927 (0.388 sec/step)\n",
            "I0205 13:39:51.312911 140689526667136 learning.py:507] global step 3202: loss = 0.3927 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 3203: loss = 0.0554 (0.392 sec/step)\n",
            "I0205 13:39:51.706948 140689526667136 learning.py:507] global step 3203: loss = 0.0554 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 3204: loss = 0.1366 (0.350 sec/step)\n",
            "I0205 13:39:52.058559 140689526667136 learning.py:507] global step 3204: loss = 0.1366 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 3205: loss = 0.0973 (0.414 sec/step)\n",
            "I0205 13:39:52.474836 140689526667136 learning.py:507] global step 3205: loss = 0.0973 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 3206: loss = 0.1677 (0.402 sec/step)\n",
            "I0205 13:39:52.878637 140689526667136 learning.py:507] global step 3206: loss = 0.1677 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 3207: loss = 0.6653 (0.394 sec/step)\n",
            "I0205 13:39:53.274032 140689526667136 learning.py:507] global step 3207: loss = 0.6653 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 3208: loss = 0.8502 (0.381 sec/step)\n",
            "I0205 13:39:53.656667 140689526667136 learning.py:507] global step 3208: loss = 0.8502 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 3209: loss = 0.0580 (0.369 sec/step)\n",
            "I0205 13:39:54.027036 140689526667136 learning.py:507] global step 3209: loss = 0.0580 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 3210: loss = 0.2309 (0.387 sec/step)\n",
            "I0205 13:39:54.415512 140689526667136 learning.py:507] global step 3210: loss = 0.2309 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 3211: loss = 1.0254 (0.390 sec/step)\n",
            "I0205 13:39:54.807879 140689526667136 learning.py:507] global step 3211: loss = 1.0254 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3212: loss = 0.2835 (0.379 sec/step)\n",
            "I0205 13:39:55.188318 140689526667136 learning.py:507] global step 3212: loss = 0.2835 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 3213: loss = 0.2401 (0.360 sec/step)\n",
            "I0205 13:39:55.549475 140689526667136 learning.py:507] global step 3213: loss = 0.2401 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 3214: loss = 0.0639 (0.391 sec/step)\n",
            "I0205 13:39:55.941501 140689526667136 learning.py:507] global step 3214: loss = 0.0639 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 3215: loss = 0.0947 (0.388 sec/step)\n",
            "I0205 13:39:56.330967 140689526667136 learning.py:507] global step 3215: loss = 0.0947 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 3216: loss = 0.2141 (0.398 sec/step)\n",
            "I0205 13:39:56.730598 140689526667136 learning.py:507] global step 3216: loss = 0.2141 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 3217: loss = 0.0652 (0.362 sec/step)\n",
            "I0205 13:39:57.094010 140689526667136 learning.py:507] global step 3217: loss = 0.0652 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 3218: loss = 0.5836 (0.385 sec/step)\n",
            "I0205 13:39:57.480573 140689526667136 learning.py:507] global step 3218: loss = 0.5836 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3219: loss = 0.0807 (0.370 sec/step)\n",
            "I0205 13:39:57.852698 140689526667136 learning.py:507] global step 3219: loss = 0.0807 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 3220: loss = 0.2471 (1.091 sec/step)\n",
            "I0205 13:39:58.944899 140689526667136 learning.py:507] global step 3220: loss = 0.2471 (1.091 sec/step)\n",
            "INFO:tensorflow:global step 3221: loss = 0.0774 (0.389 sec/step)\n",
            "I0205 13:39:59.335803 140689526667136 learning.py:507] global step 3221: loss = 0.0774 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 3222: loss = 0.1685 (0.397 sec/step)\n",
            "I0205 13:39:59.734368 140689526667136 learning.py:507] global step 3222: loss = 0.1685 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 3223: loss = 0.1028 (0.375 sec/step)\n",
            "I0205 13:40:00.111552 140689526667136 learning.py:507] global step 3223: loss = 0.1028 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 3224: loss = 0.0833 (0.378 sec/step)\n",
            "I0205 13:40:00.491084 140689526667136 learning.py:507] global step 3224: loss = 0.0833 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 3225: loss = 0.1316 (0.387 sec/step)\n",
            "I0205 13:40:00.879879 140689526667136 learning.py:507] global step 3225: loss = 0.1316 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 3226: loss = 0.0671 (0.410 sec/step)\n",
            "I0205 13:40:01.291576 140689526667136 learning.py:507] global step 3226: loss = 0.0671 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 3227: loss = 0.5158 (0.392 sec/step)\n",
            "I0205 13:40:01.685254 140689526667136 learning.py:507] global step 3227: loss = 0.5158 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 3228: loss = 0.1359 (0.421 sec/step)\n",
            "I0205 13:40:02.108728 140689526667136 learning.py:507] global step 3228: loss = 0.1359 (0.421 sec/step)\n",
            "INFO:tensorflow:global step 3229: loss = 0.1459 (0.394 sec/step)\n",
            "I0205 13:40:02.505916 140689526667136 learning.py:507] global step 3229: loss = 0.1459 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 3230: loss = 0.2307 (0.398 sec/step)\n",
            "I0205 13:40:02.905934 140689526667136 learning.py:507] global step 3230: loss = 0.2307 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 3231: loss = 0.1354 (0.426 sec/step)\n",
            "I0205 13:40:03.334316 140689526667136 learning.py:507] global step 3231: loss = 0.1354 (0.426 sec/step)\n",
            "INFO:tensorflow:global step 3232: loss = 0.1525 (0.424 sec/step)\n",
            "I0205 13:40:03.759884 140689526667136 learning.py:507] global step 3232: loss = 0.1525 (0.424 sec/step)\n",
            "INFO:tensorflow:global step 3233: loss = 0.1062 (0.393 sec/step)\n",
            "I0205 13:40:04.154614 140689526667136 learning.py:507] global step 3233: loss = 0.1062 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 3234: loss = 0.3501 (0.408 sec/step)\n",
            "I0205 13:40:04.564512 140689526667136 learning.py:507] global step 3234: loss = 0.3501 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 3235: loss = 0.3432 (0.386 sec/step)\n",
            "I0205 13:40:04.952021 140689526667136 learning.py:507] global step 3235: loss = 0.3432 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 3236: loss = 0.0967 (0.372 sec/step)\n",
            "I0205 13:40:05.325129 140689526667136 learning.py:507] global step 3236: loss = 0.0967 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 3237: loss = 0.1017 (0.388 sec/step)\n",
            "I0205 13:40:05.715296 140689526667136 learning.py:507] global step 3237: loss = 0.1017 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 3238: loss = 0.2211 (0.392 sec/step)\n",
            "I0205 13:40:06.109202 140689526667136 learning.py:507] global step 3238: loss = 0.2211 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 3239: loss = 0.0684 (0.399 sec/step)\n",
            "I0205 13:40:06.509935 140689526667136 learning.py:507] global step 3239: loss = 0.0684 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 3240: loss = 0.2309 (0.367 sec/step)\n",
            "I0205 13:40:06.879089 140689526667136 learning.py:507] global step 3240: loss = 0.2309 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 3241: loss = 0.0914 (0.351 sec/step)\n",
            "I0205 13:40:07.232104 140689526667136 learning.py:507] global step 3241: loss = 0.0914 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 3242: loss = 0.1639 (0.384 sec/step)\n",
            "I0205 13:40:07.617690 140689526667136 learning.py:507] global step 3242: loss = 0.1639 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 3243: loss = 0.3615 (0.387 sec/step)\n",
            "I0205 13:40:08.006176 140689526667136 learning.py:507] global step 3243: loss = 0.3615 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 3244: loss = 0.0749 (0.387 sec/step)\n",
            "I0205 13:40:08.394469 140689526667136 learning.py:507] global step 3244: loss = 0.0749 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 3245: loss = 0.1755 (2.330 sec/step)\n",
            "I0205 13:40:10.726258 140689526667136 learning.py:507] global step 3245: loss = 0.1755 (2.330 sec/step)\n",
            "INFO:tensorflow:global step 3246: loss = 0.1546 (0.390 sec/step)\n",
            "I0205 13:40:11.117459 140689526667136 learning.py:507] global step 3246: loss = 0.1546 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3247: loss = 0.1919 (0.388 sec/step)\n",
            "I0205 13:40:11.506756 140689526667136 learning.py:507] global step 3247: loss = 0.1919 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 3248: loss = 0.0922 (0.391 sec/step)\n",
            "I0205 13:40:11.899499 140689526667136 learning.py:507] global step 3248: loss = 0.0922 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 3249: loss = 0.1140 (0.397 sec/step)\n",
            "I0205 13:40:12.298149 140689526667136 learning.py:507] global step 3249: loss = 0.1140 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 3250: loss = 0.1295 (0.424 sec/step)\n",
            "I0205 13:40:12.724024 140689526667136 learning.py:507] global step 3250: loss = 0.1295 (0.424 sec/step)\n",
            "INFO:tensorflow:global step 3251: loss = 0.5836 (0.423 sec/step)\n",
            "I0205 13:40:13.149200 140689526667136 learning.py:507] global step 3251: loss = 0.5836 (0.423 sec/step)\n",
            "INFO:tensorflow:global step 3252: loss = 0.3418 (0.382 sec/step)\n",
            "I0205 13:40:13.533071 140689526667136 learning.py:507] global step 3252: loss = 0.3418 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 3253: loss = 1.0940 (0.582 sec/step)\n",
            "I0205 13:40:14.137374 140689526667136 learning.py:507] global step 3253: loss = 1.0940 (0.582 sec/step)\n",
            "INFO:tensorflow:global step 3254: loss = 0.0623 (1.043 sec/step)\n",
            "I0205 13:40:15.321560 140689526667136 learning.py:507] global step 3254: loss = 0.0623 (1.043 sec/step)\n",
            "INFO:tensorflow:global step 3255: loss = 0.1389 (0.697 sec/step)\n",
            "I0205 13:40:16.164252 140689526667136 learning.py:507] global step 3255: loss = 0.1389 (0.697 sec/step)\n",
            "INFO:tensorflow:global step 3256: loss = 0.2421 (0.553 sec/step)\n",
            "I0205 13:40:16.834862 140689526667136 learning.py:507] global step 3256: loss = 0.2421 (0.553 sec/step)\n",
            "INFO:tensorflow:global step 3257: loss = 0.0974 (0.570 sec/step)\n",
            "I0205 13:40:17.428921 140689526667136 learning.py:507] global step 3257: loss = 0.0974 (0.570 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 3257.\n",
            "I0205 13:40:17.438207 140686026073856 supervisor.py:1050] Recording summary at step 3257.\n",
            "INFO:tensorflow:global step 3258: loss = 0.1663 (0.399 sec/step)\n",
            "I0205 13:40:17.830354 140689526667136 learning.py:507] global step 3258: loss = 0.1663 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 3259: loss = 0.0724 (1.095 sec/step)\n",
            "I0205 13:40:18.926787 140689526667136 learning.py:507] global step 3259: loss = 0.0724 (1.095 sec/step)\n",
            "INFO:tensorflow:global step 3260: loss = 0.1061 (0.405 sec/step)\n",
            "I0205 13:40:19.333858 140689526667136 learning.py:507] global step 3260: loss = 0.1061 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 3261: loss = 0.0925 (0.385 sec/step)\n",
            "I0205 13:40:19.720762 140689526667136 learning.py:507] global step 3261: loss = 0.0925 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3262: loss = 0.1613 (0.388 sec/step)\n",
            "I0205 13:40:20.111401 140689526667136 learning.py:507] global step 3262: loss = 0.1613 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 3263: loss = 0.0446 (0.382 sec/step)\n",
            "I0205 13:40:20.495038 140689526667136 learning.py:507] global step 3263: loss = 0.0446 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 3264: loss = 0.1297 (0.369 sec/step)\n",
            "I0205 13:40:20.866083 140689526667136 learning.py:507] global step 3264: loss = 0.1297 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 3265: loss = 0.1394 (0.388 sec/step)\n",
            "I0205 13:40:21.255470 140689526667136 learning.py:507] global step 3265: loss = 0.1394 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 3266: loss = 0.1223 (0.386 sec/step)\n",
            "I0205 13:40:21.642816 140689526667136 learning.py:507] global step 3266: loss = 0.1223 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 3267: loss = 0.1756 (0.394 sec/step)\n",
            "I0205 13:40:22.037695 140689526667136 learning.py:507] global step 3267: loss = 0.1756 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 3268: loss = 0.1105 (0.349 sec/step)\n",
            "I0205 13:40:22.388341 140689526667136 learning.py:507] global step 3268: loss = 0.1105 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 3269: loss = 0.1078 (0.382 sec/step)\n",
            "I0205 13:40:22.771946 140689526667136 learning.py:507] global step 3269: loss = 0.1078 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 3270: loss = 0.0619 (0.370 sec/step)\n",
            "I0205 13:40:23.143399 140689526667136 learning.py:507] global step 3270: loss = 0.0619 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 3271: loss = 0.1359 (0.400 sec/step)\n",
            "I0205 13:40:23.545187 140689526667136 learning.py:507] global step 3271: loss = 0.1359 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 3272: loss = 0.2604 (0.382 sec/step)\n",
            "I0205 13:40:23.929222 140689526667136 learning.py:507] global step 3272: loss = 0.2604 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 3273: loss = 0.1696 (0.384 sec/step)\n",
            "I0205 13:40:24.315192 140689526667136 learning.py:507] global step 3273: loss = 0.1696 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 3274: loss = 0.1237 (0.375 sec/step)\n",
            "I0205 13:40:24.691963 140689526667136 learning.py:507] global step 3274: loss = 0.1237 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 3275: loss = 0.6129 (0.384 sec/step)\n",
            "I0205 13:40:25.077769 140689526667136 learning.py:507] global step 3275: loss = 0.6129 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 3276: loss = 0.1003 (0.381 sec/step)\n",
            "I0205 13:40:25.460508 140689526667136 learning.py:507] global step 3276: loss = 0.1003 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 3277: loss = 0.2166 (0.378 sec/step)\n",
            "I0205 13:40:25.840140 140689526667136 learning.py:507] global step 3277: loss = 0.2166 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 3278: loss = 0.4518 (0.367 sec/step)\n",
            "I0205 13:40:26.208943 140689526667136 learning.py:507] global step 3278: loss = 0.4518 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 3279: loss = 0.1187 (0.390 sec/step)\n",
            "I0205 13:40:26.600904 140689526667136 learning.py:507] global step 3279: loss = 0.1187 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3280: loss = 1.0098 (0.364 sec/step)\n",
            "I0205 13:40:26.966816 140689526667136 learning.py:507] global step 3280: loss = 1.0098 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 3281: loss = 0.2894 (0.379 sec/step)\n",
            "I0205 13:40:27.347653 140689526667136 learning.py:507] global step 3281: loss = 0.2894 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 3282: loss = 0.1878 (0.386 sec/step)\n",
            "I0205 13:40:27.735448 140689526667136 learning.py:507] global step 3282: loss = 0.1878 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 3283: loss = 0.1130 (0.456 sec/step)\n",
            "I0205 13:40:28.192703 140689526667136 learning.py:507] global step 3283: loss = 0.1130 (0.456 sec/step)\n",
            "INFO:tensorflow:global step 3284: loss = 0.1074 (0.387 sec/step)\n",
            "I0205 13:40:28.581006 140689526667136 learning.py:507] global step 3284: loss = 0.1074 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 3285: loss = 0.2650 (0.383 sec/step)\n",
            "I0205 13:40:28.965878 140689526667136 learning.py:507] global step 3285: loss = 0.2650 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 3286: loss = 0.3558 (0.390 sec/step)\n",
            "I0205 13:40:29.357271 140689526667136 learning.py:507] global step 3286: loss = 0.3558 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3287: loss = 0.1171 (0.434 sec/step)\n",
            "I0205 13:40:29.793102 140689526667136 learning.py:507] global step 3287: loss = 0.1171 (0.434 sec/step)\n",
            "INFO:tensorflow:global step 3288: loss = 0.2700 (0.417 sec/step)\n",
            "I0205 13:40:30.211587 140689526667136 learning.py:507] global step 3288: loss = 0.2700 (0.417 sec/step)\n",
            "INFO:tensorflow:global step 3289: loss = 1.1759 (0.369 sec/step)\n",
            "I0205 13:40:30.582686 140689526667136 learning.py:507] global step 3289: loss = 1.1759 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 3290: loss = 0.3010 (0.420 sec/step)\n",
            "I0205 13:40:31.004678 140689526667136 learning.py:507] global step 3290: loss = 0.3010 (0.420 sec/step)\n",
            "INFO:tensorflow:global step 3291: loss = 0.0167 (0.431 sec/step)\n",
            "I0205 13:40:31.437616 140689526667136 learning.py:507] global step 3291: loss = 0.0167 (0.431 sec/step)\n",
            "INFO:tensorflow:global step 3292: loss = 0.1085 (0.447 sec/step)\n",
            "I0205 13:40:31.886025 140689526667136 learning.py:507] global step 3292: loss = 0.1085 (0.447 sec/step)\n",
            "INFO:tensorflow:global step 3293: loss = 0.2902 (0.377 sec/step)\n",
            "I0205 13:40:32.265387 140689526667136 learning.py:507] global step 3293: loss = 0.2902 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 3294: loss = 0.5375 (0.375 sec/step)\n",
            "I0205 13:40:32.642066 140689526667136 learning.py:507] global step 3294: loss = 0.5375 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 3295: loss = 0.0366 (0.411 sec/step)\n",
            "I0205 13:40:33.055524 140689526667136 learning.py:507] global step 3295: loss = 0.0366 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 3296: loss = 0.4587 (0.403 sec/step)\n",
            "I0205 13:40:33.462003 140689526667136 learning.py:507] global step 3296: loss = 0.4587 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 3297: loss = 0.1421 (0.387 sec/step)\n",
            "I0205 13:40:33.850865 140689526667136 learning.py:507] global step 3297: loss = 0.1421 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 3298: loss = 0.6757 (0.388 sec/step)\n",
            "I0205 13:40:34.240452 140689526667136 learning.py:507] global step 3298: loss = 0.6757 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 3299: loss = 0.2614 (0.384 sec/step)\n",
            "I0205 13:40:34.626400 140689526667136 learning.py:507] global step 3299: loss = 0.2614 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 3300: loss = 0.0565 (0.358 sec/step)\n",
            "I0205 13:40:34.986052 140689526667136 learning.py:507] global step 3300: loss = 0.0565 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 3301: loss = 0.1122 (0.403 sec/step)\n",
            "I0205 13:40:35.391267 140689526667136 learning.py:507] global step 3301: loss = 0.1122 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 3302: loss = 0.3354 (0.393 sec/step)\n",
            "I0205 13:40:35.785928 140689526667136 learning.py:507] global step 3302: loss = 0.3354 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 3303: loss = 0.2069 (0.384 sec/step)\n",
            "I0205 13:40:36.171828 140689526667136 learning.py:507] global step 3303: loss = 0.2069 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 3304: loss = 0.0991 (0.404 sec/step)\n",
            "I0205 13:40:36.576882 140689526667136 learning.py:507] global step 3304: loss = 0.0991 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 3305: loss = 0.2268 (0.437 sec/step)\n",
            "I0205 13:40:37.015872 140689526667136 learning.py:507] global step 3305: loss = 0.2268 (0.437 sec/step)\n",
            "INFO:tensorflow:global step 3306: loss = 0.2465 (0.397 sec/step)\n",
            "I0205 13:40:37.414607 140689526667136 learning.py:507] global step 3306: loss = 0.2465 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 3307: loss = 0.3098 (0.390 sec/step)\n",
            "I0205 13:40:37.806289 140689526667136 learning.py:507] global step 3307: loss = 0.3098 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3308: loss = 0.0997 (0.414 sec/step)\n",
            "I0205 13:40:38.221612 140689526667136 learning.py:507] global step 3308: loss = 0.0997 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 3309: loss = 0.0946 (0.400 sec/step)\n",
            "I0205 13:40:38.623490 140689526667136 learning.py:507] global step 3309: loss = 0.0946 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 3310: loss = 0.1594 (0.395 sec/step)\n",
            "I0205 13:40:39.020151 140689526667136 learning.py:507] global step 3310: loss = 0.1594 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 3311: loss = 0.0351 (0.387 sec/step)\n",
            "I0205 13:40:39.408848 140689526667136 learning.py:507] global step 3311: loss = 0.0351 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 3312: loss = 0.0665 (0.409 sec/step)\n",
            "I0205 13:40:39.820305 140689526667136 learning.py:507] global step 3312: loss = 0.0665 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 3313: loss = 0.1015 (0.415 sec/step)\n",
            "I0205 13:40:40.236771 140689526667136 learning.py:507] global step 3313: loss = 0.1015 (0.415 sec/step)\n",
            "INFO:tensorflow:global step 3314: loss = 0.0240 (0.431 sec/step)\n",
            "I0205 13:40:40.670191 140689526667136 learning.py:507] global step 3314: loss = 0.0240 (0.431 sec/step)\n",
            "INFO:tensorflow:global step 3315: loss = 0.1051 (0.394 sec/step)\n",
            "I0205 13:40:41.066358 140689526667136 learning.py:507] global step 3315: loss = 0.1051 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 3316: loss = 0.0551 (0.426 sec/step)\n",
            "I0205 13:40:41.493565 140689526667136 learning.py:507] global step 3316: loss = 0.0551 (0.426 sec/step)\n",
            "INFO:tensorflow:global step 3317: loss = 0.1311 (0.405 sec/step)\n",
            "I0205 13:40:41.899945 140689526667136 learning.py:507] global step 3317: loss = 0.1311 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 3318: loss = 0.0995 (0.425 sec/step)\n",
            "I0205 13:40:42.326901 140689526667136 learning.py:507] global step 3318: loss = 0.0995 (0.425 sec/step)\n",
            "INFO:tensorflow:global step 3319: loss = 0.5642 (0.438 sec/step)\n",
            "I0205 13:40:42.766519 140689526667136 learning.py:507] global step 3319: loss = 0.5642 (0.438 sec/step)\n",
            "INFO:tensorflow:global step 3320: loss = 0.1139 (0.403 sec/step)\n",
            "I0205 13:40:43.173615 140689526667136 learning.py:507] global step 3320: loss = 0.1139 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 3321: loss = 0.1893 (0.387 sec/step)\n",
            "I0205 13:40:43.563703 140689526667136 learning.py:507] global step 3321: loss = 0.1893 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 3322: loss = 0.3062 (0.409 sec/step)\n",
            "I0205 13:40:43.974566 140689526667136 learning.py:507] global step 3322: loss = 0.3062 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 3323: loss = 0.8516 (0.361 sec/step)\n",
            "I0205 13:40:44.336966 140689526667136 learning.py:507] global step 3323: loss = 0.8516 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 3324: loss = 0.1809 (0.397 sec/step)\n",
            "I0205 13:40:44.735334 140689526667136 learning.py:507] global step 3324: loss = 0.1809 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 3325: loss = 0.0940 (0.379 sec/step)\n",
            "I0205 13:40:45.116104 140689526667136 learning.py:507] global step 3325: loss = 0.0940 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 3326: loss = 0.0450 (0.409 sec/step)\n",
            "I0205 13:40:45.526770 140689526667136 learning.py:507] global step 3326: loss = 0.0450 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 3327: loss = 0.1529 (0.394 sec/step)\n",
            "I0205 13:40:45.922209 140689526667136 learning.py:507] global step 3327: loss = 0.1529 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 3328: loss = 0.1020 (0.359 sec/step)\n",
            "I0205 13:40:46.282546 140689526667136 learning.py:507] global step 3328: loss = 0.1020 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 3329: loss = 0.5615 (0.398 sec/step)\n",
            "I0205 13:40:46.681967 140689526667136 learning.py:507] global step 3329: loss = 0.5615 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 3330: loss = 0.0386 (0.382 sec/step)\n",
            "I0205 13:40:47.065589 140689526667136 learning.py:507] global step 3330: loss = 0.0386 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 3331: loss = 0.1244 (0.393 sec/step)\n",
            "I0205 13:40:47.460489 140689526667136 learning.py:507] global step 3331: loss = 0.1244 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 3332: loss = 0.1096 (0.399 sec/step)\n",
            "I0205 13:40:47.861058 140689526667136 learning.py:507] global step 3332: loss = 0.1096 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 3333: loss = 0.1670 (0.386 sec/step)\n",
            "I0205 13:40:48.248960 140689526667136 learning.py:507] global step 3333: loss = 0.1670 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 3334: loss = 0.0832 (0.377 sec/step)\n",
            "I0205 13:40:48.627637 140689526667136 learning.py:507] global step 3334: loss = 0.0832 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 3335: loss = 0.1246 (0.370 sec/step)\n",
            "I0205 13:40:48.999787 140689526667136 learning.py:507] global step 3335: loss = 0.1246 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 3336: loss = 0.0369 (0.390 sec/step)\n",
            "I0205 13:40:49.391423 140689526667136 learning.py:507] global step 3336: loss = 0.0369 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3337: loss = 0.1649 (0.372 sec/step)\n",
            "I0205 13:40:49.765687 140689526667136 learning.py:507] global step 3337: loss = 0.1649 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 3338: loss = 0.1847 (0.365 sec/step)\n",
            "I0205 13:40:50.132751 140689526667136 learning.py:507] global step 3338: loss = 0.1847 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 3339: loss = 0.3560 (0.398 sec/step)\n",
            "I0205 13:40:50.532837 140689526667136 learning.py:507] global step 3339: loss = 0.3560 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 3340: loss = 0.0200 (0.360 sec/step)\n",
            "I0205 13:40:50.894256 140689526667136 learning.py:507] global step 3340: loss = 0.0200 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 3341: loss = 0.0642 (0.383 sec/step)\n",
            "I0205 13:40:51.278757 140689526667136 learning.py:507] global step 3341: loss = 0.0642 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 3342: loss = 0.2261 (0.347 sec/step)\n",
            "I0205 13:40:51.627440 140689526667136 learning.py:507] global step 3342: loss = 0.2261 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 3343: loss = 0.1198 (0.380 sec/step)\n",
            "I0205 13:40:52.009325 140689526667136 learning.py:507] global step 3343: loss = 0.1198 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 3344: loss = 0.1355 (0.395 sec/step)\n",
            "I0205 13:40:52.406570 140689526667136 learning.py:507] global step 3344: loss = 0.1355 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 3345: loss = 0.0793 (0.434 sec/step)\n",
            "I0205 13:40:52.842103 140689526667136 learning.py:507] global step 3345: loss = 0.0793 (0.434 sec/step)\n",
            "INFO:tensorflow:global step 3346: loss = 0.9306 (0.405 sec/step)\n",
            "I0205 13:40:53.248960 140689526667136 learning.py:507] global step 3346: loss = 0.9306 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 3347: loss = 0.3211 (0.392 sec/step)\n",
            "I0205 13:40:53.642611 140689526667136 learning.py:507] global step 3347: loss = 0.3211 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 3348: loss = 0.0689 (0.375 sec/step)\n",
            "I0205 13:40:54.019124 140689526667136 learning.py:507] global step 3348: loss = 0.0689 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 3349: loss = 0.8805 (0.374 sec/step)\n",
            "I0205 13:40:54.395272 140689526667136 learning.py:507] global step 3349: loss = 0.8805 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 3350: loss = 0.1708 (0.427 sec/step)\n",
            "I0205 13:40:54.824288 140689526667136 learning.py:507] global step 3350: loss = 0.1708 (0.427 sec/step)\n",
            "INFO:tensorflow:global step 3351: loss = 0.1618 (0.373 sec/step)\n",
            "I0205 13:40:55.198990 140689526667136 learning.py:507] global step 3351: loss = 0.1618 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 3352: loss = 0.3026 (0.370 sec/step)\n",
            "I0205 13:40:55.570566 140689526667136 learning.py:507] global step 3352: loss = 0.3026 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 3353: loss = 0.0140 (0.365 sec/step)\n",
            "I0205 13:40:55.937435 140689526667136 learning.py:507] global step 3353: loss = 0.0140 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 3354: loss = 0.2011 (0.376 sec/step)\n",
            "I0205 13:40:56.315264 140689526667136 learning.py:507] global step 3354: loss = 0.2011 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 3355: loss = 0.1693 (0.378 sec/step)\n",
            "I0205 13:40:56.694100 140689526667136 learning.py:507] global step 3355: loss = 0.1693 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 3356: loss = 0.0589 (0.379 sec/step)\n",
            "I0205 13:40:57.074976 140689526667136 learning.py:507] global step 3356: loss = 0.0589 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 3357: loss = 0.0891 (0.383 sec/step)\n",
            "I0205 13:40:57.460015 140689526667136 learning.py:507] global step 3357: loss = 0.0891 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 3358: loss = 0.0737 (0.374 sec/step)\n",
            "I0205 13:40:57.835703 140689526667136 learning.py:507] global step 3358: loss = 0.0737 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 3359: loss = 0.1986 (0.366 sec/step)\n",
            "I0205 13:40:58.203066 140689526667136 learning.py:507] global step 3359: loss = 0.1986 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 3360: loss = 0.0948 (0.381 sec/step)\n",
            "I0205 13:40:58.585400 140689526667136 learning.py:507] global step 3360: loss = 0.0948 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 3361: loss = 0.0739 (0.400 sec/step)\n",
            "I0205 13:40:58.986695 140689526667136 learning.py:507] global step 3361: loss = 0.0739 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 3362: loss = 0.1537 (0.374 sec/step)\n",
            "I0205 13:40:59.362414 140689526667136 learning.py:507] global step 3362: loss = 0.1537 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 3363: loss = 0.0852 (0.373 sec/step)\n",
            "I0205 13:40:59.736919 140689526667136 learning.py:507] global step 3363: loss = 0.0852 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 3364: loss = 0.1660 (0.374 sec/step)\n",
            "I0205 13:41:00.113977 140689526667136 learning.py:507] global step 3364: loss = 0.1660 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 3365: loss = 0.0542 (0.352 sec/step)\n",
            "I0205 13:41:00.467350 140689526667136 learning.py:507] global step 3365: loss = 0.0542 (0.352 sec/step)\n",
            "INFO:tensorflow:global step 3366: loss = 0.1991 (0.376 sec/step)\n",
            "I0205 13:41:00.845460 140689526667136 learning.py:507] global step 3366: loss = 0.1991 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 3367: loss = 0.3187 (0.381 sec/step)\n",
            "I0205 13:41:01.228634 140689526667136 learning.py:507] global step 3367: loss = 0.3187 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 3368: loss = 0.0789 (0.356 sec/step)\n",
            "I0205 13:41:01.587854 140689526667136 learning.py:507] global step 3368: loss = 0.0789 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 3369: loss = 0.1035 (0.381 sec/step)\n",
            "I0205 13:41:01.970756 140689526667136 learning.py:507] global step 3369: loss = 0.1035 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 3370: loss = 0.1414 (0.373 sec/step)\n",
            "I0205 13:41:02.345269 140689526667136 learning.py:507] global step 3370: loss = 0.1414 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 3371: loss = 0.1755 (0.380 sec/step)\n",
            "I0205 13:41:02.727338 140689526667136 learning.py:507] global step 3371: loss = 0.1755 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 3372: loss = 0.0924 (0.393 sec/step)\n",
            "I0205 13:41:03.121631 140689526667136 learning.py:507] global step 3372: loss = 0.0924 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 3373: loss = 0.9249 (0.359 sec/step)\n",
            "I0205 13:41:03.482027 140689526667136 learning.py:507] global step 3373: loss = 0.9249 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 3374: loss = 0.3270 (0.377 sec/step)\n",
            "I0205 13:41:03.860605 140689526667136 learning.py:507] global step 3374: loss = 0.3270 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 3375: loss = 0.1673 (0.393 sec/step)\n",
            "I0205 13:41:04.254812 140689526667136 learning.py:507] global step 3375: loss = 0.1673 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 3376: loss = 0.1831 (0.355 sec/step)\n",
            "I0205 13:41:04.611757 140689526667136 learning.py:507] global step 3376: loss = 0.1831 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 3377: loss = 0.1503 (0.376 sec/step)\n",
            "I0205 13:41:04.989113 140689526667136 learning.py:507] global step 3377: loss = 0.1503 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 3378: loss = 0.1330 (0.388 sec/step)\n",
            "I0205 13:41:05.379075 140689526667136 learning.py:507] global step 3378: loss = 0.1330 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 3379: loss = 0.3247 (0.394 sec/step)\n",
            "I0205 13:41:05.774736 140689526667136 learning.py:507] global step 3379: loss = 0.3247 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 3380: loss = 0.1834 (0.389 sec/step)\n",
            "I0205 13:41:06.165296 140689526667136 learning.py:507] global step 3380: loss = 0.1834 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 3381: loss = 0.0372 (0.350 sec/step)\n",
            "I0205 13:41:06.516556 140689526667136 learning.py:507] global step 3381: loss = 0.0372 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 3382: loss = 0.0865 (0.383 sec/step)\n",
            "I0205 13:41:06.901114 140689526667136 learning.py:507] global step 3382: loss = 0.0865 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 3383: loss = 0.1635 (0.399 sec/step)\n",
            "I0205 13:41:07.303515 140689526667136 learning.py:507] global step 3383: loss = 0.1635 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 3384: loss = 0.1446 (0.389 sec/step)\n",
            "I0205 13:41:07.693686 140689526667136 learning.py:507] global step 3384: loss = 0.1446 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 3385: loss = 0.0842 (0.398 sec/step)\n",
            "I0205 13:41:08.095976 140689526667136 learning.py:507] global step 3385: loss = 0.0842 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 3386: loss = 0.0355 (0.385 sec/step)\n",
            "I0205 13:41:08.482604 140689526667136 learning.py:507] global step 3386: loss = 0.0355 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3387: loss = 0.0954 (0.396 sec/step)\n",
            "I0205 13:41:08.880414 140689526667136 learning.py:507] global step 3387: loss = 0.0954 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 3388: loss = 0.0970 (0.394 sec/step)\n",
            "I0205 13:41:09.275956 140689526667136 learning.py:507] global step 3388: loss = 0.0970 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 3389: loss = 0.1359 (0.391 sec/step)\n",
            "I0205 13:41:09.668917 140689526667136 learning.py:507] global step 3389: loss = 0.1359 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 3390: loss = 0.2447 (0.378 sec/step)\n",
            "I0205 13:41:10.048534 140689526667136 learning.py:507] global step 3390: loss = 0.2447 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 3391: loss = 0.4728 (0.387 sec/step)\n",
            "I0205 13:41:10.436839 140689526667136 learning.py:507] global step 3391: loss = 0.4728 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 3392: loss = 0.1259 (0.385 sec/step)\n",
            "I0205 13:41:10.823972 140689526667136 learning.py:507] global step 3392: loss = 0.1259 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3393: loss = 0.1674 (0.404 sec/step)\n",
            "I0205 13:41:11.230082 140689526667136 learning.py:507] global step 3393: loss = 0.1674 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 3394: loss = 0.1952 (0.390 sec/step)\n",
            "I0205 13:41:11.621480 140689526667136 learning.py:507] global step 3394: loss = 0.1952 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3395: loss = 0.1591 (0.379 sec/step)\n",
            "I0205 13:41:12.001977 140689526667136 learning.py:507] global step 3395: loss = 0.1591 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 3396: loss = 0.1871 (0.380 sec/step)\n",
            "I0205 13:41:12.383924 140689526667136 learning.py:507] global step 3396: loss = 0.1871 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 3397: loss = 0.1969 (0.356 sec/step)\n",
            "I0205 13:41:12.741392 140689526667136 learning.py:507] global step 3397: loss = 0.1969 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 3398: loss = 0.4115 (0.366 sec/step)\n",
            "I0205 13:41:13.108793 140689526667136 learning.py:507] global step 3398: loss = 0.4115 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 3399: loss = 0.2082 (0.382 sec/step)\n",
            "I0205 13:41:13.492681 140689526667136 learning.py:507] global step 3399: loss = 0.2082 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 3400: loss = 0.7491 (0.404 sec/step)\n",
            "I0205 13:41:13.898976 140689526667136 learning.py:507] global step 3400: loss = 0.7491 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 3401: loss = 0.1013 (0.402 sec/step)\n",
            "I0205 13:41:14.302499 140689526667136 learning.py:507] global step 3401: loss = 0.1013 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 3402: loss = 0.4628 (0.380 sec/step)\n",
            "I0205 13:41:14.683788 140689526667136 learning.py:507] global step 3402: loss = 0.4628 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 3403: loss = 0.0813 (0.372 sec/step)\n",
            "I0205 13:41:15.057449 140689526667136 learning.py:507] global step 3403: loss = 0.0813 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 3404: loss = 0.1788 (0.401 sec/step)\n",
            "I0205 13:41:15.460216 140689526667136 learning.py:507] global step 3404: loss = 0.1788 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 3405: loss = 0.0831 (0.379 sec/step)\n",
            "I0205 13:41:15.840408 140689526667136 learning.py:507] global step 3405: loss = 0.0831 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 3406: loss = 0.2173 (0.403 sec/step)\n",
            "I0205 13:41:16.244755 140689526667136 learning.py:507] global step 3406: loss = 0.2173 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 3407: loss = 0.2367 (0.404 sec/step)\n",
            "I0205 13:41:16.650103 140689526667136 learning.py:507] global step 3407: loss = 0.2367 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 3408: loss = 0.2877 (0.393 sec/step)\n",
            "I0205 13:41:17.044475 140689526667136 learning.py:507] global step 3408: loss = 0.2877 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 3409: loss = 0.4050 (0.396 sec/step)\n",
            "I0205 13:41:17.442112 140689526667136 learning.py:507] global step 3409: loss = 0.4050 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 3410: loss = 0.0693 (0.402 sec/step)\n",
            "I0205 13:41:17.846262 140689526667136 learning.py:507] global step 3410: loss = 0.0693 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 3411: loss = 0.1095 (0.406 sec/step)\n",
            "I0205 13:41:18.254751 140689526667136 learning.py:507] global step 3411: loss = 0.1095 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 3412: loss = 0.0304 (0.417 sec/step)\n",
            "I0205 13:41:18.673868 140689526667136 learning.py:507] global step 3412: loss = 0.0304 (0.417 sec/step)\n",
            "INFO:tensorflow:global step 3413: loss = 0.0986 (0.398 sec/step)\n",
            "I0205 13:41:19.073807 140689526667136 learning.py:507] global step 3413: loss = 0.0986 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 3414: loss = 0.2216 (0.434 sec/step)\n",
            "I0205 13:41:19.509950 140689526667136 learning.py:507] global step 3414: loss = 0.2216 (0.434 sec/step)\n",
            "INFO:tensorflow:global step 3415: loss = 0.0682 (0.388 sec/step)\n",
            "I0205 13:41:19.900017 140689526667136 learning.py:507] global step 3415: loss = 0.0682 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 3416: loss = 0.0661 (0.366 sec/step)\n",
            "I0205 13:41:20.267570 140689526667136 learning.py:507] global step 3416: loss = 0.0661 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 3417: loss = 0.1887 (0.381 sec/step)\n",
            "I0205 13:41:20.649884 140689526667136 learning.py:507] global step 3417: loss = 0.1887 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 3418: loss = 0.6659 (0.360 sec/step)\n",
            "I0205 13:41:21.011389 140689526667136 learning.py:507] global step 3418: loss = 0.6659 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 3419: loss = 0.0395 (0.386 sec/step)\n",
            "I0205 13:41:21.399148 140689526667136 learning.py:507] global step 3419: loss = 0.0395 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 3420: loss = 0.7287 (0.421 sec/step)\n",
            "I0205 13:41:21.821983 140689526667136 learning.py:507] global step 3420: loss = 0.7287 (0.421 sec/step)\n",
            "INFO:tensorflow:global step 3421: loss = 0.1357 (0.392 sec/step)\n",
            "I0205 13:41:22.215980 140689526667136 learning.py:507] global step 3421: loss = 0.1357 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 3422: loss = 0.2358 (0.424 sec/step)\n",
            "I0205 13:41:22.641975 140689526667136 learning.py:507] global step 3422: loss = 0.2358 (0.424 sec/step)\n",
            "INFO:tensorflow:global step 3423: loss = 0.1218 (0.383 sec/step)\n",
            "I0205 13:41:23.026459 140689526667136 learning.py:507] global step 3423: loss = 0.1218 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 3424: loss = 0.1188 (0.405 sec/step)\n",
            "I0205 13:41:23.434051 140689526667136 learning.py:507] global step 3424: loss = 0.1188 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 3425: loss = 0.2939 (0.395 sec/step)\n",
            "I0205 13:41:23.830896 140689526667136 learning.py:507] global step 3425: loss = 0.2939 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 3426: loss = 0.4007 (0.402 sec/step)\n",
            "I0205 13:41:24.234386 140689526667136 learning.py:507] global step 3426: loss = 0.4007 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 3427: loss = 0.0976 (0.403 sec/step)\n",
            "I0205 13:41:24.638586 140689526667136 learning.py:507] global step 3427: loss = 0.0976 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 3428: loss = 0.1448 (0.417 sec/step)\n",
            "I0205 13:41:25.057491 140689526667136 learning.py:507] global step 3428: loss = 0.1448 (0.417 sec/step)\n",
            "INFO:tensorflow:global step 3429: loss = 0.0512 (0.366 sec/step)\n",
            "I0205 13:41:25.425079 140689526667136 learning.py:507] global step 3429: loss = 0.0512 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 3430: loss = 0.0929 (0.395 sec/step)\n",
            "I0205 13:41:25.821756 140689526667136 learning.py:507] global step 3430: loss = 0.0929 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 3431: loss = 0.1978 (0.395 sec/step)\n",
            "I0205 13:41:26.218116 140689526667136 learning.py:507] global step 3431: loss = 0.1978 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 3432: loss = 0.1865 (0.409 sec/step)\n",
            "I0205 13:41:26.628604 140689526667136 learning.py:507] global step 3432: loss = 0.1865 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 3433: loss = 0.0377 (0.392 sec/step)\n",
            "I0205 13:41:27.022541 140689526667136 learning.py:507] global step 3433: loss = 0.0377 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 3434: loss = 0.0513 (0.395 sec/step)\n",
            "I0205 13:41:27.419545 140689526667136 learning.py:507] global step 3434: loss = 0.0513 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 3435: loss = 0.3497 (0.393 sec/step)\n",
            "I0205 13:41:27.813885 140689526667136 learning.py:507] global step 3435: loss = 0.3497 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 3436: loss = 0.1813 (0.396 sec/step)\n",
            "I0205 13:41:28.211135 140689526667136 learning.py:507] global step 3436: loss = 0.1813 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 3437: loss = 0.2441 (0.394 sec/step)\n",
            "I0205 13:41:28.607159 140689526667136 learning.py:507] global step 3437: loss = 0.2441 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 3438: loss = 0.1256 (0.412 sec/step)\n",
            "I0205 13:41:29.020864 140689526667136 learning.py:507] global step 3438: loss = 0.1256 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 3439: loss = 0.1121 (0.420 sec/step)\n",
            "I0205 13:41:29.442197 140689526667136 learning.py:507] global step 3439: loss = 0.1121 (0.420 sec/step)\n",
            "INFO:tensorflow:global step 3440: loss = 0.2187 (0.419 sec/step)\n",
            "I0205 13:41:29.863302 140689526667136 learning.py:507] global step 3440: loss = 0.2187 (0.419 sec/step)\n",
            "INFO:tensorflow:global step 3441: loss = 0.1508 (0.404 sec/step)\n",
            "I0205 13:41:30.268910 140689526667136 learning.py:507] global step 3441: loss = 0.1508 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 3442: loss = 0.2070 (0.403 sec/step)\n",
            "I0205 13:41:30.674221 140689526667136 learning.py:507] global step 3442: loss = 0.2070 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 3443: loss = 0.1209 (0.459 sec/step)\n",
            "I0205 13:41:31.134660 140689526667136 learning.py:507] global step 3443: loss = 0.1209 (0.459 sec/step)\n",
            "INFO:tensorflow:global step 3444: loss = 0.0591 (0.408 sec/step)\n",
            "I0205 13:41:31.543967 140689526667136 learning.py:507] global step 3444: loss = 0.0591 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 3445: loss = 0.1458 (0.381 sec/step)\n",
            "I0205 13:41:31.927276 140689526667136 learning.py:507] global step 3445: loss = 0.1458 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 3446: loss = 0.1592 (0.417 sec/step)\n",
            "I0205 13:41:32.345841 140689526667136 learning.py:507] global step 3446: loss = 0.1592 (0.417 sec/step)\n",
            "INFO:tensorflow:global step 3447: loss = 0.2431 (0.373 sec/step)\n",
            "I0205 13:41:32.720767 140689526667136 learning.py:507] global step 3447: loss = 0.2431 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 3448: loss = 0.0984 (0.413 sec/step)\n",
            "I0205 13:41:33.135597 140689526667136 learning.py:507] global step 3448: loss = 0.0984 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 3449: loss = 0.0688 (0.369 sec/step)\n",
            "I0205 13:41:33.506904 140689526667136 learning.py:507] global step 3449: loss = 0.0688 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 3450: loss = 0.0158 (0.396 sec/step)\n",
            "I0205 13:41:33.904245 140689526667136 learning.py:507] global step 3450: loss = 0.0158 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 3451: loss = 0.1718 (0.386 sec/step)\n",
            "I0205 13:41:34.291795 140689526667136 learning.py:507] global step 3451: loss = 0.1718 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 3452: loss = 0.1461 (0.376 sec/step)\n",
            "I0205 13:41:34.669238 140689526667136 learning.py:507] global step 3452: loss = 0.1461 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 3453: loss = 0.2553 (0.407 sec/step)\n",
            "I0205 13:41:35.077810 140689526667136 learning.py:507] global step 3453: loss = 0.2553 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 3454: loss = 0.2296 (0.375 sec/step)\n",
            "I0205 13:41:35.454077 140689526667136 learning.py:507] global step 3454: loss = 0.2296 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 3455: loss = 0.3679 (0.347 sec/step)\n",
            "I0205 13:41:35.802826 140689526667136 learning.py:507] global step 3455: loss = 0.3679 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 3456: loss = 0.1094 (0.374 sec/step)\n",
            "I0205 13:41:36.177932 140689526667136 learning.py:507] global step 3456: loss = 0.1094 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 3457: loss = 0.0868 (0.386 sec/step)\n",
            "I0205 13:41:36.565392 140689526667136 learning.py:507] global step 3457: loss = 0.0868 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 3458: loss = 0.0493 (0.391 sec/step)\n",
            "I0205 13:41:36.957772 140689526667136 learning.py:507] global step 3458: loss = 0.0493 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 3459: loss = 0.0326 (0.410 sec/step)\n",
            "I0205 13:41:37.369520 140689526667136 learning.py:507] global step 3459: loss = 0.0326 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 3460: loss = 0.0617 (0.397 sec/step)\n",
            "I0205 13:41:37.768153 140689526667136 learning.py:507] global step 3460: loss = 0.0617 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 3461: loss = 0.0969 (0.388 sec/step)\n",
            "I0205 13:41:38.157814 140689526667136 learning.py:507] global step 3461: loss = 0.0969 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 3462: loss = 0.1720 (0.395 sec/step)\n",
            "I0205 13:41:38.554216 140689526667136 learning.py:507] global step 3462: loss = 0.1720 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 3463: loss = 0.4315 (0.414 sec/step)\n",
            "I0205 13:41:38.969443 140689526667136 learning.py:507] global step 3463: loss = 0.4315 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 3464: loss = 0.2345 (0.382 sec/step)\n",
            "I0205 13:41:39.352621 140689526667136 learning.py:507] global step 3464: loss = 0.2345 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 3465: loss = 0.0717 (0.374 sec/step)\n",
            "I0205 13:41:39.728236 140689526667136 learning.py:507] global step 3465: loss = 0.0717 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 3466: loss = 0.0845 (0.408 sec/step)\n",
            "I0205 13:41:40.137829 140689526667136 learning.py:507] global step 3466: loss = 0.0845 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 3467: loss = 0.1160 (0.392 sec/step)\n",
            "I0205 13:41:40.531621 140689526667136 learning.py:507] global step 3467: loss = 0.1160 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 3468: loss = 0.1099 (0.401 sec/step)\n",
            "I0205 13:41:40.933939 140689526667136 learning.py:507] global step 3468: loss = 0.1099 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 3469: loss = 0.1072 (0.407 sec/step)\n",
            "I0205 13:41:41.342711 140689526667136 learning.py:507] global step 3469: loss = 0.1072 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 3470: loss = 0.2097 (0.380 sec/step)\n",
            "I0205 13:41:41.723898 140689526667136 learning.py:507] global step 3470: loss = 0.2097 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 3471: loss = 0.0517 (0.395 sec/step)\n",
            "I0205 13:41:42.120566 140689526667136 learning.py:507] global step 3471: loss = 0.0517 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 3472: loss = 0.1032 (0.371 sec/step)\n",
            "I0205 13:41:42.492995 140689526667136 learning.py:507] global step 3472: loss = 0.1032 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 3473: loss = 0.3791 (0.399 sec/step)\n",
            "I0205 13:41:42.893276 140689526667136 learning.py:507] global step 3473: loss = 0.3791 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 3474: loss = 0.0782 (0.366 sec/step)\n",
            "I0205 13:41:43.260702 140689526667136 learning.py:507] global step 3474: loss = 0.0782 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 3475: loss = 0.2385 (0.397 sec/step)\n",
            "I0205 13:41:43.659290 140689526667136 learning.py:507] global step 3475: loss = 0.2385 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 3476: loss = 0.1000 (0.384 sec/step)\n",
            "I0205 13:41:44.044682 140689526667136 learning.py:507] global step 3476: loss = 0.1000 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 3477: loss = 0.1809 (0.385 sec/step)\n",
            "I0205 13:41:44.430869 140689526667136 learning.py:507] global step 3477: loss = 0.1809 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3478: loss = 0.1399 (0.401 sec/step)\n",
            "I0205 13:41:44.833517 140689526667136 learning.py:507] global step 3478: loss = 0.1399 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 3479: loss = 0.2941 (0.395 sec/step)\n",
            "I0205 13:41:45.229890 140689526667136 learning.py:507] global step 3479: loss = 0.2941 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 3480: loss = 0.2032 (0.381 sec/step)\n",
            "I0205 13:41:45.612373 140689526667136 learning.py:507] global step 3480: loss = 0.2032 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 3481: loss = 0.2179 (0.420 sec/step)\n",
            "I0205 13:41:46.033895 140689526667136 learning.py:507] global step 3481: loss = 0.2179 (0.420 sec/step)\n",
            "INFO:tensorflow:global step 3482: loss = 0.1231 (0.407 sec/step)\n",
            "I0205 13:41:46.442613 140689526667136 learning.py:507] global step 3482: loss = 0.1231 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 3483: loss = 0.1141 (0.399 sec/step)\n",
            "I0205 13:41:46.842885 140689526667136 learning.py:507] global step 3483: loss = 0.1141 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 3484: loss = 0.3010 (0.412 sec/step)\n",
            "I0205 13:41:47.256220 140689526667136 learning.py:507] global step 3484: loss = 0.3010 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 3485: loss = 0.7050 (0.386 sec/step)\n",
            "I0205 13:41:47.644077 140689526667136 learning.py:507] global step 3485: loss = 0.7050 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 3486: loss = 0.2861 (0.379 sec/step)\n",
            "I0205 13:41:48.024877 140689526667136 learning.py:507] global step 3486: loss = 0.2861 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 3487: loss = 0.2648 (0.388 sec/step)\n",
            "I0205 13:41:48.415034 140689526667136 learning.py:507] global step 3487: loss = 0.2648 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 3488: loss = 0.2048 (0.400 sec/step)\n",
            "I0205 13:41:48.816680 140689526667136 learning.py:507] global step 3488: loss = 0.2048 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 3489: loss = 0.0416 (0.389 sec/step)\n",
            "I0205 13:41:49.207803 140689526667136 learning.py:507] global step 3489: loss = 0.0416 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 3490: loss = 0.1417 (0.416 sec/step)\n",
            "I0205 13:41:49.625484 140689526667136 learning.py:507] global step 3490: loss = 0.1417 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 3491: loss = 0.2191 (0.390 sec/step)\n",
            "I0205 13:41:50.017306 140689526667136 learning.py:507] global step 3491: loss = 0.2191 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3492: loss = 0.0957 (0.380 sec/step)\n",
            "I0205 13:41:50.398411 140689526667136 learning.py:507] global step 3492: loss = 0.0957 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 3493: loss = 0.0887 (0.401 sec/step)\n",
            "I0205 13:41:50.800951 140689526667136 learning.py:507] global step 3493: loss = 0.0887 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 3494: loss = 0.0578 (0.360 sec/step)\n",
            "I0205 13:41:51.162227 140689526667136 learning.py:507] global step 3494: loss = 0.0578 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 3495: loss = 0.1070 (0.372 sec/step)\n",
            "I0205 13:41:51.536264 140689526667136 learning.py:507] global step 3495: loss = 0.1070 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 3496: loss = 0.0941 (0.377 sec/step)\n",
            "I0205 13:41:51.914496 140689526667136 learning.py:507] global step 3496: loss = 0.0941 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 3497: loss = 0.3170 (0.385 sec/step)\n",
            "I0205 13:41:52.301279 140689526667136 learning.py:507] global step 3497: loss = 0.3170 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3498: loss = 0.1273 (0.410 sec/step)\n",
            "I0205 13:41:52.712519 140689526667136 learning.py:507] global step 3498: loss = 0.1273 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 3499: loss = 0.0859 (0.408 sec/step)\n",
            "I0205 13:41:53.122738 140689526667136 learning.py:507] global step 3499: loss = 0.0859 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 3500: loss = 0.1520 (0.438 sec/step)\n",
            "I0205 13:41:53.563309 140689526667136 learning.py:507] global step 3500: loss = 0.1520 (0.438 sec/step)\n",
            "INFO:tensorflow:global step 3501: loss = 0.2323 (0.421 sec/step)\n",
            "I0205 13:41:53.986679 140689526667136 learning.py:507] global step 3501: loss = 0.2323 (0.421 sec/step)\n",
            "INFO:tensorflow:global step 3502: loss = 0.1270 (0.377 sec/step)\n",
            "I0205 13:41:54.365283 140689526667136 learning.py:507] global step 3502: loss = 0.1270 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 3503: loss = 0.1289 (0.400 sec/step)\n",
            "I0205 13:41:54.767334 140689526667136 learning.py:507] global step 3503: loss = 0.1289 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 3504: loss = 0.0356 (0.377 sec/step)\n",
            "I0205 13:41:55.145673 140689526667136 learning.py:507] global step 3504: loss = 0.0356 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 3505: loss = 0.2872 (0.403 sec/step)\n",
            "I0205 13:41:55.550506 140689526667136 learning.py:507] global step 3505: loss = 0.2872 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 3506: loss = 0.0709 (0.391 sec/step)\n",
            "I0205 13:41:55.943206 140689526667136 learning.py:507] global step 3506: loss = 0.0709 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 3507: loss = 0.9582 (0.375 sec/step)\n",
            "I0205 13:41:56.320142 140689526667136 learning.py:507] global step 3507: loss = 0.9582 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 3508: loss = 0.5172 (0.408 sec/step)\n",
            "I0205 13:41:56.729093 140689526667136 learning.py:507] global step 3508: loss = 0.5172 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 3509: loss = 0.1354 (0.401 sec/step)\n",
            "I0205 13:41:57.132399 140689526667136 learning.py:507] global step 3509: loss = 0.1354 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 3510: loss = 0.0462 (0.377 sec/step)\n",
            "I0205 13:41:57.511307 140689526667136 learning.py:507] global step 3510: loss = 0.0462 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 3511: loss = 0.0720 (0.397 sec/step)\n",
            "I0205 13:41:57.909984 140689526667136 learning.py:507] global step 3511: loss = 0.0720 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 3512: loss = 0.0538 (0.384 sec/step)\n",
            "I0205 13:41:58.295833 140689526667136 learning.py:507] global step 3512: loss = 0.0538 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 3513: loss = 0.1954 (0.404 sec/step)\n",
            "I0205 13:41:58.701182 140689526667136 learning.py:507] global step 3513: loss = 0.1954 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 3514: loss = 0.1992 (0.414 sec/step)\n",
            "I0205 13:41:59.116309 140689526667136 learning.py:507] global step 3514: loss = 0.1992 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 3515: loss = 0.1150 (0.417 sec/step)\n",
            "I0205 13:41:59.536243 140689526667136 learning.py:507] global step 3515: loss = 0.1150 (0.417 sec/step)\n",
            "INFO:tensorflow:global step 3516: loss = 0.4416 (0.393 sec/step)\n",
            "I0205 13:41:59.930913 140689526667136 learning.py:507] global step 3516: loss = 0.4416 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 3517: loss = 0.1059 (0.395 sec/step)\n",
            "I0205 13:42:00.327734 140689526667136 learning.py:507] global step 3517: loss = 0.1059 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 3518: loss = 0.1166 (0.378 sec/step)\n",
            "I0205 13:42:00.707184 140689526667136 learning.py:507] global step 3518: loss = 0.1166 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 3519: loss = 0.0840 (0.402 sec/step)\n",
            "I0205 13:42:01.111116 140689526667136 learning.py:507] global step 3519: loss = 0.0840 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 3520: loss = 0.0365 (0.392 sec/step)\n",
            "I0205 13:42:01.504656 140689526667136 learning.py:507] global step 3520: loss = 0.0365 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 3521: loss = 0.2405 (0.427 sec/step)\n",
            "I0205 13:42:01.933054 140689526667136 learning.py:507] global step 3521: loss = 0.2405 (0.427 sec/step)\n",
            "INFO:tensorflow:global step 3522: loss = 0.1534 (0.387 sec/step)\n",
            "I0205 13:42:02.321414 140689526667136 learning.py:507] global step 3522: loss = 0.1534 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 3523: loss = 0.4286 (0.403 sec/step)\n",
            "I0205 13:42:02.726362 140689526667136 learning.py:507] global step 3523: loss = 0.4286 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 3524: loss = 0.1997 (0.395 sec/step)\n",
            "I0205 13:42:03.122510 140689526667136 learning.py:507] global step 3524: loss = 0.1997 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 3525: loss = 0.1095 (0.410 sec/step)\n",
            "I0205 13:42:03.534959 140689526667136 learning.py:507] global step 3525: loss = 0.1095 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 3526: loss = 0.1771 (0.410 sec/step)\n",
            "I0205 13:42:03.946769 140689526667136 learning.py:507] global step 3526: loss = 0.1771 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 3527: loss = 0.0731 (0.382 sec/step)\n",
            "I0205 13:42:04.330484 140689526667136 learning.py:507] global step 3527: loss = 0.0731 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 3528: loss = 0.3310 (0.383 sec/step)\n",
            "I0205 13:42:04.715454 140689526667136 learning.py:507] global step 3528: loss = 0.3310 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 3529: loss = 0.3690 (0.409 sec/step)\n",
            "I0205 13:42:05.126379 140689526667136 learning.py:507] global step 3529: loss = 0.3690 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 3530: loss = 0.0267 (0.404 sec/step)\n",
            "I0205 13:42:05.532609 140689526667136 learning.py:507] global step 3530: loss = 0.0267 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 3531: loss = 0.0557 (0.392 sec/step)\n",
            "I0205 13:42:05.926524 140689526667136 learning.py:507] global step 3531: loss = 0.0557 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 3532: loss = 0.1142 (0.413 sec/step)\n",
            "I0205 13:42:06.341826 140689526667136 learning.py:507] global step 3532: loss = 0.1142 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 3533: loss = 0.3447 (0.413 sec/step)\n",
            "I0205 13:42:06.757542 140689526667136 learning.py:507] global step 3533: loss = 0.3447 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 3534: loss = 0.5430 (0.373 sec/step)\n",
            "I0205 13:42:07.133267 140689526667136 learning.py:507] global step 3534: loss = 0.5430 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 3535: loss = 0.1862 (0.424 sec/step)\n",
            "I0205 13:42:07.558769 140689526667136 learning.py:507] global step 3535: loss = 0.1862 (0.424 sec/step)\n",
            "INFO:tensorflow:global step 3536: loss = 0.0918 (0.393 sec/step)\n",
            "I0205 13:42:07.953237 140689526667136 learning.py:507] global step 3536: loss = 0.0918 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 3537: loss = 0.0774 (0.429 sec/step)\n",
            "I0205 13:42:08.384055 140689526667136 learning.py:507] global step 3537: loss = 0.0774 (0.429 sec/step)\n",
            "INFO:tensorflow:global step 3538: loss = 0.0215 (0.416 sec/step)\n",
            "I0205 13:42:08.802429 140689526667136 learning.py:507] global step 3538: loss = 0.0215 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 3539: loss = 0.1646 (0.411 sec/step)\n",
            "I0205 13:42:09.215358 140689526667136 learning.py:507] global step 3539: loss = 0.1646 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 3540: loss = 0.0923 (0.408 sec/step)\n",
            "I0205 13:42:09.625439 140689526667136 learning.py:507] global step 3540: loss = 0.0923 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 3541: loss = 0.0721 (0.415 sec/step)\n",
            "I0205 13:42:10.042655 140689526667136 learning.py:507] global step 3541: loss = 0.0721 (0.415 sec/step)\n",
            "INFO:tensorflow:global step 3542: loss = 0.1584 (0.399 sec/step)\n",
            "I0205 13:42:10.443416 140689526667136 learning.py:507] global step 3542: loss = 0.1584 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 3543: loss = 0.0798 (0.396 sec/step)\n",
            "I0205 13:42:10.841572 140689526667136 learning.py:507] global step 3543: loss = 0.0798 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 3544: loss = 0.0979 (0.404 sec/step)\n",
            "I0205 13:42:11.246867 140689526667136 learning.py:507] global step 3544: loss = 0.0979 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 3545: loss = 0.0865 (0.399 sec/step)\n",
            "I0205 13:42:11.648046 140689526667136 learning.py:507] global step 3545: loss = 0.0865 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 3546: loss = 0.1477 (0.399 sec/step)\n",
            "I0205 13:42:12.048005 140689526667136 learning.py:507] global step 3546: loss = 0.1477 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 3547: loss = 0.0514 (0.401 sec/step)\n",
            "I0205 13:42:12.450909 140689526667136 learning.py:507] global step 3547: loss = 0.0514 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 3548: loss = 0.3208 (0.406 sec/step)\n",
            "I0205 13:42:12.859251 140689526667136 learning.py:507] global step 3548: loss = 0.3208 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 3549: loss = 0.1385 (0.367 sec/step)\n",
            "I0205 13:42:13.227805 140689526667136 learning.py:507] global step 3549: loss = 0.1385 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 3550: loss = 0.2483 (0.385 sec/step)\n",
            "I0205 13:42:13.614098 140689526667136 learning.py:507] global step 3550: loss = 0.2483 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3551: loss = 0.1843 (0.743 sec/step)\n",
            "I0205 13:42:14.435011 140689526667136 learning.py:507] global step 3551: loss = 0.1843 (0.743 sec/step)\n",
            "INFO:tensorflow:global step 3552: loss = 0.3402 (1.049 sec/step)\n",
            "I0205 13:42:15.650818 140689526667136 learning.py:507] global step 3552: loss = 0.3402 (1.049 sec/step)\n",
            "INFO:tensorflow:global step 3553: loss = 0.1533 (0.616 sec/step)\n",
            "I0205 13:42:16.272786 140689526667136 learning.py:507] global step 3553: loss = 0.1533 (0.616 sec/step)\n",
            "INFO:tensorflow:global step 3554: loss = 0.0987 (0.619 sec/step)\n",
            "I0205 13:42:16.909122 140689526667136 learning.py:507] global step 3554: loss = 0.0987 (0.619 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 3554.\n",
            "I0205 13:42:17.497363 140686026073856 supervisor.py:1050] Recording summary at step 3554.\n",
            "INFO:tensorflow:global step 3555: loss = 0.3054 (0.600 sec/step)\n",
            "I0205 13:42:17.511123 140689526667136 learning.py:507] global step 3555: loss = 0.3054 (0.600 sec/step)\n",
            "INFO:tensorflow:global step 3556: loss = 0.0930 (0.383 sec/step)\n",
            "I0205 13:42:17.895741 140689526667136 learning.py:507] global step 3556: loss = 0.0930 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 3557: loss = 0.2102 (0.372 sec/step)\n",
            "I0205 13:42:18.269498 140689526667136 learning.py:507] global step 3557: loss = 0.2102 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 3558: loss = 0.4362 (0.381 sec/step)\n",
            "I0205 13:42:18.652235 140689526667136 learning.py:507] global step 3558: loss = 0.4362 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 3559: loss = 0.1718 (0.380 sec/step)\n",
            "I0205 13:42:19.033836 140689526667136 learning.py:507] global step 3559: loss = 0.1718 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 3560: loss = 0.2165 (0.430 sec/step)\n",
            "I0205 13:42:19.465469 140689526667136 learning.py:507] global step 3560: loss = 0.2165 (0.430 sec/step)\n",
            "INFO:tensorflow:global step 3561: loss = 0.1789 (0.389 sec/step)\n",
            "I0205 13:42:19.856446 140689526667136 learning.py:507] global step 3561: loss = 0.1789 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 3562: loss = 0.0586 (0.383 sec/step)\n",
            "I0205 13:42:20.241542 140689526667136 learning.py:507] global step 3562: loss = 0.0586 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 3563: loss = 0.1574 (0.361 sec/step)\n",
            "I0205 13:42:20.603966 140689526667136 learning.py:507] global step 3563: loss = 0.1574 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 3564: loss = 0.0552 (0.377 sec/step)\n",
            "I0205 13:42:20.982537 140689526667136 learning.py:507] global step 3564: loss = 0.0552 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 3565: loss = 0.0678 (0.367 sec/step)\n",
            "I0205 13:42:21.351130 140689526667136 learning.py:507] global step 3565: loss = 0.0678 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 3566: loss = 0.1537 (0.391 sec/step)\n",
            "I0205 13:42:21.743750 140689526667136 learning.py:507] global step 3566: loss = 0.1537 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 3567: loss = 0.4128 (0.404 sec/step)\n",
            "I0205 13:42:22.149775 140689526667136 learning.py:507] global step 3567: loss = 0.4128 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 3568: loss = 0.1282 (0.394 sec/step)\n",
            "I0205 13:42:22.545232 140689526667136 learning.py:507] global step 3568: loss = 0.1282 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 3569: loss = 0.4941 (0.419 sec/step)\n",
            "I0205 13:42:22.966236 140689526667136 learning.py:507] global step 3569: loss = 0.4941 (0.419 sec/step)\n",
            "INFO:tensorflow:global step 3570: loss = 0.1335 (0.410 sec/step)\n",
            "I0205 13:42:23.377897 140689526667136 learning.py:507] global step 3570: loss = 0.1335 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 3571: loss = 0.3163 (0.397 sec/step)\n",
            "I0205 13:42:23.776627 140689526667136 learning.py:507] global step 3571: loss = 0.3163 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 3572: loss = 0.0706 (0.409 sec/step)\n",
            "I0205 13:42:24.186973 140689526667136 learning.py:507] global step 3572: loss = 0.0706 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 3573: loss = 0.2142 (0.395 sec/step)\n",
            "I0205 13:42:24.583346 140689526667136 learning.py:507] global step 3573: loss = 0.2142 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 3574: loss = 0.1765 (0.398 sec/step)\n",
            "I0205 13:42:24.983066 140689526667136 learning.py:507] global step 3574: loss = 0.1765 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 3575: loss = 0.1508 (0.362 sec/step)\n",
            "I0205 13:42:25.346978 140689526667136 learning.py:507] global step 3575: loss = 0.1508 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 3576: loss = 0.2518 (0.359 sec/step)\n",
            "I0205 13:42:25.707781 140689526667136 learning.py:507] global step 3576: loss = 0.2518 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 3577: loss = 0.0775 (0.370 sec/step)\n",
            "I0205 13:42:26.079228 140689526667136 learning.py:507] global step 3577: loss = 0.0775 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 3578: loss = 0.2681 (0.392 sec/step)\n",
            "I0205 13:42:26.473020 140689526667136 learning.py:507] global step 3578: loss = 0.2681 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 3579: loss = 0.5303 (0.389 sec/step)\n",
            "I0205 13:42:26.863651 140689526667136 learning.py:507] global step 3579: loss = 0.5303 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 3580: loss = 0.2387 (0.413 sec/step)\n",
            "I0205 13:42:27.278108 140689526667136 learning.py:507] global step 3580: loss = 0.2387 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 3581: loss = 0.1430 (0.437 sec/step)\n",
            "I0205 13:42:27.716548 140689526667136 learning.py:507] global step 3581: loss = 0.1430 (0.437 sec/step)\n",
            "INFO:tensorflow:global step 3582: loss = 0.0810 (0.398 sec/step)\n",
            "I0205 13:42:28.116778 140689526667136 learning.py:507] global step 3582: loss = 0.0810 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 3583: loss = 0.0973 (0.390 sec/step)\n",
            "I0205 13:42:28.508069 140689526667136 learning.py:507] global step 3583: loss = 0.0973 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3584: loss = 0.0903 (0.387 sec/step)\n",
            "I0205 13:42:28.896794 140689526667136 learning.py:507] global step 3584: loss = 0.0903 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 3585: loss = 0.0917 (0.386 sec/step)\n",
            "I0205 13:42:29.283869 140689526667136 learning.py:507] global step 3585: loss = 0.0917 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 3586: loss = 0.2036 (0.412 sec/step)\n",
            "I0205 13:42:29.697960 140689526667136 learning.py:507] global step 3586: loss = 0.2036 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 3587: loss = 0.1005 (0.368 sec/step)\n",
            "I0205 13:42:30.067879 140689526667136 learning.py:507] global step 3587: loss = 0.1005 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 3588: loss = 0.0962 (0.418 sec/step)\n",
            "I0205 13:42:30.487464 140689526667136 learning.py:507] global step 3588: loss = 0.0962 (0.418 sec/step)\n",
            "INFO:tensorflow:global step 3589: loss = 0.1461 (0.411 sec/step)\n",
            "I0205 13:42:30.900229 140689526667136 learning.py:507] global step 3589: loss = 0.1461 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 3590: loss = 0.1472 (0.396 sec/step)\n",
            "I0205 13:42:31.298084 140689526667136 learning.py:507] global step 3590: loss = 0.1472 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 3591: loss = 0.0862 (0.419 sec/step)\n",
            "I0205 13:42:31.719254 140689526667136 learning.py:507] global step 3591: loss = 0.0862 (0.419 sec/step)\n",
            "INFO:tensorflow:global step 3592: loss = 0.2097 (0.441 sec/step)\n",
            "I0205 13:42:32.161947 140689526667136 learning.py:507] global step 3592: loss = 0.2097 (0.441 sec/step)\n",
            "INFO:tensorflow:global step 3593: loss = 0.0842 (0.381 sec/step)\n",
            "I0205 13:42:32.544086 140689526667136 learning.py:507] global step 3593: loss = 0.0842 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 3594: loss = 0.1041 (0.399 sec/step)\n",
            "I0205 13:42:32.945281 140689526667136 learning.py:507] global step 3594: loss = 0.1041 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 3595: loss = 0.0705 (0.387 sec/step)\n",
            "I0205 13:42:33.333733 140689526667136 learning.py:507] global step 3595: loss = 0.0705 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 3596: loss = 0.2346 (0.405 sec/step)\n",
            "I0205 13:42:33.740206 140689526667136 learning.py:507] global step 3596: loss = 0.2346 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 3597: loss = 0.1174 (0.404 sec/step)\n",
            "I0205 13:42:34.145969 140689526667136 learning.py:507] global step 3597: loss = 0.1174 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 3598: loss = 0.1796 (0.390 sec/step)\n",
            "I0205 13:42:34.537401 140689526667136 learning.py:507] global step 3598: loss = 0.1796 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3599: loss = 0.0356 (0.385 sec/step)\n",
            "I0205 13:42:34.923975 140689526667136 learning.py:507] global step 3599: loss = 0.0356 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3600: loss = 0.3208 (0.378 sec/step)\n",
            "I0205 13:42:35.303583 140689526667136 learning.py:507] global step 3600: loss = 0.3208 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 3601: loss = 0.4741 (0.390 sec/step)\n",
            "I0205 13:42:35.695501 140689526667136 learning.py:507] global step 3601: loss = 0.4741 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3602: loss = 0.0366 (0.387 sec/step)\n",
            "I0205 13:42:36.084231 140689526667136 learning.py:507] global step 3602: loss = 0.0366 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 3603: loss = 0.1048 (0.401 sec/step)\n",
            "I0205 13:42:36.486723 140689526667136 learning.py:507] global step 3603: loss = 0.1048 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 3604: loss = 0.1793 (0.387 sec/step)\n",
            "I0205 13:42:36.875658 140689526667136 learning.py:507] global step 3604: loss = 0.1793 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 3605: loss = 0.1104 (0.380 sec/step)\n",
            "I0205 13:42:37.257717 140689526667136 learning.py:507] global step 3605: loss = 0.1104 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 3606: loss = 0.0960 (0.378 sec/step)\n",
            "I0205 13:42:37.638291 140689526667136 learning.py:507] global step 3606: loss = 0.0960 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 3607: loss = 0.2193 (0.371 sec/step)\n",
            "I0205 13:42:38.010481 140689526667136 learning.py:507] global step 3607: loss = 0.2193 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 3608: loss = 0.0765 (0.374 sec/step)\n",
            "I0205 13:42:38.385985 140689526667136 learning.py:507] global step 3608: loss = 0.0765 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 3609: loss = 0.1496 (0.417 sec/step)\n",
            "I0205 13:42:38.804117 140689526667136 learning.py:507] global step 3609: loss = 0.1496 (0.417 sec/step)\n",
            "INFO:tensorflow:global step 3610: loss = 0.0445 (0.387 sec/step)\n",
            "I0205 13:42:39.192471 140689526667136 learning.py:507] global step 3610: loss = 0.0445 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 3611: loss = 0.1102 (0.397 sec/step)\n",
            "I0205 13:42:39.591051 140689526667136 learning.py:507] global step 3611: loss = 0.1102 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 3612: loss = 0.1378 (0.404 sec/step)\n",
            "I0205 13:42:39.997033 140689526667136 learning.py:507] global step 3612: loss = 0.1378 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 3613: loss = 0.4483 (0.394 sec/step)\n",
            "I0205 13:42:40.392875 140689526667136 learning.py:507] global step 3613: loss = 0.4483 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 3614: loss = 0.0930 (0.368 sec/step)\n",
            "I0205 13:42:40.763030 140689526667136 learning.py:507] global step 3614: loss = 0.0930 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 3615: loss = 0.2425 (0.369 sec/step)\n",
            "I0205 13:42:41.133322 140689526667136 learning.py:507] global step 3615: loss = 0.2425 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 3616: loss = 0.1204 (0.399 sec/step)\n",
            "I0205 13:42:41.533598 140689526667136 learning.py:507] global step 3616: loss = 0.1204 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 3617: loss = 0.1413 (0.390 sec/step)\n",
            "I0205 13:42:41.925517 140689526667136 learning.py:507] global step 3617: loss = 0.1413 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3618: loss = 0.1129 (0.382 sec/step)\n",
            "I0205 13:42:42.309685 140689526667136 learning.py:507] global step 3618: loss = 0.1129 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 3619: loss = 0.1312 (0.376 sec/step)\n",
            "I0205 13:42:42.687145 140689526667136 learning.py:507] global step 3619: loss = 0.1312 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 3620: loss = 0.2442 (0.400 sec/step)\n",
            "I0205 13:42:43.089070 140689526667136 learning.py:507] global step 3620: loss = 0.2442 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 3621: loss = 0.4404 (0.379 sec/step)\n",
            "I0205 13:42:43.469878 140689526667136 learning.py:507] global step 3621: loss = 0.4404 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 3622: loss = 0.1233 (0.378 sec/step)\n",
            "I0205 13:42:43.849263 140689526667136 learning.py:507] global step 3622: loss = 0.1233 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 3623: loss = 0.1181 (0.412 sec/step)\n",
            "I0205 13:42:44.262978 140689526667136 learning.py:507] global step 3623: loss = 0.1181 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 3624: loss = 0.0800 (0.364 sec/step)\n",
            "I0205 13:42:44.629010 140689526667136 learning.py:507] global step 3624: loss = 0.0800 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 3625: loss = 0.0917 (0.394 sec/step)\n",
            "I0205 13:42:45.025042 140689526667136 learning.py:507] global step 3625: loss = 0.0917 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 3626: loss = 0.3585 (0.389 sec/step)\n",
            "I0205 13:42:45.415248 140689526667136 learning.py:507] global step 3626: loss = 0.3585 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 3627: loss = 0.1140 (0.407 sec/step)\n",
            "I0205 13:42:45.824574 140689526667136 learning.py:507] global step 3627: loss = 0.1140 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 3628: loss = 0.3788 (0.403 sec/step)\n",
            "I0205 13:42:46.229318 140689526667136 learning.py:507] global step 3628: loss = 0.3788 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 3629: loss = 0.3769 (0.406 sec/step)\n",
            "I0205 13:42:46.637275 140689526667136 learning.py:507] global step 3629: loss = 0.3769 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 3630: loss = 0.0381 (0.409 sec/step)\n",
            "I0205 13:42:47.048405 140689526667136 learning.py:507] global step 3630: loss = 0.0381 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 3631: loss = 0.1879 (0.403 sec/step)\n",
            "I0205 13:42:47.452763 140689526667136 learning.py:507] global step 3631: loss = 0.1879 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 3632: loss = 0.6590 (0.396 sec/step)\n",
            "I0205 13:42:47.850524 140689526667136 learning.py:507] global step 3632: loss = 0.6590 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 3633: loss = 0.1611 (0.392 sec/step)\n",
            "I0205 13:42:48.244424 140689526667136 learning.py:507] global step 3633: loss = 0.1611 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 3634: loss = 0.0874 (0.386 sec/step)\n",
            "I0205 13:42:48.632176 140689526667136 learning.py:507] global step 3634: loss = 0.0874 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 3635: loss = 0.1760 (0.405 sec/step)\n",
            "I0205 13:42:49.038484 140689526667136 learning.py:507] global step 3635: loss = 0.1760 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 3636: loss = 0.0350 (0.416 sec/step)\n",
            "I0205 13:42:49.456621 140689526667136 learning.py:507] global step 3636: loss = 0.0350 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 3637: loss = 0.0408 (0.382 sec/step)\n",
            "I0205 13:42:49.840617 140689526667136 learning.py:507] global step 3637: loss = 0.0408 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 3638: loss = 0.0720 (0.385 sec/step)\n",
            "I0205 13:42:50.227476 140689526667136 learning.py:507] global step 3638: loss = 0.0720 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3639: loss = 0.1441 (0.391 sec/step)\n",
            "I0205 13:42:50.620152 140689526667136 learning.py:507] global step 3639: loss = 0.1441 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 3640: loss = 0.2978 (0.397 sec/step)\n",
            "I0205 13:42:51.019260 140689526667136 learning.py:507] global step 3640: loss = 0.2978 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 3641: loss = 0.1211 (0.363 sec/step)\n",
            "I0205 13:42:51.384389 140689526667136 learning.py:507] global step 3641: loss = 0.1211 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 3642: loss = 0.0314 (0.406 sec/step)\n",
            "I0205 13:42:51.792053 140689526667136 learning.py:507] global step 3642: loss = 0.0314 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 3643: loss = 0.3730 (0.416 sec/step)\n",
            "I0205 13:42:52.209780 140689526667136 learning.py:507] global step 3643: loss = 0.3730 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 3644: loss = 0.1847 (0.404 sec/step)\n",
            "I0205 13:42:52.616028 140689526667136 learning.py:507] global step 3644: loss = 0.1847 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 3645: loss = 0.0653 (0.402 sec/step)\n",
            "I0205 13:42:53.019925 140689526667136 learning.py:507] global step 3645: loss = 0.0653 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 3646: loss = 0.2305 (0.409 sec/step)\n",
            "I0205 13:42:53.430759 140689526667136 learning.py:507] global step 3646: loss = 0.2305 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 3647: loss = 0.3410 (0.397 sec/step)\n",
            "I0205 13:42:53.829650 140689526667136 learning.py:507] global step 3647: loss = 0.3410 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 3648: loss = 0.0605 (0.389 sec/step)\n",
            "I0205 13:42:54.220314 140689526667136 learning.py:507] global step 3648: loss = 0.0605 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 3649: loss = 0.1041 (0.389 sec/step)\n",
            "I0205 13:42:54.610470 140689526667136 learning.py:507] global step 3649: loss = 0.1041 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 3650: loss = 0.2062 (0.380 sec/step)\n",
            "I0205 13:42:54.991820 140689526667136 learning.py:507] global step 3650: loss = 0.2062 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 3651: loss = 0.3103 (0.402 sec/step)\n",
            "I0205 13:42:55.394765 140689526667136 learning.py:507] global step 3651: loss = 0.3103 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 3652: loss = 0.0939 (0.381 sec/step)\n",
            "I0205 13:42:55.777885 140689526667136 learning.py:507] global step 3652: loss = 0.0939 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 3653: loss = 0.1067 (0.366 sec/step)\n",
            "I0205 13:42:56.145057 140689526667136 learning.py:507] global step 3653: loss = 0.1067 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 3654: loss = 0.3273 (0.403 sec/step)\n",
            "I0205 13:42:56.549711 140689526667136 learning.py:507] global step 3654: loss = 0.3273 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 3655: loss = 0.1348 (0.385 sec/step)\n",
            "I0205 13:42:56.936570 140689526667136 learning.py:507] global step 3655: loss = 0.1348 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3656: loss = 0.1977 (0.380 sec/step)\n",
            "I0205 13:42:57.318637 140689526667136 learning.py:507] global step 3656: loss = 0.1977 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 3657: loss = 0.1326 (0.358 sec/step)\n",
            "I0205 13:42:57.678672 140689526667136 learning.py:507] global step 3657: loss = 0.1326 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 3658: loss = 0.0413 (0.378 sec/step)\n",
            "I0205 13:42:58.058333 140689526667136 learning.py:507] global step 3658: loss = 0.0413 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 3659: loss = 0.0678 (0.379 sec/step)\n",
            "I0205 13:42:58.438699 140689526667136 learning.py:507] global step 3659: loss = 0.0678 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 3660: loss = 0.0919 (0.354 sec/step)\n",
            "I0205 13:42:58.794262 140689526667136 learning.py:507] global step 3660: loss = 0.0919 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 3661: loss = 0.0435 (0.378 sec/step)\n",
            "I0205 13:42:59.173826 140689526667136 learning.py:507] global step 3661: loss = 0.0435 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 3662: loss = 0.1147 (0.392 sec/step)\n",
            "I0205 13:42:59.567689 140689526667136 learning.py:507] global step 3662: loss = 0.1147 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 3663: loss = 0.0915 (0.384 sec/step)\n",
            "I0205 13:42:59.953262 140689526667136 learning.py:507] global step 3663: loss = 0.0915 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 3664: loss = 0.1000 (0.390 sec/step)\n",
            "I0205 13:43:00.344392 140689526667136 learning.py:507] global step 3664: loss = 0.1000 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3665: loss = 0.1708 (1.014 sec/step)\n",
            "I0205 13:43:01.360137 140689526667136 learning.py:507] global step 3665: loss = 0.1708 (1.014 sec/step)\n",
            "INFO:tensorflow:global step 3666: loss = 0.4228 (0.363 sec/step)\n",
            "I0205 13:43:01.724703 140689526667136 learning.py:507] global step 3666: loss = 0.4228 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 3667: loss = 0.1341 (0.401 sec/step)\n",
            "I0205 13:43:02.127742 140689526667136 learning.py:507] global step 3667: loss = 0.1341 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 3668: loss = 0.1692 (0.404 sec/step)\n",
            "I0205 13:43:02.532943 140689526667136 learning.py:507] global step 3668: loss = 0.1692 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 3669: loss = 0.1096 (0.398 sec/step)\n",
            "I0205 13:43:02.932811 140689526667136 learning.py:507] global step 3669: loss = 0.1096 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 3670: loss = 0.0519 (0.415 sec/step)\n",
            "I0205 13:43:03.349175 140689526667136 learning.py:507] global step 3670: loss = 0.0519 (0.415 sec/step)\n",
            "INFO:tensorflow:global step 3671: loss = 0.1759 (0.375 sec/step)\n",
            "I0205 13:43:03.725986 140689526667136 learning.py:507] global step 3671: loss = 0.1759 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 3672: loss = 0.3639 (0.411 sec/step)\n",
            "I0205 13:43:04.138557 140689526667136 learning.py:507] global step 3672: loss = 0.3639 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 3673: loss = 0.1352 (0.367 sec/step)\n",
            "I0205 13:43:04.507207 140689526667136 learning.py:507] global step 3673: loss = 0.1352 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 3674: loss = 0.2950 (0.369 sec/step)\n",
            "I0205 13:43:04.877744 140689526667136 learning.py:507] global step 3674: loss = 0.2950 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 3675: loss = 0.0596 (0.391 sec/step)\n",
            "I0205 13:43:05.270656 140689526667136 learning.py:507] global step 3675: loss = 0.0596 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 3676: loss = 0.0961 (0.404 sec/step)\n",
            "I0205 13:43:05.676356 140689526667136 learning.py:507] global step 3676: loss = 0.0961 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 3677: loss = 0.0967 (0.368 sec/step)\n",
            "I0205 13:43:06.046158 140689526667136 learning.py:507] global step 3677: loss = 0.0967 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 3678: loss = 0.1270 (0.381 sec/step)\n",
            "I0205 13:43:06.428476 140689526667136 learning.py:507] global step 3678: loss = 0.1270 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 3679: loss = 1.0240 (0.375 sec/step)\n",
            "I0205 13:43:06.805452 140689526667136 learning.py:507] global step 3679: loss = 1.0240 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 3680: loss = 0.0307 (0.385 sec/step)\n",
            "I0205 13:43:07.192272 140689526667136 learning.py:507] global step 3680: loss = 0.0307 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3681: loss = 0.0702 (0.366 sec/step)\n",
            "I0205 13:43:07.559747 140689526667136 learning.py:507] global step 3681: loss = 0.0702 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 3682: loss = 0.1595 (0.401 sec/step)\n",
            "I0205 13:43:07.962102 140689526667136 learning.py:507] global step 3682: loss = 0.1595 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 3683: loss = 0.6991 (0.391 sec/step)\n",
            "I0205 13:43:08.354687 140689526667136 learning.py:507] global step 3683: loss = 0.6991 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 3684: loss = 0.1648 (0.384 sec/step)\n",
            "I0205 13:43:08.741183 140689526667136 learning.py:507] global step 3684: loss = 0.1648 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 3685: loss = 0.0948 (0.386 sec/step)\n",
            "I0205 13:43:09.128697 140689526667136 learning.py:507] global step 3685: loss = 0.0948 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 3686: loss = 0.2984 (0.385 sec/step)\n",
            "I0205 13:43:09.515117 140689526667136 learning.py:507] global step 3686: loss = 0.2984 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3687: loss = 0.1291 (0.411 sec/step)\n",
            "I0205 13:43:09.927628 140689526667136 learning.py:507] global step 3687: loss = 0.1291 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 3688: loss = 0.1086 (0.386 sec/step)\n",
            "I0205 13:43:10.316077 140689526667136 learning.py:507] global step 3688: loss = 0.1086 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 3689: loss = 0.0902 (0.383 sec/step)\n",
            "I0205 13:43:10.700768 140689526667136 learning.py:507] global step 3689: loss = 0.0902 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 3690: loss = 0.0663 (0.385 sec/step)\n",
            "I0205 13:43:11.087704 140689526667136 learning.py:507] global step 3690: loss = 0.0663 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3691: loss = 0.1220 (0.387 sec/step)\n",
            "I0205 13:43:11.475993 140689526667136 learning.py:507] global step 3691: loss = 0.1220 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 3692: loss = 0.1399 (0.420 sec/step)\n",
            "I0205 13:43:11.897898 140689526667136 learning.py:507] global step 3692: loss = 0.1399 (0.420 sec/step)\n",
            "INFO:tensorflow:global step 3693: loss = 0.1385 (0.374 sec/step)\n",
            "I0205 13:43:12.273824 140689526667136 learning.py:507] global step 3693: loss = 0.1385 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 3694: loss = 0.0296 (0.385 sec/step)\n",
            "I0205 13:43:12.660587 140689526667136 learning.py:507] global step 3694: loss = 0.0296 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3695: loss = 0.1451 (0.367 sec/step)\n",
            "I0205 13:43:13.029189 140689526667136 learning.py:507] global step 3695: loss = 0.1451 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 3696: loss = 0.4875 (0.357 sec/step)\n",
            "I0205 13:43:13.387598 140689526667136 learning.py:507] global step 3696: loss = 0.4875 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 3697: loss = 0.3432 (0.373 sec/step)\n",
            "I0205 13:43:13.762526 140689526667136 learning.py:507] global step 3697: loss = 0.3432 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 3698: loss = 0.0615 (0.399 sec/step)\n",
            "I0205 13:43:14.163246 140689526667136 learning.py:507] global step 3698: loss = 0.0615 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 3699: loss = 0.2012 (0.369 sec/step)\n",
            "I0205 13:43:14.534034 140689526667136 learning.py:507] global step 3699: loss = 0.2012 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 3700: loss = 0.2209 (0.402 sec/step)\n",
            "I0205 13:43:14.937266 140689526667136 learning.py:507] global step 3700: loss = 0.2209 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 3701: loss = 0.1399 (0.380 sec/step)\n",
            "I0205 13:43:15.318699 140689526667136 learning.py:507] global step 3701: loss = 0.1399 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 3702: loss = 0.1115 (0.391 sec/step)\n",
            "I0205 13:43:15.711648 140689526667136 learning.py:507] global step 3702: loss = 0.1115 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 3703: loss = 0.0429 (0.368 sec/step)\n",
            "I0205 13:43:16.080983 140689526667136 learning.py:507] global step 3703: loss = 0.0429 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 3704: loss = 0.0894 (0.362 sec/step)\n",
            "I0205 13:43:16.444379 140689526667136 learning.py:507] global step 3704: loss = 0.0894 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 3705: loss = 0.0634 (0.370 sec/step)\n",
            "I0205 13:43:16.816191 140689526667136 learning.py:507] global step 3705: loss = 0.0634 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 3706: loss = 0.3440 (0.363 sec/step)\n",
            "I0205 13:43:17.180760 140689526667136 learning.py:507] global step 3706: loss = 0.3440 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 3707: loss = 0.1485 (0.365 sec/step)\n",
            "I0205 13:43:17.547090 140689526667136 learning.py:507] global step 3707: loss = 0.1485 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 3708: loss = 0.7687 (0.371 sec/step)\n",
            "I0205 13:43:17.919661 140689526667136 learning.py:507] global step 3708: loss = 0.7687 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 3709: loss = 0.3235 (0.377 sec/step)\n",
            "I0205 13:43:18.298442 140689526667136 learning.py:507] global step 3709: loss = 0.3235 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 3710: loss = 0.1487 (0.376 sec/step)\n",
            "I0205 13:43:18.676320 140689526667136 learning.py:507] global step 3710: loss = 0.1487 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 3711: loss = 0.0601 (0.404 sec/step)\n",
            "I0205 13:43:19.081657 140689526667136 learning.py:507] global step 3711: loss = 0.0601 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 3712: loss = 0.1064 (0.393 sec/step)\n",
            "I0205 13:43:19.475854 140689526667136 learning.py:507] global step 3712: loss = 0.1064 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 3713: loss = 0.0353 (0.383 sec/step)\n",
            "I0205 13:43:19.860127 140689526667136 learning.py:507] global step 3713: loss = 0.0353 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 3714: loss = 0.1464 (0.418 sec/step)\n",
            "I0205 13:43:20.279753 140689526667136 learning.py:507] global step 3714: loss = 0.1464 (0.418 sec/step)\n",
            "INFO:tensorflow:global step 3715: loss = 0.1992 (0.385 sec/step)\n",
            "I0205 13:43:20.666448 140689526667136 learning.py:507] global step 3715: loss = 0.1992 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3716: loss = 0.1287 (0.404 sec/step)\n",
            "I0205 13:43:21.071803 140689526667136 learning.py:507] global step 3716: loss = 0.1287 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 3717: loss = 0.2105 (0.372 sec/step)\n",
            "I0205 13:43:21.445957 140689526667136 learning.py:507] global step 3717: loss = 0.2105 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 3718: loss = 0.1013 (0.397 sec/step)\n",
            "I0205 13:43:21.844858 140689526667136 learning.py:507] global step 3718: loss = 0.1013 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 3719: loss = 0.1069 (0.374 sec/step)\n",
            "I0205 13:43:22.220837 140689526667136 learning.py:507] global step 3719: loss = 0.1069 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 3720: loss = 0.1000 (0.404 sec/step)\n",
            "I0205 13:43:22.626859 140689526667136 learning.py:507] global step 3720: loss = 0.1000 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 3721: loss = 0.3329 (0.376 sec/step)\n",
            "I0205 13:43:23.004745 140689526667136 learning.py:507] global step 3721: loss = 0.3329 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 3722: loss = 0.5337 (0.397 sec/step)\n",
            "I0205 13:43:23.403199 140689526667136 learning.py:507] global step 3722: loss = 0.5337 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 3723: loss = 0.1621 (0.377 sec/step)\n",
            "I0205 13:43:23.781665 140689526667136 learning.py:507] global step 3723: loss = 0.1621 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 3724: loss = 0.0600 (0.383 sec/step)\n",
            "I0205 13:43:24.165747 140689526667136 learning.py:507] global step 3724: loss = 0.0600 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 3725: loss = 0.2244 (0.393 sec/step)\n",
            "I0205 13:43:24.560122 140689526667136 learning.py:507] global step 3725: loss = 0.2244 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 3726: loss = 0.0968 (0.378 sec/step)\n",
            "I0205 13:43:24.939872 140689526667136 learning.py:507] global step 3726: loss = 0.0968 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 3727: loss = 0.1837 (0.377 sec/step)\n",
            "I0205 13:43:25.318659 140689526667136 learning.py:507] global step 3727: loss = 0.1837 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 3728: loss = 0.0568 (0.419 sec/step)\n",
            "I0205 13:43:25.739465 140689526667136 learning.py:507] global step 3728: loss = 0.0568 (0.419 sec/step)\n",
            "INFO:tensorflow:global step 3729: loss = 0.3456 (0.396 sec/step)\n",
            "I0205 13:43:26.137362 140689526667136 learning.py:507] global step 3729: loss = 0.3456 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 3730: loss = 0.1863 (0.386 sec/step)\n",
            "I0205 13:43:26.524661 140689526667136 learning.py:507] global step 3730: loss = 0.1863 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 3731: loss = 0.1910 (0.401 sec/step)\n",
            "I0205 13:43:26.927790 140689526667136 learning.py:507] global step 3731: loss = 0.1910 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 3732: loss = 0.0747 (0.386 sec/step)\n",
            "I0205 13:43:27.315527 140689526667136 learning.py:507] global step 3732: loss = 0.0747 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 3733: loss = 0.1672 (0.389 sec/step)\n",
            "I0205 13:43:27.706011 140689526667136 learning.py:507] global step 3733: loss = 0.1672 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 3734: loss = 1.1177 (0.382 sec/step)\n",
            "I0205 13:43:28.089461 140689526667136 learning.py:507] global step 3734: loss = 1.1177 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 3735: loss = 0.1151 (0.374 sec/step)\n",
            "I0205 13:43:28.465357 140689526667136 learning.py:507] global step 3735: loss = 0.1151 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 3736: loss = 0.1633 (0.408 sec/step)\n",
            "I0205 13:43:28.875635 140689526667136 learning.py:507] global step 3736: loss = 0.1633 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 3737: loss = 0.1374 (0.372 sec/step)\n",
            "I0205 13:43:29.249300 140689526667136 learning.py:507] global step 3737: loss = 0.1374 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 3738: loss = 0.1813 (0.412 sec/step)\n",
            "I0205 13:43:29.662511 140689526667136 learning.py:507] global step 3738: loss = 0.1813 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 3739: loss = 0.2551 (0.440 sec/step)\n",
            "I0205 13:43:30.104479 140689526667136 learning.py:507] global step 3739: loss = 0.2551 (0.440 sec/step)\n",
            "INFO:tensorflow:global step 3740: loss = 0.2980 (0.398 sec/step)\n",
            "I0205 13:43:30.504357 140689526667136 learning.py:507] global step 3740: loss = 0.2980 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 3741: loss = 0.0857 (0.423 sec/step)\n",
            "I0205 13:43:30.929942 140689526667136 learning.py:507] global step 3741: loss = 0.0857 (0.423 sec/step)\n",
            "INFO:tensorflow:global step 3742: loss = 0.1663 (0.414 sec/step)\n",
            "I0205 13:43:31.345827 140689526667136 learning.py:507] global step 3742: loss = 0.1663 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 3743: loss = 0.2275 (0.436 sec/step)\n",
            "I0205 13:43:31.783745 140689526667136 learning.py:507] global step 3743: loss = 0.2275 (0.436 sec/step)\n",
            "INFO:tensorflow:global step 3744: loss = 0.6777 (0.407 sec/step)\n",
            "I0205 13:43:32.192041 140689526667136 learning.py:507] global step 3744: loss = 0.6777 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 3745: loss = 0.1294 (0.381 sec/step)\n",
            "I0205 13:43:32.574319 140689526667136 learning.py:507] global step 3745: loss = 0.1294 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 3746: loss = 0.1206 (0.419 sec/step)\n",
            "I0205 13:43:32.994985 140689526667136 learning.py:507] global step 3746: loss = 0.1206 (0.419 sec/step)\n",
            "INFO:tensorflow:global step 3747: loss = 0.0461 (0.380 sec/step)\n",
            "I0205 13:43:33.376802 140689526667136 learning.py:507] global step 3747: loss = 0.0461 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 3748: loss = 0.2088 (0.382 sec/step)\n",
            "I0205 13:43:33.760483 140689526667136 learning.py:507] global step 3748: loss = 0.2088 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 3749: loss = 0.0398 (0.404 sec/step)\n",
            "I0205 13:43:34.166313 140689526667136 learning.py:507] global step 3749: loss = 0.0398 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 3750: loss = 0.1130 (0.393 sec/step)\n",
            "I0205 13:43:34.561457 140689526667136 learning.py:507] global step 3750: loss = 0.1130 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 3751: loss = 0.0878 (0.391 sec/step)\n",
            "I0205 13:43:34.953768 140689526667136 learning.py:507] global step 3751: loss = 0.0878 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 3752: loss = 0.0701 (0.370 sec/step)\n",
            "I0205 13:43:35.325468 140689526667136 learning.py:507] global step 3752: loss = 0.0701 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 3753: loss = 0.1304 (0.387 sec/step)\n",
            "I0205 13:43:35.714618 140689526667136 learning.py:507] global step 3753: loss = 0.1304 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 3754: loss = 0.1560 (0.377 sec/step)\n",
            "I0205 13:43:36.093645 140689526667136 learning.py:507] global step 3754: loss = 0.1560 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 3755: loss = 0.0546 (0.395 sec/step)\n",
            "I0205 13:43:36.490427 140689526667136 learning.py:507] global step 3755: loss = 0.0546 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 3756: loss = 0.1926 (0.392 sec/step)\n",
            "I0205 13:43:36.884220 140689526667136 learning.py:507] global step 3756: loss = 0.1926 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 3757: loss = 0.1222 (0.388 sec/step)\n",
            "I0205 13:43:37.273706 140689526667136 learning.py:507] global step 3757: loss = 0.1222 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 3758: loss = 0.0675 (0.384 sec/step)\n",
            "I0205 13:43:37.659691 140689526667136 learning.py:507] global step 3758: loss = 0.0675 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 3759: loss = 0.1493 (0.375 sec/step)\n",
            "I0205 13:43:38.036308 140689526667136 learning.py:507] global step 3759: loss = 0.1493 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 3760: loss = 0.2070 (0.394 sec/step)\n",
            "I0205 13:43:38.432137 140689526667136 learning.py:507] global step 3760: loss = 0.2070 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 3761: loss = 0.1108 (0.377 sec/step)\n",
            "I0205 13:43:38.811038 140689526667136 learning.py:507] global step 3761: loss = 0.1108 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 3762: loss = 0.6958 (0.385 sec/step)\n",
            "I0205 13:43:39.197983 140689526667136 learning.py:507] global step 3762: loss = 0.6958 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3763: loss = 0.4705 (0.416 sec/step)\n",
            "I0205 13:43:39.616393 140689526667136 learning.py:507] global step 3763: loss = 0.4705 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 3764: loss = 0.0648 (0.401 sec/step)\n",
            "I0205 13:43:40.019478 140689526667136 learning.py:507] global step 3764: loss = 0.0648 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 3765: loss = 0.0533 (0.409 sec/step)\n",
            "I0205 13:43:40.430612 140689526667136 learning.py:507] global step 3765: loss = 0.0533 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 3766: loss = 0.0991 (0.376 sec/step)\n",
            "I0205 13:43:40.808155 140689526667136 learning.py:507] global step 3766: loss = 0.0991 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 3767: loss = 0.2026 (0.388 sec/step)\n",
            "I0205 13:43:41.197913 140689526667136 learning.py:507] global step 3767: loss = 0.2026 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 3768: loss = 0.1922 (0.378 sec/step)\n",
            "I0205 13:43:41.577708 140689526667136 learning.py:507] global step 3768: loss = 0.1922 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 3769: loss = 0.1544 (0.381 sec/step)\n",
            "I0205 13:43:41.960499 140689526667136 learning.py:507] global step 3769: loss = 0.1544 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 3770: loss = 0.0636 (0.396 sec/step)\n",
            "I0205 13:43:42.358437 140689526667136 learning.py:507] global step 3770: loss = 0.0636 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 3771: loss = 0.2314 (0.410 sec/step)\n",
            "I0205 13:43:42.769841 140689526667136 learning.py:507] global step 3771: loss = 0.2314 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 3772: loss = 0.3066 (0.379 sec/step)\n",
            "I0205 13:43:43.150198 140689526667136 learning.py:507] global step 3772: loss = 0.3066 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 3773: loss = 0.0760 (0.389 sec/step)\n",
            "I0205 13:43:43.540753 140689526667136 learning.py:507] global step 3773: loss = 0.0760 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 3774: loss = 0.1297 (0.404 sec/step)\n",
            "I0205 13:43:43.946285 140689526667136 learning.py:507] global step 3774: loss = 0.1297 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 3775: loss = 0.0685 (0.391 sec/step)\n",
            "I0205 13:43:44.338880 140689526667136 learning.py:507] global step 3775: loss = 0.0685 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 3776: loss = 0.0530 (0.386 sec/step)\n",
            "I0205 13:43:44.726559 140689526667136 learning.py:507] global step 3776: loss = 0.0530 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 3777: loss = 0.1423 (0.344 sec/step)\n",
            "I0205 13:43:45.072053 140689526667136 learning.py:507] global step 3777: loss = 0.1423 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 3778: loss = 1.3946 (0.393 sec/step)\n",
            "I0205 13:43:45.466714 140689526667136 learning.py:507] global step 3778: loss = 1.3946 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 3779: loss = 0.1741 (0.407 sec/step)\n",
            "I0205 13:43:45.875465 140689526667136 learning.py:507] global step 3779: loss = 0.1741 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 3780: loss = 0.2694 (0.390 sec/step)\n",
            "I0205 13:43:46.266914 140689526667136 learning.py:507] global step 3780: loss = 0.2694 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3781: loss = 0.1613 (0.388 sec/step)\n",
            "I0205 13:43:46.656413 140689526667136 learning.py:507] global step 3781: loss = 0.1613 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 3782: loss = 0.0802 (0.402 sec/step)\n",
            "I0205 13:43:47.059910 140689526667136 learning.py:507] global step 3782: loss = 0.0802 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 3783: loss = 0.0768 (0.406 sec/step)\n",
            "I0205 13:43:47.467770 140689526667136 learning.py:507] global step 3783: loss = 0.0768 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 3784: loss = 0.3345 (0.389 sec/step)\n",
            "I0205 13:43:47.862559 140689526667136 learning.py:507] global step 3784: loss = 0.3345 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 3785: loss = 0.0371 (0.394 sec/step)\n",
            "I0205 13:43:48.258612 140689526667136 learning.py:507] global step 3785: loss = 0.0371 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 3786: loss = 0.0571 (0.392 sec/step)\n",
            "I0205 13:43:48.652144 140689526667136 learning.py:507] global step 3786: loss = 0.0571 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 3787: loss = 0.1631 (0.412 sec/step)\n",
            "I0205 13:43:49.065955 140689526667136 learning.py:507] global step 3787: loss = 0.1631 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 3788: loss = 0.3786 (0.389 sec/step)\n",
            "I0205 13:43:49.456843 140689526667136 learning.py:507] global step 3788: loss = 0.3786 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 3789: loss = 0.0985 (0.395 sec/step)\n",
            "I0205 13:43:49.853573 140689526667136 learning.py:507] global step 3789: loss = 0.0985 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 3790: loss = 0.1190 (0.404 sec/step)\n",
            "I0205 13:43:50.258923 140689526667136 learning.py:507] global step 3790: loss = 0.1190 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 3791: loss = 0.2643 (0.393 sec/step)\n",
            "I0205 13:43:50.654202 140689526667136 learning.py:507] global step 3791: loss = 0.2643 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 3792: loss = 0.3606 (0.403 sec/step)\n",
            "I0205 13:43:51.059205 140689526667136 learning.py:507] global step 3792: loss = 0.3606 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 3793: loss = 0.1806 (0.371 sec/step)\n",
            "I0205 13:43:51.433107 140689526667136 learning.py:507] global step 3793: loss = 0.1806 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 3794: loss = 0.2627 (0.378 sec/step)\n",
            "I0205 13:43:51.813362 140689526667136 learning.py:507] global step 3794: loss = 0.2627 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 3795: loss = 0.5471 (0.395 sec/step)\n",
            "I0205 13:43:52.209885 140689526667136 learning.py:507] global step 3795: loss = 0.5471 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 3796: loss = 0.1184 (0.427 sec/step)\n",
            "I0205 13:43:52.638683 140689526667136 learning.py:507] global step 3796: loss = 0.1184 (0.427 sec/step)\n",
            "INFO:tensorflow:global step 3797: loss = 0.3910 (0.418 sec/step)\n",
            "I0205 13:43:53.058519 140689526667136 learning.py:507] global step 3797: loss = 0.3910 (0.418 sec/step)\n",
            "INFO:tensorflow:global step 3798: loss = 0.0712 (0.389 sec/step)\n",
            "I0205 13:43:53.449067 140689526667136 learning.py:507] global step 3798: loss = 0.0712 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 3799: loss = 0.2064 (0.390 sec/step)\n",
            "I0205 13:43:53.840876 140689526667136 learning.py:507] global step 3799: loss = 0.2064 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3800: loss = 0.0948 (0.376 sec/step)\n",
            "I0205 13:43:54.218834 140689526667136 learning.py:507] global step 3800: loss = 0.0948 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 3801: loss = 0.0680 (0.393 sec/step)\n",
            "I0205 13:43:54.613466 140689526667136 learning.py:507] global step 3801: loss = 0.0680 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 3802: loss = 0.1707 (0.363 sec/step)\n",
            "I0205 13:43:54.977945 140689526667136 learning.py:507] global step 3802: loss = 0.1707 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 3803: loss = 0.4505 (0.390 sec/step)\n",
            "I0205 13:43:55.369460 140689526667136 learning.py:507] global step 3803: loss = 0.4505 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3804: loss = 0.0479 (0.398 sec/step)\n",
            "I0205 13:43:55.769065 140689526667136 learning.py:507] global step 3804: loss = 0.0479 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 3805: loss = 0.1542 (0.374 sec/step)\n",
            "I0205 13:43:56.144763 140689526667136 learning.py:507] global step 3805: loss = 0.1542 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 3806: loss = 0.0248 (0.381 sec/step)\n",
            "I0205 13:43:56.527190 140689526667136 learning.py:507] global step 3806: loss = 0.0248 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 3807: loss = 0.1518 (0.376 sec/step)\n",
            "I0205 13:43:56.905321 140689526667136 learning.py:507] global step 3807: loss = 0.1518 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 3808: loss = 0.0230 (0.399 sec/step)\n",
            "I0205 13:43:57.305743 140689526667136 learning.py:507] global step 3808: loss = 0.0230 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 3809: loss = 0.4877 (0.374 sec/step)\n",
            "I0205 13:43:57.681294 140689526667136 learning.py:507] global step 3809: loss = 0.4877 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 3810: loss = 0.0405 (0.384 sec/step)\n",
            "I0205 13:43:58.066854 140689526667136 learning.py:507] global step 3810: loss = 0.0405 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 3811: loss = 0.2512 (0.400 sec/step)\n",
            "I0205 13:43:58.468908 140689526667136 learning.py:507] global step 3811: loss = 0.2512 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 3812: loss = 0.2739 (0.386 sec/step)\n",
            "I0205 13:43:58.856867 140689526667136 learning.py:507] global step 3812: loss = 0.2739 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 3813: loss = 0.1826 (0.390 sec/step)\n",
            "I0205 13:43:59.248373 140689526667136 learning.py:507] global step 3813: loss = 0.1826 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3814: loss = 0.2309 (0.383 sec/step)\n",
            "I0205 13:43:59.632577 140689526667136 learning.py:507] global step 3814: loss = 0.2309 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 3815: loss = 0.0523 (0.377 sec/step)\n",
            "I0205 13:44:00.011113 140689526667136 learning.py:507] global step 3815: loss = 0.0523 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 3816: loss = 0.2582 (0.397 sec/step)\n",
            "I0205 13:44:00.409339 140689526667136 learning.py:507] global step 3816: loss = 0.2582 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 3817: loss = 0.0728 (0.388 sec/step)\n",
            "I0205 13:44:00.798989 140689526667136 learning.py:507] global step 3817: loss = 0.0728 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 3818: loss = 0.0925 (0.375 sec/step)\n",
            "I0205 13:44:01.176118 140689526667136 learning.py:507] global step 3818: loss = 0.0925 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 3819: loss = 0.5733 (0.382 sec/step)\n",
            "I0205 13:44:01.560473 140689526667136 learning.py:507] global step 3819: loss = 0.5733 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 3820: loss = 0.1437 (0.388 sec/step)\n",
            "I0205 13:44:01.949779 140689526667136 learning.py:507] global step 3820: loss = 0.1437 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 3821: loss = 0.0881 (0.381 sec/step)\n",
            "I0205 13:44:02.332209 140689526667136 learning.py:507] global step 3821: loss = 0.0881 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 3822: loss = 0.0347 (0.362 sec/step)\n",
            "I0205 13:44:02.695136 140689526667136 learning.py:507] global step 3822: loss = 0.0347 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 3823: loss = 0.2909 (0.390 sec/step)\n",
            "I0205 13:44:03.086434 140689526667136 learning.py:507] global step 3823: loss = 0.2909 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3824: loss = 0.2303 (0.379 sec/step)\n",
            "I0205 13:44:03.467758 140689526667136 learning.py:507] global step 3824: loss = 0.2303 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 3825: loss = 0.5585 (0.369 sec/step)\n",
            "I0205 13:44:03.838296 140689526667136 learning.py:507] global step 3825: loss = 0.5585 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 3826: loss = 0.0417 (0.410 sec/step)\n",
            "I0205 13:44:04.250002 140689526667136 learning.py:507] global step 3826: loss = 0.0417 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 3827: loss = 0.2949 (0.389 sec/step)\n",
            "I0205 13:44:04.640866 140689526667136 learning.py:507] global step 3827: loss = 0.2949 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 3828: loss = 0.2224 (0.382 sec/step)\n",
            "I0205 13:44:05.024905 140689526667136 learning.py:507] global step 3828: loss = 0.2224 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 3829: loss = 0.1036 (0.388 sec/step)\n",
            "I0205 13:44:05.414240 140689526667136 learning.py:507] global step 3829: loss = 0.1036 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 3830: loss = 0.1124 (0.362 sec/step)\n",
            "I0205 13:44:05.778197 140689526667136 learning.py:507] global step 3830: loss = 0.1124 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 3831: loss = 0.0590 (0.407 sec/step)\n",
            "I0205 13:44:06.186442 140689526667136 learning.py:507] global step 3831: loss = 0.0590 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 3832: loss = 0.2032 (0.382 sec/step)\n",
            "I0205 13:44:06.570398 140689526667136 learning.py:507] global step 3832: loss = 0.2032 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 3833: loss = 0.1040 (0.352 sec/step)\n",
            "I0205 13:44:06.923706 140689526667136 learning.py:507] global step 3833: loss = 0.1040 (0.352 sec/step)\n",
            "INFO:tensorflow:global step 3834: loss = 0.1260 (0.361 sec/step)\n",
            "I0205 13:44:07.286260 140689526667136 learning.py:507] global step 3834: loss = 0.1260 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 3835: loss = 0.2663 (0.373 sec/step)\n",
            "I0205 13:44:07.660575 140689526667136 learning.py:507] global step 3835: loss = 0.2663 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 3836: loss = 0.2376 (0.392 sec/step)\n",
            "I0205 13:44:08.054444 140689526667136 learning.py:507] global step 3836: loss = 0.2376 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 3837: loss = 0.3255 (0.382 sec/step)\n",
            "I0205 13:44:08.437955 140689526667136 learning.py:507] global step 3837: loss = 0.3255 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 3838: loss = 0.3721 (0.394 sec/step)\n",
            "I0205 13:44:08.833579 140689526667136 learning.py:507] global step 3838: loss = 0.3721 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 3839: loss = 0.0647 (0.415 sec/step)\n",
            "I0205 13:44:09.250590 140689526667136 learning.py:507] global step 3839: loss = 0.0647 (0.415 sec/step)\n",
            "INFO:tensorflow:global step 3840: loss = 0.2040 (0.369 sec/step)\n",
            "I0205 13:44:09.621092 140689526667136 learning.py:507] global step 3840: loss = 0.2040 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 3841: loss = 0.2788 (0.362 sec/step)\n",
            "I0205 13:44:09.984828 140689526667136 learning.py:507] global step 3841: loss = 0.2788 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 3842: loss = 0.0659 (0.407 sec/step)\n",
            "I0205 13:44:10.392853 140689526667136 learning.py:507] global step 3842: loss = 0.0659 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 3843: loss = 0.2737 (0.360 sec/step)\n",
            "I0205 13:44:10.754255 140689526667136 learning.py:507] global step 3843: loss = 0.2737 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 3844: loss = 0.1882 (0.393 sec/step)\n",
            "I0205 13:44:11.149373 140689526667136 learning.py:507] global step 3844: loss = 0.1882 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 3845: loss = 0.0216 (0.357 sec/step)\n",
            "I0205 13:44:11.507966 140689526667136 learning.py:507] global step 3845: loss = 0.0216 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 3846: loss = 0.1527 (0.385 sec/step)\n",
            "I0205 13:44:11.894644 140689526667136 learning.py:507] global step 3846: loss = 0.1527 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3847: loss = 0.2024 (0.398 sec/step)\n",
            "I0205 13:44:12.294740 140689526667136 learning.py:507] global step 3847: loss = 0.2024 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 3848: loss = 0.2435 (0.347 sec/step)\n",
            "I0205 13:44:12.643026 140689526667136 learning.py:507] global step 3848: loss = 0.2435 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 3849: loss = 0.0405 (0.385 sec/step)\n",
            "I0205 13:44:13.030021 140689526667136 learning.py:507] global step 3849: loss = 0.0405 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3850: loss = 0.2507 (0.405 sec/step)\n",
            "I0205 13:44:13.436584 140689526667136 learning.py:507] global step 3850: loss = 0.2507 (0.405 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path ../training/model.ckpt\n",
            "I0205 13:44:13.745397 140686000895744 supervisor.py:1117] Saving checkpoint to path ../training/model.ckpt\n",
            "INFO:tensorflow:global step 3851: loss = 0.1850 (1.603 sec/step)\n",
            "I0205 13:44:15.509907 140689526667136 learning.py:507] global step 3851: loss = 0.1850 (1.603 sec/step)\n",
            "INFO:tensorflow:global step 3852: loss = 0.1086 (1.400 sec/step)\n",
            "I0205 13:44:17.658672 140689526667136 learning.py:507] global step 3852: loss = 0.1086 (1.400 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 3852.\n",
            "I0205 13:44:17.999813 140686026073856 supervisor.py:1050] Recording summary at step 3852.\n",
            "INFO:tensorflow:global step 3853: loss = 0.1052 (0.513 sec/step)\n",
            "I0205 13:44:18.338091 140689526667136 learning.py:507] global step 3853: loss = 0.1052 (0.513 sec/step)\n",
            "INFO:tensorflow:global step 3854: loss = 0.0946 (0.377 sec/step)\n",
            "I0205 13:44:18.716657 140689526667136 learning.py:507] global step 3854: loss = 0.0946 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 3855: loss = 0.2603 (0.397 sec/step)\n",
            "I0205 13:44:19.119187 140689526667136 learning.py:507] global step 3855: loss = 0.2603 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 3856: loss = 0.2664 (0.411 sec/step)\n",
            "I0205 13:44:19.532526 140689526667136 learning.py:507] global step 3856: loss = 0.2664 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 3857: loss = 0.1387 (0.380 sec/step)\n",
            "I0205 13:44:19.914585 140689526667136 learning.py:507] global step 3857: loss = 0.1387 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 3858: loss = 0.0652 (0.373 sec/step)\n",
            "I0205 13:44:20.289498 140689526667136 learning.py:507] global step 3858: loss = 0.0652 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 3859: loss = 0.1801 (0.387 sec/step)\n",
            "I0205 13:44:20.678233 140689526667136 learning.py:507] global step 3859: loss = 0.1801 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 3860: loss = 0.4634 (0.411 sec/step)\n",
            "I0205 13:44:21.091537 140689526667136 learning.py:507] global step 3860: loss = 0.4634 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 3861: loss = 0.1651 (0.419 sec/step)\n",
            "I0205 13:44:21.512146 140689526667136 learning.py:507] global step 3861: loss = 0.1651 (0.419 sec/step)\n",
            "INFO:tensorflow:global step 3862: loss = 0.0301 (0.362 sec/step)\n",
            "I0205 13:44:21.876030 140689526667136 learning.py:507] global step 3862: loss = 0.0301 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 3863: loss = 0.0196 (0.365 sec/step)\n",
            "I0205 13:44:22.242791 140689526667136 learning.py:507] global step 3863: loss = 0.0196 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 3864: loss = 0.1641 (0.356 sec/step)\n",
            "I0205 13:44:22.600328 140689526667136 learning.py:507] global step 3864: loss = 0.1641 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 3865: loss = 0.0307 (0.402 sec/step)\n",
            "I0205 13:44:23.004281 140689526667136 learning.py:507] global step 3865: loss = 0.0307 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 3866: loss = 0.0764 (0.402 sec/step)\n",
            "I0205 13:44:23.407754 140689526667136 learning.py:507] global step 3866: loss = 0.0764 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 3867: loss = 0.5447 (0.402 sec/step)\n",
            "I0205 13:44:23.811902 140689526667136 learning.py:507] global step 3867: loss = 0.5447 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 3868: loss = 0.1963 (0.388 sec/step)\n",
            "I0205 13:44:24.201758 140689526667136 learning.py:507] global step 3868: loss = 0.1963 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 3869: loss = 0.3639 (0.346 sec/step)\n",
            "I0205 13:44:24.548909 140689526667136 learning.py:507] global step 3869: loss = 0.3639 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 3870: loss = 0.1602 (0.385 sec/step)\n",
            "I0205 13:44:24.935221 140689526667136 learning.py:507] global step 3870: loss = 0.1602 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3871: loss = 0.1241 (0.381 sec/step)\n",
            "I0205 13:44:25.317928 140689526667136 learning.py:507] global step 3871: loss = 0.1241 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 3872: loss = 0.1233 (0.393 sec/step)\n",
            "I0205 13:44:25.712620 140689526667136 learning.py:507] global step 3872: loss = 0.1233 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 3873: loss = 0.0152 (0.390 sec/step)\n",
            "I0205 13:44:26.104379 140689526667136 learning.py:507] global step 3873: loss = 0.0152 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3874: loss = 0.2145 (0.394 sec/step)\n",
            "I0205 13:44:26.499693 140689526667136 learning.py:507] global step 3874: loss = 0.2145 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 3875: loss = 0.2128 (0.402 sec/step)\n",
            "I0205 13:44:26.903291 140689526667136 learning.py:507] global step 3875: loss = 0.2128 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 3876: loss = 0.0935 (0.380 sec/step)\n",
            "I0205 13:44:27.284395 140689526667136 learning.py:507] global step 3876: loss = 0.0935 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 3877: loss = 0.6013 (0.411 sec/step)\n",
            "I0205 13:44:27.696858 140689526667136 learning.py:507] global step 3877: loss = 0.6013 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 3878: loss = 0.0419 (0.415 sec/step)\n",
            "I0205 13:44:28.113650 140689526667136 learning.py:507] global step 3878: loss = 0.0419 (0.415 sec/step)\n",
            "INFO:tensorflow:global step 3879: loss = 0.1922 (0.373 sec/step)\n",
            "I0205 13:44:28.488320 140689526667136 learning.py:507] global step 3879: loss = 0.1922 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 3880: loss = 0.3578 (0.377 sec/step)\n",
            "I0205 13:44:28.866706 140689526667136 learning.py:507] global step 3880: loss = 0.3578 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 3881: loss = 0.2474 (0.404 sec/step)\n",
            "I0205 13:44:29.272258 140689526667136 learning.py:507] global step 3881: loss = 0.2474 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 3882: loss = 0.0468 (0.424 sec/step)\n",
            "I0205 13:44:29.699075 140689526667136 learning.py:507] global step 3882: loss = 0.0468 (0.424 sec/step)\n",
            "INFO:tensorflow:global step 3883: loss = 0.0594 (0.411 sec/step)\n",
            "I0205 13:44:30.112052 140689526667136 learning.py:507] global step 3883: loss = 0.0594 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 3884: loss = 0.3512 (0.416 sec/step)\n",
            "I0205 13:44:30.529771 140689526667136 learning.py:507] global step 3884: loss = 0.3512 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 3885: loss = 0.1250 (0.449 sec/step)\n",
            "I0205 13:44:30.980706 140689526667136 learning.py:507] global step 3885: loss = 0.1250 (0.449 sec/step)\n",
            "INFO:tensorflow:global step 3886: loss = 0.0477 (0.420 sec/step)\n",
            "I0205 13:44:31.402217 140689526667136 learning.py:507] global step 3886: loss = 0.0477 (0.420 sec/step)\n",
            "INFO:tensorflow:global step 3887: loss = 0.5752 (0.434 sec/step)\n",
            "I0205 13:44:31.838044 140689526667136 learning.py:507] global step 3887: loss = 0.5752 (0.434 sec/step)\n",
            "INFO:tensorflow:global step 3888: loss = 0.1101 (0.392 sec/step)\n",
            "I0205 13:44:32.231421 140689526667136 learning.py:507] global step 3888: loss = 0.1101 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 3889: loss = 0.5305 (0.385 sec/step)\n",
            "I0205 13:44:32.617767 140689526667136 learning.py:507] global step 3889: loss = 0.5305 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3890: loss = 0.0303 (0.417 sec/step)\n",
            "I0205 13:44:33.036854 140689526667136 learning.py:507] global step 3890: loss = 0.0303 (0.417 sec/step)\n",
            "INFO:tensorflow:global step 3891: loss = 0.0687 (0.388 sec/step)\n",
            "I0205 13:44:33.427394 140689526667136 learning.py:507] global step 3891: loss = 0.0687 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 3892: loss = 0.0891 (0.399 sec/step)\n",
            "I0205 13:44:33.828472 140689526667136 learning.py:507] global step 3892: loss = 0.0891 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 3893: loss = 0.1300 (0.389 sec/step)\n",
            "I0205 13:44:34.219572 140689526667136 learning.py:507] global step 3893: loss = 0.1300 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 3894: loss = 0.0574 (0.372 sec/step)\n",
            "I0205 13:44:34.592656 140689526667136 learning.py:507] global step 3894: loss = 0.0574 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 3895: loss = 0.0286 (0.365 sec/step)\n",
            "I0205 13:44:34.959619 140689526667136 learning.py:507] global step 3895: loss = 0.0286 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 3896: loss = 0.1357 (0.392 sec/step)\n",
            "I0205 13:44:35.353085 140689526667136 learning.py:507] global step 3896: loss = 0.1357 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 3897: loss = 0.0364 (0.372 sec/step)\n",
            "I0205 13:44:35.726645 140689526667136 learning.py:507] global step 3897: loss = 0.0364 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 3898: loss = 0.1063 (0.391 sec/step)\n",
            "I0205 13:44:36.119359 140689526667136 learning.py:507] global step 3898: loss = 0.1063 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 3899: loss = 0.2100 (0.379 sec/step)\n",
            "I0205 13:44:36.499976 140689526667136 learning.py:507] global step 3899: loss = 0.2100 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 3900: loss = 0.1677 (0.399 sec/step)\n",
            "I0205 13:44:36.900784 140689526667136 learning.py:507] global step 3900: loss = 0.1677 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 3901: loss = 0.0512 (0.401 sec/step)\n",
            "I0205 13:44:37.303259 140689526667136 learning.py:507] global step 3901: loss = 0.0512 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 3902: loss = 0.0888 (0.381 sec/step)\n",
            "I0205 13:44:37.685302 140689526667136 learning.py:507] global step 3902: loss = 0.0888 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 3903: loss = 0.0914 (0.409 sec/step)\n",
            "I0205 13:44:38.095925 140689526667136 learning.py:507] global step 3903: loss = 0.0914 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 3904: loss = 0.0799 (0.384 sec/step)\n",
            "I0205 13:44:38.482181 140689526667136 learning.py:507] global step 3904: loss = 0.0799 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 3905: loss = 0.0268 (0.400 sec/step)\n",
            "I0205 13:44:38.884223 140689526667136 learning.py:507] global step 3905: loss = 0.0268 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 3906: loss = 0.1453 (0.367 sec/step)\n",
            "I0205 13:44:39.253187 140689526667136 learning.py:507] global step 3906: loss = 0.1453 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 3907: loss = 0.0805 (0.343 sec/step)\n",
            "I0205 13:44:39.598193 140689526667136 learning.py:507] global step 3907: loss = 0.0805 (0.343 sec/step)\n",
            "INFO:tensorflow:global step 3908: loss = 0.1607 (0.397 sec/step)\n",
            "I0205 13:44:39.996273 140689526667136 learning.py:507] global step 3908: loss = 0.1607 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 3909: loss = 0.1436 (0.373 sec/step)\n",
            "I0205 13:44:40.371642 140689526667136 learning.py:507] global step 3909: loss = 0.1436 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 3910: loss = 0.2220 (0.359 sec/step)\n",
            "I0205 13:44:40.732398 140689526667136 learning.py:507] global step 3910: loss = 0.2220 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 3911: loss = 0.0313 (0.399 sec/step)\n",
            "I0205 13:44:41.133322 140689526667136 learning.py:507] global step 3911: loss = 0.0313 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 3912: loss = 0.1429 (0.382 sec/step)\n",
            "I0205 13:44:41.516536 140689526667136 learning.py:507] global step 3912: loss = 0.1429 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 3913: loss = 0.0973 (0.368 sec/step)\n",
            "I0205 13:44:41.886220 140689526667136 learning.py:507] global step 3913: loss = 0.0973 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 3914: loss = 0.5071 (0.394 sec/step)\n",
            "I0205 13:44:42.281992 140689526667136 learning.py:507] global step 3914: loss = 0.5071 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 3915: loss = 0.2998 (0.396 sec/step)\n",
            "I0205 13:44:42.680026 140689526667136 learning.py:507] global step 3915: loss = 0.2998 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 3916: loss = 0.0422 (0.395 sec/step)\n",
            "I0205 13:44:43.076092 140689526667136 learning.py:507] global step 3916: loss = 0.0422 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 3917: loss = 0.0758 (0.362 sec/step)\n",
            "I0205 13:44:43.439468 140689526667136 learning.py:507] global step 3917: loss = 0.0758 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 3918: loss = 0.0581 (0.368 sec/step)\n",
            "I0205 13:44:43.809112 140689526667136 learning.py:507] global step 3918: loss = 0.0581 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 3919: loss = 0.1383 (0.394 sec/step)\n",
            "I0205 13:44:44.204538 140689526667136 learning.py:507] global step 3919: loss = 0.1383 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 3920: loss = 0.1294 (0.370 sec/step)\n",
            "I0205 13:44:44.575431 140689526667136 learning.py:507] global step 3920: loss = 0.1294 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 3921: loss = 0.0464 (0.377 sec/step)\n",
            "I0205 13:44:44.953406 140689526667136 learning.py:507] global step 3921: loss = 0.0464 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 3922: loss = 0.1221 (0.402 sec/step)\n",
            "I0205 13:44:45.356461 140689526667136 learning.py:507] global step 3922: loss = 0.1221 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 3923: loss = 0.3209 (0.344 sec/step)\n",
            "I0205 13:44:45.701612 140689526667136 learning.py:507] global step 3923: loss = 0.3209 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 3924: loss = 0.0845 (0.370 sec/step)\n",
            "I0205 13:44:46.073476 140689526667136 learning.py:507] global step 3924: loss = 0.0845 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 3925: loss = 0.0441 (0.375 sec/step)\n",
            "I0205 13:44:46.449703 140689526667136 learning.py:507] global step 3925: loss = 0.0441 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 3926: loss = 0.0426 (0.353 sec/step)\n",
            "I0205 13:44:46.804278 140689526667136 learning.py:507] global step 3926: loss = 0.0426 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 3927: loss = 0.1467 (0.379 sec/step)\n",
            "I0205 13:44:47.184928 140689526667136 learning.py:507] global step 3927: loss = 0.1467 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 3928: loss = 0.2492 (0.381 sec/step)\n",
            "I0205 13:44:47.567177 140689526667136 learning.py:507] global step 3928: loss = 0.2492 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 3929: loss = 0.1115 (0.401 sec/step)\n",
            "I0205 13:44:47.969898 140689526667136 learning.py:507] global step 3929: loss = 0.1115 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 3930: loss = 0.3044 (0.372 sec/step)\n",
            "I0205 13:44:48.342982 140689526667136 learning.py:507] global step 3930: loss = 0.3044 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 3931: loss = 0.0426 (0.390 sec/step)\n",
            "I0205 13:44:48.734233 140689526667136 learning.py:507] global step 3931: loss = 0.0426 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3932: loss = 0.0963 (0.421 sec/step)\n",
            "I0205 13:44:49.157550 140689526667136 learning.py:507] global step 3932: loss = 0.0963 (0.421 sec/step)\n",
            "INFO:tensorflow:global step 3933: loss = 0.0811 (0.377 sec/step)\n",
            "I0205 13:44:49.536031 140689526667136 learning.py:507] global step 3933: loss = 0.0811 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 3934: loss = 0.0456 (0.392 sec/step)\n",
            "I0205 13:44:49.929976 140689526667136 learning.py:507] global step 3934: loss = 0.0456 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 3935: loss = 0.4134 (0.384 sec/step)\n",
            "I0205 13:44:50.316321 140689526667136 learning.py:507] global step 3935: loss = 0.4134 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 3936: loss = 0.1283 (0.360 sec/step)\n",
            "I0205 13:44:50.678881 140689526667136 learning.py:507] global step 3936: loss = 0.1283 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 3937: loss = 0.1571 (0.370 sec/step)\n",
            "I0205 13:44:51.050571 140689526667136 learning.py:507] global step 3937: loss = 0.1571 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 3938: loss = 0.0831 (0.397 sec/step)\n",
            "I0205 13:44:51.449658 140689526667136 learning.py:507] global step 3938: loss = 0.0831 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 3939: loss = 0.1528 (0.379 sec/step)\n",
            "I0205 13:44:51.830368 140689526667136 learning.py:507] global step 3939: loss = 0.1528 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 3940: loss = 0.2548 (0.405 sec/step)\n",
            "I0205 13:44:52.237607 140689526667136 learning.py:507] global step 3940: loss = 0.2548 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 3941: loss = 0.2792 (0.418 sec/step)\n",
            "I0205 13:44:52.657657 140689526667136 learning.py:507] global step 3941: loss = 0.2792 (0.418 sec/step)\n",
            "INFO:tensorflow:global step 3942: loss = 0.0381 (0.406 sec/step)\n",
            "I0205 13:44:53.066417 140689526667136 learning.py:507] global step 3942: loss = 0.0381 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 3943: loss = 0.0642 (0.408 sec/step)\n",
            "I0205 13:44:53.476422 140689526667136 learning.py:507] global step 3943: loss = 0.0642 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 3944: loss = 0.1165 (0.367 sec/step)\n",
            "I0205 13:44:53.844849 140689526667136 learning.py:507] global step 3944: loss = 0.1165 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 3945: loss = 0.0876 (0.372 sec/step)\n",
            "I0205 13:44:54.218807 140689526667136 learning.py:507] global step 3945: loss = 0.0876 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 3946: loss = 0.0278 (0.363 sec/step)\n",
            "I0205 13:44:54.583721 140689526667136 learning.py:507] global step 3946: loss = 0.0278 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 3947: loss = 0.0499 (0.381 sec/step)\n",
            "I0205 13:44:54.966137 140689526667136 learning.py:507] global step 3947: loss = 0.0499 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 3948: loss = 0.1862 (0.381 sec/step)\n",
            "I0205 13:44:55.348451 140689526667136 learning.py:507] global step 3948: loss = 0.1862 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 3949: loss = 0.7431 (0.361 sec/step)\n",
            "I0205 13:44:55.711664 140689526667136 learning.py:507] global step 3949: loss = 0.7431 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 3950: loss = 0.1231 (0.380 sec/step)\n",
            "I0205 13:44:56.093970 140689526667136 learning.py:507] global step 3950: loss = 0.1231 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 3951: loss = 0.1497 (0.409 sec/step)\n",
            "I0205 13:44:56.504838 140689526667136 learning.py:507] global step 3951: loss = 0.1497 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 3952: loss = 0.0401 (0.387 sec/step)\n",
            "I0205 13:44:56.893582 140689526667136 learning.py:507] global step 3952: loss = 0.0401 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 3953: loss = 0.0807 (0.379 sec/step)\n",
            "I0205 13:44:57.274597 140689526667136 learning.py:507] global step 3953: loss = 0.0807 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 3954: loss = 0.0835 (0.394 sec/step)\n",
            "I0205 13:44:57.670303 140689526667136 learning.py:507] global step 3954: loss = 0.0835 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 3955: loss = 0.2826 (0.377 sec/step)\n",
            "I0205 13:44:58.048739 140689526667136 learning.py:507] global step 3955: loss = 0.2826 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 3956: loss = 0.2250 (0.384 sec/step)\n",
            "I0205 13:44:58.435221 140689526667136 learning.py:507] global step 3956: loss = 0.2250 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 3957: loss = 0.1933 (0.392 sec/step)\n",
            "I0205 13:44:58.828821 140689526667136 learning.py:507] global step 3957: loss = 0.1933 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 3958: loss = 0.1783 (0.420 sec/step)\n",
            "I0205 13:44:59.251084 140689526667136 learning.py:507] global step 3958: loss = 0.1783 (0.420 sec/step)\n",
            "INFO:tensorflow:global step 3959: loss = 0.0576 (0.384 sec/step)\n",
            "I0205 13:44:59.636744 140689526667136 learning.py:507] global step 3959: loss = 0.0576 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 3960: loss = 0.0677 (0.372 sec/step)\n",
            "I0205 13:45:00.010529 140689526667136 learning.py:507] global step 3960: loss = 0.0677 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 3961: loss = 1.3757 (0.407 sec/step)\n",
            "I0205 13:45:00.420852 140689526667136 learning.py:507] global step 3961: loss = 1.3757 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 3962: loss = 0.2181 (0.339 sec/step)\n",
            "I0205 13:45:00.761986 140689526667136 learning.py:507] global step 3962: loss = 0.2181 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 3963: loss = 0.2337 (0.392 sec/step)\n",
            "I0205 13:45:01.155420 140689526667136 learning.py:507] global step 3963: loss = 0.2337 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 3964: loss = 0.2778 (0.383 sec/step)\n",
            "I0205 13:45:01.540097 140689526667136 learning.py:507] global step 3964: loss = 0.2778 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 3965: loss = 0.1654 (0.390 sec/step)\n",
            "I0205 13:45:01.931421 140689526667136 learning.py:507] global step 3965: loss = 0.1654 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3966: loss = 0.4044 (0.386 sec/step)\n",
            "I0205 13:45:02.318957 140689526667136 learning.py:507] global step 3966: loss = 0.4044 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 3967: loss = 0.1238 (0.389 sec/step)\n",
            "I0205 13:45:02.710037 140689526667136 learning.py:507] global step 3967: loss = 0.1238 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 3968: loss = 0.2593 (0.384 sec/step)\n",
            "I0205 13:45:03.096105 140689526667136 learning.py:507] global step 3968: loss = 0.2593 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 3969: loss = 0.3803 (0.401 sec/step)\n",
            "I0205 13:45:03.499485 140689526667136 learning.py:507] global step 3969: loss = 0.3803 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 3970: loss = 0.1897 (0.422 sec/step)\n",
            "I0205 13:45:03.923304 140689526667136 learning.py:507] global step 3970: loss = 0.1897 (0.422 sec/step)\n",
            "INFO:tensorflow:global step 3971: loss = 0.0642 (0.373 sec/step)\n",
            "I0205 13:45:04.298084 140689526667136 learning.py:507] global step 3971: loss = 0.0642 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 3972: loss = 0.5135 (0.351 sec/step)\n",
            "I0205 13:45:04.650387 140689526667136 learning.py:507] global step 3972: loss = 0.5135 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 3973: loss = 0.1107 (0.372 sec/step)\n",
            "I0205 13:45:05.024095 140689526667136 learning.py:507] global step 3973: loss = 0.1107 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 3974: loss = 0.1475 (0.365 sec/step)\n",
            "I0205 13:45:05.391156 140689526667136 learning.py:507] global step 3974: loss = 0.1475 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 3975: loss = 0.1412 (0.379 sec/step)\n",
            "I0205 13:45:05.771466 140689526667136 learning.py:507] global step 3975: loss = 0.1412 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 3976: loss = 0.2871 (0.373 sec/step)\n",
            "I0205 13:45:06.146835 140689526667136 learning.py:507] global step 3976: loss = 0.2871 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 3977: loss = 0.1293 (0.345 sec/step)\n",
            "I0205 13:45:06.493811 140689526667136 learning.py:507] global step 3977: loss = 0.1293 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 3978: loss = 0.0457 (0.366 sec/step)\n",
            "I0205 13:45:06.861708 140689526667136 learning.py:507] global step 3978: loss = 0.0457 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 3979: loss = 0.0701 (0.382 sec/step)\n",
            "I0205 13:45:07.245268 140689526667136 learning.py:507] global step 3979: loss = 0.0701 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 3980: loss = 0.0726 (0.390 sec/step)\n",
            "I0205 13:45:07.636482 140689526667136 learning.py:507] global step 3980: loss = 0.0726 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 3981: loss = 0.3299 (0.381 sec/step)\n",
            "I0205 13:45:08.019140 140689526667136 learning.py:507] global step 3981: loss = 0.3299 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 3982: loss = 0.2749 (0.406 sec/step)\n",
            "I0205 13:45:08.426796 140689526667136 learning.py:507] global step 3982: loss = 0.2749 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 3983: loss = 0.2510 (0.383 sec/step)\n",
            "I0205 13:45:08.811562 140689526667136 learning.py:507] global step 3983: loss = 0.2510 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 3984: loss = 0.1149 (0.391 sec/step)\n",
            "I0205 13:45:09.203868 140689526667136 learning.py:507] global step 3984: loss = 0.1149 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 3985: loss = 0.1015 (0.410 sec/step)\n",
            "I0205 13:45:09.615158 140689526667136 learning.py:507] global step 3985: loss = 0.1015 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 3986: loss = 0.1161 (0.393 sec/step)\n",
            "I0205 13:45:10.009937 140689526667136 learning.py:507] global step 3986: loss = 0.1161 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 3987: loss = 0.1179 (0.379 sec/step)\n",
            "I0205 13:45:10.390440 140689526667136 learning.py:507] global step 3987: loss = 0.1179 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 3988: loss = 0.3062 (0.402 sec/step)\n",
            "I0205 13:45:10.793805 140689526667136 learning.py:507] global step 3988: loss = 0.3062 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 3989: loss = 0.1009 (0.375 sec/step)\n",
            "I0205 13:45:11.170698 140689526667136 learning.py:507] global step 3989: loss = 0.1009 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 3990: loss = 0.1104 (0.385 sec/step)\n",
            "I0205 13:45:11.556940 140689526667136 learning.py:507] global step 3990: loss = 0.1104 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 3991: loss = 0.0554 (0.365 sec/step)\n",
            "I0205 13:45:11.923371 140689526667136 learning.py:507] global step 3991: loss = 0.0554 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 3992: loss = 0.0779 (0.351 sec/step)\n",
            "I0205 13:45:12.276115 140689526667136 learning.py:507] global step 3992: loss = 0.0779 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 3993: loss = 0.1247 (0.365 sec/step)\n",
            "I0205 13:45:12.643213 140689526667136 learning.py:507] global step 3993: loss = 0.1247 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 3994: loss = 0.0378 (0.365 sec/step)\n",
            "I0205 13:45:13.009755 140689526667136 learning.py:507] global step 3994: loss = 0.0378 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 3995: loss = 0.0923 (0.380 sec/step)\n",
            "I0205 13:45:13.390962 140689526667136 learning.py:507] global step 3995: loss = 0.0923 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 3996: loss = 0.2363 (0.392 sec/step)\n",
            "I0205 13:45:13.784452 140689526667136 learning.py:507] global step 3996: loss = 0.2363 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 3997: loss = 0.1101 (0.381 sec/step)\n",
            "I0205 13:45:14.167560 140689526667136 learning.py:507] global step 3997: loss = 0.1101 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 3998: loss = 0.1157 (0.367 sec/step)\n",
            "I0205 13:45:14.536148 140689526667136 learning.py:507] global step 3998: loss = 0.1157 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 3999: loss = 0.1202 (0.370 sec/step)\n",
            "I0205 13:45:14.907542 140689526667136 learning.py:507] global step 3999: loss = 0.1202 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 4000: loss = 0.1718 (0.391 sec/step)\n",
            "I0205 13:45:15.299804 140689526667136 learning.py:507] global step 4000: loss = 0.1718 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 4001: loss = 0.0630 (0.404 sec/step)\n",
            "I0205 13:45:15.705013 140689526667136 learning.py:507] global step 4001: loss = 0.0630 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 4002: loss = 0.1367 (0.377 sec/step)\n",
            "I0205 13:45:16.083284 140689526667136 learning.py:507] global step 4002: loss = 0.1367 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 4003: loss = 0.2740 (0.388 sec/step)\n",
            "I0205 13:45:16.473427 140689526667136 learning.py:507] global step 4003: loss = 0.2740 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 4004: loss = 0.2352 (0.396 sec/step)\n",
            "I0205 13:45:16.871224 140689526667136 learning.py:507] global step 4004: loss = 0.2352 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 4005: loss = 0.0971 (0.368 sec/step)\n",
            "I0205 13:45:17.240830 140689526667136 learning.py:507] global step 4005: loss = 0.0971 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 4006: loss = 0.2931 (0.382 sec/step)\n",
            "I0205 13:45:17.624040 140689526667136 learning.py:507] global step 4006: loss = 0.2931 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 4007: loss = 0.0678 (0.392 sec/step)\n",
            "I0205 13:45:18.017819 140689526667136 learning.py:507] global step 4007: loss = 0.0678 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 4008: loss = 0.4141 (0.381 sec/step)\n",
            "I0205 13:45:18.400414 140689526667136 learning.py:507] global step 4008: loss = 0.4141 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4009: loss = 0.1285 (0.377 sec/step)\n",
            "I0205 13:45:18.778996 140689526667136 learning.py:507] global step 4009: loss = 0.1285 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 4010: loss = 0.0795 (0.407 sec/step)\n",
            "I0205 13:45:19.187764 140689526667136 learning.py:507] global step 4010: loss = 0.0795 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 4011: loss = 0.1320 (0.392 sec/step)\n",
            "I0205 13:45:19.581955 140689526667136 learning.py:507] global step 4011: loss = 0.1320 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 4012: loss = 0.1247 (0.375 sec/step)\n",
            "I0205 13:45:19.958299 140689526667136 learning.py:507] global step 4012: loss = 0.1247 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 4013: loss = 0.0603 (0.366 sec/step)\n",
            "I0205 13:45:20.325876 140689526667136 learning.py:507] global step 4013: loss = 0.0603 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 4014: loss = 0.3020 (0.369 sec/step)\n",
            "I0205 13:45:20.696046 140689526667136 learning.py:507] global step 4014: loss = 0.3020 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 4015: loss = 0.2389 (0.380 sec/step)\n",
            "I0205 13:45:21.077559 140689526667136 learning.py:507] global step 4015: loss = 0.2389 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 4016: loss = 0.6217 (0.375 sec/step)\n",
            "I0205 13:45:21.454574 140689526667136 learning.py:507] global step 4016: loss = 0.6217 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 4017: loss = 0.1360 (0.394 sec/step)\n",
            "I0205 13:45:21.850656 140689526667136 learning.py:507] global step 4017: loss = 0.1360 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 4018: loss = 0.4738 (0.388 sec/step)\n",
            "I0205 13:45:22.240554 140689526667136 learning.py:507] global step 4018: loss = 0.4738 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 4019: loss = 0.0338 (0.375 sec/step)\n",
            "I0205 13:45:22.617533 140689526667136 learning.py:507] global step 4019: loss = 0.0338 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 4020: loss = 0.1119 (0.391 sec/step)\n",
            "I0205 13:45:23.010246 140689526667136 learning.py:507] global step 4020: loss = 0.1119 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 4021: loss = 0.2026 (0.377 sec/step)\n",
            "I0205 13:45:23.388500 140689526667136 learning.py:507] global step 4021: loss = 0.2026 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 4022: loss = 0.6699 (0.387 sec/step)\n",
            "I0205 13:45:23.776808 140689526667136 learning.py:507] global step 4022: loss = 0.6699 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 4023: loss = 0.1840 (0.382 sec/step)\n",
            "I0205 13:45:24.160810 140689526667136 learning.py:507] global step 4023: loss = 0.1840 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 4024: loss = 0.5248 (0.404 sec/step)\n",
            "I0205 13:45:24.566106 140689526667136 learning.py:507] global step 4024: loss = 0.5248 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 4025: loss = 0.2033 (0.398 sec/step)\n",
            "I0205 13:45:24.966084 140689526667136 learning.py:507] global step 4025: loss = 0.2033 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 4026: loss = 0.2034 (0.386 sec/step)\n",
            "I0205 13:45:25.354202 140689526667136 learning.py:507] global step 4026: loss = 0.2034 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 4027: loss = 0.0964 (0.372 sec/step)\n",
            "I0205 13:45:25.729014 140689526667136 learning.py:507] global step 4027: loss = 0.0964 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 4028: loss = 0.1490 (0.392 sec/step)\n",
            "I0205 13:45:26.122374 140689526667136 learning.py:507] global step 4028: loss = 0.1490 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 4029: loss = 0.1499 (0.381 sec/step)\n",
            "I0205 13:45:26.505182 140689526667136 learning.py:507] global step 4029: loss = 0.1499 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4030: loss = 0.8079 (0.362 sec/step)\n",
            "I0205 13:45:26.868860 140689526667136 learning.py:507] global step 4030: loss = 0.8079 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 4031: loss = 0.4507 (0.376 sec/step)\n",
            "I0205 13:45:27.246011 140689526667136 learning.py:507] global step 4031: loss = 0.4507 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 4032: loss = 0.1234 (0.376 sec/step)\n",
            "I0205 13:45:27.623709 140689526667136 learning.py:507] global step 4032: loss = 0.1234 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 4033: loss = 0.3869 (0.382 sec/step)\n",
            "I0205 13:45:28.007540 140689526667136 learning.py:507] global step 4033: loss = 0.3869 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 4034: loss = 0.1601 (0.386 sec/step)\n",
            "I0205 13:45:28.394894 140689526667136 learning.py:507] global step 4034: loss = 0.1601 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 4035: loss = 0.0581 (0.390 sec/step)\n",
            "I0205 13:45:28.786789 140689526667136 learning.py:507] global step 4035: loss = 0.0581 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 4036: loss = 0.4447 (0.403 sec/step)\n",
            "I0205 13:45:29.191121 140689526667136 learning.py:507] global step 4036: loss = 0.4447 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 4037: loss = 0.0672 (0.418 sec/step)\n",
            "I0205 13:45:29.611444 140689526667136 learning.py:507] global step 4037: loss = 0.0672 (0.418 sec/step)\n",
            "INFO:tensorflow:global step 4038: loss = 0.3027 (0.429 sec/step)\n",
            "I0205 13:45:30.042468 140689526667136 learning.py:507] global step 4038: loss = 0.3027 (0.429 sec/step)\n",
            "INFO:tensorflow:global step 4039: loss = 0.4742 (0.399 sec/step)\n",
            "I0205 13:45:30.443898 140689526667136 learning.py:507] global step 4039: loss = 0.4742 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 4040: loss = 0.1906 (0.385 sec/step)\n",
            "I0205 13:45:30.830695 140689526667136 learning.py:507] global step 4040: loss = 0.1906 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 4041: loss = 0.0968 (0.430 sec/step)\n",
            "I0205 13:45:31.262377 140689526667136 learning.py:507] global step 4041: loss = 0.0968 (0.430 sec/step)\n",
            "INFO:tensorflow:global step 4042: loss = 0.3314 (0.387 sec/step)\n",
            "I0205 13:45:31.651777 140689526667136 learning.py:507] global step 4042: loss = 0.3314 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 4043: loss = 0.0565 (0.386 sec/step)\n",
            "I0205 13:45:32.039593 140689526667136 learning.py:507] global step 4043: loss = 0.0565 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 4044: loss = 0.0443 (0.367 sec/step)\n",
            "I0205 13:45:32.408134 140689526667136 learning.py:507] global step 4044: loss = 0.0443 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 4045: loss = 0.1416 (0.360 sec/step)\n",
            "I0205 13:45:32.769995 140689526667136 learning.py:507] global step 4045: loss = 0.1416 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 4046: loss = 0.1063 (0.393 sec/step)\n",
            "I0205 13:45:33.164176 140689526667136 learning.py:507] global step 4046: loss = 0.1063 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 4047: loss = 0.1434 (0.358 sec/step)\n",
            "I0205 13:45:33.523510 140689526667136 learning.py:507] global step 4047: loss = 0.1434 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 4048: loss = 0.2313 (0.387 sec/step)\n",
            "I0205 13:45:33.912100 140689526667136 learning.py:507] global step 4048: loss = 0.2313 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 4049: loss = 0.1506 (0.353 sec/step)\n",
            "I0205 13:45:34.266791 140689526667136 learning.py:507] global step 4049: loss = 0.1506 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 4050: loss = 0.1655 (0.369 sec/step)\n",
            "I0205 13:45:34.637607 140689526667136 learning.py:507] global step 4050: loss = 0.1655 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 4051: loss = 0.0781 (0.378 sec/step)\n",
            "I0205 13:45:35.016945 140689526667136 learning.py:507] global step 4051: loss = 0.0781 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 4052: loss = 0.6600 (0.378 sec/step)\n",
            "I0205 13:45:35.396777 140689526667136 learning.py:507] global step 4052: loss = 0.6600 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 4053: loss = 0.2558 (0.374 sec/step)\n",
            "I0205 13:45:35.771897 140689526667136 learning.py:507] global step 4053: loss = 0.2558 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 4054: loss = 0.4157 (0.403 sec/step)\n",
            "I0205 13:45:36.176210 140689526667136 learning.py:507] global step 4054: loss = 0.4157 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 4055: loss = 0.2922 (0.358 sec/step)\n",
            "I0205 13:45:36.535583 140689526667136 learning.py:507] global step 4055: loss = 0.2922 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 4056: loss = 0.0782 (0.384 sec/step)\n",
            "I0205 13:45:36.921313 140689526667136 learning.py:507] global step 4056: loss = 0.0782 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 4057: loss = 0.0923 (0.373 sec/step)\n",
            "I0205 13:45:37.295860 140689526667136 learning.py:507] global step 4057: loss = 0.0923 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 4058: loss = 0.0956 (0.375 sec/step)\n",
            "I0205 13:45:37.672575 140689526667136 learning.py:507] global step 4058: loss = 0.0956 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 4059: loss = 0.0979 (0.369 sec/step)\n",
            "I0205 13:45:38.042995 140689526667136 learning.py:507] global step 4059: loss = 0.0979 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 4060: loss = 0.0427 (0.364 sec/step)\n",
            "I0205 13:45:38.409006 140689526667136 learning.py:507] global step 4060: loss = 0.0427 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 4061: loss = 0.0993 (0.359 sec/step)\n",
            "I0205 13:45:38.769154 140689526667136 learning.py:507] global step 4061: loss = 0.0993 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 4062: loss = 0.3583 (0.390 sec/step)\n",
            "I0205 13:45:39.160706 140689526667136 learning.py:507] global step 4062: loss = 0.3583 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 4063: loss = 0.0522 (0.408 sec/step)\n",
            "I0205 13:45:39.570328 140689526667136 learning.py:507] global step 4063: loss = 0.0522 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 4064: loss = 0.0583 (0.386 sec/step)\n",
            "I0205 13:45:39.958409 140689526667136 learning.py:507] global step 4064: loss = 0.0583 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 4065: loss = 0.5016 (0.377 sec/step)\n",
            "I0205 13:45:40.337305 140689526667136 learning.py:507] global step 4065: loss = 0.5016 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 4066: loss = 0.3033 (0.394 sec/step)\n",
            "I0205 13:45:40.732785 140689526667136 learning.py:507] global step 4066: loss = 0.3033 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 4067: loss = 0.1357 (0.391 sec/step)\n",
            "I0205 13:45:41.125119 140689526667136 learning.py:507] global step 4067: loss = 0.1357 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 4068: loss = 0.1927 (0.395 sec/step)\n",
            "I0205 13:45:41.521658 140689526667136 learning.py:507] global step 4068: loss = 0.1927 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 4069: loss = 0.0952 (0.366 sec/step)\n",
            "I0205 13:45:41.889870 140689526667136 learning.py:507] global step 4069: loss = 0.0952 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 4070: loss = 0.6204 (0.388 sec/step)\n",
            "I0205 13:45:42.279932 140689526667136 learning.py:507] global step 4070: loss = 0.6204 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 4071: loss = 0.1059 (0.398 sec/step)\n",
            "I0205 13:45:42.679949 140689526667136 learning.py:507] global step 4071: loss = 0.1059 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 4072: loss = 0.5859 (0.381 sec/step)\n",
            "I0205 13:45:43.063064 140689526667136 learning.py:507] global step 4072: loss = 0.5859 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4073: loss = 0.1360 (0.388 sec/step)\n",
            "I0205 13:45:43.453005 140689526667136 learning.py:507] global step 4073: loss = 0.1360 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 4074: loss = 0.0816 (0.413 sec/step)\n",
            "I0205 13:45:43.867994 140689526667136 learning.py:507] global step 4074: loss = 0.0816 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 4075: loss = 0.3356 (0.421 sec/step)\n",
            "I0205 13:45:44.291069 140689526667136 learning.py:507] global step 4075: loss = 0.3356 (0.421 sec/step)\n",
            "INFO:tensorflow:global step 4076: loss = 0.2268 (0.356 sec/step)\n",
            "I0205 13:45:44.648838 140689526667136 learning.py:507] global step 4076: loss = 0.2268 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 4077: loss = 0.0259 (0.379 sec/step)\n",
            "I0205 13:45:45.029661 140689526667136 learning.py:507] global step 4077: loss = 0.0259 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 4078: loss = 0.3381 (0.370 sec/step)\n",
            "I0205 13:45:45.401301 140689526667136 learning.py:507] global step 4078: loss = 0.3381 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 4079: loss = 0.2055 (0.355 sec/step)\n",
            "I0205 13:45:45.757755 140689526667136 learning.py:507] global step 4079: loss = 0.2055 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 4080: loss = 0.1302 (0.381 sec/step)\n",
            "I0205 13:45:46.142222 140689526667136 learning.py:507] global step 4080: loss = 0.1302 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4081: loss = 0.1015 (0.368 sec/step)\n",
            "I0205 13:45:46.511939 140689526667136 learning.py:507] global step 4081: loss = 0.1015 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 4082: loss = 0.0378 (0.359 sec/step)\n",
            "I0205 13:45:46.872075 140689526667136 learning.py:507] global step 4082: loss = 0.0378 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 4083: loss = 0.1368 (0.367 sec/step)\n",
            "I0205 13:45:47.240994 140689526667136 learning.py:507] global step 4083: loss = 0.1368 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 4084: loss = 0.0591 (0.408 sec/step)\n",
            "I0205 13:45:47.650381 140689526667136 learning.py:507] global step 4084: loss = 0.0591 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 4085: loss = 0.0466 (0.365 sec/step)\n",
            "I0205 13:45:48.017587 140689526667136 learning.py:507] global step 4085: loss = 0.0466 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 4086: loss = 0.2313 (0.375 sec/step)\n",
            "I0205 13:45:48.393851 140689526667136 learning.py:507] global step 4086: loss = 0.2313 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 4087: loss = 0.1817 (0.406 sec/step)\n",
            "I0205 13:45:48.801557 140689526667136 learning.py:507] global step 4087: loss = 0.1817 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 4088: loss = 0.1598 (0.389 sec/step)\n",
            "I0205 13:45:49.191670 140689526667136 learning.py:507] global step 4088: loss = 0.1598 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 4089: loss = 0.1916 (0.385 sec/step)\n",
            "I0205 13:45:49.578076 140689526667136 learning.py:507] global step 4089: loss = 0.1916 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 4090: loss = 0.7639 (0.402 sec/step)\n",
            "I0205 13:45:49.981551 140689526667136 learning.py:507] global step 4090: loss = 0.7639 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 4091: loss = 0.0978 (0.364 sec/step)\n",
            "I0205 13:45:50.346871 140689526667136 learning.py:507] global step 4091: loss = 0.0978 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 4092: loss = 0.1574 (0.414 sec/step)\n",
            "I0205 13:45:50.762338 140689526667136 learning.py:507] global step 4092: loss = 0.1574 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 4093: loss = 0.0766 (0.397 sec/step)\n",
            "I0205 13:45:51.161126 140689526667136 learning.py:507] global step 4093: loss = 0.0766 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 4094: loss = 0.0627 (0.391 sec/step)\n",
            "I0205 13:45:51.553737 140689526667136 learning.py:507] global step 4094: loss = 0.0627 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 4095: loss = 0.2497 (0.392 sec/step)\n",
            "I0205 13:45:51.947640 140689526667136 learning.py:507] global step 4095: loss = 0.2497 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 4096: loss = 0.0665 (0.407 sec/step)\n",
            "I0205 13:45:52.356041 140689526667136 learning.py:507] global step 4096: loss = 0.0665 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 4097: loss = 0.3330 (0.435 sec/step)\n",
            "I0205 13:45:52.792654 140689526667136 learning.py:507] global step 4097: loss = 0.3330 (0.435 sec/step)\n",
            "INFO:tensorflow:global step 4098: loss = 0.1837 (0.410 sec/step)\n",
            "I0205 13:45:53.204124 140689526667136 learning.py:507] global step 4098: loss = 0.1837 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 4099: loss = 0.1224 (0.398 sec/step)\n",
            "I0205 13:45:53.604350 140689526667136 learning.py:507] global step 4099: loss = 0.1224 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 4100: loss = 0.1389 (0.414 sec/step)\n",
            "I0205 13:45:54.019777 140689526667136 learning.py:507] global step 4100: loss = 0.1389 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 4101: loss = 0.1747 (0.432 sec/step)\n",
            "I0205 13:45:54.453778 140689526667136 learning.py:507] global step 4101: loss = 0.1747 (0.432 sec/step)\n",
            "INFO:tensorflow:global step 4102: loss = 0.0581 (0.402 sec/step)\n",
            "I0205 13:45:54.857364 140689526667136 learning.py:507] global step 4102: loss = 0.0581 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 4103: loss = 0.1813 (0.398 sec/step)\n",
            "I0205 13:45:55.257056 140689526667136 learning.py:507] global step 4103: loss = 0.1813 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 4104: loss = 0.0877 (0.400 sec/step)\n",
            "I0205 13:45:55.660822 140689526667136 learning.py:507] global step 4104: loss = 0.0877 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 4105: loss = 0.2179 (0.394 sec/step)\n",
            "I0205 13:45:56.056909 140689526667136 learning.py:507] global step 4105: loss = 0.2179 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 4106: loss = 0.2774 (0.386 sec/step)\n",
            "I0205 13:45:56.444043 140689526667136 learning.py:507] global step 4106: loss = 0.2774 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 4107: loss = 0.8499 (0.391 sec/step)\n",
            "I0205 13:45:56.837016 140689526667136 learning.py:507] global step 4107: loss = 0.8499 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 4108: loss = 1.2280 (0.390 sec/step)\n",
            "I0205 13:45:57.228557 140689526667136 learning.py:507] global step 4108: loss = 1.2280 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 4109: loss = 0.0616 (0.381 sec/step)\n",
            "I0205 13:45:57.610889 140689526667136 learning.py:507] global step 4109: loss = 0.0616 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4110: loss = 0.1791 (0.392 sec/step)\n",
            "I0205 13:45:58.004798 140689526667136 learning.py:507] global step 4110: loss = 0.1791 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 4111: loss = 0.2004 (0.375 sec/step)\n",
            "I0205 13:45:58.381384 140689526667136 learning.py:507] global step 4111: loss = 0.2004 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 4112: loss = 0.9700 (0.381 sec/step)\n",
            "I0205 13:45:58.764492 140689526667136 learning.py:507] global step 4112: loss = 0.9700 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4113: loss = 0.2909 (0.358 sec/step)\n",
            "I0205 13:45:59.123592 140689526667136 learning.py:507] global step 4113: loss = 0.2909 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 4114: loss = 0.1033 (0.383 sec/step)\n",
            "I0205 13:45:59.507928 140689526667136 learning.py:507] global step 4114: loss = 0.1033 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 4115: loss = 0.1343 (0.403 sec/step)\n",
            "I0205 13:45:59.912625 140689526667136 learning.py:507] global step 4115: loss = 0.1343 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 4116: loss = 0.2069 (0.371 sec/step)\n",
            "I0205 13:46:00.285550 140689526667136 learning.py:507] global step 4116: loss = 0.2069 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 4117: loss = 0.1385 (0.391 sec/step)\n",
            "I0205 13:46:00.678603 140689526667136 learning.py:507] global step 4117: loss = 0.1385 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 4118: loss = 0.0740 (0.392 sec/step)\n",
            "I0205 13:46:01.073472 140689526667136 learning.py:507] global step 4118: loss = 0.0740 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 4119: loss = 0.0997 (0.419 sec/step)\n",
            "I0205 13:46:01.494632 140689526667136 learning.py:507] global step 4119: loss = 0.0997 (0.419 sec/step)\n",
            "INFO:tensorflow:global step 4120: loss = 0.2570 (0.382 sec/step)\n",
            "I0205 13:46:01.878053 140689526667136 learning.py:507] global step 4120: loss = 0.2570 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 4121: loss = 0.2315 (0.371 sec/step)\n",
            "I0205 13:46:02.250596 140689526667136 learning.py:507] global step 4121: loss = 0.2315 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 4122: loss = 0.0371 (0.382 sec/step)\n",
            "I0205 13:46:02.634813 140689526667136 learning.py:507] global step 4122: loss = 0.0371 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 4123: loss = 0.3869 (0.395 sec/step)\n",
            "I0205 13:46:03.031809 140689526667136 learning.py:507] global step 4123: loss = 0.3869 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 4124: loss = 0.0960 (0.406 sec/step)\n",
            "I0205 13:46:03.439655 140689526667136 learning.py:507] global step 4124: loss = 0.0960 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 4125: loss = 0.0986 (0.385 sec/step)\n",
            "I0205 13:46:03.825881 140689526667136 learning.py:507] global step 4125: loss = 0.0986 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 4126: loss = 0.1255 (0.365 sec/step)\n",
            "I0205 13:46:04.193177 140689526667136 learning.py:507] global step 4126: loss = 0.1255 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 4127: loss = 0.1899 (0.376 sec/step)\n",
            "I0205 13:46:04.571128 140689526667136 learning.py:507] global step 4127: loss = 0.1899 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 4128: loss = 0.1559 (0.373 sec/step)\n",
            "I0205 13:46:04.945203 140689526667136 learning.py:507] global step 4128: loss = 0.1559 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 4129: loss = 0.0630 (0.352 sec/step)\n",
            "I0205 13:46:05.298417 140689526667136 learning.py:507] global step 4129: loss = 0.0630 (0.352 sec/step)\n",
            "INFO:tensorflow:global step 4130: loss = 0.1919 (0.392 sec/step)\n",
            "I0205 13:46:05.692756 140689526667136 learning.py:507] global step 4130: loss = 0.1919 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 4131: loss = 0.3835 (0.409 sec/step)\n",
            "I0205 13:46:06.103387 140689526667136 learning.py:507] global step 4131: loss = 0.3835 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 4132: loss = 0.0276 (0.378 sec/step)\n",
            "I0205 13:46:06.482640 140689526667136 learning.py:507] global step 4132: loss = 0.0276 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 4133: loss = 0.0715 (0.365 sec/step)\n",
            "I0205 13:46:06.849236 140689526667136 learning.py:507] global step 4133: loss = 0.0715 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 4134: loss = 0.4010 (0.384 sec/step)\n",
            "I0205 13:46:07.234822 140689526667136 learning.py:507] global step 4134: loss = 0.4010 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 4135: loss = 0.1022 (0.374 sec/step)\n",
            "I0205 13:46:07.610245 140689526667136 learning.py:507] global step 4135: loss = 0.1022 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 4136: loss = 0.2140 (0.400 sec/step)\n",
            "I0205 13:46:08.012994 140689526667136 learning.py:507] global step 4136: loss = 0.2140 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 4137: loss = 0.0541 (0.380 sec/step)\n",
            "I0205 13:46:08.394645 140689526667136 learning.py:507] global step 4137: loss = 0.0541 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 4138: loss = 0.0981 (0.393 sec/step)\n",
            "I0205 13:46:08.789561 140689526667136 learning.py:507] global step 4138: loss = 0.0981 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 4139: loss = 0.4168 (0.383 sec/step)\n",
            "I0205 13:46:09.174523 140689526667136 learning.py:507] global step 4139: loss = 0.4168 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 4140: loss = 0.1423 (0.397 sec/step)\n",
            "I0205 13:46:09.573102 140689526667136 learning.py:507] global step 4140: loss = 0.1423 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 4141: loss = 0.1378 (0.384 sec/step)\n",
            "I0205 13:46:09.958479 140689526667136 learning.py:507] global step 4141: loss = 0.1378 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 4142: loss = 0.3498 (0.380 sec/step)\n",
            "I0205 13:46:10.339918 140689526667136 learning.py:507] global step 4142: loss = 0.3498 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 4143: loss = 0.1429 (0.405 sec/step)\n",
            "I0205 13:46:10.746735 140689526667136 learning.py:507] global step 4143: loss = 0.1429 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 4144: loss = 0.3197 (0.377 sec/step)\n",
            "I0205 13:46:11.125809 140689526667136 learning.py:507] global step 4144: loss = 0.3197 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 4145: loss = 0.9738 (0.378 sec/step)\n",
            "I0205 13:46:11.505727 140689526667136 learning.py:507] global step 4145: loss = 0.9738 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 4146: loss = 0.1340 (0.375 sec/step)\n",
            "I0205 13:46:11.882315 140689526667136 learning.py:507] global step 4146: loss = 0.1340 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 4147: loss = 0.8917 (0.385 sec/step)\n",
            "I0205 13:46:12.268491 140689526667136 learning.py:507] global step 4147: loss = 0.8917 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 4148: loss = 0.0804 (0.388 sec/step)\n",
            "I0205 13:46:12.659097 140689526667136 learning.py:507] global step 4148: loss = 0.0804 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 4149: loss = 0.3669 (0.379 sec/step)\n",
            "I0205 13:46:13.039417 140689526667136 learning.py:507] global step 4149: loss = 0.3669 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 4150: loss = 0.0898 (0.376 sec/step)\n",
            "I0205 13:46:13.416839 140689526667136 learning.py:507] global step 4150: loss = 0.0898 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 4151: loss = 0.0314 (0.375 sec/step)\n",
            "I0205 13:46:13.818706 140689526667136 learning.py:507] global step 4151: loss = 0.0314 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 4152: loss = 0.1948 (0.790 sec/step)\n",
            "I0205 13:46:14.899539 140689526667136 learning.py:507] global step 4152: loss = 0.1948 (0.790 sec/step)\n",
            "INFO:tensorflow:global step 4153: loss = 0.2173 (0.756 sec/step)\n",
            "I0205 13:46:15.793496 140689526667136 learning.py:507] global step 4153: loss = 0.2173 (0.756 sec/step)\n",
            "INFO:tensorflow:global step 4154: loss = 0.0611 (0.615 sec/step)\n",
            "I0205 13:46:16.414985 140689526667136 learning.py:507] global step 4154: loss = 0.0611 (0.615 sec/step)\n",
            "INFO:tensorflow:global step 4155: loss = 0.2292 (0.701 sec/step)\n",
            "I0205 13:46:17.118966 140689526667136 learning.py:507] global step 4155: loss = 0.2292 (0.701 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 4155.\n",
            "I0205 13:46:17.507218 140686026073856 supervisor.py:1050] Recording summary at step 4155.\n",
            "INFO:tensorflow:global step 4156: loss = 0.1195 (0.476 sec/step)\n",
            "I0205 13:46:17.599977 140689526667136 learning.py:507] global step 4156: loss = 0.1195 (0.476 sec/step)\n",
            "INFO:tensorflow:global step 4157: loss = 0.1378 (0.366 sec/step)\n",
            "I0205 13:46:17.967734 140689526667136 learning.py:507] global step 4157: loss = 0.1378 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 4158: loss = 0.1769 (0.393 sec/step)\n",
            "I0205 13:46:18.362278 140689526667136 learning.py:507] global step 4158: loss = 0.1769 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 4159: loss = 0.0450 (0.386 sec/step)\n",
            "I0205 13:46:18.750097 140689526667136 learning.py:507] global step 4159: loss = 0.0450 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 4160: loss = 0.1153 (0.393 sec/step)\n",
            "I0205 13:46:19.144314 140689526667136 learning.py:507] global step 4160: loss = 0.1153 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 4161: loss = 0.1111 (0.399 sec/step)\n",
            "I0205 13:46:19.545153 140689526667136 learning.py:507] global step 4161: loss = 0.1111 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 4162: loss = 0.2739 (0.384 sec/step)\n",
            "I0205 13:46:19.930613 140689526667136 learning.py:507] global step 4162: loss = 0.2739 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 4163: loss = 0.2733 (0.361 sec/step)\n",
            "I0205 13:46:20.292745 140689526667136 learning.py:507] global step 4163: loss = 0.2733 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 4164: loss = 0.2634 (0.392 sec/step)\n",
            "I0205 13:46:20.686703 140689526667136 learning.py:507] global step 4164: loss = 0.2634 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 4165: loss = 0.1167 (0.376 sec/step)\n",
            "I0205 13:46:21.063808 140689526667136 learning.py:507] global step 4165: loss = 0.1167 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 4166: loss = 0.0972 (0.421 sec/step)\n",
            "I0205 13:46:21.486525 140689526667136 learning.py:507] global step 4166: loss = 0.0972 (0.421 sec/step)\n",
            "INFO:tensorflow:global step 4167: loss = 0.1091 (0.372 sec/step)\n",
            "I0205 13:46:21.860379 140689526667136 learning.py:507] global step 4167: loss = 0.1091 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 4168: loss = 0.0701 (0.388 sec/step)\n",
            "I0205 13:46:22.250054 140689526667136 learning.py:507] global step 4168: loss = 0.0701 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 4169: loss = 0.2152 (0.394 sec/step)\n",
            "I0205 13:46:22.646425 140689526667136 learning.py:507] global step 4169: loss = 0.2152 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 4170: loss = 0.1491 (0.369 sec/step)\n",
            "I0205 13:46:23.017048 140689526667136 learning.py:507] global step 4170: loss = 0.1491 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 4171: loss = 0.1336 (0.397 sec/step)\n",
            "I0205 13:46:23.415553 140689526667136 learning.py:507] global step 4171: loss = 0.1336 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 4172: loss = 0.1034 (0.403 sec/step)\n",
            "I0205 13:46:23.820644 140689526667136 learning.py:507] global step 4172: loss = 0.1034 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 4173: loss = 0.1321 (0.365 sec/step)\n",
            "I0205 13:46:24.187544 140689526667136 learning.py:507] global step 4173: loss = 0.1321 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 4174: loss = 0.3402 (0.385 sec/step)\n",
            "I0205 13:46:24.573737 140689526667136 learning.py:507] global step 4174: loss = 0.3402 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 4175: loss = 0.2163 (0.371 sec/step)\n",
            "I0205 13:46:24.946391 140689526667136 learning.py:507] global step 4175: loss = 0.2163 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 4176: loss = 0.0402 (0.366 sec/step)\n",
            "I0205 13:46:25.314426 140689526667136 learning.py:507] global step 4176: loss = 0.0402 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 4177: loss = 0.1078 (0.389 sec/step)\n",
            "I0205 13:46:25.705574 140689526667136 learning.py:507] global step 4177: loss = 0.1078 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 4178: loss = 0.1998 (0.421 sec/step)\n",
            "I0205 13:46:26.128298 140689526667136 learning.py:507] global step 4178: loss = 0.1998 (0.421 sec/step)\n",
            "INFO:tensorflow:global step 4179: loss = 0.6436 (0.406 sec/step)\n",
            "I0205 13:46:26.535534 140689526667136 learning.py:507] global step 4179: loss = 0.6436 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 4180: loss = 0.5348 (0.428 sec/step)\n",
            "I0205 13:46:26.964986 140689526667136 learning.py:507] global step 4180: loss = 0.5348 (0.428 sec/step)\n",
            "INFO:tensorflow:global step 4181: loss = 0.0711 (0.384 sec/step)\n",
            "I0205 13:46:27.350392 140689526667136 learning.py:507] global step 4181: loss = 0.0711 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 4182: loss = 0.1682 (0.392 sec/step)\n",
            "I0205 13:46:27.744541 140689526667136 learning.py:507] global step 4182: loss = 0.1682 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 4183: loss = 0.3075 (0.404 sec/step)\n",
            "I0205 13:46:28.150136 140689526667136 learning.py:507] global step 4183: loss = 0.3075 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 4184: loss = 0.1152 (0.382 sec/step)\n",
            "I0205 13:46:28.533272 140689526667136 learning.py:507] global step 4184: loss = 0.1152 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 4185: loss = 0.0627 (0.399 sec/step)\n",
            "I0205 13:46:28.933883 140689526667136 learning.py:507] global step 4185: loss = 0.0627 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 4186: loss = 0.2445 (0.413 sec/step)\n",
            "I0205 13:46:29.348711 140689526667136 learning.py:507] global step 4186: loss = 0.2445 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 4187: loss = 0.2009 (0.410 sec/step)\n",
            "I0205 13:46:29.760308 140689526667136 learning.py:507] global step 4187: loss = 0.2009 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 4188: loss = 0.0448 (0.419 sec/step)\n",
            "I0205 13:46:30.181292 140689526667136 learning.py:507] global step 4188: loss = 0.0448 (0.419 sec/step)\n",
            "INFO:tensorflow:global step 4189: loss = 0.1656 (0.412 sec/step)\n",
            "I0205 13:46:30.595157 140689526667136 learning.py:507] global step 4189: loss = 0.1656 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 4190: loss = 0.0718 (0.430 sec/step)\n",
            "I0205 13:46:31.027457 140689526667136 learning.py:507] global step 4190: loss = 0.0718 (0.430 sec/step)\n",
            "INFO:tensorflow:global step 4191: loss = 0.4827 (0.419 sec/step)\n",
            "I0205 13:46:31.448633 140689526667136 learning.py:507] global step 4191: loss = 0.4827 (0.419 sec/step)\n",
            "INFO:tensorflow:global step 4192: loss = 0.2451 (0.394 sec/step)\n",
            "I0205 13:46:31.844892 140689526667136 learning.py:507] global step 4192: loss = 0.2451 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 4193: loss = 0.1644 (0.374 sec/step)\n",
            "I0205 13:46:32.220610 140689526667136 learning.py:507] global step 4193: loss = 0.1644 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 4194: loss = 0.1803 (0.371 sec/step)\n",
            "I0205 13:46:32.593482 140689526667136 learning.py:507] global step 4194: loss = 0.1803 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 4195: loss = 0.0899 (0.437 sec/step)\n",
            "I0205 13:46:33.032156 140689526667136 learning.py:507] global step 4195: loss = 0.0899 (0.437 sec/step)\n",
            "INFO:tensorflow:global step 4196: loss = 0.1169 (0.395 sec/step)\n",
            "I0205 13:46:33.429144 140689526667136 learning.py:507] global step 4196: loss = 0.1169 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 4197: loss = 0.2468 (0.382 sec/step)\n",
            "I0205 13:46:33.812796 140689526667136 learning.py:507] global step 4197: loss = 0.2468 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 4198: loss = 0.2082 (0.383 sec/step)\n",
            "I0205 13:46:34.197479 140689526667136 learning.py:507] global step 4198: loss = 0.2082 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 4199: loss = 0.2773 (0.370 sec/step)\n",
            "I0205 13:46:34.569136 140689526667136 learning.py:507] global step 4199: loss = 0.2773 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 4200: loss = 0.0409 (0.355 sec/step)\n",
            "I0205 13:46:34.926052 140689526667136 learning.py:507] global step 4200: loss = 0.0409 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 4201: loss = 0.1216 (0.354 sec/step)\n",
            "I0205 13:46:35.281313 140689526667136 learning.py:507] global step 4201: loss = 0.1216 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 4202: loss = 0.1242 (0.364 sec/step)\n",
            "I0205 13:46:35.646719 140689526667136 learning.py:507] global step 4202: loss = 0.1242 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 4203: loss = 0.1115 (0.414 sec/step)\n",
            "I0205 13:46:36.062312 140689526667136 learning.py:507] global step 4203: loss = 0.1115 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 4204: loss = 0.1616 (0.395 sec/step)\n",
            "I0205 13:46:36.458634 140689526667136 learning.py:507] global step 4204: loss = 0.1616 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 4205: loss = 0.5978 (0.351 sec/step)\n",
            "I0205 13:46:36.810909 140689526667136 learning.py:507] global step 4205: loss = 0.5978 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 4206: loss = 0.1893 (0.392 sec/step)\n",
            "I0205 13:46:37.204278 140689526667136 learning.py:507] global step 4206: loss = 0.1893 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 4207: loss = 0.1021 (0.396 sec/step)\n",
            "I0205 13:46:37.602355 140689526667136 learning.py:507] global step 4207: loss = 0.1021 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 4208: loss = 0.4944 (0.381 sec/step)\n",
            "I0205 13:46:37.985188 140689526667136 learning.py:507] global step 4208: loss = 0.4944 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4209: loss = 0.0948 (0.379 sec/step)\n",
            "I0205 13:46:38.366328 140689526667136 learning.py:507] global step 4209: loss = 0.0948 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 4210: loss = 0.0426 (0.419 sec/step)\n",
            "I0205 13:46:38.787233 140689526667136 learning.py:507] global step 4210: loss = 0.0426 (0.419 sec/step)\n",
            "INFO:tensorflow:global step 4211: loss = 0.2429 (0.386 sec/step)\n",
            "I0205 13:46:39.175145 140689526667136 learning.py:507] global step 4211: loss = 0.2429 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 4212: loss = 0.1787 (0.393 sec/step)\n",
            "I0205 13:46:39.570023 140689526667136 learning.py:507] global step 4212: loss = 0.1787 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 4213: loss = 0.0620 (0.366 sec/step)\n",
            "I0205 13:46:39.937500 140689526667136 learning.py:507] global step 4213: loss = 0.0620 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 4214: loss = 0.0565 (0.376 sec/step)\n",
            "I0205 13:46:40.314796 140689526667136 learning.py:507] global step 4214: loss = 0.0565 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 4215: loss = 0.1761 (0.352 sec/step)\n",
            "I0205 13:46:40.668915 140689526667136 learning.py:507] global step 4215: loss = 0.1761 (0.352 sec/step)\n",
            "INFO:tensorflow:global step 4216: loss = 0.0882 (0.369 sec/step)\n",
            "I0205 13:46:41.039472 140689526667136 learning.py:507] global step 4216: loss = 0.0882 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 4217: loss = 0.0344 (0.354 sec/step)\n",
            "I0205 13:46:41.395062 140689526667136 learning.py:507] global step 4217: loss = 0.0344 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 4218: loss = 0.2813 (0.390 sec/step)\n",
            "I0205 13:46:41.786466 140689526667136 learning.py:507] global step 4218: loss = 0.2813 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 4219: loss = 0.1119 (0.383 sec/step)\n",
            "I0205 13:46:42.170935 140689526667136 learning.py:507] global step 4219: loss = 0.1119 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 4220: loss = 0.3534 (0.378 sec/step)\n",
            "I0205 13:46:42.551149 140689526667136 learning.py:507] global step 4220: loss = 0.3534 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 4221: loss = 0.4534 (0.372 sec/step)\n",
            "I0205 13:46:42.924865 140689526667136 learning.py:507] global step 4221: loss = 0.4534 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 4222: loss = 0.1194 (0.372 sec/step)\n",
            "I0205 13:46:43.298610 140689526667136 learning.py:507] global step 4222: loss = 0.1194 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 4223: loss = 0.1748 (0.366 sec/step)\n",
            "I0205 13:46:43.665670 140689526667136 learning.py:507] global step 4223: loss = 0.1748 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 4224: loss = 0.0823 (0.381 sec/step)\n",
            "I0205 13:46:44.048146 140689526667136 learning.py:507] global step 4224: loss = 0.0823 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4225: loss = 0.2577 (0.382 sec/step)\n",
            "I0205 13:46:44.431213 140689526667136 learning.py:507] global step 4225: loss = 0.2577 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 4226: loss = 0.2938 (0.377 sec/step)\n",
            "I0205 13:46:44.809757 140689526667136 learning.py:507] global step 4226: loss = 0.2938 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 4227: loss = 0.2188 (0.384 sec/step)\n",
            "I0205 13:46:45.195432 140689526667136 learning.py:507] global step 4227: loss = 0.2188 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 4228: loss = 0.1190 (0.357 sec/step)\n",
            "I0205 13:46:45.554391 140689526667136 learning.py:507] global step 4228: loss = 0.1190 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 4229: loss = 0.1295 (0.398 sec/step)\n",
            "I0205 13:46:45.954327 140689526667136 learning.py:507] global step 4229: loss = 0.1295 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 4230: loss = 0.1474 (0.379 sec/step)\n",
            "I0205 13:46:46.335150 140689526667136 learning.py:507] global step 4230: loss = 0.1474 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 4231: loss = 0.1153 (0.400 sec/step)\n",
            "I0205 13:46:46.737143 140689526667136 learning.py:507] global step 4231: loss = 0.1153 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 4232: loss = 0.2585 (0.378 sec/step)\n",
            "I0205 13:46:47.116976 140689526667136 learning.py:507] global step 4232: loss = 0.2585 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 4233: loss = 0.0934 (0.365 sec/step)\n",
            "I0205 13:46:47.483451 140689526667136 learning.py:507] global step 4233: loss = 0.0934 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 4234: loss = 0.0393 (0.373 sec/step)\n",
            "I0205 13:46:47.858055 140689526667136 learning.py:507] global step 4234: loss = 0.0393 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 4235: loss = 0.1888 (0.374 sec/step)\n",
            "I0205 13:46:48.233703 140689526667136 learning.py:507] global step 4235: loss = 0.1888 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 4236: loss = 0.0880 (0.371 sec/step)\n",
            "I0205 13:46:48.605907 140689526667136 learning.py:507] global step 4236: loss = 0.0880 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 4237: loss = 0.1564 (0.382 sec/step)\n",
            "I0205 13:46:48.989917 140689526667136 learning.py:507] global step 4237: loss = 0.1564 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 4238: loss = 0.2665 (0.359 sec/step)\n",
            "I0205 13:46:49.350348 140689526667136 learning.py:507] global step 4238: loss = 0.2665 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 4239: loss = 0.1164 (0.383 sec/step)\n",
            "I0205 13:46:49.735364 140689526667136 learning.py:507] global step 4239: loss = 0.1164 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 4240: loss = 0.0633 (0.354 sec/step)\n",
            "I0205 13:46:50.091062 140689526667136 learning.py:507] global step 4240: loss = 0.0633 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 4241: loss = 0.2376 (0.359 sec/step)\n",
            "I0205 13:46:50.451467 140689526667136 learning.py:507] global step 4241: loss = 0.2376 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 4242: loss = 0.2640 (0.381 sec/step)\n",
            "I0205 13:46:50.834137 140689526667136 learning.py:507] global step 4242: loss = 0.2640 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4243: loss = 0.0687 (0.392 sec/step)\n",
            "I0205 13:46:51.227495 140689526667136 learning.py:507] global step 4243: loss = 0.0687 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 4244: loss = 0.0977 (0.358 sec/step)\n",
            "I0205 13:46:51.587337 140689526667136 learning.py:507] global step 4244: loss = 0.0977 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 4245: loss = 0.0602 (0.366 sec/step)\n",
            "I0205 13:46:51.955399 140689526667136 learning.py:507] global step 4245: loss = 0.0602 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 4246: loss = 0.2107 (0.407 sec/step)\n",
            "I0205 13:46:52.364142 140689526667136 learning.py:507] global step 4246: loss = 0.2107 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 4247: loss = 0.5038 (0.417 sec/step)\n",
            "I0205 13:46:52.783619 140689526667136 learning.py:507] global step 4247: loss = 0.5038 (0.417 sec/step)\n",
            "INFO:tensorflow:global step 4248: loss = 0.0426 (0.406 sec/step)\n",
            "I0205 13:46:53.191665 140689526667136 learning.py:507] global step 4248: loss = 0.0426 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 4249: loss = 0.1474 (0.369 sec/step)\n",
            "I0205 13:46:53.562245 140689526667136 learning.py:507] global step 4249: loss = 0.1474 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 4250: loss = 0.3794 (0.383 sec/step)\n",
            "I0205 13:46:53.946428 140689526667136 learning.py:507] global step 4250: loss = 0.3794 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 4251: loss = 0.1420 (0.397 sec/step)\n",
            "I0205 13:46:54.345675 140689526667136 learning.py:507] global step 4251: loss = 0.1420 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 4252: loss = 0.0782 (0.378 sec/step)\n",
            "I0205 13:46:54.725599 140689526667136 learning.py:507] global step 4252: loss = 0.0782 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 4253: loss = 0.3641 (0.365 sec/step)\n",
            "I0205 13:46:55.091749 140689526667136 learning.py:507] global step 4253: loss = 0.3641 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 4254: loss = 0.2052 (0.379 sec/step)\n",
            "I0205 13:46:55.472240 140689526667136 learning.py:507] global step 4254: loss = 0.2052 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 4255: loss = 0.0910 (0.374 sec/step)\n",
            "I0205 13:46:55.847855 140689526667136 learning.py:507] global step 4255: loss = 0.0910 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 4256: loss = 0.0456 (0.367 sec/step)\n",
            "I0205 13:46:56.215892 140689526667136 learning.py:507] global step 4256: loss = 0.0456 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 4257: loss = 0.0464 (0.380 sec/step)\n",
            "I0205 13:46:56.597079 140689526667136 learning.py:507] global step 4257: loss = 0.0464 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 4258: loss = 0.0712 (0.399 sec/step)\n",
            "I0205 13:46:56.997973 140689526667136 learning.py:507] global step 4258: loss = 0.0712 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 4259: loss = 0.3208 (0.356 sec/step)\n",
            "I0205 13:46:57.355955 140689526667136 learning.py:507] global step 4259: loss = 0.3208 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 4260: loss = 0.0625 (0.366 sec/step)\n",
            "I0205 13:46:57.723121 140689526667136 learning.py:507] global step 4260: loss = 0.0625 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 4261: loss = 0.0577 (0.386 sec/step)\n",
            "I0205 13:46:58.111221 140689526667136 learning.py:507] global step 4261: loss = 0.0577 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 4262: loss = 0.1760 (0.397 sec/step)\n",
            "I0205 13:46:58.509640 140689526667136 learning.py:507] global step 4262: loss = 0.1760 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 4263: loss = 0.1076 (0.374 sec/step)\n",
            "I0205 13:46:58.885969 140689526667136 learning.py:507] global step 4263: loss = 0.1076 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 4264: loss = 0.0896 (0.388 sec/step)\n",
            "I0205 13:46:59.275502 140689526667136 learning.py:507] global step 4264: loss = 0.0896 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 4265: loss = 0.2338 (0.380 sec/step)\n",
            "I0205 13:46:59.657622 140689526667136 learning.py:507] global step 4265: loss = 0.2338 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 4266: loss = 0.1544 (0.386 sec/step)\n",
            "I0205 13:47:00.045582 140689526667136 learning.py:507] global step 4266: loss = 0.1544 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 4267: loss = 0.0805 (0.379 sec/step)\n",
            "I0205 13:47:00.426430 140689526667136 learning.py:507] global step 4267: loss = 0.0805 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 4268: loss = 0.2361 (0.384 sec/step)\n",
            "I0205 13:47:00.811636 140689526667136 learning.py:507] global step 4268: loss = 0.2361 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 4269: loss = 0.2581 (0.390 sec/step)\n",
            "I0205 13:47:01.203237 140689526667136 learning.py:507] global step 4269: loss = 0.2581 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 4270: loss = 0.2147 (0.384 sec/step)\n",
            "I0205 13:47:01.588446 140689526667136 learning.py:507] global step 4270: loss = 0.2147 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 4271: loss = 0.3883 (0.380 sec/step)\n",
            "I0205 13:47:01.970245 140689526667136 learning.py:507] global step 4271: loss = 0.3883 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 4272: loss = 0.1149 (0.388 sec/step)\n",
            "I0205 13:47:02.360475 140689526667136 learning.py:507] global step 4272: loss = 0.1149 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 4273: loss = 0.1138 (0.386 sec/step)\n",
            "I0205 13:47:02.748122 140689526667136 learning.py:507] global step 4273: loss = 0.1138 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 4274: loss = 0.6426 (0.402 sec/step)\n",
            "I0205 13:47:03.152203 140689526667136 learning.py:507] global step 4274: loss = 0.6426 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 4275: loss = 0.2157 (0.393 sec/step)\n",
            "I0205 13:47:03.546904 140689526667136 learning.py:507] global step 4275: loss = 0.2157 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 4276: loss = 0.0130 (0.397 sec/step)\n",
            "I0205 13:47:03.945254 140689526667136 learning.py:507] global step 4276: loss = 0.0130 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 4277: loss = 0.1414 (0.358 sec/step)\n",
            "I0205 13:47:04.305225 140689526667136 learning.py:507] global step 4277: loss = 0.1414 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 4278: loss = 0.1220 (0.391 sec/step)\n",
            "I0205 13:47:04.698266 140689526667136 learning.py:507] global step 4278: loss = 0.1220 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 4279: loss = 0.4289 (0.385 sec/step)\n",
            "I0205 13:47:05.085135 140689526667136 learning.py:507] global step 4279: loss = 0.4289 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 4280: loss = 0.1042 (0.411 sec/step)\n",
            "I0205 13:47:05.497077 140689526667136 learning.py:507] global step 4280: loss = 0.1042 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 4281: loss = 0.1891 (0.386 sec/step)\n",
            "I0205 13:47:05.884753 140689526667136 learning.py:507] global step 4281: loss = 0.1891 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 4282: loss = 0.0901 (0.387 sec/step)\n",
            "I0205 13:47:06.273890 140689526667136 learning.py:507] global step 4282: loss = 0.0901 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 4283: loss = 0.1898 (0.380 sec/step)\n",
            "I0205 13:47:06.655953 140689526667136 learning.py:507] global step 4283: loss = 0.1898 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 4284: loss = 0.1206 (0.381 sec/step)\n",
            "I0205 13:47:07.039005 140689526667136 learning.py:507] global step 4284: loss = 0.1206 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4285: loss = 0.2983 (0.401 sec/step)\n",
            "I0205 13:47:07.441501 140689526667136 learning.py:507] global step 4285: loss = 0.2983 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 4286: loss = 0.2097 (0.383 sec/step)\n",
            "I0205 13:47:07.826107 140689526667136 learning.py:507] global step 4286: loss = 0.2097 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 4287: loss = 0.0741 (0.393 sec/step)\n",
            "I0205 13:47:08.220598 140689526667136 learning.py:507] global step 4287: loss = 0.0741 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 4288: loss = 0.1923 (0.398 sec/step)\n",
            "I0205 13:47:08.620495 140689526667136 learning.py:507] global step 4288: loss = 0.1923 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 4289: loss = 0.0465 (0.410 sec/step)\n",
            "I0205 13:47:09.032496 140689526667136 learning.py:507] global step 4289: loss = 0.0465 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 4290: loss = 0.2214 (0.392 sec/step)\n",
            "I0205 13:47:09.425537 140689526667136 learning.py:507] global step 4290: loss = 0.2214 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 4291: loss = 0.0853 (0.404 sec/step)\n",
            "I0205 13:47:09.831632 140689526667136 learning.py:507] global step 4291: loss = 0.0853 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 4292: loss = 0.1081 (0.397 sec/step)\n",
            "I0205 13:47:10.230485 140689526667136 learning.py:507] global step 4292: loss = 0.1081 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 4293: loss = 0.1269 (0.383 sec/step)\n",
            "I0205 13:47:10.615268 140689526667136 learning.py:507] global step 4293: loss = 0.1269 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 4294: loss = 0.0713 (0.380 sec/step)\n",
            "I0205 13:47:10.997092 140689526667136 learning.py:507] global step 4294: loss = 0.0713 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 4295: loss = 0.1741 (0.396 sec/step)\n",
            "I0205 13:47:11.394138 140689526667136 learning.py:507] global step 4295: loss = 0.1741 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 4296: loss = 0.1827 (0.369 sec/step)\n",
            "I0205 13:47:11.764471 140689526667136 learning.py:507] global step 4296: loss = 0.1827 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 4297: loss = 0.0633 (0.366 sec/step)\n",
            "I0205 13:47:12.132383 140689526667136 learning.py:507] global step 4297: loss = 0.0633 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 4298: loss = 0.0720 (0.378 sec/step)\n",
            "I0205 13:47:12.511775 140689526667136 learning.py:507] global step 4298: loss = 0.0720 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 4299: loss = 0.2659 (0.374 sec/step)\n",
            "I0205 13:47:12.887663 140689526667136 learning.py:507] global step 4299: loss = 0.2659 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 4300: loss = 0.1455 (0.372 sec/step)\n",
            "I0205 13:47:13.261355 140689526667136 learning.py:507] global step 4300: loss = 0.1455 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 4301: loss = 0.1528 (0.401 sec/step)\n",
            "I0205 13:47:13.663789 140689526667136 learning.py:507] global step 4301: loss = 0.1528 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 4302: loss = 0.2478 (0.396 sec/step)\n",
            "I0205 13:47:14.061356 140689526667136 learning.py:507] global step 4302: loss = 0.2478 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 4303: loss = 0.2381 (0.387 sec/step)\n",
            "I0205 13:47:14.449601 140689526667136 learning.py:507] global step 4303: loss = 0.2381 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 4304: loss = 0.0288 (0.404 sec/step)\n",
            "I0205 13:47:14.855083 140689526667136 learning.py:507] global step 4304: loss = 0.0288 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 4305: loss = 0.0673 (0.391 sec/step)\n",
            "I0205 13:47:15.247227 140689526667136 learning.py:507] global step 4305: loss = 0.0673 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 4306: loss = 0.0947 (0.362 sec/step)\n",
            "I0205 13:47:15.610606 140689526667136 learning.py:507] global step 4306: loss = 0.0947 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 4307: loss = 0.0227 (0.365 sec/step)\n",
            "I0205 13:47:15.976838 140689526667136 learning.py:507] global step 4307: loss = 0.0227 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 4308: loss = 0.4082 (0.373 sec/step)\n",
            "I0205 13:47:16.351665 140689526667136 learning.py:507] global step 4308: loss = 0.4082 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 4309: loss = 0.0915 (0.392 sec/step)\n",
            "I0205 13:47:16.745577 140689526667136 learning.py:507] global step 4309: loss = 0.0915 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 4310: loss = 0.0124 (0.413 sec/step)\n",
            "I0205 13:47:17.160238 140689526667136 learning.py:507] global step 4310: loss = 0.0124 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 4311: loss = 0.0949 (0.381 sec/step)\n",
            "I0205 13:47:17.542981 140689526667136 learning.py:507] global step 4311: loss = 0.0949 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4312: loss = 0.0456 (0.386 sec/step)\n",
            "I0205 13:47:17.930953 140689526667136 learning.py:507] global step 4312: loss = 0.0456 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 4313: loss = 0.0465 (0.392 sec/step)\n",
            "I0205 13:47:18.324509 140689526667136 learning.py:507] global step 4313: loss = 0.0465 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 4314: loss = 0.1123 (0.429 sec/step)\n",
            "I0205 13:47:18.754959 140689526667136 learning.py:507] global step 4314: loss = 0.1123 (0.429 sec/step)\n",
            "INFO:tensorflow:global step 4315: loss = 0.0752 (0.410 sec/step)\n",
            "I0205 13:47:19.166636 140689526667136 learning.py:507] global step 4315: loss = 0.0752 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 4316: loss = 0.3142 (0.396 sec/step)\n",
            "I0205 13:47:19.564826 140689526667136 learning.py:507] global step 4316: loss = 0.3142 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 4317: loss = 0.0590 (0.373 sec/step)\n",
            "I0205 13:47:19.939833 140689526667136 learning.py:507] global step 4317: loss = 0.0590 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 4318: loss = 0.3503 (0.391 sec/step)\n",
            "I0205 13:47:20.332521 140689526667136 learning.py:507] global step 4318: loss = 0.3503 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 4319: loss = 0.2817 (0.366 sec/step)\n",
            "I0205 13:47:20.700224 140689526667136 learning.py:507] global step 4319: loss = 0.2817 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 4320: loss = 0.2388 (0.389 sec/step)\n",
            "I0205 13:47:21.091110 140689526667136 learning.py:507] global step 4320: loss = 0.2388 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 4321: loss = 0.0886 (0.397 sec/step)\n",
            "I0205 13:47:21.490238 140689526667136 learning.py:507] global step 4321: loss = 0.0886 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 4322: loss = 0.1011 (0.396 sec/step)\n",
            "I0205 13:47:21.888064 140689526667136 learning.py:507] global step 4322: loss = 0.1011 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 4323: loss = 0.0719 (0.362 sec/step)\n",
            "I0205 13:47:22.251950 140689526667136 learning.py:507] global step 4323: loss = 0.0719 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 4324: loss = 0.2343 (0.398 sec/step)\n",
            "I0205 13:47:22.651356 140689526667136 learning.py:507] global step 4324: loss = 0.2343 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 4325: loss = 0.1130 (0.380 sec/step)\n",
            "I0205 13:47:23.033582 140689526667136 learning.py:507] global step 4325: loss = 0.1130 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 4326: loss = 0.2502 (0.392 sec/step)\n",
            "I0205 13:47:23.427554 140689526667136 learning.py:507] global step 4326: loss = 0.2502 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 4327: loss = 0.1717 (0.376 sec/step)\n",
            "I0205 13:47:23.805763 140689526667136 learning.py:507] global step 4327: loss = 0.1717 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 4328: loss = 0.0331 (0.393 sec/step)\n",
            "I0205 13:47:24.200285 140689526667136 learning.py:507] global step 4328: loss = 0.0331 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 4329: loss = 0.5000 (0.378 sec/step)\n",
            "I0205 13:47:24.580330 140689526667136 learning.py:507] global step 4329: loss = 0.5000 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 4330: loss = 0.1947 (0.370 sec/step)\n",
            "I0205 13:47:24.951971 140689526667136 learning.py:507] global step 4330: loss = 0.1947 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 4331: loss = 0.1181 (0.360 sec/step)\n",
            "I0205 13:47:25.314068 140689526667136 learning.py:507] global step 4331: loss = 0.1181 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 4332: loss = 0.0440 (0.373 sec/step)\n",
            "I0205 13:47:25.688626 140689526667136 learning.py:507] global step 4332: loss = 0.0440 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 4333: loss = 0.2323 (0.393 sec/step)\n",
            "I0205 13:47:26.082995 140689526667136 learning.py:507] global step 4333: loss = 0.2323 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 4334: loss = 0.0563 (0.390 sec/step)\n",
            "I0205 13:47:26.473990 140689526667136 learning.py:507] global step 4334: loss = 0.0563 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 4335: loss = 0.2484 (0.356 sec/step)\n",
            "I0205 13:47:26.831146 140689526667136 learning.py:507] global step 4335: loss = 0.2484 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 4336: loss = 0.2169 (0.390 sec/step)\n",
            "I0205 13:47:27.222967 140689526667136 learning.py:507] global step 4336: loss = 0.2169 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 4337: loss = 0.0668 (0.385 sec/step)\n",
            "I0205 13:47:27.609231 140689526667136 learning.py:507] global step 4337: loss = 0.0668 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 4338: loss = 0.0678 (0.388 sec/step)\n",
            "I0205 13:47:27.998300 140689526667136 learning.py:507] global step 4338: loss = 0.0678 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 4339: loss = 0.1295 (0.371 sec/step)\n",
            "I0205 13:47:28.371289 140689526667136 learning.py:507] global step 4339: loss = 0.1295 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 4340: loss = 0.0924 (0.372 sec/step)\n",
            "I0205 13:47:28.745056 140689526667136 learning.py:507] global step 4340: loss = 0.0924 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 4341: loss = 0.1679 (0.363 sec/step)\n",
            "I0205 13:47:29.110063 140689526667136 learning.py:507] global step 4341: loss = 0.1679 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 4342: loss = 0.1889 (0.417 sec/step)\n",
            "I0205 13:47:29.528828 140689526667136 learning.py:507] global step 4342: loss = 0.1889 (0.417 sec/step)\n",
            "INFO:tensorflow:global step 4343: loss = 0.1072 (0.413 sec/step)\n",
            "I0205 13:47:29.943388 140689526667136 learning.py:507] global step 4343: loss = 0.1072 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 4344: loss = 0.3697 (0.402 sec/step)\n",
            "I0205 13:47:30.347992 140689526667136 learning.py:507] global step 4344: loss = 0.3697 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 4345: loss = 0.2867 (0.402 sec/step)\n",
            "I0205 13:47:30.751970 140689526667136 learning.py:507] global step 4345: loss = 0.2867 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 4346: loss = 0.1616 (0.403 sec/step)\n",
            "I0205 13:47:31.156940 140689526667136 learning.py:507] global step 4346: loss = 0.1616 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 4347: loss = 0.0910 (0.427 sec/step)\n",
            "I0205 13:47:31.585411 140689526667136 learning.py:507] global step 4347: loss = 0.0910 (0.427 sec/step)\n",
            "INFO:tensorflow:global step 4348: loss = 0.2002 (0.376 sec/step)\n",
            "I0205 13:47:31.962739 140689526667136 learning.py:507] global step 4348: loss = 0.2002 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 4349: loss = 0.3898 (0.363 sec/step)\n",
            "I0205 13:47:32.327507 140689526667136 learning.py:507] global step 4349: loss = 0.3898 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 4350: loss = 0.1050 (0.377 sec/step)\n",
            "I0205 13:47:32.706528 140689526667136 learning.py:507] global step 4350: loss = 0.1050 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 4351: loss = 0.2045 (0.388 sec/step)\n",
            "I0205 13:47:33.096421 140689526667136 learning.py:507] global step 4351: loss = 0.2045 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 4352: loss = 0.3076 (0.396 sec/step)\n",
            "I0205 13:47:33.494123 140689526667136 learning.py:507] global step 4352: loss = 0.3076 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 4353: loss = 0.1785 (0.399 sec/step)\n",
            "I0205 13:47:33.894363 140689526667136 learning.py:507] global step 4353: loss = 0.1785 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 4354: loss = 0.3466 (0.382 sec/step)\n",
            "I0205 13:47:34.278076 140689526667136 learning.py:507] global step 4354: loss = 0.3466 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 4355: loss = 0.1387 (0.384 sec/step)\n",
            "I0205 13:47:34.663670 140689526667136 learning.py:507] global step 4355: loss = 0.1387 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 4356: loss = 0.0660 (0.362 sec/step)\n",
            "I0205 13:47:35.027072 140689526667136 learning.py:507] global step 4356: loss = 0.0660 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 4357: loss = 0.0928 (0.350 sec/step)\n",
            "I0205 13:47:35.378301 140689526667136 learning.py:507] global step 4357: loss = 0.0928 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 4358: loss = 0.0748 (0.394 sec/step)\n",
            "I0205 13:47:35.773546 140689526667136 learning.py:507] global step 4358: loss = 0.0748 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 4359: loss = 0.0734 (0.380 sec/step)\n",
            "I0205 13:47:36.154855 140689526667136 learning.py:507] global step 4359: loss = 0.0734 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 4360: loss = 0.1591 (0.387 sec/step)\n",
            "I0205 13:47:36.543703 140689526667136 learning.py:507] global step 4360: loss = 0.1591 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 4361: loss = 0.0641 (0.382 sec/step)\n",
            "I0205 13:47:36.927436 140689526667136 learning.py:507] global step 4361: loss = 0.0641 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 4362: loss = 0.2543 (0.380 sec/step)\n",
            "I0205 13:47:37.309177 140689526667136 learning.py:507] global step 4362: loss = 0.2543 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 4363: loss = 0.2634 (0.395 sec/step)\n",
            "I0205 13:47:37.705455 140689526667136 learning.py:507] global step 4363: loss = 0.2634 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 4364: loss = 0.0566 (0.382 sec/step)\n",
            "I0205 13:47:38.088843 140689526667136 learning.py:507] global step 4364: loss = 0.0566 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 4365: loss = 0.1828 (0.353 sec/step)\n",
            "I0205 13:47:38.442991 140689526667136 learning.py:507] global step 4365: loss = 0.1828 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 4366: loss = 0.0221 (0.404 sec/step)\n",
            "I0205 13:47:38.848457 140689526667136 learning.py:507] global step 4366: loss = 0.0221 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 4367: loss = 0.1372 (0.398 sec/step)\n",
            "I0205 13:47:39.247430 140689526667136 learning.py:507] global step 4367: loss = 0.1372 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 4368: loss = 0.0739 (0.369 sec/step)\n",
            "I0205 13:47:39.617872 140689526667136 learning.py:507] global step 4368: loss = 0.0739 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 4369: loss = 0.0516 (0.370 sec/step)\n",
            "I0205 13:47:39.989258 140689526667136 learning.py:507] global step 4369: loss = 0.0516 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 4370: loss = 0.0493 (0.392 sec/step)\n",
            "I0205 13:47:40.382643 140689526667136 learning.py:507] global step 4370: loss = 0.0493 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 4371: loss = 0.1063 (0.380 sec/step)\n",
            "I0205 13:47:40.763905 140689526667136 learning.py:507] global step 4371: loss = 0.1063 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 4372: loss = 0.0795 (0.400 sec/step)\n",
            "I0205 13:47:41.165544 140689526667136 learning.py:507] global step 4372: loss = 0.0795 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 4373: loss = 0.0714 (0.366 sec/step)\n",
            "I0205 13:47:41.532473 140689526667136 learning.py:507] global step 4373: loss = 0.0714 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 4374: loss = 0.3823 (0.377 sec/step)\n",
            "I0205 13:47:41.911712 140689526667136 learning.py:507] global step 4374: loss = 0.3823 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 4375: loss = 0.2466 (0.365 sec/step)\n",
            "I0205 13:47:42.278190 140689526667136 learning.py:507] global step 4375: loss = 0.2466 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 4376: loss = 0.0647 (0.340 sec/step)\n",
            "I0205 13:47:42.619766 140689526667136 learning.py:507] global step 4376: loss = 0.0647 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 4377: loss = 0.6608 (0.385 sec/step)\n",
            "I0205 13:47:43.006118 140689526667136 learning.py:507] global step 4377: loss = 0.6608 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 4378: loss = 0.0747 (0.373 sec/step)\n",
            "I0205 13:47:43.380614 140689526667136 learning.py:507] global step 4378: loss = 0.0747 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 4379: loss = 0.1672 (0.363 sec/step)\n",
            "I0205 13:47:43.745425 140689526667136 learning.py:507] global step 4379: loss = 0.1672 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 4380: loss = 0.1053 (0.393 sec/step)\n",
            "I0205 13:47:44.140507 140689526667136 learning.py:507] global step 4380: loss = 0.1053 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 4381: loss = 0.2449 (0.376 sec/step)\n",
            "I0205 13:47:44.517898 140689526667136 learning.py:507] global step 4381: loss = 0.2449 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 4382: loss = 0.1592 (0.388 sec/step)\n",
            "I0205 13:47:44.907780 140689526667136 learning.py:507] global step 4382: loss = 0.1592 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 4383: loss = 0.4172 (0.384 sec/step)\n",
            "I0205 13:47:45.293258 140689526667136 learning.py:507] global step 4383: loss = 0.4172 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 4384: loss = 0.1231 (0.399 sec/step)\n",
            "I0205 13:47:45.693674 140689526667136 learning.py:507] global step 4384: loss = 0.1231 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 4385: loss = 0.0772 (0.409 sec/step)\n",
            "I0205 13:47:46.104482 140689526667136 learning.py:507] global step 4385: loss = 0.0772 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 4386: loss = 0.1174 (0.397 sec/step)\n",
            "I0205 13:47:46.503654 140689526667136 learning.py:507] global step 4386: loss = 0.1174 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 4387: loss = 0.6198 (0.394 sec/step)\n",
            "I0205 13:47:46.899223 140689526667136 learning.py:507] global step 4387: loss = 0.6198 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 4388: loss = 0.3212 (0.397 sec/step)\n",
            "I0205 13:47:47.298630 140689526667136 learning.py:507] global step 4388: loss = 0.3212 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 4389: loss = 0.1546 (0.409 sec/step)\n",
            "I0205 13:47:47.709120 140689526667136 learning.py:507] global step 4389: loss = 0.1546 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 4390: loss = 0.3702 (0.375 sec/step)\n",
            "I0205 13:47:48.086110 140689526667136 learning.py:507] global step 4390: loss = 0.3702 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 4391: loss = 0.2671 (0.408 sec/step)\n",
            "I0205 13:47:48.496083 140689526667136 learning.py:507] global step 4391: loss = 0.2671 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 4392: loss = 1.2320 (0.433 sec/step)\n",
            "I0205 13:47:48.931263 140689526667136 learning.py:507] global step 4392: loss = 1.2320 (0.433 sec/step)\n",
            "INFO:tensorflow:global step 4393: loss = 0.1412 (0.394 sec/step)\n",
            "I0205 13:47:49.326915 140689526667136 learning.py:507] global step 4393: loss = 0.1412 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 4394: loss = 0.0633 (0.406 sec/step)\n",
            "I0205 13:47:49.734111 140689526667136 learning.py:507] global step 4394: loss = 0.0633 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 4395: loss = 0.4116 (0.355 sec/step)\n",
            "I0205 13:47:50.090619 140689526667136 learning.py:507] global step 4395: loss = 0.4116 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 4396: loss = 0.1814 (0.379 sec/step)\n",
            "I0205 13:47:50.471423 140689526667136 learning.py:507] global step 4396: loss = 0.1814 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 4397: loss = 0.1672 (0.368 sec/step)\n",
            "I0205 13:47:50.840931 140689526667136 learning.py:507] global step 4397: loss = 0.1672 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 4398: loss = 0.2662 (0.411 sec/step)\n",
            "I0205 13:47:51.253216 140689526667136 learning.py:507] global step 4398: loss = 0.2662 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 4399: loss = 0.1374 (0.400 sec/step)\n",
            "I0205 13:47:51.654751 140689526667136 learning.py:507] global step 4399: loss = 0.1374 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 4400: loss = 0.3250 (0.385 sec/step)\n",
            "I0205 13:47:52.041262 140689526667136 learning.py:507] global step 4400: loss = 0.3250 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 4401: loss = 0.1551 (0.379 sec/step)\n",
            "I0205 13:47:52.421845 140689526667136 learning.py:507] global step 4401: loss = 0.1551 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 4402: loss = 0.2142 (0.425 sec/step)\n",
            "I0205 13:47:52.848313 140689526667136 learning.py:507] global step 4402: loss = 0.2142 (0.425 sec/step)\n",
            "INFO:tensorflow:global step 4403: loss = 0.0813 (0.409 sec/step)\n",
            "I0205 13:47:53.259539 140689526667136 learning.py:507] global step 4403: loss = 0.0813 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 4404: loss = 0.2520 (0.409 sec/step)\n",
            "I0205 13:47:53.669947 140689526667136 learning.py:507] global step 4404: loss = 0.2520 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 4405: loss = 0.9213 (0.383 sec/step)\n",
            "I0205 13:47:54.054921 140689526667136 learning.py:507] global step 4405: loss = 0.9213 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 4406: loss = 0.0759 (0.413 sec/step)\n",
            "I0205 13:47:54.469285 140689526667136 learning.py:507] global step 4406: loss = 0.0759 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 4407: loss = 0.3671 (0.376 sec/step)\n",
            "I0205 13:47:54.846689 140689526667136 learning.py:507] global step 4407: loss = 0.3671 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 4408: loss = 0.0688 (0.345 sec/step)\n",
            "I0205 13:47:55.193697 140689526667136 learning.py:507] global step 4408: loss = 0.0688 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 4409: loss = 0.1387 (0.382 sec/step)\n",
            "I0205 13:47:55.577797 140689526667136 learning.py:507] global step 4409: loss = 0.1387 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 4410: loss = 0.0611 (0.360 sec/step)\n",
            "I0205 13:47:55.939042 140689526667136 learning.py:507] global step 4410: loss = 0.0611 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 4411: loss = 0.2256 (0.353 sec/step)\n",
            "I0205 13:47:56.293851 140689526667136 learning.py:507] global step 4411: loss = 0.2256 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 4412: loss = 0.1822 (0.394 sec/step)\n",
            "I0205 13:47:56.689806 140689526667136 learning.py:507] global step 4412: loss = 0.1822 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 4413: loss = 0.0944 (0.390 sec/step)\n",
            "I0205 13:47:57.081672 140689526667136 learning.py:507] global step 4413: loss = 0.0944 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 4414: loss = 0.0914 (0.374 sec/step)\n",
            "I0205 13:47:57.457649 140689526667136 learning.py:507] global step 4414: loss = 0.0914 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 4415: loss = 0.0194 (0.370 sec/step)\n",
            "I0205 13:47:57.829493 140689526667136 learning.py:507] global step 4415: loss = 0.0194 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 4416: loss = 0.1644 (0.384 sec/step)\n",
            "I0205 13:47:58.214832 140689526667136 learning.py:507] global step 4416: loss = 0.1644 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 4417: loss = 0.1123 (0.366 sec/step)\n",
            "I0205 13:47:58.582558 140689526667136 learning.py:507] global step 4417: loss = 0.1123 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 4418: loss = 0.3639 (0.409 sec/step)\n",
            "I0205 13:47:58.992870 140689526667136 learning.py:507] global step 4418: loss = 0.3639 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 4419: loss = 0.1942 (0.384 sec/step)\n",
            "I0205 13:47:59.378785 140689526667136 learning.py:507] global step 4419: loss = 0.1942 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 4420: loss = 0.0811 (0.381 sec/step)\n",
            "I0205 13:47:59.761482 140689526667136 learning.py:507] global step 4420: loss = 0.0811 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4421: loss = 0.4561 (0.381 sec/step)\n",
            "I0205 13:48:00.143899 140689526667136 learning.py:507] global step 4421: loss = 0.4561 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4422: loss = 0.5030 (0.357 sec/step)\n",
            "I0205 13:48:00.502099 140689526667136 learning.py:507] global step 4422: loss = 0.5030 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 4423: loss = 0.0332 (0.398 sec/step)\n",
            "I0205 13:48:00.901872 140689526667136 learning.py:507] global step 4423: loss = 0.0332 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 4424: loss = 0.1087 (0.369 sec/step)\n",
            "I0205 13:48:01.272627 140689526667136 learning.py:507] global step 4424: loss = 0.1087 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 4425: loss = 0.6836 (0.353 sec/step)\n",
            "I0205 13:48:01.626838 140689526667136 learning.py:507] global step 4425: loss = 0.6836 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 4426: loss = 0.3408 (0.394 sec/step)\n",
            "I0205 13:48:02.021949 140689526667136 learning.py:507] global step 4426: loss = 0.3408 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 4427: loss = 0.0691 (0.392 sec/step)\n",
            "I0205 13:48:02.415935 140689526667136 learning.py:507] global step 4427: loss = 0.0691 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 4428: loss = 0.0353 (0.376 sec/step)\n",
            "I0205 13:48:02.793204 140689526667136 learning.py:507] global step 4428: loss = 0.0353 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 4429: loss = 0.1237 (0.416 sec/step)\n",
            "I0205 13:48:03.211967 140689526667136 learning.py:507] global step 4429: loss = 0.1237 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 4430: loss = 0.2300 (0.390 sec/step)\n",
            "I0205 13:48:03.603656 140689526667136 learning.py:507] global step 4430: loss = 0.2300 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 4431: loss = 0.1182 (0.385 sec/step)\n",
            "I0205 13:48:03.991052 140689526667136 learning.py:507] global step 4431: loss = 0.1182 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 4432: loss = 0.0867 (0.401 sec/step)\n",
            "I0205 13:48:04.393829 140689526667136 learning.py:507] global step 4432: loss = 0.0867 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 4433: loss = 0.2867 (0.376 sec/step)\n",
            "I0205 13:48:04.771678 140689526667136 learning.py:507] global step 4433: loss = 0.2867 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 4434: loss = 0.2118 (0.379 sec/step)\n",
            "I0205 13:48:05.152000 140689526667136 learning.py:507] global step 4434: loss = 0.2118 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 4435: loss = 1.3509 (0.390 sec/step)\n",
            "I0205 13:48:05.544151 140689526667136 learning.py:507] global step 4435: loss = 1.3509 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 4436: loss = 0.3740 (0.382 sec/step)\n",
            "I0205 13:48:05.927970 140689526667136 learning.py:507] global step 4436: loss = 0.3740 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 4437: loss = 0.1468 (0.398 sec/step)\n",
            "I0205 13:48:06.327953 140689526667136 learning.py:507] global step 4437: loss = 0.1468 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 4438: loss = 0.1485 (0.385 sec/step)\n",
            "I0205 13:48:06.714688 140689526667136 learning.py:507] global step 4438: loss = 0.1485 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 4439: loss = 0.0950 (0.367 sec/step)\n",
            "I0205 13:48:07.083235 140689526667136 learning.py:507] global step 4439: loss = 0.0950 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 4440: loss = 0.1125 (0.393 sec/step)\n",
            "I0205 13:48:07.477803 140689526667136 learning.py:507] global step 4440: loss = 0.1125 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 4441: loss = 0.2441 (0.377 sec/step)\n",
            "I0205 13:48:07.856815 140689526667136 learning.py:507] global step 4441: loss = 0.2441 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 4442: loss = 0.2410 (0.394 sec/step)\n",
            "I0205 13:48:08.252147 140689526667136 learning.py:507] global step 4442: loss = 0.2410 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 4443: loss = 0.6124 (0.399 sec/step)\n",
            "I0205 13:48:08.652401 140689526667136 learning.py:507] global step 4443: loss = 0.6124 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 4444: loss = 0.0961 (0.400 sec/step)\n",
            "I0205 13:48:09.054040 140689526667136 learning.py:507] global step 4444: loss = 0.0961 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 4445: loss = 0.0984 (0.396 sec/step)\n",
            "I0205 13:48:09.451531 140689526667136 learning.py:507] global step 4445: loss = 0.0984 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 4446: loss = 0.1598 (0.369 sec/step)\n",
            "I0205 13:48:09.822080 140689526667136 learning.py:507] global step 4446: loss = 0.1598 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 4447: loss = 0.1217 (0.382 sec/step)\n",
            "I0205 13:48:10.205306 140689526667136 learning.py:507] global step 4447: loss = 0.1217 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 4448: loss = 0.1021 (0.366 sec/step)\n",
            "I0205 13:48:10.572332 140689526667136 learning.py:507] global step 4448: loss = 0.1021 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 4449: loss = 0.1706 (0.391 sec/step)\n",
            "I0205 13:48:10.964682 140689526667136 learning.py:507] global step 4449: loss = 0.1706 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 4450: loss = 0.0338 (0.353 sec/step)\n",
            "I0205 13:48:11.318842 140689526667136 learning.py:507] global step 4450: loss = 0.0338 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 4451: loss = 0.1268 (0.376 sec/step)\n",
            "I0205 13:48:11.696426 140689526667136 learning.py:507] global step 4451: loss = 0.1268 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 4452: loss = 0.1639 (0.370 sec/step)\n",
            "I0205 13:48:12.067932 140689526667136 learning.py:507] global step 4452: loss = 0.1639 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 4453: loss = 0.1341 (0.348 sec/step)\n",
            "I0205 13:48:12.418076 140689526667136 learning.py:507] global step 4453: loss = 0.1341 (0.348 sec/step)\n",
            "INFO:tensorflow:global step 4454: loss = 0.0612 (0.388 sec/step)\n",
            "I0205 13:48:12.807924 140689526667136 learning.py:507] global step 4454: loss = 0.0612 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 4455: loss = 0.0948 (0.371 sec/step)\n",
            "I0205 13:48:13.180792 140689526667136 learning.py:507] global step 4455: loss = 0.0948 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 4456: loss = 0.1494 (0.403 sec/step)\n",
            "I0205 13:48:13.585175 140689526667136 learning.py:507] global step 4456: loss = 0.1494 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 4457: loss = 0.0230 (0.642 sec/step)\n",
            "I0205 13:48:14.363135 140689526667136 learning.py:507] global step 4457: loss = 0.0230 (0.642 sec/step)\n",
            "INFO:tensorflow:global step 4458: loss = 0.2442 (0.967 sec/step)\n",
            "I0205 13:48:15.499510 140689526667136 learning.py:507] global step 4458: loss = 0.2442 (0.967 sec/step)\n",
            "INFO:tensorflow:global step 4459: loss = 0.3818 (0.641 sec/step)\n",
            "I0205 13:48:16.158679 140689526667136 learning.py:507] global step 4459: loss = 0.3818 (0.641 sec/step)\n",
            "INFO:tensorflow:global step 4460: loss = 0.5584 (0.630 sec/step)\n",
            "I0205 13:48:16.799707 140689526667136 learning.py:507] global step 4460: loss = 0.5584 (0.630 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 4460.\n",
            "I0205 13:48:17.092660 140686026073856 supervisor.py:1050] Recording summary at step 4460.\n",
            "INFO:tensorflow:global step 4461: loss = 0.0723 (0.520 sec/step)\n",
            "I0205 13:48:17.323084 140689526667136 learning.py:507] global step 4461: loss = 0.0723 (0.520 sec/step)\n",
            "INFO:tensorflow:global step 4462: loss = 0.1778 (0.393 sec/step)\n",
            "I0205 13:48:17.717644 140689526667136 learning.py:507] global step 4462: loss = 0.1778 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 4463: loss = 0.2807 (0.376 sec/step)\n",
            "I0205 13:48:18.094977 140689526667136 learning.py:507] global step 4463: loss = 0.2807 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 4464: loss = 0.4688 (0.375 sec/step)\n",
            "I0205 13:48:18.471350 140689526667136 learning.py:507] global step 4464: loss = 0.4688 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 4465: loss = 0.0377 (0.393 sec/step)\n",
            "I0205 13:48:18.866361 140689526667136 learning.py:507] global step 4465: loss = 0.0377 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 4466: loss = 0.3342 (0.396 sec/step)\n",
            "I0205 13:48:19.264726 140689526667136 learning.py:507] global step 4466: loss = 0.3342 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 4467: loss = 0.0580 (0.419 sec/step)\n",
            "I0205 13:48:19.685482 140689526667136 learning.py:507] global step 4467: loss = 0.0580 (0.419 sec/step)\n",
            "INFO:tensorflow:global step 4468: loss = 0.0740 (0.359 sec/step)\n",
            "I0205 13:48:20.045658 140689526667136 learning.py:507] global step 4468: loss = 0.0740 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 4469: loss = 0.0351 (0.359 sec/step)\n",
            "I0205 13:48:20.406247 140689526667136 learning.py:507] global step 4469: loss = 0.0351 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 4470: loss = 1.0923 (0.382 sec/step)\n",
            "I0205 13:48:20.789932 140689526667136 learning.py:507] global step 4470: loss = 1.0923 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 4471: loss = 0.1631 (0.389 sec/step)\n",
            "I0205 13:48:21.180910 140689526667136 learning.py:507] global step 4471: loss = 0.1631 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 4472: loss = 0.1166 (0.376 sec/step)\n",
            "I0205 13:48:21.559508 140689526667136 learning.py:507] global step 4472: loss = 0.1166 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 4473: loss = 0.2046 (0.374 sec/step)\n",
            "I0205 13:48:21.935302 140689526667136 learning.py:507] global step 4473: loss = 0.2046 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 4474: loss = 0.2747 (0.396 sec/step)\n",
            "I0205 13:48:22.333721 140689526667136 learning.py:507] global step 4474: loss = 0.2747 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 4475: loss = 0.0844 (0.366 sec/step)\n",
            "I0205 13:48:22.701804 140689526667136 learning.py:507] global step 4475: loss = 0.0844 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 4476: loss = 0.1444 (0.400 sec/step)\n",
            "I0205 13:48:23.103884 140689526667136 learning.py:507] global step 4476: loss = 0.1444 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 4477: loss = 0.0972 (0.391 sec/step)\n",
            "I0205 13:48:23.496437 140689526667136 learning.py:507] global step 4477: loss = 0.0972 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 4478: loss = 0.3074 (0.390 sec/step)\n",
            "I0205 13:48:23.888725 140689526667136 learning.py:507] global step 4478: loss = 0.3074 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 4479: loss = 0.1546 (0.393 sec/step)\n",
            "I0205 13:48:24.283348 140689526667136 learning.py:507] global step 4479: loss = 0.1546 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 4480: loss = 0.0555 (0.398 sec/step)\n",
            "I0205 13:48:24.682525 140689526667136 learning.py:507] global step 4480: loss = 0.0555 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 4481: loss = 0.1540 (0.399 sec/step)\n",
            "I0205 13:48:25.083330 140689526667136 learning.py:507] global step 4481: loss = 0.1540 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 4482: loss = 0.0531 (0.399 sec/step)\n",
            "I0205 13:48:25.484443 140689526667136 learning.py:507] global step 4482: loss = 0.0531 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 4483: loss = 0.1142 (0.385 sec/step)\n",
            "I0205 13:48:25.871132 140689526667136 learning.py:507] global step 4483: loss = 0.1142 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 4484: loss = 0.0712 (0.359 sec/step)\n",
            "I0205 13:48:26.232243 140689526667136 learning.py:507] global step 4484: loss = 0.0712 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 4485: loss = 0.0466 (0.376 sec/step)\n",
            "I0205 13:48:26.609787 140689526667136 learning.py:507] global step 4485: loss = 0.0466 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 4486: loss = 0.0980 (0.367 sec/step)\n",
            "I0205 13:48:26.978926 140689526667136 learning.py:507] global step 4486: loss = 0.0980 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 4487: loss = 0.1237 (0.372 sec/step)\n",
            "I0205 13:48:27.352977 140689526667136 learning.py:507] global step 4487: loss = 0.1237 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 4488: loss = 0.4562 (0.387 sec/step)\n",
            "I0205 13:48:27.742273 140689526667136 learning.py:507] global step 4488: loss = 0.4562 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 4489: loss = 0.2671 (0.386 sec/step)\n",
            "I0205 13:48:28.130250 140689526667136 learning.py:507] global step 4489: loss = 0.2671 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 4490: loss = 0.1031 (0.376 sec/step)\n",
            "I0205 13:48:28.507813 140689526667136 learning.py:507] global step 4490: loss = 0.1031 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 4491: loss = 0.0495 (0.369 sec/step)\n",
            "I0205 13:48:28.878207 140689526667136 learning.py:507] global step 4491: loss = 0.0495 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 4492: loss = 0.2176 (0.398 sec/step)\n",
            "I0205 13:48:29.277839 140689526667136 learning.py:507] global step 4492: loss = 0.2176 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 4493: loss = 0.2819 (0.408 sec/step)\n",
            "I0205 13:48:29.687673 140689526667136 learning.py:507] global step 4493: loss = 0.2819 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 4494: loss = 0.2234 (0.428 sec/step)\n",
            "I0205 13:48:30.117272 140689526667136 learning.py:507] global step 4494: loss = 0.2234 (0.428 sec/step)\n",
            "INFO:tensorflow:global step 4495: loss = 0.0302 (0.400 sec/step)\n",
            "I0205 13:48:30.519204 140689526667136 learning.py:507] global step 4495: loss = 0.0302 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 4496: loss = 0.0958 (0.404 sec/step)\n",
            "I0205 13:48:30.925294 140689526667136 learning.py:507] global step 4496: loss = 0.0958 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 4497: loss = 0.1111 (0.445 sec/step)\n",
            "I0205 13:48:31.371876 140689526667136 learning.py:507] global step 4497: loss = 0.1111 (0.445 sec/step)\n",
            "INFO:tensorflow:global step 4498: loss = 0.1630 (0.405 sec/step)\n",
            "I0205 13:48:31.778755 140689526667136 learning.py:507] global step 4498: loss = 0.1630 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 4499: loss = 0.1165 (0.401 sec/step)\n",
            "I0205 13:48:32.181217 140689526667136 learning.py:507] global step 4499: loss = 0.1165 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 4500: loss = 0.2635 (0.381 sec/step)\n",
            "I0205 13:48:32.563549 140689526667136 learning.py:507] global step 4500: loss = 0.2635 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4501: loss = 0.0501 (0.410 sec/step)\n",
            "I0205 13:48:32.975014 140689526667136 learning.py:507] global step 4501: loss = 0.0501 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 4502: loss = 0.0779 (0.399 sec/step)\n",
            "I0205 13:48:33.375784 140689526667136 learning.py:507] global step 4502: loss = 0.0779 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 4503: loss = 0.1718 (0.395 sec/step)\n",
            "I0205 13:48:33.772227 140689526667136 learning.py:507] global step 4503: loss = 0.1718 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 4504: loss = 0.0783 (0.403 sec/step)\n",
            "I0205 13:48:34.177061 140689526667136 learning.py:507] global step 4504: loss = 0.0783 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 4505: loss = 0.1173 (0.390 sec/step)\n",
            "I0205 13:48:34.568370 140689526667136 learning.py:507] global step 4505: loss = 0.1173 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 4506: loss = 0.1688 (0.402 sec/step)\n",
            "I0205 13:48:34.971931 140689526667136 learning.py:507] global step 4506: loss = 0.1688 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 4507: loss = 0.0112 (0.404 sec/step)\n",
            "I0205 13:48:35.377270 140689526667136 learning.py:507] global step 4507: loss = 0.0112 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 4508: loss = 0.3168 (0.351 sec/step)\n",
            "I0205 13:48:35.730327 140689526667136 learning.py:507] global step 4508: loss = 0.3168 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 4509: loss = 0.0536 (0.384 sec/step)\n",
            "I0205 13:48:36.115592 140689526667136 learning.py:507] global step 4509: loss = 0.0536 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 4510: loss = 0.0997 (0.384 sec/step)\n",
            "I0205 13:48:36.501211 140689526667136 learning.py:507] global step 4510: loss = 0.0997 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 4511: loss = 0.1354 (0.388 sec/step)\n",
            "I0205 13:48:36.890854 140689526667136 learning.py:507] global step 4511: loss = 0.1354 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 4512: loss = 0.0632 (0.378 sec/step)\n",
            "I0205 13:48:37.271116 140689526667136 learning.py:507] global step 4512: loss = 0.0632 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 4513: loss = 0.1285 (0.353 sec/step)\n",
            "I0205 13:48:37.625916 140689526667136 learning.py:507] global step 4513: loss = 0.1285 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 4514: loss = 0.1033 (0.354 sec/step)\n",
            "I0205 13:48:37.981648 140689526667136 learning.py:507] global step 4514: loss = 0.1033 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 4515: loss = 0.0537 (0.393 sec/step)\n",
            "I0205 13:48:38.376075 140689526667136 learning.py:507] global step 4515: loss = 0.0537 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 4516: loss = 0.0746 (0.400 sec/step)\n",
            "I0205 13:48:38.777540 140689526667136 learning.py:507] global step 4516: loss = 0.0746 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 4517: loss = 0.3031 (0.377 sec/step)\n",
            "I0205 13:48:39.156668 140689526667136 learning.py:507] global step 4517: loss = 0.3031 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 4518: loss = 0.1058 (0.409 sec/step)\n",
            "I0205 13:48:39.567543 140689526667136 learning.py:507] global step 4518: loss = 0.1058 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 4519: loss = 0.0846 (0.404 sec/step)\n",
            "I0205 13:48:39.973703 140689526667136 learning.py:507] global step 4519: loss = 0.0846 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 4520: loss = 0.1526 (0.381 sec/step)\n",
            "I0205 13:48:40.355933 140689526667136 learning.py:507] global step 4520: loss = 0.1526 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4521: loss = 0.1677 (0.386 sec/step)\n",
            "I0205 13:48:40.744216 140689526667136 learning.py:507] global step 4521: loss = 0.1677 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 4522: loss = 0.0490 (0.381 sec/step)\n",
            "I0205 13:48:41.126881 140689526667136 learning.py:507] global step 4522: loss = 0.0490 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4523: loss = 0.0712 (0.464 sec/step)\n",
            "I0205 13:48:41.594763 140689526667136 learning.py:507] global step 4523: loss = 0.0712 (0.464 sec/step)\n",
            "INFO:tensorflow:global step 4524: loss = 0.2541 (0.380 sec/step)\n",
            "I0205 13:48:41.977111 140689526667136 learning.py:507] global step 4524: loss = 0.2541 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 4525: loss = 0.0563 (0.406 sec/step)\n",
            "I0205 13:48:42.384083 140689526667136 learning.py:507] global step 4525: loss = 0.0563 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 4526: loss = 0.2473 (0.363 sec/step)\n",
            "I0205 13:48:42.749591 140689526667136 learning.py:507] global step 4526: loss = 0.2473 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 4527: loss = 0.1122 (0.381 sec/step)\n",
            "I0205 13:48:43.132075 140689526667136 learning.py:507] global step 4527: loss = 0.1122 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4528: loss = 0.5257 (0.399 sec/step)\n",
            "I0205 13:48:43.532970 140689526667136 learning.py:507] global step 4528: loss = 0.5257 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 4529: loss = 0.9750 (0.404 sec/step)\n",
            "I0205 13:48:43.938406 140689526667136 learning.py:507] global step 4529: loss = 0.9750 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 4530: loss = 0.7657 (0.413 sec/step)\n",
            "I0205 13:48:44.353493 140689526667136 learning.py:507] global step 4530: loss = 0.7657 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 4531: loss = 0.0943 (0.391 sec/step)\n",
            "I0205 13:48:44.746055 140689526667136 learning.py:507] global step 4531: loss = 0.0943 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 4532: loss = 0.1287 (0.395 sec/step)\n",
            "I0205 13:48:45.142784 140689526667136 learning.py:507] global step 4532: loss = 0.1287 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 4533: loss = 0.5400 (0.400 sec/step)\n",
            "I0205 13:48:45.544514 140689526667136 learning.py:507] global step 4533: loss = 0.5400 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 4534: loss = 0.0320 (0.398 sec/step)\n",
            "I0205 13:48:45.943783 140689526667136 learning.py:507] global step 4534: loss = 0.0320 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 4535: loss = 0.4081 (0.394 sec/step)\n",
            "I0205 13:48:46.339327 140689526667136 learning.py:507] global step 4535: loss = 0.4081 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 4536: loss = 0.0858 (0.428 sec/step)\n",
            "I0205 13:48:46.769407 140689526667136 learning.py:507] global step 4536: loss = 0.0858 (0.428 sec/step)\n",
            "INFO:tensorflow:global step 4537: loss = 0.1231 (0.375 sec/step)\n",
            "I0205 13:48:47.146437 140689526667136 learning.py:507] global step 4537: loss = 0.1231 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 4538: loss = 0.1098 (0.405 sec/step)\n",
            "I0205 13:48:47.552700 140689526667136 learning.py:507] global step 4538: loss = 0.1098 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 4539: loss = 0.0459 (0.380 sec/step)\n",
            "I0205 13:48:47.934515 140689526667136 learning.py:507] global step 4539: loss = 0.0459 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 4540: loss = 0.1497 (0.404 sec/step)\n",
            "I0205 13:48:48.341000 140689526667136 learning.py:507] global step 4540: loss = 0.1497 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 4541: loss = 0.8814 (0.399 sec/step)\n",
            "I0205 13:48:48.741563 140689526667136 learning.py:507] global step 4541: loss = 0.8814 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 4542: loss = 0.1080 (0.384 sec/step)\n",
            "I0205 13:48:49.127423 140689526667136 learning.py:507] global step 4542: loss = 0.1080 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 4543: loss = 0.1318 (0.377 sec/step)\n",
            "I0205 13:48:49.506192 140689526667136 learning.py:507] global step 4543: loss = 0.1318 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 4544: loss = 0.4734 (0.390 sec/step)\n",
            "I0205 13:48:49.897964 140689526667136 learning.py:507] global step 4544: loss = 0.4734 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 4545: loss = 0.1592 (0.356 sec/step)\n",
            "I0205 13:48:50.255404 140689526667136 learning.py:507] global step 4545: loss = 0.1592 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 4546: loss = 0.0795 (0.415 sec/step)\n",
            "I0205 13:48:50.672286 140689526667136 learning.py:507] global step 4546: loss = 0.0795 (0.415 sec/step)\n",
            "INFO:tensorflow:global step 4547: loss = 0.0923 (0.373 sec/step)\n",
            "I0205 13:48:51.046971 140689526667136 learning.py:507] global step 4547: loss = 0.0923 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 4548: loss = 0.0671 (0.389 sec/step)\n",
            "I0205 13:48:51.437365 140689526667136 learning.py:507] global step 4548: loss = 0.0671 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 4549: loss = 0.1416 (0.411 sec/step)\n",
            "I0205 13:48:51.851337 140689526667136 learning.py:507] global step 4549: loss = 0.1416 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 4550: loss = 0.1217 (0.397 sec/step)\n",
            "I0205 13:48:52.251089 140689526667136 learning.py:507] global step 4550: loss = 0.1217 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 4551: loss = 0.1922 (0.433 sec/step)\n",
            "I0205 13:48:52.685967 140689526667136 learning.py:507] global step 4551: loss = 0.1922 (0.433 sec/step)\n",
            "INFO:tensorflow:global step 4552: loss = 0.1806 (0.412 sec/step)\n",
            "I0205 13:48:53.099808 140689526667136 learning.py:507] global step 4552: loss = 0.1806 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 4553: loss = 0.0340 (0.411 sec/step)\n",
            "I0205 13:48:53.512775 140689526667136 learning.py:507] global step 4553: loss = 0.0340 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 4554: loss = 0.2393 (0.421 sec/step)\n",
            "I0205 13:48:53.935572 140689526667136 learning.py:507] global step 4554: loss = 0.2393 (0.421 sec/step)\n",
            "INFO:tensorflow:global step 4555: loss = 0.1424 (0.413 sec/step)\n",
            "I0205 13:48:54.350453 140689526667136 learning.py:507] global step 4555: loss = 0.1424 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 4556: loss = 0.2254 (0.393 sec/step)\n",
            "I0205 13:48:54.746936 140689526667136 learning.py:507] global step 4556: loss = 0.2254 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 4557: loss = 0.4637 (0.404 sec/step)\n",
            "I0205 13:48:55.153269 140689526667136 learning.py:507] global step 4557: loss = 0.4637 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 4558: loss = 0.6439 (0.392 sec/step)\n",
            "I0205 13:48:55.547513 140689526667136 learning.py:507] global step 4558: loss = 0.6439 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 4559: loss = 0.0586 (0.405 sec/step)\n",
            "I0205 13:48:55.955441 140689526667136 learning.py:507] global step 4559: loss = 0.0586 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 4560: loss = 0.3566 (0.405 sec/step)\n",
            "I0205 13:48:56.362516 140689526667136 learning.py:507] global step 4560: loss = 0.3566 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 4561: loss = 0.1085 (0.403 sec/step)\n",
            "I0205 13:48:56.766941 140689526667136 learning.py:507] global step 4561: loss = 0.1085 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 4562: loss = 0.2552 (0.390 sec/step)\n",
            "I0205 13:48:57.159283 140689526667136 learning.py:507] global step 4562: loss = 0.2552 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 4563: loss = 0.1031 (0.378 sec/step)\n",
            "I0205 13:48:57.539190 140689526667136 learning.py:507] global step 4563: loss = 0.1031 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 4564: loss = 0.2945 (0.368 sec/step)\n",
            "I0205 13:48:57.908835 140689526667136 learning.py:507] global step 4564: loss = 0.2945 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 4565: loss = 0.9961 (0.399 sec/step)\n",
            "I0205 13:48:58.309619 140689526667136 learning.py:507] global step 4565: loss = 0.9961 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 4566: loss = 0.1392 (0.398 sec/step)\n",
            "I0205 13:48:58.709038 140689526667136 learning.py:507] global step 4566: loss = 0.1392 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 4567: loss = 0.3469 (0.417 sec/step)\n",
            "I0205 13:48:59.127310 140689526667136 learning.py:507] global step 4567: loss = 0.3469 (0.417 sec/step)\n",
            "INFO:tensorflow:global step 4568: loss = 0.1319 (0.419 sec/step)\n",
            "I0205 13:48:59.548384 140689526667136 learning.py:507] global step 4568: loss = 0.1319 (0.419 sec/step)\n",
            "INFO:tensorflow:global step 4569: loss = 0.3473 (0.395 sec/step)\n",
            "I0205 13:48:59.945041 140689526667136 learning.py:507] global step 4569: loss = 0.3473 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 4570: loss = 0.3459 (0.393 sec/step)\n",
            "I0205 13:49:00.339287 140689526667136 learning.py:507] global step 4570: loss = 0.3459 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 4571: loss = 0.3212 (0.394 sec/step)\n",
            "I0205 13:49:00.734555 140689526667136 learning.py:507] global step 4571: loss = 0.3212 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 4572: loss = 0.3853 (0.440 sec/step)\n",
            "I0205 13:49:01.177036 140689526667136 learning.py:507] global step 4572: loss = 0.3853 (0.440 sec/step)\n",
            "INFO:tensorflow:global step 4573: loss = 0.2197 (0.391 sec/step)\n",
            "I0205 13:49:01.570007 140689526667136 learning.py:507] global step 4573: loss = 0.2197 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 4574: loss = 0.6017 (0.384 sec/step)\n",
            "I0205 13:49:01.955787 140689526667136 learning.py:507] global step 4574: loss = 0.6017 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 4575: loss = 0.0933 (0.403 sec/step)\n",
            "I0205 13:49:02.361057 140689526667136 learning.py:507] global step 4575: loss = 0.0933 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 4576: loss = 0.1249 (0.369 sec/step)\n",
            "I0205 13:49:02.732215 140689526667136 learning.py:507] global step 4576: loss = 0.1249 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 4577: loss = 0.2838 (0.408 sec/step)\n",
            "I0205 13:49:03.141916 140689526667136 learning.py:507] global step 4577: loss = 0.2838 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 4578: loss = 0.0824 (0.388 sec/step)\n",
            "I0205 13:49:03.531852 140689526667136 learning.py:507] global step 4578: loss = 0.0824 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 4579: loss = 0.2275 (0.394 sec/step)\n",
            "I0205 13:49:03.927457 140689526667136 learning.py:507] global step 4579: loss = 0.2275 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 4580: loss = 0.0474 (0.384 sec/step)\n",
            "I0205 13:49:04.313600 140689526667136 learning.py:507] global step 4580: loss = 0.0474 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 4581: loss = 0.1563 (0.398 sec/step)\n",
            "I0205 13:49:04.713122 140689526667136 learning.py:507] global step 4581: loss = 0.1563 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 4582: loss = 0.0730 (0.386 sec/step)\n",
            "I0205 13:49:05.100866 140689526667136 learning.py:507] global step 4582: loss = 0.0730 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 4583: loss = 0.2941 (0.410 sec/step)\n",
            "I0205 13:49:05.512691 140689526667136 learning.py:507] global step 4583: loss = 0.2941 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 4584: loss = 0.0682 (0.361 sec/step)\n",
            "I0205 13:49:05.875769 140689526667136 learning.py:507] global step 4584: loss = 0.0682 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 4585: loss = 0.0802 (0.365 sec/step)\n",
            "I0205 13:49:06.242547 140689526667136 learning.py:507] global step 4585: loss = 0.0802 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 4586: loss = 0.4288 (0.384 sec/step)\n",
            "I0205 13:49:06.627848 140689526667136 learning.py:507] global step 4586: loss = 0.4288 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 4587: loss = 0.2992 (0.391 sec/step)\n",
            "I0205 13:49:07.020750 140689526667136 learning.py:507] global step 4587: loss = 0.2992 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 4588: loss = 0.0411 (0.374 sec/step)\n",
            "I0205 13:49:07.396709 140689526667136 learning.py:507] global step 4588: loss = 0.0411 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 4589: loss = 0.0413 (0.395 sec/step)\n",
            "I0205 13:49:07.793399 140689526667136 learning.py:507] global step 4589: loss = 0.0413 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 4590: loss = 0.3483 (0.396 sec/step)\n",
            "I0205 13:49:08.190938 140689526667136 learning.py:507] global step 4590: loss = 0.3483 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 4591: loss = 0.1708 (0.387 sec/step)\n",
            "I0205 13:49:08.582891 140689526667136 learning.py:507] global step 4591: loss = 0.1708 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 4592: loss = 0.1518 (0.368 sec/step)\n",
            "I0205 13:49:08.953061 140689526667136 learning.py:507] global step 4592: loss = 0.1518 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 4593: loss = 0.1687 (0.422 sec/step)\n",
            "I0205 13:49:09.376861 140689526667136 learning.py:507] global step 4593: loss = 0.1687 (0.422 sec/step)\n",
            "INFO:tensorflow:global step 4594: loss = 0.2624 (0.387 sec/step)\n",
            "I0205 13:49:09.766086 140689526667136 learning.py:507] global step 4594: loss = 0.2624 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 4595: loss = 0.2938 (0.396 sec/step)\n",
            "I0205 13:49:10.163613 140689526667136 learning.py:507] global step 4595: loss = 0.2938 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 4596: loss = 0.4876 (0.357 sec/step)\n",
            "I0205 13:49:10.522769 140689526667136 learning.py:507] global step 4596: loss = 0.4876 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 4597: loss = 0.1137 (0.393 sec/step)\n",
            "I0205 13:49:10.917702 140689526667136 learning.py:507] global step 4597: loss = 0.1137 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 4598: loss = 0.0833 (0.370 sec/step)\n",
            "I0205 13:49:11.289386 140689526667136 learning.py:507] global step 4598: loss = 0.0833 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 4599: loss = 0.0368 (0.379 sec/step)\n",
            "I0205 13:49:11.670430 140689526667136 learning.py:507] global step 4599: loss = 0.0368 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 4600: loss = 0.2417 (0.410 sec/step)\n",
            "I0205 13:49:12.082075 140689526667136 learning.py:507] global step 4600: loss = 0.2417 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 4601: loss = 0.0709 (0.422 sec/step)\n",
            "I0205 13:49:12.505799 140689526667136 learning.py:507] global step 4601: loss = 0.0709 (0.422 sec/step)\n",
            "INFO:tensorflow:global step 4602: loss = 0.5797 (0.403 sec/step)\n",
            "I0205 13:49:12.910108 140689526667136 learning.py:507] global step 4602: loss = 0.5797 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 4603: loss = 0.1639 (0.398 sec/step)\n",
            "I0205 13:49:13.309953 140689526667136 learning.py:507] global step 4603: loss = 0.1639 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 4604: loss = 0.1011 (0.372 sec/step)\n",
            "I0205 13:49:13.683676 140689526667136 learning.py:507] global step 4604: loss = 0.1011 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 4605: loss = 0.0677 (0.373 sec/step)\n",
            "I0205 13:49:14.058880 140689526667136 learning.py:507] global step 4605: loss = 0.0677 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 4606: loss = 0.2711 (0.382 sec/step)\n",
            "I0205 13:49:14.442572 140689526667136 learning.py:507] global step 4606: loss = 0.2711 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 4607: loss = 0.0298 (0.377 sec/step)\n",
            "I0205 13:49:14.821400 140689526667136 learning.py:507] global step 4607: loss = 0.0298 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 4608: loss = 0.0820 (0.388 sec/step)\n",
            "I0205 13:49:15.211116 140689526667136 learning.py:507] global step 4608: loss = 0.0820 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 4609: loss = 0.6415 (0.359 sec/step)\n",
            "I0205 13:49:15.571992 140689526667136 learning.py:507] global step 4609: loss = 0.6415 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 4610: loss = 0.2811 (0.377 sec/step)\n",
            "I0205 13:49:15.950207 140689526667136 learning.py:507] global step 4610: loss = 0.2811 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 4611: loss = 0.2695 (0.406 sec/step)\n",
            "I0205 13:49:16.358026 140689526667136 learning.py:507] global step 4611: loss = 0.2695 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 4612: loss = 0.0809 (0.365 sec/step)\n",
            "I0205 13:49:16.724836 140689526667136 learning.py:507] global step 4612: loss = 0.0809 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 4613: loss = 0.0560 (0.359 sec/step)\n",
            "I0205 13:49:17.085274 140689526667136 learning.py:507] global step 4613: loss = 0.0560 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 4614: loss = 0.0786 (0.385 sec/step)\n",
            "I0205 13:49:17.472329 140689526667136 learning.py:507] global step 4614: loss = 0.0786 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 4615: loss = 0.4257 (0.365 sec/step)\n",
            "I0205 13:49:17.838744 140689526667136 learning.py:507] global step 4615: loss = 0.4257 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 4616: loss = 0.0499 (0.404 sec/step)\n",
            "I0205 13:49:18.244064 140689526667136 learning.py:507] global step 4616: loss = 0.0499 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 4617: loss = 0.2259 (0.396 sec/step)\n",
            "I0205 13:49:18.641448 140689526667136 learning.py:507] global step 4617: loss = 0.2259 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 4618: loss = 0.0709 (0.382 sec/step)\n",
            "I0205 13:49:19.025339 140689526667136 learning.py:507] global step 4618: loss = 0.0709 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 4619: loss = 0.3755 (0.405 sec/step)\n",
            "I0205 13:49:19.431994 140689526667136 learning.py:507] global step 4619: loss = 0.3755 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 4620: loss = 0.0971 (0.393 sec/step)\n",
            "I0205 13:49:19.826775 140689526667136 learning.py:507] global step 4620: loss = 0.0971 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 4621: loss = 0.0857 (0.392 sec/step)\n",
            "I0205 13:49:20.220601 140689526667136 learning.py:507] global step 4621: loss = 0.0857 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 4622: loss = 0.0635 (0.405 sec/step)\n",
            "I0205 13:49:20.627797 140689526667136 learning.py:507] global step 4622: loss = 0.0635 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 4623: loss = 0.0523 (0.369 sec/step)\n",
            "I0205 13:49:20.998096 140689526667136 learning.py:507] global step 4623: loss = 0.0523 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 4624: loss = 0.2336 (0.387 sec/step)\n",
            "I0205 13:49:21.386563 140689526667136 learning.py:507] global step 4624: loss = 0.2336 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 4625: loss = 1.1798 (0.395 sec/step)\n",
            "I0205 13:49:21.783418 140689526667136 learning.py:507] global step 4625: loss = 1.1798 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 4626: loss = 0.3046 (0.394 sec/step)\n",
            "I0205 13:49:22.179436 140689526667136 learning.py:507] global step 4626: loss = 0.3046 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 4627: loss = 0.2506 (0.361 sec/step)\n",
            "I0205 13:49:22.541939 140689526667136 learning.py:507] global step 4627: loss = 0.2506 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 4628: loss = 0.0731 (0.428 sec/step)\n",
            "I0205 13:49:22.971831 140689526667136 learning.py:507] global step 4628: loss = 0.0731 (0.428 sec/step)\n",
            "INFO:tensorflow:global step 4629: loss = 0.1108 (0.383 sec/step)\n",
            "I0205 13:49:23.356572 140689526667136 learning.py:507] global step 4629: loss = 0.1108 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 4630: loss = 0.1159 (0.380 sec/step)\n",
            "I0205 13:49:23.740593 140689526667136 learning.py:507] global step 4630: loss = 0.1159 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 4631: loss = 0.0178 (0.396 sec/step)\n",
            "I0205 13:49:24.137963 140689526667136 learning.py:507] global step 4631: loss = 0.0178 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 4632: loss = 0.5205 (0.398 sec/step)\n",
            "I0205 13:49:24.537150 140689526667136 learning.py:507] global step 4632: loss = 0.5205 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 4633: loss = 0.1166 (0.369 sec/step)\n",
            "I0205 13:49:24.908159 140689526667136 learning.py:507] global step 4633: loss = 0.1166 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 4634: loss = 0.0971 (0.396 sec/step)\n",
            "I0205 13:49:25.305668 140689526667136 learning.py:507] global step 4634: loss = 0.0971 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 4635: loss = 0.1684 (0.363 sec/step)\n",
            "I0205 13:49:25.670317 140689526667136 learning.py:507] global step 4635: loss = 0.1684 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 4636: loss = 0.0869 (0.364 sec/step)\n",
            "I0205 13:49:26.035597 140689526667136 learning.py:507] global step 4636: loss = 0.0869 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 4637: loss = 0.0965 (0.387 sec/step)\n",
            "I0205 13:49:26.424954 140689526667136 learning.py:507] global step 4637: loss = 0.0965 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 4638: loss = 0.0800 (0.379 sec/step)\n",
            "I0205 13:49:26.806046 140689526667136 learning.py:507] global step 4638: loss = 0.0800 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 4639: loss = 0.2241 (0.409 sec/step)\n",
            "I0205 13:49:27.216929 140689526667136 learning.py:507] global step 4639: loss = 0.2241 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 4640: loss = 0.1573 (0.390 sec/step)\n",
            "I0205 13:49:27.608477 140689526667136 learning.py:507] global step 4640: loss = 0.1573 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 4641: loss = 0.2863 (0.356 sec/step)\n",
            "I0205 13:49:27.966191 140689526667136 learning.py:507] global step 4641: loss = 0.2863 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 4642: loss = 0.1109 (0.358 sec/step)\n",
            "I0205 13:49:28.325976 140689526667136 learning.py:507] global step 4642: loss = 0.1109 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 4643: loss = 0.0912 (0.363 sec/step)\n",
            "I0205 13:49:28.690756 140689526667136 learning.py:507] global step 4643: loss = 0.0912 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 4644: loss = 0.2638 (0.399 sec/step)\n",
            "I0205 13:49:29.091629 140689526667136 learning.py:507] global step 4644: loss = 0.2638 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 4645: loss = 0.2788 (0.403 sec/step)\n",
            "I0205 13:49:29.496177 140689526667136 learning.py:507] global step 4645: loss = 0.2788 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 4646: loss = 0.2666 (0.429 sec/step)\n",
            "I0205 13:49:29.927249 140689526667136 learning.py:507] global step 4646: loss = 0.2666 (0.429 sec/step)\n",
            "INFO:tensorflow:global step 4647: loss = 0.2025 (0.378 sec/step)\n",
            "I0205 13:49:30.307060 140689526667136 learning.py:507] global step 4647: loss = 0.2025 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 4648: loss = 0.1322 (0.387 sec/step)\n",
            "I0205 13:49:30.696336 140689526667136 learning.py:507] global step 4648: loss = 0.1322 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 4649: loss = 0.0859 (0.404 sec/step)\n",
            "I0205 13:49:31.102472 140689526667136 learning.py:507] global step 4649: loss = 0.0859 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 4650: loss = 0.0585 (0.410 sec/step)\n",
            "I0205 13:49:31.514477 140689526667136 learning.py:507] global step 4650: loss = 0.0585 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 4651: loss = 0.2131 (0.397 sec/step)\n",
            "I0205 13:49:31.913337 140689526667136 learning.py:507] global step 4651: loss = 0.2131 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 4652: loss = 0.0861 (0.383 sec/step)\n",
            "I0205 13:49:32.297826 140689526667136 learning.py:507] global step 4652: loss = 0.0861 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 4653: loss = 0.2222 (0.388 sec/step)\n",
            "I0205 13:49:32.687465 140689526667136 learning.py:507] global step 4653: loss = 0.2222 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 4654: loss = 0.0522 (0.398 sec/step)\n",
            "I0205 13:49:33.087653 140689526667136 learning.py:507] global step 4654: loss = 0.0522 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 4655: loss = 0.0684 (0.366 sec/step)\n",
            "I0205 13:49:33.455940 140689526667136 learning.py:507] global step 4655: loss = 0.0684 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 4656: loss = 0.2505 (0.381 sec/step)\n",
            "I0205 13:49:33.838061 140689526667136 learning.py:507] global step 4656: loss = 0.2505 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4657: loss = 0.0671 (0.382 sec/step)\n",
            "I0205 13:49:34.221485 140689526667136 learning.py:507] global step 4657: loss = 0.0671 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 4658: loss = 0.5334 (0.396 sec/step)\n",
            "I0205 13:49:34.619241 140689526667136 learning.py:507] global step 4658: loss = 0.5334 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 4659: loss = 0.0883 (0.365 sec/step)\n",
            "I0205 13:49:34.986027 140689526667136 learning.py:507] global step 4659: loss = 0.0883 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 4660: loss = 0.1198 (0.374 sec/step)\n",
            "I0205 13:49:35.361713 140689526667136 learning.py:507] global step 4660: loss = 0.1198 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 4661: loss = 0.2678 (0.401 sec/step)\n",
            "I0205 13:49:35.763944 140689526667136 learning.py:507] global step 4661: loss = 0.2678 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 4662: loss = 0.0282 (0.390 sec/step)\n",
            "I0205 13:49:36.155948 140689526667136 learning.py:507] global step 4662: loss = 0.0282 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 4663: loss = 0.0175 (0.369 sec/step)\n",
            "I0205 13:49:36.526451 140689526667136 learning.py:507] global step 4663: loss = 0.0175 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 4664: loss = 0.0379 (0.381 sec/step)\n",
            "I0205 13:49:36.909323 140689526667136 learning.py:507] global step 4664: loss = 0.0379 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4665: loss = 0.0569 (0.365 sec/step)\n",
            "I0205 13:49:37.276143 140689526667136 learning.py:507] global step 4665: loss = 0.0569 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 4666: loss = 0.3919 (0.394 sec/step)\n",
            "I0205 13:49:37.671751 140689526667136 learning.py:507] global step 4666: loss = 0.3919 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 4667: loss = 0.4551 (0.377 sec/step)\n",
            "I0205 13:49:38.050595 140689526667136 learning.py:507] global step 4667: loss = 0.4551 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 4668: loss = 0.1357 (0.395 sec/step)\n",
            "I0205 13:49:38.447390 140689526667136 learning.py:507] global step 4668: loss = 0.1357 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 4669: loss = 0.1290 (0.396 sec/step)\n",
            "I0205 13:49:38.845328 140689526667136 learning.py:507] global step 4669: loss = 0.1290 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 4670: loss = 0.2050 (0.381 sec/step)\n",
            "I0205 13:49:39.227978 140689526667136 learning.py:507] global step 4670: loss = 0.2050 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4671: loss = 0.0259 (0.351 sec/step)\n",
            "I0205 13:49:39.580894 140689526667136 learning.py:507] global step 4671: loss = 0.0259 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 4672: loss = 0.0633 (0.366 sec/step)\n",
            "I0205 13:49:39.948646 140689526667136 learning.py:507] global step 4672: loss = 0.0633 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 4673: loss = 0.2376 (0.365 sec/step)\n",
            "I0205 13:49:40.315919 140689526667136 learning.py:507] global step 4673: loss = 0.2376 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 4674: loss = 0.1704 (0.358 sec/step)\n",
            "I0205 13:49:40.675236 140689526667136 learning.py:507] global step 4674: loss = 0.1704 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 4675: loss = 0.2703 (0.393 sec/step)\n",
            "I0205 13:49:41.069491 140689526667136 learning.py:507] global step 4675: loss = 0.2703 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 4676: loss = 0.0798 (0.379 sec/step)\n",
            "I0205 13:49:41.450012 140689526667136 learning.py:507] global step 4676: loss = 0.0798 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 4677: loss = 0.1076 (0.381 sec/step)\n",
            "I0205 13:49:41.832305 140689526667136 learning.py:507] global step 4677: loss = 0.1076 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4678: loss = 0.1869 (0.366 sec/step)\n",
            "I0205 13:49:42.200223 140689526667136 learning.py:507] global step 4678: loss = 0.1869 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 4679: loss = 0.3208 (0.345 sec/step)\n",
            "I0205 13:49:42.546875 140689526667136 learning.py:507] global step 4679: loss = 0.3208 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 4680: loss = 0.2513 (0.383 sec/step)\n",
            "I0205 13:49:42.932287 140689526667136 learning.py:507] global step 4680: loss = 0.2513 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 4681: loss = 0.0735 (0.358 sec/step)\n",
            "I0205 13:49:43.291584 140689526667136 learning.py:507] global step 4681: loss = 0.0735 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 4682: loss = 0.3811 (0.368 sec/step)\n",
            "I0205 13:49:43.661175 140689526667136 learning.py:507] global step 4682: loss = 0.3811 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 4683: loss = 0.1695 (0.397 sec/step)\n",
            "I0205 13:49:44.059437 140689526667136 learning.py:507] global step 4683: loss = 0.1695 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 4684: loss = 0.0776 (0.379 sec/step)\n",
            "I0205 13:49:44.439943 140689526667136 learning.py:507] global step 4684: loss = 0.0776 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 4685: loss = 0.1065 (0.383 sec/step)\n",
            "I0205 13:49:44.824437 140689526667136 learning.py:507] global step 4685: loss = 0.1065 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 4686: loss = 0.0988 (0.369 sec/step)\n",
            "I0205 13:49:45.195280 140689526667136 learning.py:507] global step 4686: loss = 0.0988 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 4687: loss = 0.0339 (0.388 sec/step)\n",
            "I0205 13:49:45.584952 140689526667136 learning.py:507] global step 4687: loss = 0.0339 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 4688: loss = 0.0849 (0.403 sec/step)\n",
            "I0205 13:49:45.990522 140689526667136 learning.py:507] global step 4688: loss = 0.0849 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 4689: loss = 0.3287 (0.380 sec/step)\n",
            "I0205 13:49:46.372276 140689526667136 learning.py:507] global step 4689: loss = 0.3287 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 4690: loss = 0.3791 (0.387 sec/step)\n",
            "I0205 13:49:46.760389 140689526667136 learning.py:507] global step 4690: loss = 0.3791 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 4691: loss = 0.3250 (0.394 sec/step)\n",
            "I0205 13:49:47.156240 140689526667136 learning.py:507] global step 4691: loss = 0.3250 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 4692: loss = 0.1312 (0.394 sec/step)\n",
            "I0205 13:49:47.551721 140689526667136 learning.py:507] global step 4692: loss = 0.1312 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 4693: loss = 0.0917 (0.360 sec/step)\n",
            "I0205 13:49:47.913554 140689526667136 learning.py:507] global step 4693: loss = 0.0917 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 4694: loss = 0.0831 (0.377 sec/step)\n",
            "I0205 13:49:48.292119 140689526667136 learning.py:507] global step 4694: loss = 0.0831 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 4695: loss = 0.2038 (0.372 sec/step)\n",
            "I0205 13:49:48.665501 140689526667136 learning.py:507] global step 4695: loss = 0.2038 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 4696: loss = 0.0570 (0.370 sec/step)\n",
            "I0205 13:49:49.037208 140689526667136 learning.py:507] global step 4696: loss = 0.0570 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 4697: loss = 0.0932 (0.373 sec/step)\n",
            "I0205 13:49:49.411694 140689526667136 learning.py:507] global step 4697: loss = 0.0932 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 4698: loss = 0.1947 (0.361 sec/step)\n",
            "I0205 13:49:49.774281 140689526667136 learning.py:507] global step 4698: loss = 0.1947 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 4699: loss = 0.0558 (0.396 sec/step)\n",
            "I0205 13:49:50.172096 140689526667136 learning.py:507] global step 4699: loss = 0.0558 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 4700: loss = 0.1347 (0.358 sec/step)\n",
            "I0205 13:49:50.531723 140689526667136 learning.py:507] global step 4700: loss = 0.1347 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 4701: loss = 0.0284 (0.381 sec/step)\n",
            "I0205 13:49:50.914526 140689526667136 learning.py:507] global step 4701: loss = 0.0284 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4702: loss = 0.1828 (0.391 sec/step)\n",
            "I0205 13:49:51.307360 140689526667136 learning.py:507] global step 4702: loss = 0.1828 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 4703: loss = 0.0884 (0.405 sec/step)\n",
            "I0205 13:49:51.714002 140689526667136 learning.py:507] global step 4703: loss = 0.0884 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 4704: loss = 0.1371 (0.407 sec/step)\n",
            "I0205 13:49:52.122486 140689526667136 learning.py:507] global step 4704: loss = 0.1371 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 4705: loss = 0.1440 (0.418 sec/step)\n",
            "I0205 13:49:52.542258 140689526667136 learning.py:507] global step 4705: loss = 0.1440 (0.418 sec/step)\n",
            "INFO:tensorflow:global step 4706: loss = 0.0380 (0.416 sec/step)\n",
            "I0205 13:49:52.960749 140689526667136 learning.py:507] global step 4706: loss = 0.0380 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 4707: loss = 0.1458 (0.391 sec/step)\n",
            "I0205 13:49:53.354340 140689526667136 learning.py:507] global step 4707: loss = 0.1458 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 4708: loss = 0.0544 (0.388 sec/step)\n",
            "I0205 13:49:53.743777 140689526667136 learning.py:507] global step 4708: loss = 0.0544 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 4709: loss = 0.0784 (0.361 sec/step)\n",
            "I0205 13:49:54.106598 140689526667136 learning.py:507] global step 4709: loss = 0.0784 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 4710: loss = 0.3163 (0.398 sec/step)\n",
            "I0205 13:49:54.506634 140689526667136 learning.py:507] global step 4710: loss = 0.3163 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 4711: loss = 0.2434 (0.371 sec/step)\n",
            "I0205 13:49:54.879650 140689526667136 learning.py:507] global step 4711: loss = 0.2434 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 4712: loss = 0.3607 (0.379 sec/step)\n",
            "I0205 13:49:55.260311 140689526667136 learning.py:507] global step 4712: loss = 0.3607 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 4713: loss = 0.0733 (0.366 sec/step)\n",
            "I0205 13:49:55.627600 140689526667136 learning.py:507] global step 4713: loss = 0.0733 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 4714: loss = 0.2270 (0.367 sec/step)\n",
            "I0205 13:49:55.996295 140689526667136 learning.py:507] global step 4714: loss = 0.2270 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 4715: loss = 0.1834 (0.382 sec/step)\n",
            "I0205 13:49:56.380146 140689526667136 learning.py:507] global step 4715: loss = 0.1834 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 4716: loss = 0.0227 (0.368 sec/step)\n",
            "I0205 13:49:56.749864 140689526667136 learning.py:507] global step 4716: loss = 0.0227 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 4717: loss = 0.2798 (0.398 sec/step)\n",
            "I0205 13:49:57.149388 140689526667136 learning.py:507] global step 4717: loss = 0.2798 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 4718: loss = 0.0378 (0.397 sec/step)\n",
            "I0205 13:49:57.547731 140689526667136 learning.py:507] global step 4718: loss = 0.0378 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 4719: loss = 0.0754 (0.358 sec/step)\n",
            "I0205 13:49:57.907292 140689526667136 learning.py:507] global step 4719: loss = 0.0754 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 4720: loss = 0.1298 (0.380 sec/step)\n",
            "I0205 13:49:58.289600 140689526667136 learning.py:507] global step 4720: loss = 0.1298 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 4721: loss = 0.0752 (0.405 sec/step)\n",
            "I0205 13:49:58.698761 140689526667136 learning.py:507] global step 4721: loss = 0.0752 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 4722: loss = 0.1001 (0.393 sec/step)\n",
            "I0205 13:49:59.092901 140689526667136 learning.py:507] global step 4722: loss = 0.1001 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 4723: loss = 0.2748 (0.404 sec/step)\n",
            "I0205 13:49:59.498985 140689526667136 learning.py:507] global step 4723: loss = 0.2748 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 4724: loss = 0.1700 (0.389 sec/step)\n",
            "I0205 13:49:59.889363 140689526667136 learning.py:507] global step 4724: loss = 0.1700 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 4725: loss = 0.0537 (0.360 sec/step)\n",
            "I0205 13:50:00.251363 140689526667136 learning.py:507] global step 4725: loss = 0.0537 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 4726: loss = 0.1488 (0.380 sec/step)\n",
            "I0205 13:50:00.632668 140689526667136 learning.py:507] global step 4726: loss = 0.1488 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 4727: loss = 0.2939 (0.370 sec/step)\n",
            "I0205 13:50:01.004440 140689526667136 learning.py:507] global step 4727: loss = 0.2939 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 4728: loss = 0.1211 (0.396 sec/step)\n",
            "I0205 13:50:01.402275 140689526667136 learning.py:507] global step 4728: loss = 0.1211 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 4729: loss = 0.3297 (0.385 sec/step)\n",
            "I0205 13:50:01.788658 140689526667136 learning.py:507] global step 4729: loss = 0.3297 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 4730: loss = 0.1178 (0.356 sec/step)\n",
            "I0205 13:50:02.146405 140689526667136 learning.py:507] global step 4730: loss = 0.1178 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 4731: loss = 0.0727 (0.365 sec/step)\n",
            "I0205 13:50:02.513192 140689526667136 learning.py:507] global step 4731: loss = 0.0727 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 4732: loss = 0.9139 (0.399 sec/step)\n",
            "I0205 13:50:02.913800 140689526667136 learning.py:507] global step 4732: loss = 0.9139 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 4733: loss = 0.1758 (0.379 sec/step)\n",
            "I0205 13:50:03.294360 140689526667136 learning.py:507] global step 4733: loss = 0.1758 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 4734: loss = 0.2779 (0.382 sec/step)\n",
            "I0205 13:50:03.677965 140689526667136 learning.py:507] global step 4734: loss = 0.2779 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 4735: loss = 0.0433 (0.386 sec/step)\n",
            "I0205 13:50:04.065544 140689526667136 learning.py:507] global step 4735: loss = 0.0433 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 4736: loss = 0.7705 (0.355 sec/step)\n",
            "I0205 13:50:04.421653 140689526667136 learning.py:507] global step 4736: loss = 0.7705 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 4737: loss = 0.0488 (0.381 sec/step)\n",
            "I0205 13:50:04.803940 140689526667136 learning.py:507] global step 4737: loss = 0.0488 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4738: loss = 0.1260 (0.382 sec/step)\n",
            "I0205 13:50:05.187350 140689526667136 learning.py:507] global step 4738: loss = 0.1260 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 4739: loss = 0.1848 (0.355 sec/step)\n",
            "I0205 13:50:05.543933 140689526667136 learning.py:507] global step 4739: loss = 0.1848 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 4740: loss = 0.0398 (0.394 sec/step)\n",
            "I0205 13:50:05.939626 140689526667136 learning.py:507] global step 4740: loss = 0.0398 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 4741: loss = 0.1563 (0.354 sec/step)\n",
            "I0205 13:50:06.295083 140689526667136 learning.py:507] global step 4741: loss = 0.1563 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 4742: loss = 0.2065 (0.378 sec/step)\n",
            "I0205 13:50:06.674463 140689526667136 learning.py:507] global step 4742: loss = 0.2065 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 4743: loss = 0.4849 (0.374 sec/step)\n",
            "I0205 13:50:07.050342 140689526667136 learning.py:507] global step 4743: loss = 0.4849 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 4744: loss = 0.1426 (0.359 sec/step)\n",
            "I0205 13:50:07.411296 140689526667136 learning.py:507] global step 4744: loss = 0.1426 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 4745: loss = 0.1725 (0.414 sec/step)\n",
            "I0205 13:50:07.826773 140689526667136 learning.py:507] global step 4745: loss = 0.1725 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 4746: loss = 0.0420 (0.406 sec/step)\n",
            "I0205 13:50:08.234368 140689526667136 learning.py:507] global step 4746: loss = 0.0420 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 4747: loss = 0.1775 (0.379 sec/step)\n",
            "I0205 13:50:08.615633 140689526667136 learning.py:507] global step 4747: loss = 0.1775 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 4748: loss = 0.0450 (0.377 sec/step)\n",
            "I0205 13:50:08.994716 140689526667136 learning.py:507] global step 4748: loss = 0.0450 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 4749: loss = 0.0728 (0.369 sec/step)\n",
            "I0205 13:50:09.365874 140689526667136 learning.py:507] global step 4749: loss = 0.0728 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 4750: loss = 0.3205 (0.356 sec/step)\n",
            "I0205 13:50:09.723798 140689526667136 learning.py:507] global step 4750: loss = 0.3205 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 4751: loss = 0.1904 (0.384 sec/step)\n",
            "I0205 13:50:10.109408 140689526667136 learning.py:507] global step 4751: loss = 0.1904 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 4752: loss = 0.0663 (0.387 sec/step)\n",
            "I0205 13:50:10.497644 140689526667136 learning.py:507] global step 4752: loss = 0.0663 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 4753: loss = 0.0764 (0.365 sec/step)\n",
            "I0205 13:50:10.864684 140689526667136 learning.py:507] global step 4753: loss = 0.0764 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 4754: loss = 0.1976 (0.389 sec/step)\n",
            "I0205 13:50:11.255111 140689526667136 learning.py:507] global step 4754: loss = 0.1976 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 4755: loss = 0.1714 (0.378 sec/step)\n",
            "I0205 13:50:11.634263 140689526667136 learning.py:507] global step 4755: loss = 0.1714 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 4756: loss = 0.2769 (0.399 sec/step)\n",
            "I0205 13:50:12.035241 140689526667136 learning.py:507] global step 4756: loss = 0.2769 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 4757: loss = 0.0553 (0.381 sec/step)\n",
            "I0205 13:50:12.418257 140689526667136 learning.py:507] global step 4757: loss = 0.0553 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4758: loss = 0.2627 (0.385 sec/step)\n",
            "I0205 13:50:12.805261 140689526667136 learning.py:507] global step 4758: loss = 0.2627 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 4759: loss = 0.0915 (0.376 sec/step)\n",
            "I0205 13:50:13.182634 140689526667136 learning.py:507] global step 4759: loss = 0.0915 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 4760: loss = 0.2633 (0.385 sec/step)\n",
            "I0205 13:50:13.569279 140689526667136 learning.py:507] global step 4760: loss = 0.2633 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 4761: loss = 0.2299 (0.541 sec/step)\n",
            "I0205 13:50:14.112129 140689526667136 learning.py:507] global step 4761: loss = 0.2299 (0.541 sec/step)\n",
            "INFO:tensorflow:global step 4762: loss = 0.1440 (0.873 sec/step)\n",
            "I0205 13:50:15.027379 140689526667136 learning.py:507] global step 4762: loss = 0.1440 (0.873 sec/step)\n",
            "INFO:tensorflow:global step 4763: loss = 0.1234 (0.777 sec/step)\n",
            "I0205 13:50:15.891633 140689526667136 learning.py:507] global step 4763: loss = 0.1234 (0.777 sec/step)\n",
            "INFO:tensorflow:global step 4764: loss = 0.3745 (0.719 sec/step)\n",
            "I0205 13:50:16.615239 140689526667136 learning.py:507] global step 4764: loss = 0.3745 (0.719 sec/step)\n",
            "INFO:tensorflow:global step 4765: loss = 0.0568 (0.662 sec/step)\n",
            "I0205 13:50:17.280519 140689526667136 learning.py:507] global step 4765: loss = 0.0568 (0.662 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 4765.\n",
            "I0205 13:50:17.340376 140686026073856 supervisor.py:1050] Recording summary at step 4765.\n",
            "INFO:tensorflow:global step 4766: loss = 0.3022 (0.405 sec/step)\n",
            "I0205 13:50:17.689596 140689526667136 learning.py:507] global step 4766: loss = 0.3022 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 4767: loss = 0.1007 (0.390 sec/step)\n",
            "I0205 13:50:18.081514 140689526667136 learning.py:507] global step 4767: loss = 0.1007 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 4768: loss = 0.1547 (0.383 sec/step)\n",
            "I0205 13:50:18.466063 140689526667136 learning.py:507] global step 4768: loss = 0.1547 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 4769: loss = 0.0758 (0.405 sec/step)\n",
            "I0205 13:50:18.872616 140689526667136 learning.py:507] global step 4769: loss = 0.0758 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 4770: loss = 0.1682 (0.419 sec/step)\n",
            "I0205 13:50:19.294024 140689526667136 learning.py:507] global step 4770: loss = 0.1682 (0.419 sec/step)\n",
            "INFO:tensorflow:global step 4771: loss = 0.3537 (0.371 sec/step)\n",
            "I0205 13:50:19.666683 140689526667136 learning.py:507] global step 4771: loss = 0.3537 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 4772: loss = 0.1543 (0.379 sec/step)\n",
            "I0205 13:50:20.047192 140689526667136 learning.py:507] global step 4772: loss = 0.1543 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 4773: loss = 0.2540 (0.387 sec/step)\n",
            "I0205 13:50:20.436276 140689526667136 learning.py:507] global step 4773: loss = 0.2540 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 4774: loss = 0.3730 (0.390 sec/step)\n",
            "I0205 13:50:20.827624 140689526667136 learning.py:507] global step 4774: loss = 0.3730 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 4775: loss = 0.1302 (0.368 sec/step)\n",
            "I0205 13:50:21.197470 140689526667136 learning.py:507] global step 4775: loss = 0.1302 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 4776: loss = 0.2891 (0.424 sec/step)\n",
            "I0205 13:50:21.622845 140689526667136 learning.py:507] global step 4776: loss = 0.2891 (0.424 sec/step)\n",
            "INFO:tensorflow:global step 4777: loss = 0.1527 (0.381 sec/step)\n",
            "I0205 13:50:22.005104 140689526667136 learning.py:507] global step 4777: loss = 0.1527 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4778: loss = 0.0783 (0.361 sec/step)\n",
            "I0205 13:50:22.367816 140689526667136 learning.py:507] global step 4778: loss = 0.0783 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 4779: loss = 0.1510 (0.388 sec/step)\n",
            "I0205 13:50:22.757029 140689526667136 learning.py:507] global step 4779: loss = 0.1510 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 4780: loss = 0.1142 (0.371 sec/step)\n",
            "I0205 13:50:23.130124 140689526667136 learning.py:507] global step 4780: loss = 0.1142 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 4781: loss = 0.2733 (0.355 sec/step)\n",
            "I0205 13:50:23.486725 140689526667136 learning.py:507] global step 4781: loss = 0.2733 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 4782: loss = 0.1530 (0.370 sec/step)\n",
            "I0205 13:50:23.858426 140689526667136 learning.py:507] global step 4782: loss = 0.1530 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 4783: loss = 0.4046 (0.376 sec/step)\n",
            "I0205 13:50:24.235901 140689526667136 learning.py:507] global step 4783: loss = 0.4046 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 4784: loss = 0.1628 (0.378 sec/step)\n",
            "I0205 13:50:24.615468 140689526667136 learning.py:507] global step 4784: loss = 0.1628 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 4785: loss = 0.1558 (0.376 sec/step)\n",
            "I0205 13:50:24.995048 140689526667136 learning.py:507] global step 4785: loss = 0.1558 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 4786: loss = 0.0549 (0.397 sec/step)\n",
            "I0205 13:50:25.397523 140689526667136 learning.py:507] global step 4786: loss = 0.0549 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 4787: loss = 0.0420 (0.384 sec/step)\n",
            "I0205 13:50:25.783046 140689526667136 learning.py:507] global step 4787: loss = 0.0420 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 4788: loss = 0.1515 (0.417 sec/step)\n",
            "I0205 13:50:26.201723 140689526667136 learning.py:507] global step 4788: loss = 0.1515 (0.417 sec/step)\n",
            "INFO:tensorflow:global step 4789: loss = 1.0657 (0.377 sec/step)\n",
            "I0205 13:50:26.579965 140689526667136 learning.py:507] global step 4789: loss = 1.0657 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 4790: loss = 0.1025 (0.377 sec/step)\n",
            "I0205 13:50:26.958894 140689526667136 learning.py:507] global step 4790: loss = 0.1025 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 4791: loss = 0.3568 (0.356 sec/step)\n",
            "I0205 13:50:27.315934 140689526667136 learning.py:507] global step 4791: loss = 0.3568 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 4792: loss = 0.1711 (0.369 sec/step)\n",
            "I0205 13:50:27.687156 140689526667136 learning.py:507] global step 4792: loss = 0.1711 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 4793: loss = 0.1439 (0.410 sec/step)\n",
            "I0205 13:50:28.099220 140689526667136 learning.py:507] global step 4793: loss = 0.1439 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 4794: loss = 0.0730 (0.369 sec/step)\n",
            "I0205 13:50:28.470180 140689526667136 learning.py:507] global step 4794: loss = 0.0730 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 4795: loss = 0.3273 (0.371 sec/step)\n",
            "I0205 13:50:28.842983 140689526667136 learning.py:507] global step 4795: loss = 0.3273 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 4796: loss = 0.0865 (0.400 sec/step)\n",
            "I0205 13:50:29.244939 140689526667136 learning.py:507] global step 4796: loss = 0.0865 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 4797: loss = 0.0673 (0.394 sec/step)\n",
            "I0205 13:50:29.640841 140689526667136 learning.py:507] global step 4797: loss = 0.0673 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 4798: loss = 0.0737 (0.413 sec/step)\n",
            "I0205 13:50:30.055374 140689526667136 learning.py:507] global step 4798: loss = 0.0737 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 4799: loss = 0.1628 (0.367 sec/step)\n",
            "I0205 13:50:30.424566 140689526667136 learning.py:507] global step 4799: loss = 0.1628 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 4800: loss = 0.1087 (0.399 sec/step)\n",
            "I0205 13:50:30.825232 140689526667136 learning.py:507] global step 4800: loss = 0.1087 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 4801: loss = 0.1995 (0.433 sec/step)\n",
            "I0205 13:50:31.260618 140689526667136 learning.py:507] global step 4801: loss = 0.1995 (0.433 sec/step)\n",
            "INFO:tensorflow:global step 4802: loss = 0.0798 (0.393 sec/step)\n",
            "I0205 13:50:31.655109 140689526667136 learning.py:507] global step 4802: loss = 0.0798 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 4803: loss = 0.3870 (0.376 sec/step)\n",
            "I0205 13:50:32.032568 140689526667136 learning.py:507] global step 4803: loss = 0.3870 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 4804: loss = 0.2249 (0.407 sec/step)\n",
            "I0205 13:50:32.441757 140689526667136 learning.py:507] global step 4804: loss = 0.2249 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 4805: loss = 0.1520 (0.366 sec/step)\n",
            "I0205 13:50:32.809496 140689526667136 learning.py:507] global step 4805: loss = 0.1520 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 4806: loss = 0.0876 (0.411 sec/step)\n",
            "I0205 13:50:33.222918 140689526667136 learning.py:507] global step 4806: loss = 0.0876 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 4807: loss = 0.1042 (0.351 sec/step)\n",
            "I0205 13:50:33.576456 140689526667136 learning.py:507] global step 4807: loss = 0.1042 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 4808: loss = 0.0922 (0.362 sec/step)\n",
            "I0205 13:50:33.940442 140689526667136 learning.py:507] global step 4808: loss = 0.0922 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 4809: loss = 0.1075 (0.376 sec/step)\n",
            "I0205 13:50:34.317687 140689526667136 learning.py:507] global step 4809: loss = 0.1075 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 4810: loss = 0.1808 (0.378 sec/step)\n",
            "I0205 13:50:34.697229 140689526667136 learning.py:507] global step 4810: loss = 0.1808 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 4811: loss = 0.1347 (0.385 sec/step)\n",
            "I0205 13:50:35.084023 140689526667136 learning.py:507] global step 4811: loss = 0.1347 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 4812: loss = 0.1915 (0.378 sec/step)\n",
            "I0205 13:50:35.462942 140689526667136 learning.py:507] global step 4812: loss = 0.1915 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 4813: loss = 0.0728 (0.389 sec/step)\n",
            "I0205 13:50:35.853461 140689526667136 learning.py:507] global step 4813: loss = 0.0728 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 4814: loss = 0.0635 (0.369 sec/step)\n",
            "I0205 13:50:36.223749 140689526667136 learning.py:507] global step 4814: loss = 0.0635 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 4815: loss = 0.3522 (0.379 sec/step)\n",
            "I0205 13:50:36.604678 140689526667136 learning.py:507] global step 4815: loss = 0.3522 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 4816: loss = 0.3160 (0.383 sec/step)\n",
            "I0205 13:50:36.989560 140689526667136 learning.py:507] global step 4816: loss = 0.3160 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 4817: loss = 1.1091 (0.369 sec/step)\n",
            "I0205 13:50:37.360583 140689526667136 learning.py:507] global step 4817: loss = 1.1091 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 4818: loss = 0.0653 (0.351 sec/step)\n",
            "I0205 13:50:37.713589 140689526667136 learning.py:507] global step 4818: loss = 0.0653 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 4819: loss = 0.0745 (0.369 sec/step)\n",
            "I0205 13:50:38.084032 140689526667136 learning.py:507] global step 4819: loss = 0.0745 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 4820: loss = 0.1736 (0.371 sec/step)\n",
            "I0205 13:50:38.456319 140689526667136 learning.py:507] global step 4820: loss = 0.1736 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 4821: loss = 0.1018 (0.388 sec/step)\n",
            "I0205 13:50:38.846314 140689526667136 learning.py:507] global step 4821: loss = 0.1018 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 4822: loss = 0.8624 (0.381 sec/step)\n",
            "I0205 13:50:39.229028 140689526667136 learning.py:507] global step 4822: loss = 0.8624 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4823: loss = 0.0908 (0.403 sec/step)\n",
            "I0205 13:50:39.634153 140689526667136 learning.py:507] global step 4823: loss = 0.0908 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 4824: loss = 0.1606 (0.353 sec/step)\n",
            "I0205 13:50:39.988210 140689526667136 learning.py:507] global step 4824: loss = 0.1606 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 4825: loss = 0.1704 (0.363 sec/step)\n",
            "I0205 13:50:40.352563 140689526667136 learning.py:507] global step 4825: loss = 0.1704 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 4826: loss = 0.0813 (0.387 sec/step)\n",
            "I0205 13:50:40.741086 140689526667136 learning.py:507] global step 4826: loss = 0.0813 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 4827: loss = 0.0932 (0.370 sec/step)\n",
            "I0205 13:50:41.112995 140689526667136 learning.py:507] global step 4827: loss = 0.0932 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 4828: loss = 0.1532 (0.375 sec/step)\n",
            "I0205 13:50:41.489945 140689526667136 learning.py:507] global step 4828: loss = 0.1532 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 4829: loss = 0.0062 (0.389 sec/step)\n",
            "I0205 13:50:41.880825 140689526667136 learning.py:507] global step 4829: loss = 0.0062 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 4830: loss = 0.0921 (0.371 sec/step)\n",
            "I0205 13:50:42.253640 140689526667136 learning.py:507] global step 4830: loss = 0.0921 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 4831: loss = 0.1925 (0.407 sec/step)\n",
            "I0205 13:50:42.662557 140689526667136 learning.py:507] global step 4831: loss = 0.1925 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 4832: loss = 0.0515 (0.369 sec/step)\n",
            "I0205 13:50:43.033074 140689526667136 learning.py:507] global step 4832: loss = 0.0515 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 4833: loss = 0.1233 (0.351 sec/step)\n",
            "I0205 13:50:43.386121 140689526667136 learning.py:507] global step 4833: loss = 0.1233 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 4834: loss = 0.0752 (0.397 sec/step)\n",
            "I0205 13:50:43.785152 140689526667136 learning.py:507] global step 4834: loss = 0.0752 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 4835: loss = 0.2729 (0.404 sec/step)\n",
            "I0205 13:50:44.191252 140689526667136 learning.py:507] global step 4835: loss = 0.2729 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 4836: loss = 0.2207 (0.387 sec/step)\n",
            "I0205 13:50:44.579975 140689526667136 learning.py:507] global step 4836: loss = 0.2207 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 4837: loss = 0.2194 (0.379 sec/step)\n",
            "I0205 13:50:44.960313 140689526667136 learning.py:507] global step 4837: loss = 0.2194 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 4838: loss = 0.0297 (0.366 sec/step)\n",
            "I0205 13:50:45.328177 140689526667136 learning.py:507] global step 4838: loss = 0.0297 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 4839: loss = 0.2008 (0.366 sec/step)\n",
            "I0205 13:50:45.695688 140689526667136 learning.py:507] global step 4839: loss = 0.2008 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 4840: loss = 0.2381 (0.378 sec/step)\n",
            "I0205 13:50:46.075386 140689526667136 learning.py:507] global step 4840: loss = 0.2381 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 4841: loss = 0.1699 (0.381 sec/step)\n",
            "I0205 13:50:46.457656 140689526667136 learning.py:507] global step 4841: loss = 0.1699 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4842: loss = 0.2993 (0.382 sec/step)\n",
            "I0205 13:50:46.841840 140689526667136 learning.py:507] global step 4842: loss = 0.2993 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 4843: loss = 0.1021 (0.392 sec/step)\n",
            "I0205 13:50:47.235251 140689526667136 learning.py:507] global step 4843: loss = 0.1021 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 4844: loss = 0.1597 (0.366 sec/step)\n",
            "I0205 13:50:47.602775 140689526667136 learning.py:507] global step 4844: loss = 0.1597 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 4845: loss = 0.0925 (0.384 sec/step)\n",
            "I0205 13:50:47.988902 140689526667136 learning.py:507] global step 4845: loss = 0.0925 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 4846: loss = 0.2525 (0.363 sec/step)\n",
            "I0205 13:50:48.353305 140689526667136 learning.py:507] global step 4846: loss = 0.2525 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 4847: loss = 0.1938 (0.389 sec/step)\n",
            "I0205 13:50:48.744155 140689526667136 learning.py:507] global step 4847: loss = 0.1938 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 4848: loss = 0.1297 (0.400 sec/step)\n",
            "I0205 13:50:49.145842 140689526667136 learning.py:507] global step 4848: loss = 0.1297 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 4849: loss = 0.0355 (0.364 sec/step)\n",
            "I0205 13:50:49.511449 140689526667136 learning.py:507] global step 4849: loss = 0.0355 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 4850: loss = 0.2634 (0.381 sec/step)\n",
            "I0205 13:50:49.894253 140689526667136 learning.py:507] global step 4850: loss = 0.2634 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4851: loss = 0.0787 (0.365 sec/step)\n",
            "I0205 13:50:50.260550 140689526667136 learning.py:507] global step 4851: loss = 0.0787 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 4852: loss = 0.3073 (0.361 sec/step)\n",
            "I0205 13:50:50.623220 140689526667136 learning.py:507] global step 4852: loss = 0.3073 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 4853: loss = 0.1356 (0.368 sec/step)\n",
            "I0205 13:50:50.993071 140689526667136 learning.py:507] global step 4853: loss = 0.1356 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 4854: loss = 0.0213 (0.391 sec/step)\n",
            "I0205 13:50:51.385336 140689526667136 learning.py:507] global step 4854: loss = 0.0213 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 4855: loss = 0.2083 (0.398 sec/step)\n",
            "I0205 13:50:51.785507 140689526667136 learning.py:507] global step 4855: loss = 0.2083 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 4856: loss = 0.0752 (0.381 sec/step)\n",
            "I0205 13:50:52.168082 140689526667136 learning.py:507] global step 4856: loss = 0.0752 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4857: loss = 0.1635 (0.412 sec/step)\n",
            "I0205 13:50:52.581922 140689526667136 learning.py:507] global step 4857: loss = 0.1635 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 4858: loss = 1.0559 (0.427 sec/step)\n",
            "I0205 13:50:53.010671 140689526667136 learning.py:507] global step 4858: loss = 1.0559 (0.427 sec/step)\n",
            "INFO:tensorflow:global step 4859: loss = 0.1239 (0.406 sec/step)\n",
            "I0205 13:50:53.418303 140689526667136 learning.py:507] global step 4859: loss = 0.1239 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 4860: loss = 0.0902 (0.364 sec/step)\n",
            "I0205 13:50:53.784082 140689526667136 learning.py:507] global step 4860: loss = 0.0902 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 4861: loss = 0.1469 (0.387 sec/step)\n",
            "I0205 13:50:54.172688 140689526667136 learning.py:507] global step 4861: loss = 0.1469 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 4862: loss = 0.1645 (0.389 sec/step)\n",
            "I0205 13:50:54.562709 140689526667136 learning.py:507] global step 4862: loss = 0.1645 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 4863: loss = 0.2910 (0.382 sec/step)\n",
            "I0205 13:50:54.946707 140689526667136 learning.py:507] global step 4863: loss = 0.2910 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 4864: loss = 0.0701 (0.368 sec/step)\n",
            "I0205 13:50:55.316587 140689526667136 learning.py:507] global step 4864: loss = 0.0701 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 4865: loss = 0.2324 (0.373 sec/step)\n",
            "I0205 13:50:55.691272 140689526667136 learning.py:507] global step 4865: loss = 0.2324 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 4866: loss = 0.0429 (0.390 sec/step)\n",
            "I0205 13:50:56.083047 140689526667136 learning.py:507] global step 4866: loss = 0.0429 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 4867: loss = 0.1317 (0.381 sec/step)\n",
            "I0205 13:50:56.465807 140689526667136 learning.py:507] global step 4867: loss = 0.1317 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4868: loss = 0.0279 (0.405 sec/step)\n",
            "I0205 13:50:56.873439 140689526667136 learning.py:507] global step 4868: loss = 0.0279 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 4869: loss = 0.0902 (0.389 sec/step)\n",
            "I0205 13:50:57.264079 140689526667136 learning.py:507] global step 4869: loss = 0.0902 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 4870: loss = 0.0279 (0.392 sec/step)\n",
            "I0205 13:50:57.657280 140689526667136 learning.py:507] global step 4870: loss = 0.0279 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 4871: loss = 0.2051 (0.356 sec/step)\n",
            "I0205 13:50:58.014728 140689526667136 learning.py:507] global step 4871: loss = 0.2051 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 4872: loss = 0.1289 (0.394 sec/step)\n",
            "I0205 13:50:58.410190 140689526667136 learning.py:507] global step 4872: loss = 0.1289 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 4873: loss = 0.3238 (0.394 sec/step)\n",
            "I0205 13:50:58.805630 140689526667136 learning.py:507] global step 4873: loss = 0.3238 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 4874: loss = 0.4334 (0.407 sec/step)\n",
            "I0205 13:50:59.214074 140689526667136 learning.py:507] global step 4874: loss = 0.4334 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 4875: loss = 0.1161 (0.389 sec/step)\n",
            "I0205 13:50:59.604691 140689526667136 learning.py:507] global step 4875: loss = 0.1161 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 4876: loss = 0.0739 (0.389 sec/step)\n",
            "I0205 13:50:59.995081 140689526667136 learning.py:507] global step 4876: loss = 0.0739 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 4877: loss = 0.4384 (0.369 sec/step)\n",
            "I0205 13:51:00.365973 140689526667136 learning.py:507] global step 4877: loss = 0.4384 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 4878: loss = 0.1157 (0.377 sec/step)\n",
            "I0205 13:51:00.744714 140689526667136 learning.py:507] global step 4878: loss = 0.1157 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 4879: loss = 0.1814 (0.394 sec/step)\n",
            "I0205 13:51:01.140917 140689526667136 learning.py:507] global step 4879: loss = 0.1814 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 4880: loss = 0.0884 (0.393 sec/step)\n",
            "I0205 13:51:01.535456 140689526667136 learning.py:507] global step 4880: loss = 0.0884 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 4881: loss = 0.1819 (0.411 sec/step)\n",
            "I0205 13:51:01.949691 140689526667136 learning.py:507] global step 4881: loss = 0.1819 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 4882: loss = 0.1624 (0.404 sec/step)\n",
            "I0205 13:51:02.355345 140689526667136 learning.py:507] global step 4882: loss = 0.1624 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 4883: loss = 0.0836 (0.379 sec/step)\n",
            "I0205 13:51:02.736079 140689526667136 learning.py:507] global step 4883: loss = 0.0836 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 4884: loss = 0.3597 (0.376 sec/step)\n",
            "I0205 13:51:03.113449 140689526667136 learning.py:507] global step 4884: loss = 0.3597 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 4885: loss = 0.0884 (0.370 sec/step)\n",
            "I0205 13:51:03.484729 140689526667136 learning.py:507] global step 4885: loss = 0.0884 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 4886: loss = 0.0611 (0.364 sec/step)\n",
            "I0205 13:51:03.850428 140689526667136 learning.py:507] global step 4886: loss = 0.0611 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 4887: loss = 0.2119 (0.377 sec/step)\n",
            "I0205 13:51:04.228891 140689526667136 learning.py:507] global step 4887: loss = 0.2119 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 4888: loss = 0.1857 (0.387 sec/step)\n",
            "I0205 13:51:04.617183 140689526667136 learning.py:507] global step 4888: loss = 0.1857 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 4889: loss = 0.0978 (0.353 sec/step)\n",
            "I0205 13:51:04.971553 140689526667136 learning.py:507] global step 4889: loss = 0.0978 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 4890: loss = 0.0868 (0.394 sec/step)\n",
            "I0205 13:51:05.367190 140689526667136 learning.py:507] global step 4890: loss = 0.0868 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 4891: loss = 0.1797 (0.404 sec/step)\n",
            "I0205 13:51:05.772673 140689526667136 learning.py:507] global step 4891: loss = 0.1797 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 4892: loss = 0.0679 (0.390 sec/step)\n",
            "I0205 13:51:06.164332 140689526667136 learning.py:507] global step 4892: loss = 0.0679 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 4893: loss = 0.3653 (0.364 sec/step)\n",
            "I0205 13:51:06.529773 140689526667136 learning.py:507] global step 4893: loss = 0.3653 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 4894: loss = 0.0905 (0.330 sec/step)\n",
            "I0205 13:51:06.861317 140689526667136 learning.py:507] global step 4894: loss = 0.0905 (0.330 sec/step)\n",
            "INFO:tensorflow:global step 4895: loss = 0.0838 (0.416 sec/step)\n",
            "I0205 13:51:07.278245 140689526667136 learning.py:507] global step 4895: loss = 0.0838 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 4896: loss = 0.0214 (0.378 sec/step)\n",
            "I0205 13:51:07.658375 140689526667136 learning.py:507] global step 4896: loss = 0.0214 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 4897: loss = 0.2150 (0.386 sec/step)\n",
            "I0205 13:51:08.045813 140689526667136 learning.py:507] global step 4897: loss = 0.2150 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 4898: loss = 0.2009 (0.405 sec/step)\n",
            "I0205 13:51:08.452935 140689526667136 learning.py:507] global step 4898: loss = 0.2009 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 4899: loss = 0.0340 (0.369 sec/step)\n",
            "I0205 13:51:08.823312 140689526667136 learning.py:507] global step 4899: loss = 0.0340 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 4900: loss = 0.0771 (0.376 sec/step)\n",
            "I0205 13:51:09.201744 140689526667136 learning.py:507] global step 4900: loss = 0.0771 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 4901: loss = 0.0549 (0.376 sec/step)\n",
            "I0205 13:51:09.579602 140689526667136 learning.py:507] global step 4901: loss = 0.0549 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 4902: loss = 0.0451 (0.384 sec/step)\n",
            "I0205 13:51:09.965648 140689526667136 learning.py:507] global step 4902: loss = 0.0451 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 4903: loss = 0.3147 (0.365 sec/step)\n",
            "I0205 13:51:10.332706 140689526667136 learning.py:507] global step 4903: loss = 0.3147 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 4904: loss = 0.0984 (0.384 sec/step)\n",
            "I0205 13:51:10.718313 140689526667136 learning.py:507] global step 4904: loss = 0.0984 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 4905: loss = 0.0397 (0.369 sec/step)\n",
            "I0205 13:51:11.088667 140689526667136 learning.py:507] global step 4905: loss = 0.0397 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 4906: loss = 0.1322 (0.394 sec/step)\n",
            "I0205 13:51:11.485076 140689526667136 learning.py:507] global step 4906: loss = 0.1322 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 4907: loss = 0.3279 (0.370 sec/step)\n",
            "I0205 13:51:11.856146 140689526667136 learning.py:507] global step 4907: loss = 0.3279 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 4908: loss = 0.0833 (0.386 sec/step)\n",
            "I0205 13:51:12.243879 140689526667136 learning.py:507] global step 4908: loss = 0.0833 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 4909: loss = 0.0513 (0.381 sec/step)\n",
            "I0205 13:51:12.626728 140689526667136 learning.py:507] global step 4909: loss = 0.0513 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4910: loss = 0.0651 (0.375 sec/step)\n",
            "I0205 13:51:13.003596 140689526667136 learning.py:507] global step 4910: loss = 0.0651 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 4911: loss = 0.4375 (0.392 sec/step)\n",
            "I0205 13:51:13.397097 140689526667136 learning.py:507] global step 4911: loss = 0.4375 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 4912: loss = 0.5284 (0.388 sec/step)\n",
            "I0205 13:51:13.786524 140689526667136 learning.py:507] global step 4912: loss = 0.5284 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 4913: loss = 0.0922 (0.410 sec/step)\n",
            "I0205 13:51:14.198716 140689526667136 learning.py:507] global step 4913: loss = 0.0922 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 4914: loss = 0.2252 (0.386 sec/step)\n",
            "I0205 13:51:14.586631 140689526667136 learning.py:507] global step 4914: loss = 0.2252 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 4915: loss = 0.0577 (0.403 sec/step)\n",
            "I0205 13:51:14.991481 140689526667136 learning.py:507] global step 4915: loss = 0.0577 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 4916: loss = 0.2354 (0.380 sec/step)\n",
            "I0205 13:51:15.373805 140689526667136 learning.py:507] global step 4916: loss = 0.2354 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 4917: loss = 0.1466 (0.394 sec/step)\n",
            "I0205 13:51:15.769757 140689526667136 learning.py:507] global step 4917: loss = 0.1466 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 4918: loss = 0.0558 (0.385 sec/step)\n",
            "I0205 13:51:16.156942 140689526667136 learning.py:507] global step 4918: loss = 0.0558 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 4919: loss = 0.1755 (0.374 sec/step)\n",
            "I0205 13:51:16.532912 140689526667136 learning.py:507] global step 4919: loss = 0.1755 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 4920: loss = 0.1255 (0.384 sec/step)\n",
            "I0205 13:51:16.918206 140689526667136 learning.py:507] global step 4920: loss = 0.1255 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 4921: loss = 0.0407 (0.366 sec/step)\n",
            "I0205 13:51:17.286390 140689526667136 learning.py:507] global step 4921: loss = 0.0407 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 4922: loss = 0.2563 (0.400 sec/step)\n",
            "I0205 13:51:17.688537 140689526667136 learning.py:507] global step 4922: loss = 0.2563 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 4923: loss = 0.2532 (0.386 sec/step)\n",
            "I0205 13:51:18.076417 140689526667136 learning.py:507] global step 4923: loss = 0.2532 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 4924: loss = 0.1960 (0.393 sec/step)\n",
            "I0205 13:51:18.470720 140689526667136 learning.py:507] global step 4924: loss = 0.1960 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 4925: loss = 0.6539 (0.371 sec/step)\n",
            "I0205 13:51:18.842717 140689526667136 learning.py:507] global step 4925: loss = 0.6539 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 4926: loss = 0.1596 (0.410 sec/step)\n",
            "I0205 13:51:19.254988 140689526667136 learning.py:507] global step 4926: loss = 0.1596 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 4927: loss = 0.2322 (0.408 sec/step)\n",
            "I0205 13:51:19.664453 140689526667136 learning.py:507] global step 4927: loss = 0.2322 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 4928: loss = 0.2670 (0.393 sec/step)\n",
            "I0205 13:51:20.059577 140689526667136 learning.py:507] global step 4928: loss = 0.2670 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 4929: loss = 0.2853 (0.389 sec/step)\n",
            "I0205 13:51:20.450274 140689526667136 learning.py:507] global step 4929: loss = 0.2853 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 4930: loss = 0.6317 (0.398 sec/step)\n",
            "I0205 13:51:20.850082 140689526667136 learning.py:507] global step 4930: loss = 0.6317 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 4931: loss = 0.2850 (0.400 sec/step)\n",
            "I0205 13:51:21.251911 140689526667136 learning.py:507] global step 4931: loss = 0.2850 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 4932: loss = 0.0710 (0.395 sec/step)\n",
            "I0205 13:51:21.649235 140689526667136 learning.py:507] global step 4932: loss = 0.0710 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 4933: loss = 0.1840 (0.374 sec/step)\n",
            "I0205 13:51:22.024431 140689526667136 learning.py:507] global step 4933: loss = 0.1840 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 4934: loss = 0.2189 (0.363 sec/step)\n",
            "I0205 13:51:22.389113 140689526667136 learning.py:507] global step 4934: loss = 0.2189 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 4935: loss = 0.0402 (0.369 sec/step)\n",
            "I0205 13:51:22.760079 140689526667136 learning.py:507] global step 4935: loss = 0.0402 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 4936: loss = 0.0537 (0.388 sec/step)\n",
            "I0205 13:51:23.149306 140689526667136 learning.py:507] global step 4936: loss = 0.0537 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 4937: loss = 0.1048 (0.395 sec/step)\n",
            "I0205 13:51:23.545981 140689526667136 learning.py:507] global step 4937: loss = 0.1048 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 4938: loss = 0.2681 (0.386 sec/step)\n",
            "I0205 13:51:23.933609 140689526667136 learning.py:507] global step 4938: loss = 0.2681 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 4939: loss = 0.3084 (0.373 sec/step)\n",
            "I0205 13:51:24.307970 140689526667136 learning.py:507] global step 4939: loss = 0.3084 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 4940: loss = 0.1211 (0.411 sec/step)\n",
            "I0205 13:51:24.720810 140689526667136 learning.py:507] global step 4940: loss = 0.1211 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 4941: loss = 0.1804 (0.381 sec/step)\n",
            "I0205 13:51:25.103570 140689526667136 learning.py:507] global step 4941: loss = 0.1804 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4942: loss = 0.1247 (0.397 sec/step)\n",
            "I0205 13:51:25.502490 140689526667136 learning.py:507] global step 4942: loss = 0.1247 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 4943: loss = 0.0823 (0.353 sec/step)\n",
            "I0205 13:51:25.856745 140689526667136 learning.py:507] global step 4943: loss = 0.0823 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 4944: loss = 0.1563 (0.359 sec/step)\n",
            "I0205 13:51:26.217655 140689526667136 learning.py:507] global step 4944: loss = 0.1563 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 4945: loss = 0.0840 (0.402 sec/step)\n",
            "I0205 13:51:26.621460 140689526667136 learning.py:507] global step 4945: loss = 0.0840 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 4946: loss = 0.0636 (0.377 sec/step)\n",
            "I0205 13:51:26.999881 140689526667136 learning.py:507] global step 4946: loss = 0.0636 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 4947: loss = 0.2241 (0.421 sec/step)\n",
            "I0205 13:51:27.422609 140689526667136 learning.py:507] global step 4947: loss = 0.2241 (0.421 sec/step)\n",
            "INFO:tensorflow:global step 4948: loss = 0.4382 (0.425 sec/step)\n",
            "I0205 13:51:27.849091 140689526667136 learning.py:507] global step 4948: loss = 0.4382 (0.425 sec/step)\n",
            "INFO:tensorflow:global step 4949: loss = 0.6634 (0.403 sec/step)\n",
            "I0205 13:51:28.254121 140689526667136 learning.py:507] global step 4949: loss = 0.6634 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 4950: loss = 0.0880 (0.414 sec/step)\n",
            "I0205 13:51:28.669842 140689526667136 learning.py:507] global step 4950: loss = 0.0880 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 4951: loss = 0.0748 (0.429 sec/step)\n",
            "I0205 13:51:29.100962 140689526667136 learning.py:507] global step 4951: loss = 0.0748 (0.429 sec/step)\n",
            "INFO:tensorflow:global step 4952: loss = 0.1351 (0.420 sec/step)\n",
            "I0205 13:51:29.523252 140689526667136 learning.py:507] global step 4952: loss = 0.1351 (0.420 sec/step)\n",
            "INFO:tensorflow:global step 4953: loss = 0.1554 (0.444 sec/step)\n",
            "I0205 13:51:29.969304 140689526667136 learning.py:507] global step 4953: loss = 0.1554 (0.444 sec/step)\n",
            "INFO:tensorflow:global step 4954: loss = 0.0716 (0.389 sec/step)\n",
            "I0205 13:51:30.359938 140689526667136 learning.py:507] global step 4954: loss = 0.0716 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 4955: loss = 0.0379 (0.379 sec/step)\n",
            "I0205 13:51:30.740193 140689526667136 learning.py:507] global step 4955: loss = 0.0379 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 4956: loss = 0.2851 (0.409 sec/step)\n",
            "I0205 13:51:31.151489 140689526667136 learning.py:507] global step 4956: loss = 0.2851 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 4957: loss = 0.1425 (0.397 sec/step)\n",
            "I0205 13:51:31.550785 140689526667136 learning.py:507] global step 4957: loss = 0.1425 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 4958: loss = 0.2961 (0.378 sec/step)\n",
            "I0205 13:51:31.930486 140689526667136 learning.py:507] global step 4958: loss = 0.2961 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 4959: loss = 0.1102 (0.376 sec/step)\n",
            "I0205 13:51:32.308071 140689526667136 learning.py:507] global step 4959: loss = 0.1102 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 4960: loss = 0.0918 (0.377 sec/step)\n",
            "I0205 13:51:32.687067 140689526667136 learning.py:507] global step 4960: loss = 0.0918 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 4961: loss = 0.1992 (0.410 sec/step)\n",
            "I0205 13:51:33.098841 140689526667136 learning.py:507] global step 4961: loss = 0.1992 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 4962: loss = 0.3248 (0.391 sec/step)\n",
            "I0205 13:51:33.491400 140689526667136 learning.py:507] global step 4962: loss = 0.3248 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 4963: loss = 0.6239 (0.407 sec/step)\n",
            "I0205 13:51:33.899833 140689526667136 learning.py:507] global step 4963: loss = 0.6239 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 4964: loss = 0.0884 (0.370 sec/step)\n",
            "I0205 13:51:34.271224 140689526667136 learning.py:507] global step 4964: loss = 0.0884 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 4965: loss = 0.1684 (0.375 sec/step)\n",
            "I0205 13:51:34.647343 140689526667136 learning.py:507] global step 4965: loss = 0.1684 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 4966: loss = 0.2783 (0.383 sec/step)\n",
            "I0205 13:51:35.032275 140689526667136 learning.py:507] global step 4966: loss = 0.2783 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 4967: loss = 0.0497 (0.373 sec/step)\n",
            "I0205 13:51:35.407204 140689526667136 learning.py:507] global step 4967: loss = 0.0497 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 4968: loss = 0.0150 (0.402 sec/step)\n",
            "I0205 13:51:35.810818 140689526667136 learning.py:507] global step 4968: loss = 0.0150 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 4969: loss = 0.1147 (0.388 sec/step)\n",
            "I0205 13:51:36.200399 140689526667136 learning.py:507] global step 4969: loss = 0.1147 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 4970: loss = 0.1096 (0.385 sec/step)\n",
            "I0205 13:51:36.586521 140689526667136 learning.py:507] global step 4970: loss = 0.1096 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 4971: loss = 0.1839 (0.371 sec/step)\n",
            "I0205 13:51:36.959202 140689526667136 learning.py:507] global step 4971: loss = 0.1839 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 4972: loss = 0.3305 (0.368 sec/step)\n",
            "I0205 13:51:37.328587 140689526667136 learning.py:507] global step 4972: loss = 0.3305 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 4973: loss = 0.0430 (0.373 sec/step)\n",
            "I0205 13:51:37.703564 140689526667136 learning.py:507] global step 4973: loss = 0.0430 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 4974: loss = 0.1211 (0.381 sec/step)\n",
            "I0205 13:51:38.086537 140689526667136 learning.py:507] global step 4974: loss = 0.1211 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4975: loss = 0.0369 (0.390 sec/step)\n",
            "I0205 13:51:38.478057 140689526667136 learning.py:507] global step 4975: loss = 0.0369 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 4976: loss = 0.1517 (0.398 sec/step)\n",
            "I0205 13:51:38.877812 140689526667136 learning.py:507] global step 4976: loss = 0.1517 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 4977: loss = 0.0993 (0.377 sec/step)\n",
            "I0205 13:51:39.256700 140689526667136 learning.py:507] global step 4977: loss = 0.0993 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 4978: loss = 0.1708 (0.377 sec/step)\n",
            "I0205 13:51:39.635140 140689526667136 learning.py:507] global step 4978: loss = 0.1708 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 4979: loss = 0.0844 (0.385 sec/step)\n",
            "I0205 13:51:40.021565 140689526667136 learning.py:507] global step 4979: loss = 0.0844 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 4980: loss = 0.0791 (0.389 sec/step)\n",
            "I0205 13:51:40.412717 140689526667136 learning.py:507] global step 4980: loss = 0.0791 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 4981: loss = 0.0858 (0.375 sec/step)\n",
            "I0205 13:51:40.789199 140689526667136 learning.py:507] global step 4981: loss = 0.0858 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 4982: loss = 0.1169 (0.401 sec/step)\n",
            "I0205 13:51:41.191837 140689526667136 learning.py:507] global step 4982: loss = 0.1169 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 4983: loss = 0.2761 (0.402 sec/step)\n",
            "I0205 13:51:41.595500 140689526667136 learning.py:507] global step 4983: loss = 0.2761 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 4984: loss = 0.0787 (0.370 sec/step)\n",
            "I0205 13:51:41.966811 140689526667136 learning.py:507] global step 4984: loss = 0.0787 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 4985: loss = 0.1423 (0.365 sec/step)\n",
            "I0205 13:51:42.333470 140689526667136 learning.py:507] global step 4985: loss = 0.1423 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 4986: loss = 0.0254 (0.379 sec/step)\n",
            "I0205 13:51:42.713376 140689526667136 learning.py:507] global step 4986: loss = 0.0254 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 4987: loss = 0.0572 (0.379 sec/step)\n",
            "I0205 13:51:43.093574 140689526667136 learning.py:507] global step 4987: loss = 0.0572 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 4988: loss = 0.1089 (0.381 sec/step)\n",
            "I0205 13:51:43.476442 140689526667136 learning.py:507] global step 4988: loss = 0.1089 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 4989: loss = 0.2176 (0.390 sec/step)\n",
            "I0205 13:51:43.868618 140689526667136 learning.py:507] global step 4989: loss = 0.2176 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 4990: loss = 0.1861 (0.394 sec/step)\n",
            "I0205 13:51:44.264089 140689526667136 learning.py:507] global step 4990: loss = 0.1861 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 4991: loss = 0.2324 (0.395 sec/step)\n",
            "I0205 13:51:44.660801 140689526667136 learning.py:507] global step 4991: loss = 0.2324 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 4992: loss = 0.4194 (0.352 sec/step)\n",
            "I0205 13:51:45.014046 140689526667136 learning.py:507] global step 4992: loss = 0.4194 (0.352 sec/step)\n",
            "INFO:tensorflow:global step 4993: loss = 0.1315 (0.393 sec/step)\n",
            "I0205 13:51:45.408578 140689526667136 learning.py:507] global step 4993: loss = 0.1315 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 4994: loss = 0.1119 (0.363 sec/step)\n",
            "I0205 13:51:45.772955 140689526667136 learning.py:507] global step 4994: loss = 0.1119 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 4995: loss = 0.1056 (0.417 sec/step)\n",
            "I0205 13:51:46.191441 140689526667136 learning.py:507] global step 4995: loss = 0.1056 (0.417 sec/step)\n",
            "INFO:tensorflow:global step 4996: loss = 0.4268 (0.367 sec/step)\n",
            "I0205 13:51:46.559259 140689526667136 learning.py:507] global step 4996: loss = 0.4268 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 4997: loss = 0.2144 (0.365 sec/step)\n",
            "I0205 13:51:46.925194 140689526667136 learning.py:507] global step 4997: loss = 0.2144 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 4998: loss = 0.0459 (0.387 sec/step)\n",
            "I0205 13:51:47.313965 140689526667136 learning.py:507] global step 4998: loss = 0.0459 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 4999: loss = 0.0679 (0.382 sec/step)\n",
            "I0205 13:51:47.696981 140689526667136 learning.py:507] global step 4999: loss = 0.0679 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5000: loss = 0.0790 (0.345 sec/step)\n",
            "I0205 13:51:48.043147 140689526667136 learning.py:507] global step 5000: loss = 0.0790 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 5001: loss = 0.0373 (0.374 sec/step)\n",
            "I0205 13:51:48.418818 140689526667136 learning.py:507] global step 5001: loss = 0.0373 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 5002: loss = 0.0617 (0.401 sec/step)\n",
            "I0205 13:51:48.821735 140689526667136 learning.py:507] global step 5002: loss = 0.0617 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 5003: loss = 0.1557 (0.412 sec/step)\n",
            "I0205 13:51:49.235623 140689526667136 learning.py:507] global step 5003: loss = 0.1557 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 5004: loss = 0.0737 (0.380 sec/step)\n",
            "I0205 13:51:49.617382 140689526667136 learning.py:507] global step 5004: loss = 0.0737 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 5005: loss = 0.3176 (0.372 sec/step)\n",
            "I0205 13:51:49.990644 140689526667136 learning.py:507] global step 5005: loss = 0.3176 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 5006: loss = 0.1763 (0.398 sec/step)\n",
            "I0205 13:51:50.390210 140689526667136 learning.py:507] global step 5006: loss = 0.1763 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 5007: loss = 0.1352 (0.407 sec/step)\n",
            "I0205 13:51:50.798550 140689526667136 learning.py:507] global step 5007: loss = 0.1352 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 5008: loss = 0.2938 (0.353 sec/step)\n",
            "I0205 13:51:51.152821 140689526667136 learning.py:507] global step 5008: loss = 0.2938 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 5009: loss = 0.2518 (0.366 sec/step)\n",
            "I0205 13:51:51.520911 140689526667136 learning.py:507] global step 5009: loss = 0.2518 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 5010: loss = 0.0441 (0.397 sec/step)\n",
            "I0205 13:51:51.919605 140689526667136 learning.py:507] global step 5010: loss = 0.0441 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 5011: loss = 0.0312 (0.418 sec/step)\n",
            "I0205 13:51:52.340151 140689526667136 learning.py:507] global step 5011: loss = 0.0312 (0.418 sec/step)\n",
            "INFO:tensorflow:global step 5012: loss = 0.6238 (0.437 sec/step)\n",
            "I0205 13:51:52.779272 140689526667136 learning.py:507] global step 5012: loss = 0.6238 (0.437 sec/step)\n",
            "INFO:tensorflow:global step 5013: loss = 0.1098 (0.411 sec/step)\n",
            "I0205 13:51:53.192503 140689526667136 learning.py:507] global step 5013: loss = 0.1098 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 5014: loss = 0.1062 (0.402 sec/step)\n",
            "I0205 13:51:53.595636 140689526667136 learning.py:507] global step 5014: loss = 0.1062 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 5015: loss = 0.0688 (0.382 sec/step)\n",
            "I0205 13:51:53.979301 140689526667136 learning.py:507] global step 5015: loss = 0.0688 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5016: loss = 0.1931 (0.386 sec/step)\n",
            "I0205 13:51:54.366507 140689526667136 learning.py:507] global step 5016: loss = 0.1931 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 5017: loss = 0.0720 (0.394 sec/step)\n",
            "I0205 13:51:54.762573 140689526667136 learning.py:507] global step 5017: loss = 0.0720 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 5018: loss = 0.1409 (0.371 sec/step)\n",
            "I0205 13:51:55.135038 140689526667136 learning.py:507] global step 5018: loss = 0.1409 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 5019: loss = 0.0371 (0.388 sec/step)\n",
            "I0205 13:51:55.524652 140689526667136 learning.py:507] global step 5019: loss = 0.0371 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 5020: loss = 0.0936 (0.392 sec/step)\n",
            "I0205 13:51:55.918742 140689526667136 learning.py:507] global step 5020: loss = 0.0936 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 5021: loss = 0.0756 (0.364 sec/step)\n",
            "I0205 13:51:56.284772 140689526667136 learning.py:507] global step 5021: loss = 0.0756 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 5022: loss = 0.0494 (0.380 sec/step)\n",
            "I0205 13:51:56.666122 140689526667136 learning.py:507] global step 5022: loss = 0.0494 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 5023: loss = 0.2142 (0.373 sec/step)\n",
            "I0205 13:51:57.040995 140689526667136 learning.py:507] global step 5023: loss = 0.2142 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 5024: loss = 0.2142 (0.395 sec/step)\n",
            "I0205 13:51:57.437638 140689526667136 learning.py:507] global step 5024: loss = 0.2142 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 5025: loss = 0.1392 (0.387 sec/step)\n",
            "I0205 13:51:57.826370 140689526667136 learning.py:507] global step 5025: loss = 0.1392 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 5026: loss = 0.0633 (0.369 sec/step)\n",
            "I0205 13:51:58.196892 140689526667136 learning.py:507] global step 5026: loss = 0.0633 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 5027: loss = 0.8226 (0.390 sec/step)\n",
            "I0205 13:51:58.588240 140689526667136 learning.py:507] global step 5027: loss = 0.8226 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5028: loss = 0.1375 (0.378 sec/step)\n",
            "I0205 13:51:58.967410 140689526667136 learning.py:507] global step 5028: loss = 0.1375 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 5029: loss = 0.2710 (0.396 sec/step)\n",
            "I0205 13:51:59.365287 140689526667136 learning.py:507] global step 5029: loss = 0.2710 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 5030: loss = 0.1265 (0.393 sec/step)\n",
            "I0205 13:51:59.759873 140689526667136 learning.py:507] global step 5030: loss = 0.1265 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 5031: loss = 0.6587 (0.350 sec/step)\n",
            "I0205 13:52:00.111257 140689526667136 learning.py:507] global step 5031: loss = 0.6587 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 5032: loss = 0.1265 (0.383 sec/step)\n",
            "I0205 13:52:00.496191 140689526667136 learning.py:507] global step 5032: loss = 0.1265 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 5033: loss = 0.1629 (0.379 sec/step)\n",
            "I0205 13:52:00.876641 140689526667136 learning.py:507] global step 5033: loss = 0.1629 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5034: loss = 0.0272 (0.364 sec/step)\n",
            "I0205 13:52:01.241904 140689526667136 learning.py:507] global step 5034: loss = 0.0272 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 5035: loss = 0.0882 (0.376 sec/step)\n",
            "I0205 13:52:01.619646 140689526667136 learning.py:507] global step 5035: loss = 0.0882 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5036: loss = 0.1419 (0.389 sec/step)\n",
            "I0205 13:52:02.010426 140689526667136 learning.py:507] global step 5036: loss = 0.1419 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 5037: loss = 0.0681 (0.386 sec/step)\n",
            "I0205 13:52:02.397590 140689526667136 learning.py:507] global step 5037: loss = 0.0681 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 5038: loss = 0.0780 (0.385 sec/step)\n",
            "I0205 13:52:02.783878 140689526667136 learning.py:507] global step 5038: loss = 0.0780 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 5039: loss = 1.1825 (0.414 sec/step)\n",
            "I0205 13:52:03.199307 140689526667136 learning.py:507] global step 5039: loss = 1.1825 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 5040: loss = 0.0674 (0.374 sec/step)\n",
            "I0205 13:52:03.574637 140689526667136 learning.py:507] global step 5040: loss = 0.0674 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 5041: loss = 0.1114 (0.383 sec/step)\n",
            "I0205 13:52:03.959580 140689526667136 learning.py:507] global step 5041: loss = 0.1114 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 5042: loss = 0.1506 (0.368 sec/step)\n",
            "I0205 13:52:04.328625 140689526667136 learning.py:507] global step 5042: loss = 0.1506 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 5043: loss = 0.0461 (0.372 sec/step)\n",
            "I0205 13:52:04.702199 140689526667136 learning.py:507] global step 5043: loss = 0.0461 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 5044: loss = 0.2044 (0.352 sec/step)\n",
            "I0205 13:52:05.055735 140689526667136 learning.py:507] global step 5044: loss = 0.2044 (0.352 sec/step)\n",
            "INFO:tensorflow:global step 5045: loss = 0.1033 (0.377 sec/step)\n",
            "I0205 13:52:05.434022 140689526667136 learning.py:507] global step 5045: loss = 0.1033 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 5046: loss = 0.1056 (0.373 sec/step)\n",
            "I0205 13:52:05.808673 140689526667136 learning.py:507] global step 5046: loss = 0.1056 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 5047: loss = 0.1157 (0.379 sec/step)\n",
            "I0205 13:52:06.189940 140689526667136 learning.py:507] global step 5047: loss = 0.1157 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5048: loss = 0.0785 (0.375 sec/step)\n",
            "I0205 13:52:06.567001 140689526667136 learning.py:507] global step 5048: loss = 0.0785 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 5049: loss = 0.1289 (0.390 sec/step)\n",
            "I0205 13:52:06.958979 140689526667136 learning.py:507] global step 5049: loss = 0.1289 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5050: loss = 0.1370 (0.408 sec/step)\n",
            "I0205 13:52:07.368419 140689526667136 learning.py:507] global step 5050: loss = 0.1370 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 5051: loss = 0.0993 (0.384 sec/step)\n",
            "I0205 13:52:07.753729 140689526667136 learning.py:507] global step 5051: loss = 0.0993 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 5052: loss = 0.1620 (0.399 sec/step)\n",
            "I0205 13:52:08.154935 140689526667136 learning.py:507] global step 5052: loss = 0.1620 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 5053: loss = 0.0836 (0.399 sec/step)\n",
            "I0205 13:52:08.555954 140689526667136 learning.py:507] global step 5053: loss = 0.0836 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 5054: loss = 0.5910 (0.391 sec/step)\n",
            "I0205 13:52:08.948281 140689526667136 learning.py:507] global step 5054: loss = 0.5910 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 5055: loss = 0.0980 (0.415 sec/step)\n",
            "I0205 13:52:09.365109 140689526667136 learning.py:507] global step 5055: loss = 0.0980 (0.415 sec/step)\n",
            "INFO:tensorflow:global step 5056: loss = 0.0383 (0.410 sec/step)\n",
            "I0205 13:52:09.776586 140689526667136 learning.py:507] global step 5056: loss = 0.0383 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 5057: loss = 0.0767 (0.393 sec/step)\n",
            "I0205 13:52:10.170892 140689526667136 learning.py:507] global step 5057: loss = 0.0767 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 5058: loss = 0.2362 (0.352 sec/step)\n",
            "I0205 13:52:10.524496 140689526667136 learning.py:507] global step 5058: loss = 0.2362 (0.352 sec/step)\n",
            "INFO:tensorflow:global step 5059: loss = 0.8307 (0.372 sec/step)\n",
            "I0205 13:52:10.897819 140689526667136 learning.py:507] global step 5059: loss = 0.8307 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 5060: loss = 0.1105 (0.345 sec/step)\n",
            "I0205 13:52:11.244489 140689526667136 learning.py:507] global step 5060: loss = 0.1105 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 5061: loss = 0.0995 (0.384 sec/step)\n",
            "I0205 13:52:11.630471 140689526667136 learning.py:507] global step 5061: loss = 0.0995 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 5062: loss = 0.0960 (0.385 sec/step)\n",
            "I0205 13:52:12.016618 140689526667136 learning.py:507] global step 5062: loss = 0.0960 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 5063: loss = 0.0977 (0.381 sec/step)\n",
            "I0205 13:52:12.399439 140689526667136 learning.py:507] global step 5063: loss = 0.0977 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 5064: loss = 0.1871 (0.414 sec/step)\n",
            "I0205 13:52:12.815263 140689526667136 learning.py:507] global step 5064: loss = 0.1871 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 5065: loss = 0.3666 (0.389 sec/step)\n",
            "I0205 13:52:13.206069 140689526667136 learning.py:507] global step 5065: loss = 0.3666 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 5066: loss = 0.2162 (0.333 sec/step)\n",
            "I0205 13:52:13.540403 140689526667136 learning.py:507] global step 5066: loss = 0.2162 (0.333 sec/step)\n",
            "INFO:tensorflow:global step 5067: loss = 0.2366 (0.583 sec/step)\n",
            "I0205 13:52:14.127219 140689526667136 learning.py:507] global step 5067: loss = 0.2366 (0.583 sec/step)\n",
            "INFO:tensorflow:global step 5068: loss = 0.0629 (0.933 sec/step)\n",
            "I0205 13:52:15.198716 140689526667136 learning.py:507] global step 5068: loss = 0.0629 (0.933 sec/step)\n",
            "INFO:tensorflow:global step 5069: loss = 0.0981 (0.627 sec/step)\n",
            "I0205 13:52:15.975713 140689526667136 learning.py:507] global step 5069: loss = 0.0981 (0.627 sec/step)\n",
            "INFO:tensorflow:global step 5070: loss = 0.7883 (0.617 sec/step)\n",
            "I0205 13:52:16.595580 140689526667136 learning.py:507] global step 5070: loss = 0.7883 (0.617 sec/step)\n",
            "INFO:tensorflow:global step 5071: loss = 0.1301 (0.526 sec/step)\n",
            "I0205 13:52:17.164427 140689526667136 learning.py:507] global step 5071: loss = 0.1301 (0.526 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 5071.\n",
            "I0205 13:52:17.309772 140686026073856 supervisor.py:1050] Recording summary at step 5071.\n",
            "INFO:tensorflow:global step 5072: loss = 0.0771 (0.450 sec/step)\n",
            "I0205 13:52:17.650106 140689526667136 learning.py:507] global step 5072: loss = 0.0771 (0.450 sec/step)\n",
            "INFO:tensorflow:global step 5073: loss = 0.0315 (0.369 sec/step)\n",
            "I0205 13:52:18.020848 140689526667136 learning.py:507] global step 5073: loss = 0.0315 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 5074: loss = 0.3121 (0.363 sec/step)\n",
            "I0205 13:52:18.385093 140689526667136 learning.py:507] global step 5074: loss = 0.3121 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 5075: loss = 0.3018 (0.374 sec/step)\n",
            "I0205 13:52:18.760270 140689526667136 learning.py:507] global step 5075: loss = 0.3018 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 5076: loss = 0.0881 (0.388 sec/step)\n",
            "I0205 13:52:19.149209 140689526667136 learning.py:507] global step 5076: loss = 0.0881 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 5077: loss = 0.2011 (0.380 sec/step)\n",
            "I0205 13:52:19.530794 140689526667136 learning.py:507] global step 5077: loss = 0.2011 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 5078: loss = 0.1028 (0.381 sec/step)\n",
            "I0205 13:52:19.913344 140689526667136 learning.py:507] global step 5078: loss = 0.1028 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 5079: loss = 0.2128 (0.379 sec/step)\n",
            "I0205 13:52:20.294373 140689526667136 learning.py:507] global step 5079: loss = 0.2128 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5080: loss = 0.1426 (0.364 sec/step)\n",
            "I0205 13:52:20.660132 140689526667136 learning.py:507] global step 5080: loss = 0.1426 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 5081: loss = 0.1511 (0.374 sec/step)\n",
            "I0205 13:52:21.036149 140689526667136 learning.py:507] global step 5081: loss = 0.1511 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 5082: loss = 0.0921 (0.382 sec/step)\n",
            "I0205 13:52:21.420199 140689526667136 learning.py:507] global step 5082: loss = 0.0921 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5083: loss = 0.2669 (0.386 sec/step)\n",
            "I0205 13:52:21.807742 140689526667136 learning.py:507] global step 5083: loss = 0.2669 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 5084: loss = 0.9550 (0.391 sec/step)\n",
            "I0205 13:52:22.200894 140689526667136 learning.py:507] global step 5084: loss = 0.9550 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 5085: loss = 0.1065 (0.369 sec/step)\n",
            "I0205 13:52:22.571508 140689526667136 learning.py:507] global step 5085: loss = 0.1065 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 5086: loss = 0.1094 (0.372 sec/step)\n",
            "I0205 13:52:22.945259 140689526667136 learning.py:507] global step 5086: loss = 0.1094 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 5087: loss = 0.0411 (0.379 sec/step)\n",
            "I0205 13:52:23.326384 140689526667136 learning.py:507] global step 5087: loss = 0.0411 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5088: loss = 0.0516 (0.376 sec/step)\n",
            "I0205 13:52:23.704466 140689526667136 learning.py:507] global step 5088: loss = 0.0516 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5089: loss = 0.2669 (0.394 sec/step)\n",
            "I0205 13:52:24.099674 140689526667136 learning.py:507] global step 5089: loss = 0.2669 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 5090: loss = 0.0920 (0.391 sec/step)\n",
            "I0205 13:52:24.492576 140689526667136 learning.py:507] global step 5090: loss = 0.0920 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 5091: loss = 0.5482 (0.385 sec/step)\n",
            "I0205 13:52:24.879772 140689526667136 learning.py:507] global step 5091: loss = 0.5482 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 5092: loss = 0.2425 (0.386 sec/step)\n",
            "I0205 13:52:25.266965 140689526667136 learning.py:507] global step 5092: loss = 0.2425 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 5093: loss = 0.1229 (0.388 sec/step)\n",
            "I0205 13:52:25.656394 140689526667136 learning.py:507] global step 5093: loss = 0.1229 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 5094: loss = 0.1311 (0.382 sec/step)\n",
            "I0205 13:52:26.040219 140689526667136 learning.py:507] global step 5094: loss = 0.1311 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5095: loss = 0.6526 (0.379 sec/step)\n",
            "I0205 13:52:26.420639 140689526667136 learning.py:507] global step 5095: loss = 0.6526 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5096: loss = 0.1050 (0.393 sec/step)\n",
            "I0205 13:52:26.815457 140689526667136 learning.py:507] global step 5096: loss = 0.1050 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 5097: loss = 0.1812 (0.407 sec/step)\n",
            "I0205 13:52:27.226520 140689526667136 learning.py:507] global step 5097: loss = 0.1812 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 5098: loss = 0.5195 (0.371 sec/step)\n",
            "I0205 13:52:27.599397 140689526667136 learning.py:507] global step 5098: loss = 0.5195 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 5099: loss = 0.1207 (0.366 sec/step)\n",
            "I0205 13:52:27.967206 140689526667136 learning.py:507] global step 5099: loss = 0.1207 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 5100: loss = 0.1079 (0.385 sec/step)\n",
            "I0205 13:52:28.353960 140689526667136 learning.py:507] global step 5100: loss = 0.1079 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 5101: loss = 0.0374 (0.385 sec/step)\n",
            "I0205 13:52:28.740997 140689526667136 learning.py:507] global step 5101: loss = 0.0374 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 5102: loss = 0.0852 (0.399 sec/step)\n",
            "I0205 13:52:29.141494 140689526667136 learning.py:507] global step 5102: loss = 0.0852 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 5103: loss = 0.0497 (0.375 sec/step)\n",
            "I0205 13:52:29.518459 140689526667136 learning.py:507] global step 5103: loss = 0.0497 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 5104: loss = 0.0530 (0.435 sec/step)\n",
            "I0205 13:52:29.955748 140689526667136 learning.py:507] global step 5104: loss = 0.0530 (0.435 sec/step)\n",
            "INFO:tensorflow:global step 5105: loss = 0.1742 (0.385 sec/step)\n",
            "I0205 13:52:30.342434 140689526667136 learning.py:507] global step 5105: loss = 0.1742 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 5106: loss = 0.1570 (0.416 sec/step)\n",
            "I0205 13:52:30.760277 140689526667136 learning.py:507] global step 5106: loss = 0.1570 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 5107: loss = 0.1167 (0.433 sec/step)\n",
            "I0205 13:52:31.195102 140689526667136 learning.py:507] global step 5107: loss = 0.1167 (0.433 sec/step)\n",
            "INFO:tensorflow:global step 5108: loss = 0.0751 (0.394 sec/step)\n",
            "I0205 13:52:31.591301 140689526667136 learning.py:507] global step 5108: loss = 0.0751 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 5109: loss = 0.6523 (0.364 sec/step)\n",
            "I0205 13:52:31.956683 140689526667136 learning.py:507] global step 5109: loss = 0.6523 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 5110: loss = 0.0865 (0.384 sec/step)\n",
            "I0205 13:52:32.345026 140689526667136 learning.py:507] global step 5110: loss = 0.0865 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 5111: loss = 0.4177 (0.369 sec/step)\n",
            "I0205 13:52:32.716069 140689526667136 learning.py:507] global step 5111: loss = 0.4177 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 5112: loss = 0.1104 (0.391 sec/step)\n",
            "I0205 13:52:33.108918 140689526667136 learning.py:507] global step 5112: loss = 0.1104 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 5113: loss = 0.1992 (0.404 sec/step)\n",
            "I0205 13:52:33.515024 140689526667136 learning.py:507] global step 5113: loss = 0.1992 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 5114: loss = 0.2683 (0.378 sec/step)\n",
            "I0205 13:52:33.894583 140689526667136 learning.py:507] global step 5114: loss = 0.2683 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 5115: loss = 0.2038 (0.389 sec/step)\n",
            "I0205 13:52:34.285104 140689526667136 learning.py:507] global step 5115: loss = 0.2038 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 5116: loss = 0.2534 (0.378 sec/step)\n",
            "I0205 13:52:34.664520 140689526667136 learning.py:507] global step 5116: loss = 0.2534 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 5117: loss = 0.1894 (0.390 sec/step)\n",
            "I0205 13:52:35.056663 140689526667136 learning.py:507] global step 5117: loss = 0.1894 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5118: loss = 0.0909 (0.392 sec/step)\n",
            "I0205 13:52:35.450070 140689526667136 learning.py:507] global step 5118: loss = 0.0909 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 5119: loss = 0.2889 (0.397 sec/step)\n",
            "I0205 13:52:35.848907 140689526667136 learning.py:507] global step 5119: loss = 0.2889 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 5120: loss = 0.2075 (0.376 sec/step)\n",
            "I0205 13:52:36.226270 140689526667136 learning.py:507] global step 5120: loss = 0.2075 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5121: loss = 0.1731 (0.357 sec/step)\n",
            "I0205 13:52:36.584912 140689526667136 learning.py:507] global step 5121: loss = 0.1731 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 5122: loss = 0.1606 (0.387 sec/step)\n",
            "I0205 13:52:36.973193 140689526667136 learning.py:507] global step 5122: loss = 0.1606 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 5123: loss = 0.1609 (0.380 sec/step)\n",
            "I0205 13:52:37.355312 140689526667136 learning.py:507] global step 5123: loss = 0.1609 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 5124: loss = 0.2657 (0.370 sec/step)\n",
            "I0205 13:52:37.727866 140689526667136 learning.py:507] global step 5124: loss = 0.2657 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 5125: loss = 0.0864 (0.383 sec/step)\n",
            "I0205 13:52:38.112271 140689526667136 learning.py:507] global step 5125: loss = 0.0864 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 5126: loss = 0.0711 (0.358 sec/step)\n",
            "I0205 13:52:38.471702 140689526667136 learning.py:507] global step 5126: loss = 0.0711 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 5127: loss = 0.1424 (0.359 sec/step)\n",
            "I0205 13:52:38.832090 140689526667136 learning.py:507] global step 5127: loss = 0.1424 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 5128: loss = 0.0627 (0.371 sec/step)\n",
            "I0205 13:52:39.204362 140689526667136 learning.py:507] global step 5128: loss = 0.0627 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 5129: loss = 0.1615 (0.391 sec/step)\n",
            "I0205 13:52:39.596413 140689526667136 learning.py:507] global step 5129: loss = 0.1615 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 5130: loss = 0.2546 (0.387 sec/step)\n",
            "I0205 13:52:39.984601 140689526667136 learning.py:507] global step 5130: loss = 0.2546 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 5131: loss = 0.4930 (0.364 sec/step)\n",
            "I0205 13:52:40.349751 140689526667136 learning.py:507] global step 5131: loss = 0.4930 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 5132: loss = 0.6103 (0.386 sec/step)\n",
            "I0205 13:52:40.737201 140689526667136 learning.py:507] global step 5132: loss = 0.6103 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 5133: loss = 0.0578 (0.363 sec/step)\n",
            "I0205 13:52:41.101853 140689526667136 learning.py:507] global step 5133: loss = 0.0578 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 5134: loss = 0.3816 (0.398 sec/step)\n",
            "I0205 13:52:41.501144 140689526667136 learning.py:507] global step 5134: loss = 0.3816 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 5135: loss = 0.2574 (0.395 sec/step)\n",
            "I0205 13:52:41.898045 140689526667136 learning.py:507] global step 5135: loss = 0.2574 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 5136: loss = 0.3341 (0.353 sec/step)\n",
            "I0205 13:52:42.252865 140689526667136 learning.py:507] global step 5136: loss = 0.3341 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 5137: loss = 0.1343 (0.402 sec/step)\n",
            "I0205 13:52:42.656186 140689526667136 learning.py:507] global step 5137: loss = 0.1343 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 5138: loss = 0.1249 (0.374 sec/step)\n",
            "I0205 13:52:43.031939 140689526667136 learning.py:507] global step 5138: loss = 0.1249 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 5139: loss = 0.0448 (0.390 sec/step)\n",
            "I0205 13:52:43.423243 140689526667136 learning.py:507] global step 5139: loss = 0.0448 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5140: loss = 0.4249 (0.365 sec/step)\n",
            "I0205 13:52:43.789796 140689526667136 learning.py:507] global step 5140: loss = 0.4249 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 5141: loss = 0.1655 (0.389 sec/step)\n",
            "I0205 13:52:44.180345 140689526667136 learning.py:507] global step 5141: loss = 0.1655 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 5142: loss = 0.4239 (0.341 sec/step)\n",
            "I0205 13:52:44.522717 140689526667136 learning.py:507] global step 5142: loss = 0.4239 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 5143: loss = 0.1595 (0.376 sec/step)\n",
            "I0205 13:52:44.900363 140689526667136 learning.py:507] global step 5143: loss = 0.1595 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5144: loss = 0.1042 (0.358 sec/step)\n",
            "I0205 13:52:45.260199 140689526667136 learning.py:507] global step 5144: loss = 0.1042 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 5145: loss = 0.0959 (0.396 sec/step)\n",
            "I0205 13:52:45.658199 140689526667136 learning.py:507] global step 5145: loss = 0.0959 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 5146: loss = 0.0534 (0.381 sec/step)\n",
            "I0205 13:52:46.040814 140689526667136 learning.py:507] global step 5146: loss = 0.0534 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 5147: loss = 0.0247 (0.368 sec/step)\n",
            "I0205 13:52:46.410359 140689526667136 learning.py:507] global step 5147: loss = 0.0247 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 5148: loss = 0.0307 (0.420 sec/step)\n",
            "I0205 13:52:46.831942 140689526667136 learning.py:507] global step 5148: loss = 0.0307 (0.420 sec/step)\n",
            "INFO:tensorflow:global step 5149: loss = 0.1159 (0.357 sec/step)\n",
            "I0205 13:52:47.190832 140689526667136 learning.py:507] global step 5149: loss = 0.1159 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 5150: loss = 0.4873 (0.407 sec/step)\n",
            "I0205 13:52:47.599102 140689526667136 learning.py:507] global step 5150: loss = 0.4873 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 5151: loss = 0.2147 (0.378 sec/step)\n",
            "I0205 13:52:47.979067 140689526667136 learning.py:507] global step 5151: loss = 0.2147 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 5152: loss = 0.1935 (0.381 sec/step)\n",
            "I0205 13:52:48.362158 140689526667136 learning.py:507] global step 5152: loss = 0.1935 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 5153: loss = 0.4042 (0.399 sec/step)\n",
            "I0205 13:52:48.762967 140689526667136 learning.py:507] global step 5153: loss = 0.4042 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 5154: loss = 0.2119 (0.352 sec/step)\n",
            "I0205 13:52:49.116454 140689526667136 learning.py:507] global step 5154: loss = 0.2119 (0.352 sec/step)\n",
            "INFO:tensorflow:global step 5155: loss = 0.1465 (0.349 sec/step)\n",
            "I0205 13:52:49.467086 140689526667136 learning.py:507] global step 5155: loss = 0.1465 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 5156: loss = 0.1942 (0.376 sec/step)\n",
            "I0205 13:52:49.844886 140689526667136 learning.py:507] global step 5156: loss = 0.1942 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5157: loss = 0.1168 (0.378 sec/step)\n",
            "I0205 13:52:50.224627 140689526667136 learning.py:507] global step 5157: loss = 0.1168 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 5158: loss = 0.2056 (0.385 sec/step)\n",
            "I0205 13:52:50.611773 140689526667136 learning.py:507] global step 5158: loss = 0.2056 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 5159: loss = 0.0240 (0.363 sec/step)\n",
            "I0205 13:52:50.976178 140689526667136 learning.py:507] global step 5159: loss = 0.0240 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 5160: loss = 0.2183 (0.371 sec/step)\n",
            "I0205 13:52:51.349100 140689526667136 learning.py:507] global step 5160: loss = 0.2183 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 5161: loss = 0.1119 (0.363 sec/step)\n",
            "I0205 13:52:51.713787 140689526667136 learning.py:507] global step 5161: loss = 0.1119 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 5162: loss = 0.6164 (0.374 sec/step)\n",
            "I0205 13:52:52.089403 140689526667136 learning.py:507] global step 5162: loss = 0.6164 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 5163: loss = 0.0865 (0.401 sec/step)\n",
            "I0205 13:52:52.492795 140689526667136 learning.py:507] global step 5163: loss = 0.0865 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 5164: loss = 0.0507 (0.413 sec/step)\n",
            "I0205 13:52:52.907846 140689526667136 learning.py:507] global step 5164: loss = 0.0507 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 5165: loss = 0.0585 (0.399 sec/step)\n",
            "I0205 13:52:53.308878 140689526667136 learning.py:507] global step 5165: loss = 0.0585 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 5166: loss = 0.0386 (0.374 sec/step)\n",
            "I0205 13:52:53.684260 140689526667136 learning.py:507] global step 5166: loss = 0.0386 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 5167: loss = 0.0407 (0.393 sec/step)\n",
            "I0205 13:52:54.078897 140689526667136 learning.py:507] global step 5167: loss = 0.0407 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 5168: loss = 0.0719 (0.370 sec/step)\n",
            "I0205 13:52:54.450916 140689526667136 learning.py:507] global step 5168: loss = 0.0719 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 5169: loss = 0.0547 (0.374 sec/step)\n",
            "I0205 13:52:54.827007 140689526667136 learning.py:507] global step 5169: loss = 0.0547 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 5170: loss = 0.2046 (0.386 sec/step)\n",
            "I0205 13:52:55.214498 140689526667136 learning.py:507] global step 5170: loss = 0.2046 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 5171: loss = 0.0572 (0.365 sec/step)\n",
            "I0205 13:52:55.580947 140689526667136 learning.py:507] global step 5171: loss = 0.0572 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 5172: loss = 0.1092 (0.388 sec/step)\n",
            "I0205 13:52:55.970464 140689526667136 learning.py:507] global step 5172: loss = 0.1092 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 5173: loss = 0.1278 (0.380 sec/step)\n",
            "I0205 13:52:56.352458 140689526667136 learning.py:507] global step 5173: loss = 0.1278 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 5174: loss = 0.2049 (0.360 sec/step)\n",
            "I0205 13:52:56.714147 140689526667136 learning.py:507] global step 5174: loss = 0.2049 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 5175: loss = 0.2498 (0.399 sec/step)\n",
            "I0205 13:52:57.114593 140689526667136 learning.py:507] global step 5175: loss = 0.2498 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 5176: loss = 0.3321 (0.393 sec/step)\n",
            "I0205 13:52:57.509429 140689526667136 learning.py:507] global step 5176: loss = 0.3321 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 5177: loss = 0.2640 (0.371 sec/step)\n",
            "I0205 13:52:57.882183 140689526667136 learning.py:507] global step 5177: loss = 0.2640 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 5178: loss = 0.4482 (0.386 sec/step)\n",
            "I0205 13:52:58.269568 140689526667136 learning.py:507] global step 5178: loss = 0.4482 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 5179: loss = 0.3092 (0.383 sec/step)\n",
            "I0205 13:52:58.653798 140689526667136 learning.py:507] global step 5179: loss = 0.3092 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 5180: loss = 0.3256 (0.430 sec/step)\n",
            "I0205 13:52:59.085873 140689526667136 learning.py:507] global step 5180: loss = 0.3256 (0.430 sec/step)\n",
            "INFO:tensorflow:global step 5181: loss = 0.0445 (0.416 sec/step)\n",
            "I0205 13:52:59.503725 140689526667136 learning.py:507] global step 5181: loss = 0.0445 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 5182: loss = 0.1158 (0.352 sec/step)\n",
            "I0205 13:52:59.857318 140689526667136 learning.py:507] global step 5182: loss = 0.1158 (0.352 sec/step)\n",
            "INFO:tensorflow:global step 5183: loss = 0.1954 (0.385 sec/step)\n",
            "I0205 13:53:00.244291 140689526667136 learning.py:507] global step 5183: loss = 0.1954 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 5184: loss = 0.0391 (0.389 sec/step)\n",
            "I0205 13:53:00.634877 140689526667136 learning.py:507] global step 5184: loss = 0.0391 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 5185: loss = 0.1007 (0.369 sec/step)\n",
            "I0205 13:53:01.005596 140689526667136 learning.py:507] global step 5185: loss = 0.1007 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 5186: loss = 0.1270 (0.380 sec/step)\n",
            "I0205 13:53:01.387305 140689526667136 learning.py:507] global step 5186: loss = 0.1270 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 5187: loss = 0.1166 (0.374 sec/step)\n",
            "I0205 13:53:01.763123 140689526667136 learning.py:507] global step 5187: loss = 0.1166 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 5188: loss = 0.1278 (0.366 sec/step)\n",
            "I0205 13:53:02.132145 140689526667136 learning.py:507] global step 5188: loss = 0.1278 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 5189: loss = 0.1382 (0.377 sec/step)\n",
            "I0205 13:53:02.511768 140689526667136 learning.py:507] global step 5189: loss = 0.1382 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 5190: loss = 0.1541 (0.393 sec/step)\n",
            "I0205 13:53:02.906298 140689526667136 learning.py:507] global step 5190: loss = 0.1541 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 5191: loss = 0.1140 (0.398 sec/step)\n",
            "I0205 13:53:03.306148 140689526667136 learning.py:507] global step 5191: loss = 0.1140 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 5192: loss = 0.0910 (0.355 sec/step)\n",
            "I0205 13:53:03.662438 140689526667136 learning.py:507] global step 5192: loss = 0.0910 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 5193: loss = 0.0544 (0.385 sec/step)\n",
            "I0205 13:53:04.048681 140689526667136 learning.py:507] global step 5193: loss = 0.0544 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 5194: loss = 0.1785 (0.387 sec/step)\n",
            "I0205 13:53:04.437487 140689526667136 learning.py:507] global step 5194: loss = 0.1785 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 5195: loss = 0.1980 (0.376 sec/step)\n",
            "I0205 13:53:04.815210 140689526667136 learning.py:507] global step 5195: loss = 0.1980 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5196: loss = 0.0878 (0.390 sec/step)\n",
            "I0205 13:53:05.206544 140689526667136 learning.py:507] global step 5196: loss = 0.0878 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5197: loss = 0.4969 (0.402 sec/step)\n",
            "I0205 13:53:05.610679 140689526667136 learning.py:507] global step 5197: loss = 0.4969 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 5198: loss = 0.0203 (0.388 sec/step)\n",
            "I0205 13:53:06.000790 140689526667136 learning.py:507] global step 5198: loss = 0.0203 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 5199: loss = 0.2250 (0.380 sec/step)\n",
            "I0205 13:53:06.382433 140689526667136 learning.py:507] global step 5199: loss = 0.2250 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 5200: loss = 0.1605 (0.391 sec/step)\n",
            "I0205 13:53:06.774795 140689526667136 learning.py:507] global step 5200: loss = 0.1605 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 5201: loss = 0.0847 (0.377 sec/step)\n",
            "I0205 13:53:07.153182 140689526667136 learning.py:507] global step 5201: loss = 0.0847 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 5202: loss = 0.0415 (0.396 sec/step)\n",
            "I0205 13:53:07.550474 140689526667136 learning.py:507] global step 5202: loss = 0.0415 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 5203: loss = 0.8446 (0.370 sec/step)\n",
            "I0205 13:53:07.921951 140689526667136 learning.py:507] global step 5203: loss = 0.8446 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 5204: loss = 0.1925 (0.374 sec/step)\n",
            "I0205 13:53:08.299655 140689526667136 learning.py:507] global step 5204: loss = 0.1925 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 5205: loss = 0.0326 (0.370 sec/step)\n",
            "I0205 13:53:08.671776 140689526667136 learning.py:507] global step 5205: loss = 0.0326 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 5206: loss = 0.2177 (0.386 sec/step)\n",
            "I0205 13:53:09.059680 140689526667136 learning.py:507] global step 5206: loss = 0.2177 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 5207: loss = 0.1919 (0.370 sec/step)\n",
            "I0205 13:53:09.431985 140689526667136 learning.py:507] global step 5207: loss = 0.1919 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 5208: loss = 0.1245 (0.384 sec/step)\n",
            "I0205 13:53:09.817597 140689526667136 learning.py:507] global step 5208: loss = 0.1245 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 5209: loss = 0.4929 (0.374 sec/step)\n",
            "I0205 13:53:10.192939 140689526667136 learning.py:507] global step 5209: loss = 0.4929 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 5210: loss = 0.1076 (0.389 sec/step)\n",
            "I0205 13:53:10.583404 140689526667136 learning.py:507] global step 5210: loss = 0.1076 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 5211: loss = 0.5847 (0.369 sec/step)\n",
            "I0205 13:53:10.954097 140689526667136 learning.py:507] global step 5211: loss = 0.5847 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 5212: loss = 0.1376 (0.379 sec/step)\n",
            "I0205 13:53:11.334632 140689526667136 learning.py:507] global step 5212: loss = 0.1376 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5213: loss = 1.0877 (0.395 sec/step)\n",
            "I0205 13:53:11.731056 140689526667136 learning.py:507] global step 5213: loss = 1.0877 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 5214: loss = 0.1385 (0.382 sec/step)\n",
            "I0205 13:53:12.114692 140689526667136 learning.py:507] global step 5214: loss = 0.1385 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5215: loss = 0.2474 (0.376 sec/step)\n",
            "I0205 13:53:12.492833 140689526667136 learning.py:507] global step 5215: loss = 0.2474 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5216: loss = 0.1694 (0.375 sec/step)\n",
            "I0205 13:53:12.869519 140689526667136 learning.py:507] global step 5216: loss = 0.1694 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 5217: loss = 0.0395 (0.394 sec/step)\n",
            "I0205 13:53:13.265358 140689526667136 learning.py:507] global step 5217: loss = 0.0395 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 5218: loss = 0.1378 (0.371 sec/step)\n",
            "I0205 13:53:13.637604 140689526667136 learning.py:507] global step 5218: loss = 0.1378 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 5219: loss = 0.1981 (0.362 sec/step)\n",
            "I0205 13:53:14.001717 140689526667136 learning.py:507] global step 5219: loss = 0.1981 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 5220: loss = 0.0984 (0.377 sec/step)\n",
            "I0205 13:53:14.380226 140689526667136 learning.py:507] global step 5220: loss = 0.0984 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 5221: loss = 0.7083 (0.383 sec/step)\n",
            "I0205 13:53:14.764812 140689526667136 learning.py:507] global step 5221: loss = 0.7083 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 5222: loss = 0.3674 (0.386 sec/step)\n",
            "I0205 13:53:15.152182 140689526667136 learning.py:507] global step 5222: loss = 0.3674 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 5223: loss = 0.1539 (0.368 sec/step)\n",
            "I0205 13:53:15.521647 140689526667136 learning.py:507] global step 5223: loss = 0.1539 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 5224: loss = 0.1567 (0.380 sec/step)\n",
            "I0205 13:53:15.903570 140689526667136 learning.py:507] global step 5224: loss = 0.1567 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 5225: loss = 0.1181 (0.380 sec/step)\n",
            "I0205 13:53:16.285238 140689526667136 learning.py:507] global step 5225: loss = 0.1181 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 5226: loss = 0.0385 (0.384 sec/step)\n",
            "I0205 13:53:16.670500 140689526667136 learning.py:507] global step 5226: loss = 0.0385 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 5227: loss = 0.3921 (0.415 sec/step)\n",
            "I0205 13:53:17.087207 140689526667136 learning.py:507] global step 5227: loss = 0.3921 (0.415 sec/step)\n",
            "INFO:tensorflow:global step 5228: loss = 0.3283 (0.374 sec/step)\n",
            "I0205 13:53:17.462606 140689526667136 learning.py:507] global step 5228: loss = 0.3283 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 5229: loss = 0.6739 (0.375 sec/step)\n",
            "I0205 13:53:17.839626 140689526667136 learning.py:507] global step 5229: loss = 0.6739 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 5230: loss = 0.0543 (0.388 sec/step)\n",
            "I0205 13:53:18.229537 140689526667136 learning.py:507] global step 5230: loss = 0.0543 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 5231: loss = 0.0586 (0.384 sec/step)\n",
            "I0205 13:53:18.615835 140689526667136 learning.py:507] global step 5231: loss = 0.0586 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 5232: loss = 0.0323 (0.372 sec/step)\n",
            "I0205 13:53:18.989046 140689526667136 learning.py:507] global step 5232: loss = 0.0323 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 5233: loss = 0.7265 (0.394 sec/step)\n",
            "I0205 13:53:19.384883 140689526667136 learning.py:507] global step 5233: loss = 0.7265 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 5234: loss = 0.1747 (0.377 sec/step)\n",
            "I0205 13:53:19.763698 140689526667136 learning.py:507] global step 5234: loss = 0.1747 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 5235: loss = 0.2370 (0.402 sec/step)\n",
            "I0205 13:53:20.167416 140689526667136 learning.py:507] global step 5235: loss = 0.2370 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 5236: loss = 0.3684 (0.356 sec/step)\n",
            "I0205 13:53:20.524874 140689526667136 learning.py:507] global step 5236: loss = 0.3684 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 5237: loss = 0.6833 (0.381 sec/step)\n",
            "I0205 13:53:20.907450 140689526667136 learning.py:507] global step 5237: loss = 0.6833 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 5238: loss = 0.1539 (0.422 sec/step)\n",
            "I0205 13:53:21.330612 140689526667136 learning.py:507] global step 5238: loss = 0.1539 (0.422 sec/step)\n",
            "INFO:tensorflow:global step 5239: loss = 0.1087 (0.405 sec/step)\n",
            "I0205 13:53:21.737679 140689526667136 learning.py:507] global step 5239: loss = 0.1087 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 5240: loss = 0.1048 (0.372 sec/step)\n",
            "I0205 13:53:22.111117 140689526667136 learning.py:507] global step 5240: loss = 0.1048 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 5241: loss = 0.0372 (0.402 sec/step)\n",
            "I0205 13:53:22.514740 140689526667136 learning.py:507] global step 5241: loss = 0.0372 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 5242: loss = 0.1048 (0.413 sec/step)\n",
            "I0205 13:53:22.929777 140689526667136 learning.py:507] global step 5242: loss = 0.1048 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 5243: loss = 0.1040 (0.372 sec/step)\n",
            "I0205 13:53:23.303532 140689526667136 learning.py:507] global step 5243: loss = 0.1040 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 5244: loss = 0.1974 (0.390 sec/step)\n",
            "I0205 13:53:23.695587 140689526667136 learning.py:507] global step 5244: loss = 0.1974 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5245: loss = 0.3216 (0.388 sec/step)\n",
            "I0205 13:53:24.086546 140689526667136 learning.py:507] global step 5245: loss = 0.3216 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 5246: loss = 0.0922 (0.383 sec/step)\n",
            "I0205 13:53:24.471259 140689526667136 learning.py:507] global step 5246: loss = 0.0922 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 5247: loss = 0.0082 (0.389 sec/step)\n",
            "I0205 13:53:24.862358 140689526667136 learning.py:507] global step 5247: loss = 0.0082 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 5248: loss = 0.0712 (0.338 sec/step)\n",
            "I0205 13:53:25.201406 140689526667136 learning.py:507] global step 5248: loss = 0.0712 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 5249: loss = 0.1365 (0.378 sec/step)\n",
            "I0205 13:53:25.580771 140689526667136 learning.py:507] global step 5249: loss = 0.1365 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 5250: loss = 0.3420 (0.390 sec/step)\n",
            "I0205 13:53:25.972510 140689526667136 learning.py:507] global step 5250: loss = 0.3420 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5251: loss = 0.1765 (0.374 sec/step)\n",
            "I0205 13:53:26.348623 140689526667136 learning.py:507] global step 5251: loss = 0.1765 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 5252: loss = 0.6244 (0.389 sec/step)\n",
            "I0205 13:53:26.739238 140689526667136 learning.py:507] global step 5252: loss = 0.6244 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 5253: loss = 0.0717 (0.356 sec/step)\n",
            "I0205 13:53:27.097870 140689526667136 learning.py:507] global step 5253: loss = 0.0717 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 5254: loss = 0.2170 (0.389 sec/step)\n",
            "I0205 13:53:27.488430 140689526667136 learning.py:507] global step 5254: loss = 0.2170 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 5255: loss = 0.1375 (0.415 sec/step)\n",
            "I0205 13:53:27.905313 140689526667136 learning.py:507] global step 5255: loss = 0.1375 (0.415 sec/step)\n",
            "INFO:tensorflow:global step 5256: loss = 0.0633 (0.392 sec/step)\n",
            "I0205 13:53:28.298602 140689526667136 learning.py:507] global step 5256: loss = 0.0633 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 5257: loss = 0.1350 (0.398 sec/step)\n",
            "I0205 13:53:28.698621 140689526667136 learning.py:507] global step 5257: loss = 0.1350 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 5258: loss = 0.1911 (0.373 sec/step)\n",
            "I0205 13:53:29.073487 140689526667136 learning.py:507] global step 5258: loss = 0.1911 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 5259: loss = 0.2439 (0.405 sec/step)\n",
            "I0205 13:53:29.479901 140689526667136 learning.py:507] global step 5259: loss = 0.2439 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 5260: loss = 0.0601 (0.492 sec/step)\n",
            "I0205 13:53:29.974045 140689526667136 learning.py:507] global step 5260: loss = 0.0601 (0.492 sec/step)\n",
            "INFO:tensorflow:global step 5261: loss = 0.1978 (0.391 sec/step)\n",
            "I0205 13:53:30.366916 140689526667136 learning.py:507] global step 5261: loss = 0.1978 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 5262: loss = 0.5744 (0.409 sec/step)\n",
            "I0205 13:53:30.777754 140689526667136 learning.py:507] global step 5262: loss = 0.5744 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 5263: loss = 0.4136 (0.426 sec/step)\n",
            "I0205 13:53:31.205398 140689526667136 learning.py:507] global step 5263: loss = 0.4136 (0.426 sec/step)\n",
            "INFO:tensorflow:global step 5264: loss = 0.1147 (0.362 sec/step)\n",
            "I0205 13:53:31.569117 140689526667136 learning.py:507] global step 5264: loss = 0.1147 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 5265: loss = 0.0853 (0.407 sec/step)\n",
            "I0205 13:53:31.977791 140689526667136 learning.py:507] global step 5265: loss = 0.0853 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 5266: loss = 0.2194 (0.366 sec/step)\n",
            "I0205 13:53:32.345860 140689526667136 learning.py:507] global step 5266: loss = 0.2194 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 5267: loss = 0.6324 (0.372 sec/step)\n",
            "I0205 13:53:32.719030 140689526667136 learning.py:507] global step 5267: loss = 0.6324 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 5268: loss = 0.1285 (0.414 sec/step)\n",
            "I0205 13:53:33.134123 140689526667136 learning.py:507] global step 5268: loss = 0.1285 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 5269: loss = 0.1046 (0.381 sec/step)\n",
            "I0205 13:53:33.516159 140689526667136 learning.py:507] global step 5269: loss = 0.1046 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 5270: loss = 0.1053 (0.413 sec/step)\n",
            "I0205 13:53:33.930572 140689526667136 learning.py:507] global step 5270: loss = 0.1053 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 5271: loss = 0.0740 (0.374 sec/step)\n",
            "I0205 13:53:34.306509 140689526667136 learning.py:507] global step 5271: loss = 0.0740 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 5272: loss = 0.1535 (0.394 sec/step)\n",
            "I0205 13:53:34.702592 140689526667136 learning.py:507] global step 5272: loss = 0.1535 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 5273: loss = 0.7482 (0.394 sec/step)\n",
            "I0205 13:53:35.098797 140689526667136 learning.py:507] global step 5273: loss = 0.7482 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 5274: loss = 0.1053 (0.350 sec/step)\n",
            "I0205 13:53:35.450390 140689526667136 learning.py:507] global step 5274: loss = 0.1053 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 5275: loss = 0.1686 (0.388 sec/step)\n",
            "I0205 13:53:35.840003 140689526667136 learning.py:507] global step 5275: loss = 0.1686 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 5276: loss = 0.0466 (0.368 sec/step)\n",
            "I0205 13:53:36.209641 140689526667136 learning.py:507] global step 5276: loss = 0.0466 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 5277: loss = 0.0705 (0.371 sec/step)\n",
            "I0205 13:53:36.582422 140689526667136 learning.py:507] global step 5277: loss = 0.0705 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 5278: loss = 0.0983 (0.376 sec/step)\n",
            "I0205 13:53:36.959984 140689526667136 learning.py:507] global step 5278: loss = 0.0983 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5279: loss = 0.2186 (0.383 sec/step)\n",
            "I0205 13:53:37.344521 140689526667136 learning.py:507] global step 5279: loss = 0.2186 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 5280: loss = 0.2088 (0.371 sec/step)\n",
            "I0205 13:53:37.716880 140689526667136 learning.py:507] global step 5280: loss = 0.2088 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 5281: loss = 0.1842 (0.377 sec/step)\n",
            "I0205 13:53:38.095625 140689526667136 learning.py:507] global step 5281: loss = 0.1842 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 5282: loss = 0.2374 (0.385 sec/step)\n",
            "I0205 13:53:38.482632 140689526667136 learning.py:507] global step 5282: loss = 0.2374 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 5283: loss = 0.3668 (0.354 sec/step)\n",
            "I0205 13:53:38.838697 140689526667136 learning.py:507] global step 5283: loss = 0.3668 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 5284: loss = 0.2044 (0.379 sec/step)\n",
            "I0205 13:53:39.219074 140689526667136 learning.py:507] global step 5284: loss = 0.2044 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5285: loss = 0.2401 (0.374 sec/step)\n",
            "I0205 13:53:39.594572 140689526667136 learning.py:507] global step 5285: loss = 0.2401 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 5286: loss = 0.1096 (0.404 sec/step)\n",
            "I0205 13:53:40.000592 140689526667136 learning.py:507] global step 5286: loss = 0.1096 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 5287: loss = 0.0485 (0.368 sec/step)\n",
            "I0205 13:53:40.370404 140689526667136 learning.py:507] global step 5287: loss = 0.0485 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 5288: loss = 0.1049 (0.397 sec/step)\n",
            "I0205 13:53:40.769546 140689526667136 learning.py:507] global step 5288: loss = 0.1049 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 5289: loss = 0.5044 (0.384 sec/step)\n",
            "I0205 13:53:41.157603 140689526667136 learning.py:507] global step 5289: loss = 0.5044 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 5290: loss = 0.1031 (0.395 sec/step)\n",
            "I0205 13:53:41.556570 140689526667136 learning.py:507] global step 5290: loss = 0.1031 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 5291: loss = 0.1081 (0.408 sec/step)\n",
            "I0205 13:53:41.967240 140689526667136 learning.py:507] global step 5291: loss = 0.1081 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 5292: loss = 0.1005 (0.367 sec/step)\n",
            "I0205 13:53:42.336054 140689526667136 learning.py:507] global step 5292: loss = 0.1005 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 5293: loss = 0.0999 (0.413 sec/step)\n",
            "I0205 13:53:42.750825 140689526667136 learning.py:507] global step 5293: loss = 0.0999 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 5294: loss = 0.2960 (0.394 sec/step)\n",
            "I0205 13:53:43.146692 140689526667136 learning.py:507] global step 5294: loss = 0.2960 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 5295: loss = 0.2111 (0.393 sec/step)\n",
            "I0205 13:53:43.541721 140689526667136 learning.py:507] global step 5295: loss = 0.2111 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 5296: loss = 0.2015 (0.393 sec/step)\n",
            "I0205 13:53:43.936200 140689526667136 learning.py:507] global step 5296: loss = 0.2015 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 5297: loss = 0.1948 (0.379 sec/step)\n",
            "I0205 13:53:44.316874 140689526667136 learning.py:507] global step 5297: loss = 0.1948 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5298: loss = 0.0966 (0.368 sec/step)\n",
            "I0205 13:53:44.686390 140689526667136 learning.py:507] global step 5298: loss = 0.0966 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 5299: loss = 0.0680 (0.394 sec/step)\n",
            "I0205 13:53:45.082132 140689526667136 learning.py:507] global step 5299: loss = 0.0680 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 5300: loss = 1.1200 (0.377 sec/step)\n",
            "I0205 13:53:45.461048 140689526667136 learning.py:507] global step 5300: loss = 1.1200 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 5301: loss = 0.0722 (0.395 sec/step)\n",
            "I0205 13:53:45.857862 140689526667136 learning.py:507] global step 5301: loss = 0.0722 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 5302: loss = 0.0827 (0.363 sec/step)\n",
            "I0205 13:53:46.222414 140689526667136 learning.py:507] global step 5302: loss = 0.0827 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 5303: loss = 0.1273 (0.386 sec/step)\n",
            "I0205 13:53:46.609614 140689526667136 learning.py:507] global step 5303: loss = 0.1273 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 5304: loss = 0.1611 (0.375 sec/step)\n",
            "I0205 13:53:46.986113 140689526667136 learning.py:507] global step 5304: loss = 0.1611 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 5305: loss = 0.0777 (0.378 sec/step)\n",
            "I0205 13:53:47.365439 140689526667136 learning.py:507] global step 5305: loss = 0.0777 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 5306: loss = 0.3019 (0.387 sec/step)\n",
            "I0205 13:53:47.754209 140689526667136 learning.py:507] global step 5306: loss = 0.3019 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 5307: loss = 0.4563 (0.388 sec/step)\n",
            "I0205 13:53:48.143809 140689526667136 learning.py:507] global step 5307: loss = 0.4563 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 5308: loss = 0.3344 (0.379 sec/step)\n",
            "I0205 13:53:48.523988 140689526667136 learning.py:507] global step 5308: loss = 0.3344 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5309: loss = 0.1415 (0.382 sec/step)\n",
            "I0205 13:53:48.907759 140689526667136 learning.py:507] global step 5309: loss = 0.1415 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5310: loss = 0.2110 (0.393 sec/step)\n",
            "I0205 13:53:49.302811 140689526667136 learning.py:507] global step 5310: loss = 0.2110 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 5311: loss = 0.0908 (0.402 sec/step)\n",
            "I0205 13:53:49.706614 140689526667136 learning.py:507] global step 5311: loss = 0.0908 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 5312: loss = 0.0837 (0.395 sec/step)\n",
            "I0205 13:53:50.103373 140689526667136 learning.py:507] global step 5312: loss = 0.0837 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 5313: loss = 0.1643 (0.390 sec/step)\n",
            "I0205 13:53:50.494526 140689526667136 learning.py:507] global step 5313: loss = 0.1643 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5314: loss = 0.0622 (0.362 sec/step)\n",
            "I0205 13:53:50.858036 140689526667136 learning.py:507] global step 5314: loss = 0.0622 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 5315: loss = 0.0852 (0.386 sec/step)\n",
            "I0205 13:53:51.246359 140689526667136 learning.py:507] global step 5315: loss = 0.0852 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 5316: loss = 0.1716 (0.377 sec/step)\n",
            "I0205 13:53:51.624897 140689526667136 learning.py:507] global step 5316: loss = 0.1716 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 5317: loss = 0.1290 (0.393 sec/step)\n",
            "I0205 13:53:52.019094 140689526667136 learning.py:507] global step 5317: loss = 0.1290 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 5318: loss = 0.1683 (0.407 sec/step)\n",
            "I0205 13:53:52.427543 140689526667136 learning.py:507] global step 5318: loss = 0.1683 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 5319: loss = 0.0673 (0.426 sec/step)\n",
            "I0205 13:53:52.855290 140689526667136 learning.py:507] global step 5319: loss = 0.0673 (0.426 sec/step)\n",
            "INFO:tensorflow:global step 5320: loss = 0.1808 (0.411 sec/step)\n",
            "I0205 13:53:53.267698 140689526667136 learning.py:507] global step 5320: loss = 0.1808 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 5321: loss = 0.1864 (0.417 sec/step)\n",
            "I0205 13:53:53.687220 140689526667136 learning.py:507] global step 5321: loss = 0.1864 (0.417 sec/step)\n",
            "INFO:tensorflow:global step 5322: loss = 0.1658 (0.400 sec/step)\n",
            "I0205 13:53:54.089249 140689526667136 learning.py:507] global step 5322: loss = 0.1658 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 5323: loss = 0.1377 (0.365 sec/step)\n",
            "I0205 13:53:54.456233 140689526667136 learning.py:507] global step 5323: loss = 0.1377 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 5324: loss = 0.0735 (0.365 sec/step)\n",
            "I0205 13:53:54.823240 140689526667136 learning.py:507] global step 5324: loss = 0.0735 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 5325: loss = 0.0426 (0.375 sec/step)\n",
            "I0205 13:53:55.199421 140689526667136 learning.py:507] global step 5325: loss = 0.0426 (0.375 sec/step)\n",
            "2020-02-05 13:53:55.220311: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 237794304 exceeds 10% of system memory.\n",
            "2020-02-05 13:53:55.446900: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 237794304 exceeds 10% of system memory.\n",
            "INFO:tensorflow:global step 5326: loss = 0.1442 (0.604 sec/step)\n",
            "I0205 13:53:55.805321 140689526667136 learning.py:507] global step 5326: loss = 0.1442 (0.604 sec/step)\n",
            "INFO:tensorflow:global step 5327: loss = 0.0995 (0.375 sec/step)\n",
            "I0205 13:53:56.182355 140689526667136 learning.py:507] global step 5327: loss = 0.0995 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 5328: loss = 0.1014 (0.356 sec/step)\n",
            "I0205 13:53:56.540233 140689526667136 learning.py:507] global step 5328: loss = 0.1014 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 5329: loss = 0.0343 (0.372 sec/step)\n",
            "I0205 13:53:56.913593 140689526667136 learning.py:507] global step 5329: loss = 0.0343 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 5330: loss = 0.1047 (0.391 sec/step)\n",
            "I0205 13:53:57.306594 140689526667136 learning.py:507] global step 5330: loss = 0.1047 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 5331: loss = 0.0515 (0.385 sec/step)\n",
            "I0205 13:53:57.693586 140689526667136 learning.py:507] global step 5331: loss = 0.0515 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 5332: loss = 0.0450 (0.375 sec/step)\n",
            "I0205 13:53:58.070151 140689526667136 learning.py:507] global step 5332: loss = 0.0450 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 5333: loss = 0.1192 (0.381 sec/step)\n",
            "I0205 13:53:58.453226 140689526667136 learning.py:507] global step 5333: loss = 0.1192 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 5334: loss = 0.0816 (0.380 sec/step)\n",
            "I0205 13:53:58.834631 140689526667136 learning.py:507] global step 5334: loss = 0.0816 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 5335: loss = 0.0758 (0.419 sec/step)\n",
            "I0205 13:53:59.255460 140689526667136 learning.py:507] global step 5335: loss = 0.0758 (0.419 sec/step)\n",
            "INFO:tensorflow:global step 5336: loss = 0.0984 (0.378 sec/step)\n",
            "I0205 13:53:59.635513 140689526667136 learning.py:507] global step 5336: loss = 0.0984 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 5337: loss = 0.1420 (0.384 sec/step)\n",
            "I0205 13:54:00.021244 140689526667136 learning.py:507] global step 5337: loss = 0.1420 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 5338: loss = 0.0391 (0.372 sec/step)\n",
            "I0205 13:54:00.395271 140689526667136 learning.py:507] global step 5338: loss = 0.0391 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 5339: loss = 0.0378 (0.411 sec/step)\n",
            "I0205 13:54:00.808517 140689526667136 learning.py:507] global step 5339: loss = 0.0378 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 5340: loss = 0.6449 (0.413 sec/step)\n",
            "I0205 13:54:01.223514 140689526667136 learning.py:507] global step 5340: loss = 0.6449 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 5341: loss = 0.2180 (0.396 sec/step)\n",
            "I0205 13:54:01.621338 140689526667136 learning.py:507] global step 5341: loss = 0.2180 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 5342: loss = 0.0439 (0.373 sec/step)\n",
            "I0205 13:54:01.996099 140689526667136 learning.py:507] global step 5342: loss = 0.0439 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 5343: loss = 0.1488 (0.382 sec/step)\n",
            "I0205 13:54:02.379486 140689526667136 learning.py:507] global step 5343: loss = 0.1488 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5344: loss = 0.1627 (0.385 sec/step)\n",
            "I0205 13:54:02.766221 140689526667136 learning.py:507] global step 5344: loss = 0.1627 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 5345: loss = 0.1367 (0.391 sec/step)\n",
            "I0205 13:54:03.158786 140689526667136 learning.py:507] global step 5345: loss = 0.1367 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 5346: loss = 0.7910 (0.394 sec/step)\n",
            "I0205 13:54:03.554316 140689526667136 learning.py:507] global step 5346: loss = 0.7910 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 5347: loss = 0.1737 (0.378 sec/step)\n",
            "I0205 13:54:03.933897 140689526667136 learning.py:507] global step 5347: loss = 0.1737 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 5348: loss = 0.0858 (0.399 sec/step)\n",
            "I0205 13:54:04.334158 140689526667136 learning.py:507] global step 5348: loss = 0.0858 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 5349: loss = 0.1397 (0.378 sec/step)\n",
            "I0205 13:54:04.713706 140689526667136 learning.py:507] global step 5349: loss = 0.1397 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 5350: loss = 0.0779 (0.409 sec/step)\n",
            "I0205 13:54:05.124685 140689526667136 learning.py:507] global step 5350: loss = 0.0779 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 5351: loss = 0.0375 (0.404 sec/step)\n",
            "I0205 13:54:05.530280 140689526667136 learning.py:507] global step 5351: loss = 0.0375 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 5352: loss = 1.0951 (0.387 sec/step)\n",
            "I0205 13:54:05.919258 140689526667136 learning.py:507] global step 5352: loss = 1.0951 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 5353: loss = 0.1433 (0.396 sec/step)\n",
            "I0205 13:54:06.316545 140689526667136 learning.py:507] global step 5353: loss = 0.1433 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 5354: loss = 0.1496 (0.387 sec/step)\n",
            "I0205 13:54:06.704964 140689526667136 learning.py:507] global step 5354: loss = 0.1496 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 5355: loss = 0.4495 (0.371 sec/step)\n",
            "I0205 13:54:07.077903 140689526667136 learning.py:507] global step 5355: loss = 0.4495 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 5356: loss = 0.0828 (0.397 sec/step)\n",
            "I0205 13:54:07.476465 140689526667136 learning.py:507] global step 5356: loss = 0.0828 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 5357: loss = 0.3073 (0.393 sec/step)\n",
            "I0205 13:54:07.870923 140689526667136 learning.py:507] global step 5357: loss = 0.3073 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 5358: loss = 0.0283 (0.414 sec/step)\n",
            "I0205 13:54:08.287056 140689526667136 learning.py:507] global step 5358: loss = 0.0283 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 5359: loss = 0.0809 (0.402 sec/step)\n",
            "I0205 13:54:08.690328 140689526667136 learning.py:507] global step 5359: loss = 0.0809 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 5360: loss = 0.1187 (0.378 sec/step)\n",
            "I0205 13:54:09.070102 140689526667136 learning.py:507] global step 5360: loss = 0.1187 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 5361: loss = 0.0493 (0.402 sec/step)\n",
            "I0205 13:54:09.473433 140689526667136 learning.py:507] global step 5361: loss = 0.0493 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 5362: loss = 0.0945 (0.390 sec/step)\n",
            "I0205 13:54:09.864922 140689526667136 learning.py:507] global step 5362: loss = 0.0945 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5363: loss = 0.0901 (0.407 sec/step)\n",
            "I0205 13:54:10.273611 140689526667136 learning.py:507] global step 5363: loss = 0.0901 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 5364: loss = 0.1253 (0.376 sec/step)\n",
            "I0205 13:54:10.650795 140689526667136 learning.py:507] global step 5364: loss = 0.1253 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5365: loss = 0.0851 (0.395 sec/step)\n",
            "I0205 13:54:11.047158 140689526667136 learning.py:507] global step 5365: loss = 0.0851 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 5366: loss = 0.3044 (0.389 sec/step)\n",
            "I0205 13:54:11.437883 140689526667136 learning.py:507] global step 5366: loss = 0.3044 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 5367: loss = 0.1787 (0.384 sec/step)\n",
            "I0205 13:54:11.823542 140689526667136 learning.py:507] global step 5367: loss = 0.1787 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 5368: loss = 0.2618 (0.388 sec/step)\n",
            "I0205 13:54:12.212698 140689526667136 learning.py:507] global step 5368: loss = 0.2618 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 5369: loss = 0.2012 (0.386 sec/step)\n",
            "I0205 13:54:12.599688 140689526667136 learning.py:507] global step 5369: loss = 0.2012 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 5370: loss = 0.6850 (0.397 sec/step)\n",
            "I0205 13:54:12.998291 140689526667136 learning.py:507] global step 5370: loss = 0.6850 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 5371: loss = 0.0943 (0.365 sec/step)\n",
            "I0205 13:54:13.364789 140689526667136 learning.py:507] global step 5371: loss = 0.0943 (0.365 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path ../training/model.ckpt\n",
            "I0205 13:54:13.745192 140686000895744 supervisor.py:1117] Saving checkpoint to path ../training/model.ckpt\n",
            "INFO:tensorflow:global step 5372: loss = 0.3680 (0.403 sec/step)\n",
            "I0205 13:54:15.296591 140689526667136 learning.py:507] global step 5372: loss = 0.3680 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 5373: loss = 0.0233 (1.539 sec/step)\n",
            "I0205 13:54:17.774241 140689526667136 learning.py:507] global step 5373: loss = 0.0233 (1.539 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 5373.\n",
            "I0205 13:54:17.775056 140686026073856 supervisor.py:1050] Recording summary at step 5373.\n",
            "INFO:tensorflow:global step 5374: loss = 0.1471 (0.491 sec/step)\n",
            "I0205 13:54:18.274042 140689526667136 learning.py:507] global step 5374: loss = 0.1471 (0.491 sec/step)\n",
            "INFO:tensorflow:global step 5375: loss = 0.0213 (0.359 sec/step)\n",
            "I0205 13:54:18.635009 140689526667136 learning.py:507] global step 5375: loss = 0.0213 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 5376: loss = 0.1490 (0.397 sec/step)\n",
            "I0205 13:54:19.033639 140689526667136 learning.py:507] global step 5376: loss = 0.1490 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 5377: loss = 0.1610 (0.384 sec/step)\n",
            "I0205 13:54:19.419279 140689526667136 learning.py:507] global step 5377: loss = 0.1610 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 5378: loss = 0.4239 (0.389 sec/step)\n",
            "I0205 13:54:19.810049 140689526667136 learning.py:507] global step 5378: loss = 0.4239 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 5379: loss = 0.2817 (0.394 sec/step)\n",
            "I0205 13:54:20.206226 140689526667136 learning.py:507] global step 5379: loss = 0.2817 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 5380: loss = 0.2019 (0.390 sec/step)\n",
            "I0205 13:54:20.597777 140689526667136 learning.py:507] global step 5380: loss = 0.2019 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5381: loss = 0.5888 (0.363 sec/step)\n",
            "I0205 13:54:20.962322 140689526667136 learning.py:507] global step 5381: loss = 0.5888 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 5382: loss = 0.0367 (0.410 sec/step)\n",
            "I0205 13:54:21.374185 140689526667136 learning.py:507] global step 5382: loss = 0.0367 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 5383: loss = 0.1630 (0.397 sec/step)\n",
            "I0205 13:54:21.772877 140689526667136 learning.py:507] global step 5383: loss = 0.1630 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 5384: loss = 0.0572 (0.375 sec/step)\n",
            "I0205 13:54:22.149247 140689526667136 learning.py:507] global step 5384: loss = 0.0572 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 5385: loss = 0.6567 (0.399 sec/step)\n",
            "I0205 13:54:22.550147 140689526667136 learning.py:507] global step 5385: loss = 0.6567 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 5386: loss = 0.2852 (0.374 sec/step)\n",
            "I0205 13:54:22.926208 140689526667136 learning.py:507] global step 5386: loss = 0.2852 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 5387: loss = 0.1643 (0.370 sec/step)\n",
            "I0205 13:54:23.297674 140689526667136 learning.py:507] global step 5387: loss = 0.1643 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 5388: loss = 0.3476 (0.399 sec/step)\n",
            "I0205 13:54:23.698962 140689526667136 learning.py:507] global step 5388: loss = 0.3476 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 5389: loss = 0.1087 (0.364 sec/step)\n",
            "I0205 13:54:24.063837 140689526667136 learning.py:507] global step 5389: loss = 0.1087 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 5390: loss = 0.2332 (0.390 sec/step)\n",
            "I0205 13:54:24.455474 140689526667136 learning.py:507] global step 5390: loss = 0.2332 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5391: loss = 0.1139 (0.382 sec/step)\n",
            "I0205 13:54:24.838989 140689526667136 learning.py:507] global step 5391: loss = 0.1139 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5392: loss = 0.1743 (0.394 sec/step)\n",
            "I0205 13:54:25.235260 140689526667136 learning.py:507] global step 5392: loss = 0.1743 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 5393: loss = 0.1583 (0.396 sec/step)\n",
            "I0205 13:54:25.632551 140689526667136 learning.py:507] global step 5393: loss = 0.1583 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 5394: loss = 0.2151 (0.365 sec/step)\n",
            "I0205 13:54:25.999110 140689526667136 learning.py:507] global step 5394: loss = 0.2151 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 5395: loss = 0.0342 (0.375 sec/step)\n",
            "I0205 13:54:26.375443 140689526667136 learning.py:507] global step 5395: loss = 0.0342 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 5396: loss = 0.4800 (0.389 sec/step)\n",
            "I0205 13:54:26.765794 140689526667136 learning.py:507] global step 5396: loss = 0.4800 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 5397: loss = 0.1832 (0.376 sec/step)\n",
            "I0205 13:54:27.143012 140689526667136 learning.py:507] global step 5397: loss = 0.1832 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5398: loss = 0.0596 (0.385 sec/step)\n",
            "I0205 13:54:27.529859 140689526667136 learning.py:507] global step 5398: loss = 0.0596 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 5399: loss = 0.0904 (0.396 sec/step)\n",
            "I0205 13:54:27.927651 140689526667136 learning.py:507] global step 5399: loss = 0.0904 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 5400: loss = 0.7355 (0.393 sec/step)\n",
            "I0205 13:54:28.322335 140689526667136 learning.py:507] global step 5400: loss = 0.7355 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 5401: loss = 0.1407 (0.377 sec/step)\n",
            "I0205 13:54:28.700301 140689526667136 learning.py:507] global step 5401: loss = 0.1407 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 5402: loss = 0.0677 (0.372 sec/step)\n",
            "I0205 13:54:29.074427 140689526667136 learning.py:507] global step 5402: loss = 0.0677 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 5403: loss = 0.3557 (0.417 sec/step)\n",
            "I0205 13:54:29.493094 140689526667136 learning.py:507] global step 5403: loss = 0.3557 (0.417 sec/step)\n",
            "INFO:tensorflow:global step 5404: loss = 0.1357 (0.450 sec/step)\n",
            "I0205 13:54:29.944780 140689526667136 learning.py:507] global step 5404: loss = 0.1357 (0.450 sec/step)\n",
            "INFO:tensorflow:global step 5405: loss = 0.0200 (0.398 sec/step)\n",
            "I0205 13:54:30.344148 140689526667136 learning.py:507] global step 5405: loss = 0.0200 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 5406: loss = 0.1499 (0.393 sec/step)\n",
            "I0205 13:54:30.738276 140689526667136 learning.py:507] global step 5406: loss = 0.1499 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 5407: loss = 0.1199 (0.420 sec/step)\n",
            "I0205 13:54:31.159895 140689526667136 learning.py:507] global step 5407: loss = 0.1199 (0.420 sec/step)\n",
            "INFO:tensorflow:global step 5408: loss = 0.0824 (0.368 sec/step)\n",
            "I0205 13:54:31.530458 140689526667136 learning.py:507] global step 5408: loss = 0.0824 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 5409: loss = 0.0449 (0.361 sec/step)\n",
            "I0205 13:54:31.893527 140689526667136 learning.py:507] global step 5409: loss = 0.0449 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 5410: loss = 0.1460 (0.393 sec/step)\n",
            "I0205 13:54:32.288564 140689526667136 learning.py:507] global step 5410: loss = 0.1460 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 5411: loss = 0.0692 (0.408 sec/step)\n",
            "I0205 13:54:32.698025 140689526667136 learning.py:507] global step 5411: loss = 0.0692 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 5412: loss = 0.2544 (0.406 sec/step)\n",
            "I0205 13:54:33.106048 140689526667136 learning.py:507] global step 5412: loss = 0.2544 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 5413: loss = 0.0439 (0.377 sec/step)\n",
            "I0205 13:54:33.484858 140689526667136 learning.py:507] global step 5413: loss = 0.0439 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 5414: loss = 0.0348 (0.395 sec/step)\n",
            "I0205 13:54:33.881317 140689526667136 learning.py:507] global step 5414: loss = 0.0348 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 5415: loss = 0.0512 (0.368 sec/step)\n",
            "I0205 13:54:34.250191 140689526667136 learning.py:507] global step 5415: loss = 0.0512 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 5416: loss = 0.1388 (0.342 sec/step)\n",
            "I0205 13:54:34.594227 140689526667136 learning.py:507] global step 5416: loss = 0.1388 (0.342 sec/step)\n",
            "INFO:tensorflow:global step 5417: loss = 0.0835 (0.389 sec/step)\n",
            "I0205 13:54:34.984485 140689526667136 learning.py:507] global step 5417: loss = 0.0835 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 5418: loss = 0.1006 (0.384 sec/step)\n",
            "I0205 13:54:35.369664 140689526667136 learning.py:507] global step 5418: loss = 0.1006 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 5419: loss = 0.0392 (0.395 sec/step)\n",
            "I0205 13:54:35.766557 140689526667136 learning.py:507] global step 5419: loss = 0.0392 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 5420: loss = 0.1396 (0.380 sec/step)\n",
            "I0205 13:54:36.148819 140689526667136 learning.py:507] global step 5420: loss = 0.1396 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 5421: loss = 0.4279 (0.381 sec/step)\n",
            "I0205 13:54:36.531876 140689526667136 learning.py:507] global step 5421: loss = 0.4279 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 5422: loss = 0.1337 (0.358 sec/step)\n",
            "I0205 13:54:36.891927 140689526667136 learning.py:507] global step 5422: loss = 0.1337 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 5423: loss = 0.1916 (0.373 sec/step)\n",
            "I0205 13:54:37.266277 140689526667136 learning.py:507] global step 5423: loss = 0.1916 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 5424: loss = 0.0437 (0.379 sec/step)\n",
            "I0205 13:54:37.646841 140689526667136 learning.py:507] global step 5424: loss = 0.0437 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5425: loss = 0.2959 (0.378 sec/step)\n",
            "I0205 13:54:38.026702 140689526667136 learning.py:507] global step 5425: loss = 0.2959 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 5426: loss = 0.0844 (0.390 sec/step)\n",
            "I0205 13:54:38.418051 140689526667136 learning.py:507] global step 5426: loss = 0.0844 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5427: loss = 0.0472 (0.373 sec/step)\n",
            "I0205 13:54:38.792299 140689526667136 learning.py:507] global step 5427: loss = 0.0472 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 5428: loss = 0.2845 (0.386 sec/step)\n",
            "I0205 13:54:39.181950 140689526667136 learning.py:507] global step 5428: loss = 0.2845 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 5429: loss = 0.1845 (0.396 sec/step)\n",
            "I0205 13:54:39.581639 140689526667136 learning.py:507] global step 5429: loss = 0.1845 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 5430: loss = 0.2840 (0.372 sec/step)\n",
            "I0205 13:54:39.955810 140689526667136 learning.py:507] global step 5430: loss = 0.2840 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 5431: loss = 0.2896 (0.379 sec/step)\n",
            "I0205 13:54:40.336199 140689526667136 learning.py:507] global step 5431: loss = 0.2896 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5432: loss = 0.1080 (0.372 sec/step)\n",
            "I0205 13:54:40.709199 140689526667136 learning.py:507] global step 5432: loss = 0.1080 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 5433: loss = 0.2835 (0.394 sec/step)\n",
            "I0205 13:54:41.104468 140689526667136 learning.py:507] global step 5433: loss = 0.2835 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 5434: loss = 0.0730 (0.379 sec/step)\n",
            "I0205 13:54:41.484833 140689526667136 learning.py:507] global step 5434: loss = 0.0730 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5435: loss = 0.3003 (0.411 sec/step)\n",
            "I0205 13:54:41.898065 140689526667136 learning.py:507] global step 5435: loss = 0.3003 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 5436: loss = 0.1458 (0.355 sec/step)\n",
            "I0205 13:54:42.254620 140689526667136 learning.py:507] global step 5436: loss = 0.1458 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 5437: loss = 0.2518 (0.381 sec/step)\n",
            "I0205 13:54:42.636999 140689526667136 learning.py:507] global step 5437: loss = 0.2518 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 5438: loss = 0.1795 (0.383 sec/step)\n",
            "I0205 13:54:43.021951 140689526667136 learning.py:507] global step 5438: loss = 0.1795 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 5439: loss = 0.1853 (0.372 sec/step)\n",
            "I0205 13:54:43.395686 140689526667136 learning.py:507] global step 5439: loss = 0.1853 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 5440: loss = 0.1236 (0.370 sec/step)\n",
            "I0205 13:54:43.767551 140689526667136 learning.py:507] global step 5440: loss = 0.1236 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 5441: loss = 0.2010 (0.384 sec/step)\n",
            "I0205 13:54:44.153511 140689526667136 learning.py:507] global step 5441: loss = 0.2010 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 5442: loss = 0.6459 (0.367 sec/step)\n",
            "I0205 13:54:44.521634 140689526667136 learning.py:507] global step 5442: loss = 0.6459 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 5443: loss = 0.2390 (0.384 sec/step)\n",
            "I0205 13:54:44.907700 140689526667136 learning.py:507] global step 5443: loss = 0.2390 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 5444: loss = 0.0341 (0.412 sec/step)\n",
            "I0205 13:54:45.321387 140689526667136 learning.py:507] global step 5444: loss = 0.0341 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 5445: loss = 0.3566 (0.406 sec/step)\n",
            "I0205 13:54:45.729306 140689526667136 learning.py:507] global step 5445: loss = 0.3566 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 5446: loss = 0.2396 (0.387 sec/step)\n",
            "I0205 13:54:46.117702 140689526667136 learning.py:507] global step 5446: loss = 0.2396 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 5447: loss = 0.0237 (0.375 sec/step)\n",
            "I0205 13:54:46.494385 140689526667136 learning.py:507] global step 5447: loss = 0.0237 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 5448: loss = 0.0824 (0.385 sec/step)\n",
            "I0205 13:54:46.881237 140689526667136 learning.py:507] global step 5448: loss = 0.0824 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 5449: loss = 0.2655 (0.386 sec/step)\n",
            "I0205 13:54:47.268843 140689526667136 learning.py:507] global step 5449: loss = 0.2655 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 5450: loss = 0.0639 (0.398 sec/step)\n",
            "I0205 13:54:47.668959 140689526667136 learning.py:507] global step 5450: loss = 0.0639 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 5451: loss = 0.4157 (0.384 sec/step)\n",
            "I0205 13:54:48.054284 140689526667136 learning.py:507] global step 5451: loss = 0.4157 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 5452: loss = 0.0363 (0.386 sec/step)\n",
            "I0205 13:54:48.442196 140689526667136 learning.py:507] global step 5452: loss = 0.0363 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 5453: loss = 0.1497 (0.382 sec/step)\n",
            "I0205 13:54:48.825506 140689526667136 learning.py:507] global step 5453: loss = 0.1497 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5454: loss = 0.2003 (0.392 sec/step)\n",
            "I0205 13:54:49.218960 140689526667136 learning.py:507] global step 5454: loss = 0.2003 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 5455: loss = 0.1683 (0.400 sec/step)\n",
            "I0205 13:54:49.620512 140689526667136 learning.py:507] global step 5455: loss = 0.1683 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 5456: loss = 0.0504 (0.382 sec/step)\n",
            "I0205 13:54:50.004342 140689526667136 learning.py:507] global step 5456: loss = 0.0504 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5457: loss = 0.1467 (0.384 sec/step)\n",
            "I0205 13:54:50.389700 140689526667136 learning.py:507] global step 5457: loss = 0.1467 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 5458: loss = 0.0379 (0.379 sec/step)\n",
            "I0205 13:54:50.770236 140689526667136 learning.py:507] global step 5458: loss = 0.0379 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5459: loss = 0.0912 (0.393 sec/step)\n",
            "I0205 13:54:51.165239 140689526667136 learning.py:507] global step 5459: loss = 0.0912 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 5460: loss = 0.2185 (0.387 sec/step)\n",
            "I0205 13:54:51.553570 140689526667136 learning.py:507] global step 5460: loss = 0.2185 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 5461: loss = 0.0463 (0.372 sec/step)\n",
            "I0205 13:54:51.927593 140689526667136 learning.py:507] global step 5461: loss = 0.0463 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 5462: loss = 0.1213 (0.396 sec/step)\n",
            "I0205 13:54:52.324877 140689526667136 learning.py:507] global step 5462: loss = 0.1213 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 5463: loss = 0.1029 (0.410 sec/step)\n",
            "I0205 13:54:52.737002 140689526667136 learning.py:507] global step 5463: loss = 0.1029 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 5464: loss = 0.0567 (0.412 sec/step)\n",
            "I0205 13:54:53.151121 140689526667136 learning.py:507] global step 5464: loss = 0.0567 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 5465: loss = 0.1328 (0.375 sec/step)\n",
            "I0205 13:54:53.529063 140689526667136 learning.py:507] global step 5465: loss = 0.1328 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 5466: loss = 0.1072 (0.372 sec/step)\n",
            "I0205 13:54:53.902800 140689526667136 learning.py:507] global step 5466: loss = 0.1072 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 5467: loss = 0.0754 (0.372 sec/step)\n",
            "I0205 13:54:54.276527 140689526667136 learning.py:507] global step 5467: loss = 0.0754 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 5468: loss = 0.4896 (0.375 sec/step)\n",
            "I0205 13:54:54.652712 140689526667136 learning.py:507] global step 5468: loss = 0.4896 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 5469: loss = 0.0387 (0.353 sec/step)\n",
            "I0205 13:54:55.007477 140689526667136 learning.py:507] global step 5469: loss = 0.0387 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 5470: loss = 0.5053 (0.370 sec/step)\n",
            "I0205 13:54:55.379070 140689526667136 learning.py:507] global step 5470: loss = 0.5053 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 5471: loss = 0.7785 (0.365 sec/step)\n",
            "I0205 13:54:55.745434 140689526667136 learning.py:507] global step 5471: loss = 0.7785 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 5472: loss = 0.0519 (0.389 sec/step)\n",
            "I0205 13:54:56.136082 140689526667136 learning.py:507] global step 5472: loss = 0.0519 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 5473: loss = 0.2166 (0.391 sec/step)\n",
            "I0205 13:54:56.528649 140689526667136 learning.py:507] global step 5473: loss = 0.2166 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 5474: loss = 0.1651 (0.390 sec/step)\n",
            "I0205 13:54:56.920388 140689526667136 learning.py:507] global step 5474: loss = 0.1651 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5475: loss = 0.1591 (0.374 sec/step)\n",
            "I0205 13:54:57.296463 140689526667136 learning.py:507] global step 5475: loss = 0.1591 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 5476: loss = 0.0462 (0.381 sec/step)\n",
            "I0205 13:54:57.679051 140689526667136 learning.py:507] global step 5476: loss = 0.0462 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 5477: loss = 0.1434 (0.368 sec/step)\n",
            "I0205 13:54:58.048502 140689526667136 learning.py:507] global step 5477: loss = 0.1434 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 5478: loss = 0.0927 (0.385 sec/step)\n",
            "I0205 13:54:58.436480 140689526667136 learning.py:507] global step 5478: loss = 0.0927 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 5479: loss = 0.2201 (0.383 sec/step)\n",
            "I0205 13:54:58.821412 140689526667136 learning.py:507] global step 5479: loss = 0.2201 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 5480: loss = 0.1568 (0.385 sec/step)\n",
            "I0205 13:54:59.207820 140689526667136 learning.py:507] global step 5480: loss = 0.1568 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 5481: loss = 0.0897 (0.390 sec/step)\n",
            "I0205 13:54:59.599374 140689526667136 learning.py:507] global step 5481: loss = 0.0897 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5482: loss = 0.0829 (0.377 sec/step)\n",
            "I0205 13:54:59.977786 140689526667136 learning.py:507] global step 5482: loss = 0.0829 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 5483: loss = 0.1052 (0.398 sec/step)\n",
            "I0205 13:55:00.377148 140689526667136 learning.py:507] global step 5483: loss = 0.1052 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 5484: loss = 0.1334 (0.399 sec/step)\n",
            "I0205 13:55:00.778069 140689526667136 learning.py:507] global step 5484: loss = 0.1334 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 5485: loss = 0.0431 (0.388 sec/step)\n",
            "I0205 13:55:01.167926 140689526667136 learning.py:507] global step 5485: loss = 0.0431 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 5486: loss = 0.3937 (0.393 sec/step)\n",
            "I0205 13:55:01.562364 140689526667136 learning.py:507] global step 5486: loss = 0.3937 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 5487: loss = 0.1231 (0.375 sec/step)\n",
            "I0205 13:55:01.938384 140689526667136 learning.py:507] global step 5487: loss = 0.1231 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 5488: loss = 0.1015 (0.376 sec/step)\n",
            "I0205 13:55:02.315515 140689526667136 learning.py:507] global step 5488: loss = 0.1015 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5489: loss = 0.1833 (0.444 sec/step)\n",
            "I0205 13:55:02.761301 140689526667136 learning.py:507] global step 5489: loss = 0.1833 (0.444 sec/step)\n",
            "INFO:tensorflow:global step 5490: loss = 0.2795 (0.394 sec/step)\n",
            "I0205 13:55:03.156792 140689526667136 learning.py:507] global step 5490: loss = 0.2795 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 5491: loss = 0.0335 (0.419 sec/step)\n",
            "I0205 13:55:03.577064 140689526667136 learning.py:507] global step 5491: loss = 0.0335 (0.419 sec/step)\n",
            "INFO:tensorflow:global step 5492: loss = 0.0667 (0.366 sec/step)\n",
            "I0205 13:55:03.944318 140689526667136 learning.py:507] global step 5492: loss = 0.0667 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 5493: loss = 0.3063 (0.370 sec/step)\n",
            "I0205 13:55:04.315910 140689526667136 learning.py:507] global step 5493: loss = 0.3063 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 5494: loss = 0.9824 (0.395 sec/step)\n",
            "I0205 13:55:04.712595 140689526667136 learning.py:507] global step 5494: loss = 0.9824 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 5495: loss = 0.3465 (0.373 sec/step)\n",
            "I0205 13:55:05.087077 140689526667136 learning.py:507] global step 5495: loss = 0.3465 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 5496: loss = 0.1021 (0.376 sec/step)\n",
            "I0205 13:55:05.465044 140689526667136 learning.py:507] global step 5496: loss = 0.1021 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5497: loss = 0.1604 (0.394 sec/step)\n",
            "I0205 13:55:05.860325 140689526667136 learning.py:507] global step 5497: loss = 0.1604 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 5498: loss = 0.0296 (0.384 sec/step)\n",
            "I0205 13:55:06.245560 140689526667136 learning.py:507] global step 5498: loss = 0.0296 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 5499: loss = 0.0723 (0.389 sec/step)\n",
            "I0205 13:55:06.635811 140689526667136 learning.py:507] global step 5499: loss = 0.0723 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 5500: loss = 0.6221 (0.370 sec/step)\n",
            "I0205 13:55:07.007919 140689526667136 learning.py:507] global step 5500: loss = 0.6221 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 5501: loss = 0.1482 (0.371 sec/step)\n",
            "I0205 13:55:07.382014 140689526667136 learning.py:507] global step 5501: loss = 0.1482 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 5502: loss = 0.1517 (0.375 sec/step)\n",
            "I0205 13:55:07.759014 140689526667136 learning.py:507] global step 5502: loss = 0.1517 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 5503: loss = 0.5237 (0.385 sec/step)\n",
            "I0205 13:55:08.145623 140689526667136 learning.py:507] global step 5503: loss = 0.5237 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 5504: loss = 0.0895 (0.406 sec/step)\n",
            "I0205 13:55:08.553637 140689526667136 learning.py:507] global step 5504: loss = 0.0895 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 5505: loss = 0.1682 (0.390 sec/step)\n",
            "I0205 13:55:08.945524 140689526667136 learning.py:507] global step 5505: loss = 0.1682 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5506: loss = 0.0429 (0.379 sec/step)\n",
            "I0205 13:55:09.327881 140689526667136 learning.py:507] global step 5506: loss = 0.0429 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5507: loss = 0.0442 (0.357 sec/step)\n",
            "I0205 13:55:09.686525 140689526667136 learning.py:507] global step 5507: loss = 0.0442 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 5508: loss = 0.0412 (0.379 sec/step)\n",
            "I0205 13:55:10.067179 140689526667136 learning.py:507] global step 5508: loss = 0.0412 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5509: loss = 0.1498 (0.360 sec/step)\n",
            "I0205 13:55:10.429114 140689526667136 learning.py:507] global step 5509: loss = 0.1498 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 5510: loss = 0.0282 (0.407 sec/step)\n",
            "I0205 13:55:10.837396 140689526667136 learning.py:507] global step 5510: loss = 0.0282 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 5511: loss = 0.2130 (0.382 sec/step)\n",
            "I0205 13:55:11.221384 140689526667136 learning.py:507] global step 5511: loss = 0.2130 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5512: loss = 0.0430 (0.371 sec/step)\n",
            "I0205 13:55:11.594687 140689526667136 learning.py:507] global step 5512: loss = 0.0430 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 5513: loss = 0.1773 (0.380 sec/step)\n",
            "I0205 13:55:11.976258 140689526667136 learning.py:507] global step 5513: loss = 0.1773 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 5514: loss = 0.2683 (0.394 sec/step)\n",
            "I0205 13:55:12.371682 140689526667136 learning.py:507] global step 5514: loss = 0.2683 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 5515: loss = 0.4105 (0.389 sec/step)\n",
            "I0205 13:55:12.762536 140689526667136 learning.py:507] global step 5515: loss = 0.4105 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 5516: loss = 0.5156 (0.398 sec/step)\n",
            "I0205 13:55:13.161977 140689526667136 learning.py:507] global step 5516: loss = 0.5156 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 5517: loss = 0.1504 (0.392 sec/step)\n",
            "I0205 13:55:13.555280 140689526667136 learning.py:507] global step 5517: loss = 0.1504 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 5518: loss = 0.2874 (0.390 sec/step)\n",
            "I0205 13:55:13.947202 140689526667136 learning.py:507] global step 5518: loss = 0.2874 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5519: loss = 0.1885 (0.386 sec/step)\n",
            "I0205 13:55:14.335095 140689526667136 learning.py:507] global step 5519: loss = 0.1885 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 5520: loss = 0.1979 (0.376 sec/step)\n",
            "I0205 13:55:14.713024 140689526667136 learning.py:507] global step 5520: loss = 0.1979 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5521: loss = 0.0921 (0.363 sec/step)\n",
            "I0205 13:55:15.082302 140689526667136 learning.py:507] global step 5521: loss = 0.0921 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 5522: loss = 0.0551 (0.392 sec/step)\n",
            "I0205 13:55:15.476059 140689526667136 learning.py:507] global step 5522: loss = 0.0551 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 5523: loss = 0.2322 (0.398 sec/step)\n",
            "I0205 13:55:15.876001 140689526667136 learning.py:507] global step 5523: loss = 0.2322 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 5524: loss = 0.0662 (0.382 sec/step)\n",
            "I0205 13:55:16.259690 140689526667136 learning.py:507] global step 5524: loss = 0.0662 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5525: loss = 0.0824 (0.371 sec/step)\n",
            "I0205 13:55:16.632679 140689526667136 learning.py:507] global step 5525: loss = 0.0824 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 5526: loss = 0.0634 (0.390 sec/step)\n",
            "I0205 13:55:17.024227 140689526667136 learning.py:507] global step 5526: loss = 0.0634 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5527: loss = 0.1409 (0.383 sec/step)\n",
            "I0205 13:55:17.409185 140689526667136 learning.py:507] global step 5527: loss = 0.1409 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 5528: loss = 0.2893 (0.384 sec/step)\n",
            "I0205 13:55:17.796240 140689526667136 learning.py:507] global step 5528: loss = 0.2893 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 5529: loss = 0.3880 (0.378 sec/step)\n",
            "I0205 13:55:18.177334 140689526667136 learning.py:507] global step 5529: loss = 0.3880 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 5530: loss = 0.1323 (0.371 sec/step)\n",
            "I0205 13:55:18.550240 140689526667136 learning.py:507] global step 5530: loss = 0.1323 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 5531: loss = 0.1516 (0.427 sec/step)\n",
            "I0205 13:55:18.981370 140689526667136 learning.py:507] global step 5531: loss = 0.1516 (0.427 sec/step)\n",
            "INFO:tensorflow:global step 5532: loss = 0.1428 (0.373 sec/step)\n",
            "I0205 13:55:19.356570 140689526667136 learning.py:507] global step 5532: loss = 0.1428 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 5533: loss = 0.1649 (0.360 sec/step)\n",
            "I0205 13:55:19.717824 140689526667136 learning.py:507] global step 5533: loss = 0.1649 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 5534: loss = 0.1282 (0.359 sec/step)\n",
            "I0205 13:55:20.079200 140689526667136 learning.py:507] global step 5534: loss = 0.1282 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 5535: loss = 0.2273 (0.394 sec/step)\n",
            "I0205 13:55:20.474714 140689526667136 learning.py:507] global step 5535: loss = 0.2273 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 5536: loss = 0.1637 (0.363 sec/step)\n",
            "I0205 13:55:20.839652 140689526667136 learning.py:507] global step 5536: loss = 0.1637 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 5537: loss = 0.0827 (0.387 sec/step)\n",
            "I0205 13:55:21.228387 140689526667136 learning.py:507] global step 5537: loss = 0.0827 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 5538: loss = 0.0499 (0.401 sec/step)\n",
            "I0205 13:55:21.630707 140689526667136 learning.py:507] global step 5538: loss = 0.0499 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 5539: loss = 1.0259 (0.385 sec/step)\n",
            "I0205 13:55:22.018151 140689526667136 learning.py:507] global step 5539: loss = 1.0259 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 5540: loss = 0.0802 (0.375 sec/step)\n",
            "I0205 13:55:22.394671 140689526667136 learning.py:507] global step 5540: loss = 0.0802 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 5541: loss = 0.0173 (0.401 sec/step)\n",
            "I0205 13:55:22.797238 140689526667136 learning.py:507] global step 5541: loss = 0.0173 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 5542: loss = 0.1394 (0.387 sec/step)\n",
            "I0205 13:55:23.185586 140689526667136 learning.py:507] global step 5542: loss = 0.1394 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 5543: loss = 0.1410 (0.377 sec/step)\n",
            "I0205 13:55:23.564413 140689526667136 learning.py:507] global step 5543: loss = 0.1410 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 5544: loss = 0.2514 (0.393 sec/step)\n",
            "I0205 13:55:23.960339 140689526667136 learning.py:507] global step 5544: loss = 0.2514 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 5545: loss = 0.1477 (0.379 sec/step)\n",
            "I0205 13:55:24.341655 140689526667136 learning.py:507] global step 5545: loss = 0.1477 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5546: loss = 0.1283 (0.393 sec/step)\n",
            "I0205 13:55:24.736306 140689526667136 learning.py:507] global step 5546: loss = 0.1283 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 5547: loss = 0.1996 (0.377 sec/step)\n",
            "I0205 13:55:25.115324 140689526667136 learning.py:507] global step 5547: loss = 0.1996 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 5548: loss = 0.0838 (0.339 sec/step)\n",
            "I0205 13:55:25.456099 140689526667136 learning.py:507] global step 5548: loss = 0.0838 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 5549: loss = 0.0790 (0.393 sec/step)\n",
            "I0205 13:55:25.850350 140689526667136 learning.py:507] global step 5549: loss = 0.0790 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 5550: loss = 0.0759 (0.391 sec/step)\n",
            "I0205 13:55:26.242267 140689526667136 learning.py:507] global step 5550: loss = 0.0759 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 5551: loss = 0.0694 (0.369 sec/step)\n",
            "I0205 13:55:26.612705 140689526667136 learning.py:507] global step 5551: loss = 0.0694 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 5552: loss = 0.1299 (0.386 sec/step)\n",
            "I0205 13:55:27.000318 140689526667136 learning.py:507] global step 5552: loss = 0.1299 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 5553: loss = 0.0974 (0.363 sec/step)\n",
            "I0205 13:55:27.364783 140689526667136 learning.py:507] global step 5553: loss = 0.0974 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 5554: loss = 0.1628 (0.376 sec/step)\n",
            "I0205 13:55:27.742625 140689526667136 learning.py:507] global step 5554: loss = 0.1628 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5555: loss = 0.0667 (0.361 sec/step)\n",
            "I0205 13:55:28.104840 140689526667136 learning.py:507] global step 5555: loss = 0.0667 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 5556: loss = 0.1476 (0.366 sec/step)\n",
            "I0205 13:55:28.472598 140689526667136 learning.py:507] global step 5556: loss = 0.1476 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 5557: loss = 0.1577 (0.376 sec/step)\n",
            "I0205 13:55:28.850577 140689526667136 learning.py:507] global step 5557: loss = 0.1577 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5558: loss = 0.2137 (0.422 sec/step)\n",
            "I0205 13:55:29.274020 140689526667136 learning.py:507] global step 5558: loss = 0.2137 (0.422 sec/step)\n",
            "INFO:tensorflow:global step 5559: loss = 0.3090 (0.429 sec/step)\n",
            "I0205 13:55:29.705121 140689526667136 learning.py:507] global step 5559: loss = 0.3090 (0.429 sec/step)\n",
            "INFO:tensorflow:global step 5560: loss = 0.3686 (0.415 sec/step)\n",
            "I0205 13:55:30.122820 140689526667136 learning.py:507] global step 5560: loss = 0.3686 (0.415 sec/step)\n",
            "INFO:tensorflow:global step 5561: loss = 0.2208 (0.362 sec/step)\n",
            "I0205 13:55:30.486852 140689526667136 learning.py:507] global step 5561: loss = 0.2208 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 5562: loss = 0.2740 (0.345 sec/step)\n",
            "I0205 13:55:30.833428 140689526667136 learning.py:507] global step 5562: loss = 0.2740 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 5563: loss = 0.0957 (0.393 sec/step)\n",
            "I0205 13:55:31.228375 140689526667136 learning.py:507] global step 5563: loss = 0.0957 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 5564: loss = 0.4890 (0.392 sec/step)\n",
            "I0205 13:55:31.621624 140689526667136 learning.py:507] global step 5564: loss = 0.4890 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 5565: loss = 0.1099 (0.391 sec/step)\n",
            "I0205 13:55:32.013990 140689526667136 learning.py:507] global step 5565: loss = 0.1099 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 5566: loss = 0.3490 (0.387 sec/step)\n",
            "I0205 13:55:32.402583 140689526667136 learning.py:507] global step 5566: loss = 0.3490 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 5567: loss = 0.0694 (0.377 sec/step)\n",
            "I0205 13:55:32.781591 140689526667136 learning.py:507] global step 5567: loss = 0.0694 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 5568: loss = 0.6700 (0.398 sec/step)\n",
            "I0205 13:55:33.181498 140689526667136 learning.py:507] global step 5568: loss = 0.6700 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 5569: loss = 0.2531 (0.376 sec/step)\n",
            "I0205 13:55:33.564675 140689526667136 learning.py:507] global step 5569: loss = 0.2531 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5570: loss = 0.1194 (0.407 sec/step)\n",
            "I0205 13:55:33.973529 140689526667136 learning.py:507] global step 5570: loss = 0.1194 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 5571: loss = 0.1267 (0.392 sec/step)\n",
            "I0205 13:55:34.367924 140689526667136 learning.py:507] global step 5571: loss = 0.1267 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 5572: loss = 0.2015 (0.371 sec/step)\n",
            "I0205 13:55:34.740858 140689526667136 learning.py:507] global step 5572: loss = 0.2015 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 5573: loss = 0.2253 (0.377 sec/step)\n",
            "I0205 13:55:35.120082 140689526667136 learning.py:507] global step 5573: loss = 0.2253 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 5574: loss = 0.0190 (0.385 sec/step)\n",
            "I0205 13:55:35.507255 140689526667136 learning.py:507] global step 5574: loss = 0.0190 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 5575: loss = 0.2402 (0.361 sec/step)\n",
            "I0205 13:55:35.869538 140689526667136 learning.py:507] global step 5575: loss = 0.2402 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 5576: loss = 0.1046 (0.402 sec/step)\n",
            "I0205 13:55:36.274534 140689526667136 learning.py:507] global step 5576: loss = 0.1046 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 5577: loss = 0.1014 (0.400 sec/step)\n",
            "I0205 13:55:36.676859 140689526667136 learning.py:507] global step 5577: loss = 0.1014 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 5578: loss = 0.1564 (0.406 sec/step)\n",
            "I0205 13:55:37.084201 140689526667136 learning.py:507] global step 5578: loss = 0.1564 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 5579: loss = 0.0813 (0.359 sec/step)\n",
            "I0205 13:55:37.444569 140689526667136 learning.py:507] global step 5579: loss = 0.0813 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 5580: loss = 0.1430 (0.380 sec/step)\n",
            "I0205 13:55:37.826383 140689526667136 learning.py:507] global step 5580: loss = 0.1430 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 5581: loss = 0.6082 (0.391 sec/step)\n",
            "I0205 13:55:38.219396 140689526667136 learning.py:507] global step 5581: loss = 0.6082 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 5582: loss = 0.2074 (0.394 sec/step)\n",
            "I0205 13:55:38.615144 140689526667136 learning.py:507] global step 5582: loss = 0.2074 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 5583: loss = 0.0886 (0.377 sec/step)\n",
            "I0205 13:55:38.993547 140689526667136 learning.py:507] global step 5583: loss = 0.0886 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 5584: loss = 0.1914 (0.379 sec/step)\n",
            "I0205 13:55:39.374502 140689526667136 learning.py:507] global step 5584: loss = 0.1914 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5585: loss = 0.0408 (0.380 sec/step)\n",
            "I0205 13:55:39.756552 140689526667136 learning.py:507] global step 5585: loss = 0.0408 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 5586: loss = 0.5308 (0.382 sec/step)\n",
            "I0205 13:55:40.140599 140689526667136 learning.py:507] global step 5586: loss = 0.5308 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5587: loss = 0.0530 (0.374 sec/step)\n",
            "I0205 13:55:40.516432 140689526667136 learning.py:507] global step 5587: loss = 0.0530 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 5588: loss = 0.0297 (0.377 sec/step)\n",
            "I0205 13:55:40.895694 140689526667136 learning.py:507] global step 5588: loss = 0.0297 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 5589: loss = 0.1170 (0.375 sec/step)\n",
            "I0205 13:55:41.271965 140689526667136 learning.py:507] global step 5589: loss = 0.1170 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 5590: loss = 0.0782 (0.365 sec/step)\n",
            "I0205 13:55:41.638606 140689526667136 learning.py:507] global step 5590: loss = 0.0782 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 5591: loss = 0.3727 (0.374 sec/step)\n",
            "I0205 13:55:42.014245 140689526667136 learning.py:507] global step 5591: loss = 0.3727 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 5592: loss = 0.0754 (0.363 sec/step)\n",
            "I0205 13:55:42.379204 140689526667136 learning.py:507] global step 5592: loss = 0.0754 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 5593: loss = 0.0361 (0.384 sec/step)\n",
            "I0205 13:55:42.764060 140689526667136 learning.py:507] global step 5593: loss = 0.0361 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 5594: loss = 0.0716 (0.409 sec/step)\n",
            "I0205 13:55:43.174957 140689526667136 learning.py:507] global step 5594: loss = 0.0716 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 5595: loss = 0.0565 (0.385 sec/step)\n",
            "I0205 13:55:43.562109 140689526667136 learning.py:507] global step 5595: loss = 0.0565 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 5596: loss = 0.1293 (0.405 sec/step)\n",
            "I0205 13:55:43.968652 140689526667136 learning.py:507] global step 5596: loss = 0.1293 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 5597: loss = 0.1641 (0.379 sec/step)\n",
            "I0205 13:55:44.348877 140689526667136 learning.py:507] global step 5597: loss = 0.1641 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5598: loss = 0.2787 (0.391 sec/step)\n",
            "I0205 13:55:44.742088 140689526667136 learning.py:507] global step 5598: loss = 0.2787 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 5599: loss = 0.2936 (0.400 sec/step)\n",
            "I0205 13:55:45.144046 140689526667136 learning.py:507] global step 5599: loss = 0.2936 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 5600: loss = 0.0769 (0.389 sec/step)\n",
            "I0205 13:55:45.534941 140689526667136 learning.py:507] global step 5600: loss = 0.0769 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 5601: loss = 0.2929 (0.398 sec/step)\n",
            "I0205 13:55:45.934545 140689526667136 learning.py:507] global step 5601: loss = 0.2929 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 5602: loss = 0.0522 (0.384 sec/step)\n",
            "I0205 13:55:46.320498 140689526667136 learning.py:507] global step 5602: loss = 0.0522 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 5603: loss = 0.1038 (0.347 sec/step)\n",
            "I0205 13:55:46.669422 140689526667136 learning.py:507] global step 5603: loss = 0.1038 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 5604: loss = 0.1060 (0.360 sec/step)\n",
            "I0205 13:55:47.030511 140689526667136 learning.py:507] global step 5604: loss = 0.1060 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 5605: loss = 0.1252 (0.357 sec/step)\n",
            "I0205 13:55:47.388972 140689526667136 learning.py:507] global step 5605: loss = 0.1252 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 5606: loss = 0.1045 (0.367 sec/step)\n",
            "I0205 13:55:47.758033 140689526667136 learning.py:507] global step 5606: loss = 0.1045 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 5607: loss = 0.1536 (0.382 sec/step)\n",
            "I0205 13:55:48.142093 140689526667136 learning.py:507] global step 5607: loss = 0.1536 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5608: loss = 0.1792 (0.369 sec/step)\n",
            "I0205 13:55:48.512659 140689526667136 learning.py:507] global step 5608: loss = 0.1792 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 5609: loss = 0.2971 (0.382 sec/step)\n",
            "I0205 13:55:48.896533 140689526667136 learning.py:507] global step 5609: loss = 0.2971 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5610: loss = 0.2453 (0.369 sec/step)\n",
            "I0205 13:55:49.267211 140689526667136 learning.py:507] global step 5610: loss = 0.2453 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 5611: loss = 0.3451 (0.431 sec/step)\n",
            "I0205 13:55:49.700242 140689526667136 learning.py:507] global step 5611: loss = 0.3451 (0.431 sec/step)\n",
            "INFO:tensorflow:global step 5612: loss = 0.0452 (0.376 sec/step)\n",
            "I0205 13:55:50.078015 140689526667136 learning.py:507] global step 5612: loss = 0.0452 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5613: loss = 0.3927 (0.386 sec/step)\n",
            "I0205 13:55:50.465558 140689526667136 learning.py:507] global step 5613: loss = 0.3927 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 5614: loss = 0.0915 (0.367 sec/step)\n",
            "I0205 13:55:50.834468 140689526667136 learning.py:507] global step 5614: loss = 0.0915 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 5615: loss = 0.0942 (0.376 sec/step)\n",
            "I0205 13:55:51.212071 140689526667136 learning.py:507] global step 5615: loss = 0.0942 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5616: loss = 0.5541 (0.381 sec/step)\n",
            "I0205 13:55:51.594327 140689526667136 learning.py:507] global step 5616: loss = 0.5541 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 5617: loss = 0.0779 (0.378 sec/step)\n",
            "I0205 13:55:51.973937 140689526667136 learning.py:507] global step 5617: loss = 0.0779 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 5618: loss = 0.0359 (0.408 sec/step)\n",
            "I0205 13:55:52.383381 140689526667136 learning.py:507] global step 5618: loss = 0.0359 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 5619: loss = 0.1558 (0.437 sec/step)\n",
            "I0205 13:55:52.822827 140689526667136 learning.py:507] global step 5619: loss = 0.1558 (0.437 sec/step)\n",
            "INFO:tensorflow:global step 5620: loss = 0.3103 (0.379 sec/step)\n",
            "I0205 13:55:53.204528 140689526667136 learning.py:507] global step 5620: loss = 0.3103 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5621: loss = 0.2711 (0.377 sec/step)\n",
            "I0205 13:55:53.582724 140689526667136 learning.py:507] global step 5621: loss = 0.2711 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 5622: loss = 0.1079 (0.385 sec/step)\n",
            "I0205 13:55:53.968970 140689526667136 learning.py:507] global step 5622: loss = 0.1079 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 5623: loss = 0.0610 (0.348 sec/step)\n",
            "I0205 13:55:54.318579 140689526667136 learning.py:507] global step 5623: loss = 0.0610 (0.348 sec/step)\n",
            "INFO:tensorflow:global step 5624: loss = 0.2362 (0.395 sec/step)\n",
            "I0205 13:55:54.715019 140689526667136 learning.py:507] global step 5624: loss = 0.2362 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 5625: loss = 0.0990 (0.370 sec/step)\n",
            "I0205 13:55:55.086663 140689526667136 learning.py:507] global step 5625: loss = 0.0990 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 5626: loss = 0.0587 (0.388 sec/step)\n",
            "I0205 13:55:55.476052 140689526667136 learning.py:507] global step 5626: loss = 0.0587 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 5627: loss = 0.0561 (0.400 sec/step)\n",
            "I0205 13:55:55.877804 140689526667136 learning.py:507] global step 5627: loss = 0.0561 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 5628: loss = 0.4546 (0.368 sec/step)\n",
            "I0205 13:55:56.247597 140689526667136 learning.py:507] global step 5628: loss = 0.4546 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 5629: loss = 0.2646 (0.395 sec/step)\n",
            "I0205 13:55:56.644441 140689526667136 learning.py:507] global step 5629: loss = 0.2646 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 5630: loss = 0.1982 (0.394 sec/step)\n",
            "I0205 13:55:57.040457 140689526667136 learning.py:507] global step 5630: loss = 0.1982 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 5631: loss = 0.0152 (0.372 sec/step)\n",
            "I0205 13:55:57.414377 140689526667136 learning.py:507] global step 5631: loss = 0.0152 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 5632: loss = 0.3028 (0.381 sec/step)\n",
            "I0205 13:55:57.797202 140689526667136 learning.py:507] global step 5632: loss = 0.3028 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 5633: loss = 0.1124 (0.378 sec/step)\n",
            "I0205 13:55:58.177079 140689526667136 learning.py:507] global step 5633: loss = 0.1124 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 5634: loss = 0.1344 (0.397 sec/step)\n",
            "I0205 13:55:58.576097 140689526667136 learning.py:507] global step 5634: loss = 0.1344 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 5635: loss = 0.0364 (0.394 sec/step)\n",
            "I0205 13:55:58.971746 140689526667136 learning.py:507] global step 5635: loss = 0.0364 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 5636: loss = 0.1602 (0.371 sec/step)\n",
            "I0205 13:55:59.344578 140689526667136 learning.py:507] global step 5636: loss = 0.1602 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 5637: loss = 0.1422 (0.384 sec/step)\n",
            "I0205 13:55:59.730398 140689526667136 learning.py:507] global step 5637: loss = 0.1422 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 5638: loss = 0.0659 (0.371 sec/step)\n",
            "I0205 13:56:00.102918 140689526667136 learning.py:507] global step 5638: loss = 0.0659 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 5639: loss = 0.0372 (0.366 sec/step)\n",
            "I0205 13:56:00.470397 140689526667136 learning.py:507] global step 5639: loss = 0.0372 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 5640: loss = 0.1806 (0.401 sec/step)\n",
            "I0205 13:56:00.872787 140689526667136 learning.py:507] global step 5640: loss = 0.1806 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 5641: loss = 0.1156 (0.396 sec/step)\n",
            "I0205 13:56:01.270744 140689526667136 learning.py:507] global step 5641: loss = 0.1156 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 5642: loss = 0.0321 (0.374 sec/step)\n",
            "I0205 13:56:01.646611 140689526667136 learning.py:507] global step 5642: loss = 0.0321 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 5643: loss = 0.0556 (0.391 sec/step)\n",
            "I0205 13:56:02.039363 140689526667136 learning.py:507] global step 5643: loss = 0.0556 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 5644: loss = 0.1494 (0.412 sec/step)\n",
            "I0205 13:56:02.452723 140689526667136 learning.py:507] global step 5644: loss = 0.1494 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 5645: loss = 0.2018 (0.389 sec/step)\n",
            "I0205 13:56:02.843587 140689526667136 learning.py:507] global step 5645: loss = 0.2018 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 5646: loss = 0.4394 (0.420 sec/step)\n",
            "I0205 13:56:03.265602 140689526667136 learning.py:507] global step 5646: loss = 0.4394 (0.420 sec/step)\n",
            "INFO:tensorflow:global step 5647: loss = 0.1933 (0.398 sec/step)\n",
            "I0205 13:56:03.665401 140689526667136 learning.py:507] global step 5647: loss = 0.1933 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 5648: loss = 0.0631 (0.381 sec/step)\n",
            "I0205 13:56:04.048197 140689526667136 learning.py:507] global step 5648: loss = 0.0631 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 5649: loss = 0.1044 (0.361 sec/step)\n",
            "I0205 13:56:04.411093 140689526667136 learning.py:507] global step 5649: loss = 0.1044 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 5650: loss = 0.0615 (0.362 sec/step)\n",
            "I0205 13:56:04.774864 140689526667136 learning.py:507] global step 5650: loss = 0.0615 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 5651: loss = 0.2067 (0.415 sec/step)\n",
            "I0205 13:56:05.191681 140689526667136 learning.py:507] global step 5651: loss = 0.2067 (0.415 sec/step)\n",
            "INFO:tensorflow:global step 5652: loss = 0.1482 (0.390 sec/step)\n",
            "I0205 13:56:05.582764 140689526667136 learning.py:507] global step 5652: loss = 0.1482 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5653: loss = 0.2627 (0.376 sec/step)\n",
            "I0205 13:56:05.960558 140689526667136 learning.py:507] global step 5653: loss = 0.2627 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5654: loss = 0.2273 (0.396 sec/step)\n",
            "I0205 13:56:06.358326 140689526667136 learning.py:507] global step 5654: loss = 0.2273 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 5655: loss = 0.6771 (0.381 sec/step)\n",
            "I0205 13:56:06.741081 140689526667136 learning.py:507] global step 5655: loss = 0.6771 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 5656: loss = 0.1098 (0.390 sec/step)\n",
            "I0205 13:56:07.132430 140689526667136 learning.py:507] global step 5656: loss = 0.1098 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5657: loss = 0.0781 (0.378 sec/step)\n",
            "I0205 13:56:07.512512 140689526667136 learning.py:507] global step 5657: loss = 0.0781 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 5658: loss = 0.1021 (0.376 sec/step)\n",
            "I0205 13:56:07.889708 140689526667136 learning.py:507] global step 5658: loss = 0.1021 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5659: loss = 0.1012 (0.390 sec/step)\n",
            "I0205 13:56:08.281452 140689526667136 learning.py:507] global step 5659: loss = 0.1012 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5660: loss = 0.1368 (0.393 sec/step)\n",
            "I0205 13:56:08.676391 140689526667136 learning.py:507] global step 5660: loss = 0.1368 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 5661: loss = 0.0868 (0.378 sec/step)\n",
            "I0205 13:56:09.056233 140689526667136 learning.py:507] global step 5661: loss = 0.0868 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 5662: loss = 0.0797 (0.380 sec/step)\n",
            "I0205 13:56:09.437442 140689526667136 learning.py:507] global step 5662: loss = 0.0797 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 5663: loss = 0.2234 (0.396 sec/step)\n",
            "I0205 13:56:09.834844 140689526667136 learning.py:507] global step 5663: loss = 0.2234 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 5664: loss = 0.1911 (0.402 sec/step)\n",
            "I0205 13:56:10.238261 140689526667136 learning.py:507] global step 5664: loss = 0.1911 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 5665: loss = 1.1146 (0.358 sec/step)\n",
            "I0205 13:56:10.597550 140689526667136 learning.py:507] global step 5665: loss = 1.1146 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 5666: loss = 0.0643 (0.388 sec/step)\n",
            "I0205 13:56:10.987449 140689526667136 learning.py:507] global step 5666: loss = 0.0643 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 5667: loss = 0.1219 (0.382 sec/step)\n",
            "I0205 13:56:11.371260 140689526667136 learning.py:507] global step 5667: loss = 0.1219 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5668: loss = 0.9037 (0.380 sec/step)\n",
            "I0205 13:56:11.752686 140689526667136 learning.py:507] global step 5668: loss = 0.9037 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 5669: loss = 0.3046 (0.366 sec/step)\n",
            "I0205 13:56:12.120522 140689526667136 learning.py:507] global step 5669: loss = 0.3046 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 5670: loss = 0.0752 (0.364 sec/step)\n",
            "I0205 13:56:12.486565 140689526667136 learning.py:507] global step 5670: loss = 0.0752 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 5671: loss = 0.2291 (0.413 sec/step)\n",
            "I0205 13:56:12.901294 140689526667136 learning.py:507] global step 5671: loss = 0.2291 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 5672: loss = 0.4595 (0.401 sec/step)\n",
            "I0205 13:56:13.303864 140689526667136 learning.py:507] global step 5672: loss = 0.4595 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 5673: loss = 0.2210 (0.395 sec/step)\n",
            "I0205 13:56:13.700610 140689526667136 learning.py:507] global step 5673: loss = 0.2210 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 5674: loss = 0.1206 (0.729 sec/step)\n",
            "I0205 13:56:14.575581 140689526667136 learning.py:507] global step 5674: loss = 0.1206 (0.729 sec/step)\n",
            "INFO:tensorflow:global step 5675: loss = 0.1110 (0.857 sec/step)\n",
            "I0205 13:56:15.579695 140689526667136 learning.py:507] global step 5675: loss = 0.1110 (0.857 sec/step)\n",
            "INFO:tensorflow:global step 5676: loss = 0.1172 (0.579 sec/step)\n",
            "I0205 13:56:16.259634 140689526667136 learning.py:507] global step 5676: loss = 0.1172 (0.579 sec/step)\n",
            "INFO:tensorflow:global step 5677: loss = 0.1698 (0.579 sec/step)\n",
            "I0205 13:56:16.842554 140689526667136 learning.py:507] global step 5677: loss = 0.1698 (0.579 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 5677.\n",
            "I0205 13:56:17.156264 140686026073856 supervisor.py:1050] Recording summary at step 5677.\n",
            "INFO:tensorflow:global step 5678: loss = 0.0939 (0.540 sec/step)\n",
            "I0205 13:56:17.384660 140689526667136 learning.py:507] global step 5678: loss = 0.0939 (0.540 sec/step)\n",
            "INFO:tensorflow:global step 5679: loss = 0.1246 (0.413 sec/step)\n",
            "I0205 13:56:17.799715 140689526667136 learning.py:507] global step 5679: loss = 0.1246 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 5680: loss = 0.3762 (0.354 sec/step)\n",
            "I0205 13:56:18.155618 140689526667136 learning.py:507] global step 5680: loss = 0.3762 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 5681: loss = 0.2093 (0.357 sec/step)\n",
            "I0205 13:56:18.514375 140689526667136 learning.py:507] global step 5681: loss = 0.2093 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 5682: loss = 0.1375 (0.374 sec/step)\n",
            "I0205 13:56:18.890243 140689526667136 learning.py:507] global step 5682: loss = 0.1375 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 5683: loss = 0.1796 (0.376 sec/step)\n",
            "I0205 13:56:19.268295 140689526667136 learning.py:507] global step 5683: loss = 0.1796 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5684: loss = 0.1022 (0.365 sec/step)\n",
            "I0205 13:56:19.634878 140689526667136 learning.py:507] global step 5684: loss = 0.1022 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 5685: loss = 0.1120 (0.380 sec/step)\n",
            "I0205 13:56:20.016383 140689526667136 learning.py:507] global step 5685: loss = 0.1120 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 5686: loss = 0.2792 (0.347 sec/step)\n",
            "I0205 13:56:20.365053 140689526667136 learning.py:507] global step 5686: loss = 0.2792 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 5687: loss = 0.2550 (0.375 sec/step)\n",
            "I0205 13:56:20.741931 140689526667136 learning.py:507] global step 5687: loss = 0.2550 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 5688: loss = 0.1964 (0.388 sec/step)\n",
            "I0205 13:56:21.131967 140689526667136 learning.py:507] global step 5688: loss = 0.1964 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 5689: loss = 0.2311 (0.401 sec/step)\n",
            "I0205 13:56:21.534549 140689526667136 learning.py:507] global step 5689: loss = 0.2311 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 5690: loss = 0.0498 (0.401 sec/step)\n",
            "I0205 13:56:21.938312 140689526667136 learning.py:507] global step 5690: loss = 0.0498 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 5691: loss = 0.5096 (0.395 sec/step)\n",
            "I0205 13:56:22.334719 140689526667136 learning.py:507] global step 5691: loss = 0.5096 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 5692: loss = 0.1418 (0.389 sec/step)\n",
            "I0205 13:56:22.725610 140689526667136 learning.py:507] global step 5692: loss = 0.1418 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 5693: loss = 0.1098 (0.367 sec/step)\n",
            "I0205 13:56:23.094511 140689526667136 learning.py:507] global step 5693: loss = 0.1098 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 5694: loss = 0.2291 (0.370 sec/step)\n",
            "I0205 13:56:23.465440 140689526667136 learning.py:507] global step 5694: loss = 0.2291 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 5695: loss = 0.4415 (0.392 sec/step)\n",
            "I0205 13:56:23.858971 140689526667136 learning.py:507] global step 5695: loss = 0.4415 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 5696: loss = 0.1440 (0.393 sec/step)\n",
            "I0205 13:56:24.253843 140689526667136 learning.py:507] global step 5696: loss = 0.1440 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 5697: loss = 0.2294 (0.397 sec/step)\n",
            "I0205 13:56:24.653017 140689526667136 learning.py:507] global step 5697: loss = 0.2294 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 5698: loss = 1.9101 (0.351 sec/step)\n",
            "I0205 13:56:25.005734 140689526667136 learning.py:507] global step 5698: loss = 1.9101 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 5699: loss = 0.0352 (0.377 sec/step)\n",
            "I0205 13:56:25.384764 140689526667136 learning.py:507] global step 5699: loss = 0.0352 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 5700: loss = 0.0193 (0.401 sec/step)\n",
            "I0205 13:56:25.787552 140689526667136 learning.py:507] global step 5700: loss = 0.0193 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 5701: loss = 0.1163 (0.382 sec/step)\n",
            "I0205 13:56:26.171900 140689526667136 learning.py:507] global step 5701: loss = 0.1163 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5702: loss = 0.1094 (0.384 sec/step)\n",
            "I0205 13:56:26.557821 140689526667136 learning.py:507] global step 5702: loss = 0.1094 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 5703: loss = 0.3536 (0.361 sec/step)\n",
            "I0205 13:56:26.919944 140689526667136 learning.py:507] global step 5703: loss = 0.3536 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 5704: loss = 0.0948 (0.385 sec/step)\n",
            "I0205 13:56:27.306275 140689526667136 learning.py:507] global step 5704: loss = 0.0948 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 5705: loss = 0.4726 (0.402 sec/step)\n",
            "I0205 13:56:27.710041 140689526667136 learning.py:507] global step 5705: loss = 0.4726 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 5706: loss = 0.0808 (0.389 sec/step)\n",
            "I0205 13:56:28.101025 140689526667136 learning.py:507] global step 5706: loss = 0.0808 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 5707: loss = 0.1335 (0.379 sec/step)\n",
            "I0205 13:56:28.481535 140689526667136 learning.py:507] global step 5707: loss = 0.1335 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5708: loss = 0.0786 (0.376 sec/step)\n",
            "I0205 13:56:28.858540 140689526667136 learning.py:507] global step 5708: loss = 0.0786 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5709: loss = 0.8147 (0.385 sec/step)\n",
            "I0205 13:56:29.244434 140689526667136 learning.py:507] global step 5709: loss = 0.8147 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 5710: loss = 0.1079 (0.429 sec/step)\n",
            "I0205 13:56:29.675392 140689526667136 learning.py:507] global step 5710: loss = 0.1079 (0.429 sec/step)\n",
            "INFO:tensorflow:global step 5711: loss = 0.0393 (0.402 sec/step)\n",
            "I0205 13:56:30.079613 140689526667136 learning.py:507] global step 5711: loss = 0.0393 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 5712: loss = 0.2086 (0.393 sec/step)\n",
            "I0205 13:56:30.474377 140689526667136 learning.py:507] global step 5712: loss = 0.2086 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 5713: loss = 0.1370 (0.372 sec/step)\n",
            "I0205 13:56:30.847691 140689526667136 learning.py:507] global step 5713: loss = 0.1370 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 5714: loss = 0.0565 (0.372 sec/step)\n",
            "I0205 13:56:31.221120 140689526667136 learning.py:507] global step 5714: loss = 0.0565 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 5715: loss = 0.0796 (0.390 sec/step)\n",
            "I0205 13:56:31.612774 140689526667136 learning.py:507] global step 5715: loss = 0.0796 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5716: loss = 0.1319 (0.401 sec/step)\n",
            "I0205 13:56:32.015596 140689526667136 learning.py:507] global step 5716: loss = 0.1319 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 5717: loss = 0.0557 (0.396 sec/step)\n",
            "I0205 13:56:32.413700 140689526667136 learning.py:507] global step 5717: loss = 0.0557 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 5718: loss = 0.2369 (0.394 sec/step)\n",
            "I0205 13:56:32.809553 140689526667136 learning.py:507] global step 5718: loss = 0.2369 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 5719: loss = 0.1833 (0.395 sec/step)\n",
            "I0205 13:56:33.206484 140689526667136 learning.py:507] global step 5719: loss = 0.1833 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 5720: loss = 0.1299 (0.390 sec/step)\n",
            "I0205 13:56:33.598148 140689526667136 learning.py:507] global step 5720: loss = 0.1299 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5721: loss = 0.3159 (0.377 sec/step)\n",
            "I0205 13:56:33.976670 140689526667136 learning.py:507] global step 5721: loss = 0.3159 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 5722: loss = 0.0737 (0.377 sec/step)\n",
            "I0205 13:56:34.355055 140689526667136 learning.py:507] global step 5722: loss = 0.0737 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 5723: loss = 0.0465 (0.356 sec/step)\n",
            "I0205 13:56:34.712587 140689526667136 learning.py:507] global step 5723: loss = 0.0465 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 5724: loss = 0.1528 (0.366 sec/step)\n",
            "I0205 13:56:35.080531 140689526667136 learning.py:507] global step 5724: loss = 0.1528 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 5725: loss = 0.1055 (0.371 sec/step)\n",
            "I0205 13:56:35.453419 140689526667136 learning.py:507] global step 5725: loss = 0.1055 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 5726: loss = 0.1655 (0.350 sec/step)\n",
            "I0205 13:56:35.805221 140689526667136 learning.py:507] global step 5726: loss = 0.1655 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 5727: loss = 0.1038 (0.372 sec/step)\n",
            "I0205 13:56:36.178669 140689526667136 learning.py:507] global step 5727: loss = 0.1038 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 5728: loss = 0.3281 (0.407 sec/step)\n",
            "I0205 13:56:36.587381 140689526667136 learning.py:507] global step 5728: loss = 0.3281 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 5729: loss = 0.0839 (0.387 sec/step)\n",
            "I0205 13:56:36.976247 140689526667136 learning.py:507] global step 5729: loss = 0.0839 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 5730: loss = 0.1141 (0.355 sec/step)\n",
            "I0205 13:56:37.333518 140689526667136 learning.py:507] global step 5730: loss = 0.1141 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 5731: loss = 0.1439 (0.380 sec/step)\n",
            "I0205 13:56:37.715106 140689526667136 learning.py:507] global step 5731: loss = 0.1439 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 5732: loss = 0.0430 (0.401 sec/step)\n",
            "I0205 13:56:38.117738 140689526667136 learning.py:507] global step 5732: loss = 0.0430 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 5733: loss = 0.2919 (0.371 sec/step)\n",
            "I0205 13:56:38.489805 140689526667136 learning.py:507] global step 5733: loss = 0.2919 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 5734: loss = 0.0676 (0.365 sec/step)\n",
            "I0205 13:56:38.856724 140689526667136 learning.py:507] global step 5734: loss = 0.0676 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 5735: loss = 0.4879 (0.380 sec/step)\n",
            "I0205 13:56:39.237955 140689526667136 learning.py:507] global step 5735: loss = 0.4879 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 5736: loss = 0.3747 (0.390 sec/step)\n",
            "I0205 13:56:39.629545 140689526667136 learning.py:507] global step 5736: loss = 0.3747 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5737: loss = 0.4080 (0.373 sec/step)\n",
            "I0205 13:56:40.003503 140689526667136 learning.py:507] global step 5737: loss = 0.4080 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 5738: loss = 0.0906 (0.365 sec/step)\n",
            "I0205 13:56:40.369761 140689526667136 learning.py:507] global step 5738: loss = 0.0906 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 5739: loss = 0.2603 (0.395 sec/step)\n",
            "I0205 13:56:40.765980 140689526667136 learning.py:507] global step 5739: loss = 0.2603 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 5740: loss = 0.1094 (0.382 sec/step)\n",
            "I0205 13:56:41.149814 140689526667136 learning.py:507] global step 5740: loss = 0.1094 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5741: loss = 0.1623 (0.379 sec/step)\n",
            "I0205 13:56:41.530796 140689526667136 learning.py:507] global step 5741: loss = 0.1623 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5742: loss = 0.1710 (0.358 sec/step)\n",
            "I0205 13:56:41.890713 140689526667136 learning.py:507] global step 5742: loss = 0.1710 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 5743: loss = 0.0809 (0.380 sec/step)\n",
            "I0205 13:56:42.272237 140689526667136 learning.py:507] global step 5743: loss = 0.0809 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 5744: loss = 0.3776 (0.386 sec/step)\n",
            "I0205 13:56:42.659713 140689526667136 learning.py:507] global step 5744: loss = 0.3776 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 5745: loss = 0.1724 (0.371 sec/step)\n",
            "I0205 13:56:43.031948 140689526667136 learning.py:507] global step 5745: loss = 0.1724 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 5746: loss = 0.2380 (0.350 sec/step)\n",
            "I0205 13:56:43.383416 140689526667136 learning.py:507] global step 5746: loss = 0.2380 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 5747: loss = 0.0481 (0.382 sec/step)\n",
            "I0205 13:56:43.767261 140689526667136 learning.py:507] global step 5747: loss = 0.0481 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5748: loss = 0.6263 (0.409 sec/step)\n",
            "I0205 13:56:44.177962 140689526667136 learning.py:507] global step 5748: loss = 0.6263 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 5749: loss = 0.0334 (0.382 sec/step)\n",
            "I0205 13:56:44.562072 140689526667136 learning.py:507] global step 5749: loss = 0.0334 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5750: loss = 0.0289 (0.382 sec/step)\n",
            "I0205 13:56:44.945424 140689526667136 learning.py:507] global step 5750: loss = 0.0289 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5751: loss = 0.6854 (0.387 sec/step)\n",
            "I0205 13:56:45.334247 140689526667136 learning.py:507] global step 5751: loss = 0.6854 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 5752: loss = 0.1096 (0.393 sec/step)\n",
            "I0205 13:56:45.729186 140689526667136 learning.py:507] global step 5752: loss = 0.1096 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 5753: loss = 0.1133 (0.354 sec/step)\n",
            "I0205 13:56:46.084821 140689526667136 learning.py:507] global step 5753: loss = 0.1133 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 5754: loss = 0.0598 (0.358 sec/step)\n",
            "I0205 13:56:46.445720 140689526667136 learning.py:507] global step 5754: loss = 0.0598 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 5755: loss = 0.4957 (0.364 sec/step)\n",
            "I0205 13:56:46.811090 140689526667136 learning.py:507] global step 5755: loss = 0.4957 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 5756: loss = 0.1253 (0.390 sec/step)\n",
            "I0205 13:56:47.202244 140689526667136 learning.py:507] global step 5756: loss = 0.1253 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5757: loss = 0.4268 (0.378 sec/step)\n",
            "I0205 13:56:47.581944 140689526667136 learning.py:507] global step 5757: loss = 0.4268 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 5758: loss = 0.9622 (0.379 sec/step)\n",
            "I0205 13:56:47.962001 140689526667136 learning.py:507] global step 5758: loss = 0.9622 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5759: loss = 0.0403 (0.374 sec/step)\n",
            "I0205 13:56:48.337587 140689526667136 learning.py:507] global step 5759: loss = 0.0403 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 5760: loss = 0.1334 (0.396 sec/step)\n",
            "I0205 13:56:48.734754 140689526667136 learning.py:507] global step 5760: loss = 0.1334 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 5761: loss = 0.2552 (0.378 sec/step)\n",
            "I0205 13:56:49.114276 140689526667136 learning.py:507] global step 5761: loss = 0.2552 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 5762: loss = 0.0953 (0.398 sec/step)\n",
            "I0205 13:56:49.514229 140689526667136 learning.py:507] global step 5762: loss = 0.0953 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 5763: loss = 0.1619 (0.394 sec/step)\n",
            "I0205 13:56:49.909807 140689526667136 learning.py:507] global step 5763: loss = 0.1619 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 5764: loss = 0.0775 (0.381 sec/step)\n",
            "I0205 13:56:50.292871 140689526667136 learning.py:507] global step 5764: loss = 0.0775 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 5765: loss = 0.0869 (0.376 sec/step)\n",
            "I0205 13:56:50.670122 140689526667136 learning.py:507] global step 5765: loss = 0.0869 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5766: loss = 0.0723 (0.353 sec/step)\n",
            "I0205 13:56:51.024795 140689526667136 learning.py:507] global step 5766: loss = 0.0723 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 5767: loss = 0.1340 (0.399 sec/step)\n",
            "I0205 13:56:51.425774 140689526667136 learning.py:507] global step 5767: loss = 0.1340 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 5768: loss = 0.1233 (0.369 sec/step)\n",
            "I0205 13:56:51.797135 140689526667136 learning.py:507] global step 5768: loss = 0.1233 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 5769: loss = 0.1894 (0.374 sec/step)\n",
            "I0205 13:56:52.173228 140689526667136 learning.py:507] global step 5769: loss = 0.1894 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 5770: loss = 0.2271 (0.428 sec/step)\n",
            "I0205 13:56:52.603293 140689526667136 learning.py:507] global step 5770: loss = 0.2271 (0.428 sec/step)\n",
            "INFO:tensorflow:global step 5771: loss = 0.0225 (0.415 sec/step)\n",
            "I0205 13:56:53.020490 140689526667136 learning.py:507] global step 5771: loss = 0.0225 (0.415 sec/step)\n",
            "INFO:tensorflow:global step 5772: loss = 0.2320 (0.368 sec/step)\n",
            "I0205 13:56:53.390206 140689526667136 learning.py:507] global step 5772: loss = 0.2320 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 5773: loss = 0.1419 (0.383 sec/step)\n",
            "I0205 13:56:53.775045 140689526667136 learning.py:507] global step 5773: loss = 0.1419 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 5774: loss = 0.1066 (0.335 sec/step)\n",
            "I0205 13:56:54.111890 140689526667136 learning.py:507] global step 5774: loss = 0.1066 (0.335 sec/step)\n",
            "INFO:tensorflow:global step 5775: loss = 0.2478 (0.398 sec/step)\n",
            "I0205 13:56:54.511188 140689526667136 learning.py:507] global step 5775: loss = 0.2478 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 5776: loss = 0.1167 (0.375 sec/step)\n",
            "I0205 13:56:54.888194 140689526667136 learning.py:507] global step 5776: loss = 0.1167 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 5777: loss = 0.0889 (0.414 sec/step)\n",
            "I0205 13:56:55.304129 140689526667136 learning.py:507] global step 5777: loss = 0.0889 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 5778: loss = 0.2518 (0.380 sec/step)\n",
            "I0205 13:56:55.685457 140689526667136 learning.py:507] global step 5778: loss = 0.2518 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 5779: loss = 0.0324 (0.396 sec/step)\n",
            "I0205 13:56:56.082953 140689526667136 learning.py:507] global step 5779: loss = 0.0324 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 5780: loss = 0.7947 (0.387 sec/step)\n",
            "I0205 13:56:56.471377 140689526667136 learning.py:507] global step 5780: loss = 0.7947 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 5781: loss = 0.0973 (0.392 sec/step)\n",
            "I0205 13:56:56.864913 140689526667136 learning.py:507] global step 5781: loss = 0.0973 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 5782: loss = 0.0807 (0.372 sec/step)\n",
            "I0205 13:56:57.238197 140689526667136 learning.py:507] global step 5782: loss = 0.0807 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 5783: loss = 0.1752 (0.379 sec/step)\n",
            "I0205 13:56:57.618666 140689526667136 learning.py:507] global step 5783: loss = 0.1752 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5784: loss = 0.1046 (0.381 sec/step)\n",
            "I0205 13:56:58.001114 140689526667136 learning.py:507] global step 5784: loss = 0.1046 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 5785: loss = 0.0720 (0.388 sec/step)\n",
            "I0205 13:56:58.390860 140689526667136 learning.py:507] global step 5785: loss = 0.0720 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 5786: loss = 0.0419 (0.362 sec/step)\n",
            "I0205 13:56:58.754141 140689526667136 learning.py:507] global step 5786: loss = 0.0419 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 5787: loss = 0.0639 (0.390 sec/step)\n",
            "I0205 13:56:59.146051 140689526667136 learning.py:507] global step 5787: loss = 0.0639 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5788: loss = 0.0646 (0.382 sec/step)\n",
            "I0205 13:56:59.529620 140689526667136 learning.py:507] global step 5788: loss = 0.0646 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5789: loss = 0.1328 (0.398 sec/step)\n",
            "I0205 13:56:59.929351 140689526667136 learning.py:507] global step 5789: loss = 0.1328 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 5790: loss = 0.1804 (0.357 sec/step)\n",
            "I0205 13:57:00.287863 140689526667136 learning.py:507] global step 5790: loss = 0.1804 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 5791: loss = 0.2406 (0.368 sec/step)\n",
            "I0205 13:57:00.657637 140689526667136 learning.py:507] global step 5791: loss = 0.2406 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 5792: loss = 0.5560 (0.381 sec/step)\n",
            "I0205 13:57:01.040330 140689526667136 learning.py:507] global step 5792: loss = 0.5560 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 5793: loss = 0.0442 (0.359 sec/step)\n",
            "I0205 13:57:01.400475 140689526667136 learning.py:507] global step 5793: loss = 0.0442 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 5794: loss = 0.2841 (0.377 sec/step)\n",
            "I0205 13:57:01.778742 140689526667136 learning.py:507] global step 5794: loss = 0.2841 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 5795: loss = 0.1625 (0.363 sec/step)\n",
            "I0205 13:57:02.143473 140689526667136 learning.py:507] global step 5795: loss = 0.1625 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 5796: loss = 0.2796 (0.403 sec/step)\n",
            "I0205 13:57:02.547939 140689526667136 learning.py:507] global step 5796: loss = 0.2796 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 5797: loss = 0.0605 (0.389 sec/step)\n",
            "I0205 13:57:02.939069 140689526667136 learning.py:507] global step 5797: loss = 0.0605 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 5798: loss = 0.1406 (0.403 sec/step)\n",
            "I0205 13:57:03.343571 140689526667136 learning.py:507] global step 5798: loss = 0.1406 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 5799: loss = 0.0963 (0.374 sec/step)\n",
            "I0205 13:57:03.719108 140689526667136 learning.py:507] global step 5799: loss = 0.0963 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 5800: loss = 0.1599 (0.384 sec/step)\n",
            "I0205 13:57:04.104373 140689526667136 learning.py:507] global step 5800: loss = 0.1599 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 5801: loss = 0.2133 (0.392 sec/step)\n",
            "I0205 13:57:04.497555 140689526667136 learning.py:507] global step 5801: loss = 0.2133 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 5802: loss = 0.1696 (0.392 sec/step)\n",
            "I0205 13:57:04.891237 140689526667136 learning.py:507] global step 5802: loss = 0.1696 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 5803: loss = 0.1794 (0.363 sec/step)\n",
            "I0205 13:57:05.255996 140689526667136 learning.py:507] global step 5803: loss = 0.1794 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 5804: loss = 0.1915 (0.378 sec/step)\n",
            "I0205 13:57:05.635159 140689526667136 learning.py:507] global step 5804: loss = 0.1915 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 5805: loss = 0.0910 (0.359 sec/step)\n",
            "I0205 13:57:05.995632 140689526667136 learning.py:507] global step 5805: loss = 0.0910 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 5806: loss = 0.3084 (0.369 sec/step)\n",
            "I0205 13:57:06.366858 140689526667136 learning.py:507] global step 5806: loss = 0.3084 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 5807: loss = 0.0525 (0.413 sec/step)\n",
            "I0205 13:57:06.781764 140689526667136 learning.py:507] global step 5807: loss = 0.0525 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 5808: loss = 0.4510 (0.363 sec/step)\n",
            "I0205 13:57:07.146466 140689526667136 learning.py:507] global step 5808: loss = 0.4510 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 5809: loss = 0.1888 (0.414 sec/step)\n",
            "I0205 13:57:07.562011 140689526667136 learning.py:507] global step 5809: loss = 0.1888 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 5810: loss = 0.0681 (0.399 sec/step)\n",
            "I0205 13:57:07.962612 140689526667136 learning.py:507] global step 5810: loss = 0.0681 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 5811: loss = 0.0598 (0.386 sec/step)\n",
            "I0205 13:57:08.350412 140689526667136 learning.py:507] global step 5811: loss = 0.0598 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 5812: loss = 0.0458 (0.390 sec/step)\n",
            "I0205 13:57:08.742491 140689526667136 learning.py:507] global step 5812: loss = 0.0458 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5813: loss = 0.1018 (0.382 sec/step)\n",
            "I0205 13:57:09.125595 140689526667136 learning.py:507] global step 5813: loss = 0.1018 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5814: loss = 0.1488 (0.345 sec/step)\n",
            "I0205 13:57:09.472441 140689526667136 learning.py:507] global step 5814: loss = 0.1488 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 5815: loss = 0.0925 (0.383 sec/step)\n",
            "I0205 13:57:09.856835 140689526667136 learning.py:507] global step 5815: loss = 0.0925 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 5816: loss = 0.2727 (0.366 sec/step)\n",
            "I0205 13:57:10.225988 140689526667136 learning.py:507] global step 5816: loss = 0.2727 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 5817: loss = 0.1383 (0.390 sec/step)\n",
            "I0205 13:57:10.617799 140689526667136 learning.py:507] global step 5817: loss = 0.1383 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5818: loss = 0.1352 (0.377 sec/step)\n",
            "I0205 13:57:10.996777 140689526667136 learning.py:507] global step 5818: loss = 0.1352 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 5819: loss = 0.0519 (0.378 sec/step)\n",
            "I0205 13:57:11.376569 140689526667136 learning.py:507] global step 5819: loss = 0.0519 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 5820: loss = 0.0914 (0.389 sec/step)\n",
            "I0205 13:57:11.766795 140689526667136 learning.py:507] global step 5820: loss = 0.0914 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 5821: loss = 0.0995 (0.353 sec/step)\n",
            "I0205 13:57:12.121588 140689526667136 learning.py:507] global step 5821: loss = 0.0995 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 5822: loss = 0.2271 (0.376 sec/step)\n",
            "I0205 13:57:12.498961 140689526667136 learning.py:507] global step 5822: loss = 0.2271 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5823: loss = 0.2442 (0.388 sec/step)\n",
            "I0205 13:57:12.888866 140689526667136 learning.py:507] global step 5823: loss = 0.2442 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 5824: loss = 0.1156 (0.389 sec/step)\n",
            "I0205 13:57:13.280024 140689526667136 learning.py:507] global step 5824: loss = 0.1156 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 5825: loss = 0.1497 (0.355 sec/step)\n",
            "I0205 13:57:13.636501 140689526667136 learning.py:507] global step 5825: loss = 0.1497 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 5826: loss = 0.0955 (0.391 sec/step)\n",
            "I0205 13:57:14.028997 140689526667136 learning.py:507] global step 5826: loss = 0.0955 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 5827: loss = 0.2563 (0.377 sec/step)\n",
            "I0205 13:57:14.407698 140689526667136 learning.py:507] global step 5827: loss = 0.2563 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 5828: loss = 0.0644 (0.398 sec/step)\n",
            "I0205 13:57:14.807150 140689526667136 learning.py:507] global step 5828: loss = 0.0644 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 5829: loss = 0.5348 (0.373 sec/step)\n",
            "I0205 13:57:15.181377 140689526667136 learning.py:507] global step 5829: loss = 0.5348 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 5830: loss = 0.0474 (0.406 sec/step)\n",
            "I0205 13:57:15.589132 140689526667136 learning.py:507] global step 5830: loss = 0.0474 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 5831: loss = 0.0442 (0.375 sec/step)\n",
            "I0205 13:57:15.965854 140689526667136 learning.py:507] global step 5831: loss = 0.0442 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 5832: loss = 0.1147 (0.395 sec/step)\n",
            "I0205 13:57:16.362625 140689526667136 learning.py:507] global step 5832: loss = 0.1147 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 5833: loss = 0.0979 (0.381 sec/step)\n",
            "I0205 13:57:16.745067 140689526667136 learning.py:507] global step 5833: loss = 0.0979 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 5834: loss = 0.0365 (0.373 sec/step)\n",
            "I0205 13:57:17.120300 140689526667136 learning.py:507] global step 5834: loss = 0.0365 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 5835: loss = 0.3190 (0.383 sec/step)\n",
            "I0205 13:57:17.505526 140689526667136 learning.py:507] global step 5835: loss = 0.3190 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 5836: loss = 0.1776 (0.400 sec/step)\n",
            "I0205 13:57:17.907405 140689526667136 learning.py:507] global step 5836: loss = 0.1776 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 5837: loss = 0.0406 (0.396 sec/step)\n",
            "I0205 13:57:18.306160 140689526667136 learning.py:507] global step 5837: loss = 0.0406 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 5838: loss = 0.1417 (0.412 sec/step)\n",
            "I0205 13:57:18.719688 140689526667136 learning.py:507] global step 5838: loss = 0.1417 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 5839: loss = 0.2091 (0.395 sec/step)\n",
            "I0205 13:57:19.117022 140689526667136 learning.py:507] global step 5839: loss = 0.2091 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 5840: loss = 0.1116 (0.373 sec/step)\n",
            "I0205 13:57:19.492146 140689526667136 learning.py:507] global step 5840: loss = 0.1116 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 5841: loss = 0.1462 (0.381 sec/step)\n",
            "I0205 13:57:19.874526 140689526667136 learning.py:507] global step 5841: loss = 0.1462 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 5842: loss = 0.0809 (0.350 sec/step)\n",
            "I0205 13:57:20.226372 140689526667136 learning.py:507] global step 5842: loss = 0.0809 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 5843: loss = 0.2140 (0.365 sec/step)\n",
            "I0205 13:57:20.592347 140689526667136 learning.py:507] global step 5843: loss = 0.2140 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 5844: loss = 0.1223 (0.375 sec/step)\n",
            "I0205 13:57:20.968528 140689526667136 learning.py:507] global step 5844: loss = 0.1223 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 5845: loss = 0.1108 (0.428 sec/step)\n",
            "I0205 13:57:21.398491 140689526667136 learning.py:507] global step 5845: loss = 0.1108 (0.428 sec/step)\n",
            "INFO:tensorflow:global step 5846: loss = 0.0757 (0.369 sec/step)\n",
            "I0205 13:57:21.769587 140689526667136 learning.py:507] global step 5846: loss = 0.0757 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 5847: loss = 0.1055 (0.398 sec/step)\n",
            "I0205 13:57:22.168753 140689526667136 learning.py:507] global step 5847: loss = 0.1055 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 5848: loss = 0.1894 (0.390 sec/step)\n",
            "I0205 13:57:22.559891 140689526667136 learning.py:507] global step 5848: loss = 0.1894 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5849: loss = 0.7629 (0.372 sec/step)\n",
            "I0205 13:57:22.933153 140689526667136 learning.py:507] global step 5849: loss = 0.7629 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 5850: loss = 0.1085 (0.388 sec/step)\n",
            "I0205 13:57:23.322516 140689526667136 learning.py:507] global step 5850: loss = 0.1085 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 5851: loss = 0.1708 (0.367 sec/step)\n",
            "I0205 13:57:23.690432 140689526667136 learning.py:507] global step 5851: loss = 0.1708 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 5852: loss = 0.5841 (0.376 sec/step)\n",
            "I0205 13:57:24.068051 140689526667136 learning.py:507] global step 5852: loss = 0.5841 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5853: loss = 0.0771 (0.386 sec/step)\n",
            "I0205 13:57:24.455130 140689526667136 learning.py:507] global step 5853: loss = 0.0771 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 5854: loss = 0.2716 (0.346 sec/step)\n",
            "I0205 13:57:24.802720 140689526667136 learning.py:507] global step 5854: loss = 0.2716 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 5855: loss = 0.0862 (0.378 sec/step)\n",
            "I0205 13:57:25.182384 140689526667136 learning.py:507] global step 5855: loss = 0.0862 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 5856: loss = 0.1718 (0.362 sec/step)\n",
            "I0205 13:57:25.545559 140689526667136 learning.py:507] global step 5856: loss = 0.1718 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 5857: loss = 0.5507 (0.369 sec/step)\n",
            "I0205 13:57:25.916518 140689526667136 learning.py:507] global step 5857: loss = 0.5507 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 5858: loss = 0.2199 (0.376 sec/step)\n",
            "I0205 13:57:26.294232 140689526667136 learning.py:507] global step 5858: loss = 0.2199 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5859: loss = 0.3094 (0.368 sec/step)\n",
            "I0205 13:57:26.663808 140689526667136 learning.py:507] global step 5859: loss = 0.3094 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 5860: loss = 0.0357 (0.354 sec/step)\n",
            "I0205 13:57:27.019269 140689526667136 learning.py:507] global step 5860: loss = 0.0357 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 5861: loss = 0.2049 (0.391 sec/step)\n",
            "I0205 13:57:27.412352 140689526667136 learning.py:507] global step 5861: loss = 0.2049 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 5862: loss = 0.0386 (0.396 sec/step)\n",
            "I0205 13:57:27.809688 140689526667136 learning.py:507] global step 5862: loss = 0.0386 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 5863: loss = 0.1883 (0.401 sec/step)\n",
            "I0205 13:57:28.213752 140689526667136 learning.py:507] global step 5863: loss = 0.1883 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 5864: loss = 0.3122 (0.397 sec/step)\n",
            "I0205 13:57:28.613095 140689526667136 learning.py:507] global step 5864: loss = 0.3122 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 5865: loss = 0.1025 (0.396 sec/step)\n",
            "I0205 13:57:29.010669 140689526667136 learning.py:507] global step 5865: loss = 0.1025 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 5866: loss = 0.3502 (0.413 sec/step)\n",
            "I0205 13:57:29.425890 140689526667136 learning.py:507] global step 5866: loss = 0.3502 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 5867: loss = 0.0807 (0.419 sec/step)\n",
            "I0205 13:57:29.846059 140689526667136 learning.py:507] global step 5867: loss = 0.0807 (0.419 sec/step)\n",
            "INFO:tensorflow:global step 5868: loss = 0.2661 (0.390 sec/step)\n",
            "I0205 13:57:30.237467 140689526667136 learning.py:507] global step 5868: loss = 0.2661 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5869: loss = 0.0746 (0.394 sec/step)\n",
            "I0205 13:57:30.632787 140689526667136 learning.py:507] global step 5869: loss = 0.0746 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 5870: loss = 0.0593 (0.372 sec/step)\n",
            "I0205 13:57:31.006599 140689526667136 learning.py:507] global step 5870: loss = 0.0593 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 5871: loss = 0.0231 (0.377 sec/step)\n",
            "I0205 13:57:31.384949 140689526667136 learning.py:507] global step 5871: loss = 0.0231 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 5872: loss = 0.3632 (0.384 sec/step)\n",
            "I0205 13:57:31.770877 140689526667136 learning.py:507] global step 5872: loss = 0.3632 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 5873: loss = 0.1428 (0.367 sec/step)\n",
            "I0205 13:57:32.139669 140689526667136 learning.py:507] global step 5873: loss = 0.1428 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 5874: loss = 0.0355 (0.397 sec/step)\n",
            "I0205 13:57:32.538986 140689526667136 learning.py:507] global step 5874: loss = 0.0355 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 5875: loss = 0.0787 (0.408 sec/step)\n",
            "I0205 13:57:32.948234 140689526667136 learning.py:507] global step 5875: loss = 0.0787 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 5876: loss = 0.1073 (0.397 sec/step)\n",
            "I0205 13:57:33.347063 140689526667136 learning.py:507] global step 5876: loss = 0.1073 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 5877: loss = 0.0461 (0.373 sec/step)\n",
            "I0205 13:57:33.722820 140689526667136 learning.py:507] global step 5877: loss = 0.0461 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 5878: loss = 0.0469 (0.379 sec/step)\n",
            "I0205 13:57:34.103554 140689526667136 learning.py:507] global step 5878: loss = 0.0469 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5879: loss = 0.1012 (0.379 sec/step)\n",
            "I0205 13:57:34.483872 140689526667136 learning.py:507] global step 5879: loss = 0.1012 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5880: loss = 0.0261 (0.385 sec/step)\n",
            "I0205 13:57:34.870560 140689526667136 learning.py:507] global step 5880: loss = 0.0261 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 5881: loss = 0.0650 (0.378 sec/step)\n",
            "I0205 13:57:35.250388 140689526667136 learning.py:507] global step 5881: loss = 0.0650 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 5882: loss = 0.2777 (0.360 sec/step)\n",
            "I0205 13:57:35.611946 140689526667136 learning.py:507] global step 5882: loss = 0.2777 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 5883: loss = 0.0578 (0.375 sec/step)\n",
            "I0205 13:57:35.989012 140689526667136 learning.py:507] global step 5883: loss = 0.0578 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 5884: loss = 0.0874 (0.369 sec/step)\n",
            "I0205 13:57:36.359466 140689526667136 learning.py:507] global step 5884: loss = 0.0874 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 5885: loss = 0.1624 (0.385 sec/step)\n",
            "I0205 13:57:36.746356 140689526667136 learning.py:507] global step 5885: loss = 0.1624 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 5886: loss = 0.0599 (0.376 sec/step)\n",
            "I0205 13:57:37.124213 140689526667136 learning.py:507] global step 5886: loss = 0.0599 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5887: loss = 0.1087 (0.378 sec/step)\n",
            "I0205 13:57:37.503511 140689526667136 learning.py:507] global step 5887: loss = 0.1087 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 5888: loss = 0.2166 (0.386 sec/step)\n",
            "I0205 13:57:37.891623 140689526667136 learning.py:507] global step 5888: loss = 0.2166 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 5889: loss = 0.1290 (0.378 sec/step)\n",
            "I0205 13:57:38.271585 140689526667136 learning.py:507] global step 5889: loss = 0.1290 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 5890: loss = 0.4195 (0.369 sec/step)\n",
            "I0205 13:57:38.642521 140689526667136 learning.py:507] global step 5890: loss = 0.4195 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 5891: loss = 0.1622 (0.376 sec/step)\n",
            "I0205 13:57:39.020550 140689526667136 learning.py:507] global step 5891: loss = 0.1622 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5892: loss = 0.0775 (0.384 sec/step)\n",
            "I0205 13:57:39.406557 140689526667136 learning.py:507] global step 5892: loss = 0.0775 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 5893: loss = 0.0564 (0.391 sec/step)\n",
            "I0205 13:57:39.799374 140689526667136 learning.py:507] global step 5893: loss = 0.0564 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 5894: loss = 0.1527 (0.390 sec/step)\n",
            "I0205 13:57:40.191136 140689526667136 learning.py:507] global step 5894: loss = 0.1527 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5895: loss = 0.2316 (0.379 sec/step)\n",
            "I0205 13:57:40.571918 140689526667136 learning.py:507] global step 5895: loss = 0.2316 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5896: loss = 0.0662 (0.391 sec/step)\n",
            "I0205 13:57:40.964561 140689526667136 learning.py:507] global step 5896: loss = 0.0662 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 5897: loss = 0.0420 (0.336 sec/step)\n",
            "I0205 13:57:41.302009 140689526667136 learning.py:507] global step 5897: loss = 0.0420 (0.336 sec/step)\n",
            "INFO:tensorflow:global step 5898: loss = 0.1596 (0.376 sec/step)\n",
            "I0205 13:57:41.679270 140689526667136 learning.py:507] global step 5898: loss = 0.1596 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5899: loss = 0.3342 (0.375 sec/step)\n",
            "I0205 13:57:42.055891 140689526667136 learning.py:507] global step 5899: loss = 0.3342 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 5900: loss = 0.1661 (0.404 sec/step)\n",
            "I0205 13:57:42.462101 140689526667136 learning.py:507] global step 5900: loss = 0.1661 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 5901: loss = 0.0574 (0.382 sec/step)\n",
            "I0205 13:57:42.845477 140689526667136 learning.py:507] global step 5901: loss = 0.0574 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5902: loss = 0.3219 (0.390 sec/step)\n",
            "I0205 13:57:43.237260 140689526667136 learning.py:507] global step 5902: loss = 0.3219 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 5903: loss = 0.2060 (0.387 sec/step)\n",
            "I0205 13:57:43.626267 140689526667136 learning.py:507] global step 5903: loss = 0.2060 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 5904: loss = 0.1207 (0.386 sec/step)\n",
            "I0205 13:57:44.013975 140689526667136 learning.py:507] global step 5904: loss = 0.1207 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 5905: loss = 0.2183 (0.370 sec/step)\n",
            "I0205 13:57:44.385784 140689526667136 learning.py:507] global step 5905: loss = 0.2183 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 5906: loss = 0.0291 (0.394 sec/step)\n",
            "I0205 13:57:44.781413 140689526667136 learning.py:507] global step 5906: loss = 0.0291 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 5907: loss = 0.1201 (0.386 sec/step)\n",
            "I0205 13:57:45.169429 140689526667136 learning.py:507] global step 5907: loss = 0.1201 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 5908: loss = 0.1125 (0.373 sec/step)\n",
            "I0205 13:57:45.544132 140689526667136 learning.py:507] global step 5908: loss = 0.1125 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 5909: loss = 0.1105 (0.389 sec/step)\n",
            "I0205 13:57:45.934726 140689526667136 learning.py:507] global step 5909: loss = 0.1105 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 5910: loss = 0.0356 (0.394 sec/step)\n",
            "I0205 13:57:46.330192 140689526667136 learning.py:507] global step 5910: loss = 0.0356 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 5911: loss = 0.1047 (0.386 sec/step)\n",
            "I0205 13:57:46.718143 140689526667136 learning.py:507] global step 5911: loss = 0.1047 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 5912: loss = 0.1297 (0.383 sec/step)\n",
            "I0205 13:57:47.103043 140689526667136 learning.py:507] global step 5912: loss = 0.1297 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 5913: loss = 0.1434 (0.394 sec/step)\n",
            "I0205 13:57:47.498579 140689526667136 learning.py:507] global step 5913: loss = 0.1434 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 5914: loss = 0.3165 (0.373 sec/step)\n",
            "I0205 13:57:47.873334 140689526667136 learning.py:507] global step 5914: loss = 0.3165 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 5915: loss = 0.0560 (0.382 sec/step)\n",
            "I0205 13:57:48.256559 140689526667136 learning.py:507] global step 5915: loss = 0.0560 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5916: loss = 0.2308 (0.384 sec/step)\n",
            "I0205 13:57:48.642535 140689526667136 learning.py:507] global step 5916: loss = 0.2308 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 5917: loss = 0.1643 (0.387 sec/step)\n",
            "I0205 13:57:49.031056 140689526667136 learning.py:507] global step 5917: loss = 0.1643 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 5918: loss = 0.9003 (0.354 sec/step)\n",
            "I0205 13:57:49.386230 140689526667136 learning.py:507] global step 5918: loss = 0.9003 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 5919: loss = 0.0544 (0.404 sec/step)\n",
            "I0205 13:57:49.792315 140689526667136 learning.py:507] global step 5919: loss = 0.0544 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 5920: loss = 0.5050 (0.383 sec/step)\n",
            "I0205 13:57:50.176651 140689526667136 learning.py:507] global step 5920: loss = 0.5050 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 5921: loss = 0.1625 (0.420 sec/step)\n",
            "I0205 13:57:50.598224 140689526667136 learning.py:507] global step 5921: loss = 0.1625 (0.420 sec/step)\n",
            "INFO:tensorflow:global step 5922: loss = 0.0988 (0.387 sec/step)\n",
            "I0205 13:57:50.987026 140689526667136 learning.py:507] global step 5922: loss = 0.0988 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 5923: loss = 0.3060 (0.379 sec/step)\n",
            "I0205 13:57:51.367502 140689526667136 learning.py:507] global step 5923: loss = 0.3060 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5924: loss = 0.2940 (0.371 sec/step)\n",
            "I0205 13:57:51.740615 140689526667136 learning.py:507] global step 5924: loss = 0.2940 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 5925: loss = 0.1569 (0.397 sec/step)\n",
            "I0205 13:57:52.139962 140689526667136 learning.py:507] global step 5925: loss = 0.1569 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 5926: loss = 0.1244 (0.411 sec/step)\n",
            "I0205 13:57:52.552647 140689526667136 learning.py:507] global step 5926: loss = 0.1244 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 5927: loss = 0.1419 (0.413 sec/step)\n",
            "I0205 13:57:52.967088 140689526667136 learning.py:507] global step 5927: loss = 0.1419 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 5928: loss = 0.0739 (0.371 sec/step)\n",
            "I0205 13:57:53.339591 140689526667136 learning.py:507] global step 5928: loss = 0.0739 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 5929: loss = 0.0611 (0.364 sec/step)\n",
            "I0205 13:57:53.705131 140689526667136 learning.py:507] global step 5929: loss = 0.0611 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 5930: loss = 0.1118 (0.413 sec/step)\n",
            "I0205 13:57:54.119523 140689526667136 learning.py:507] global step 5930: loss = 0.1118 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 5931: loss = 0.0445 (0.351 sec/step)\n",
            "I0205 13:57:54.472050 140689526667136 learning.py:507] global step 5931: loss = 0.0445 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 5932: loss = 0.0799 (0.374 sec/step)\n",
            "I0205 13:57:54.848805 140689526667136 learning.py:507] global step 5932: loss = 0.0799 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 5933: loss = 0.3526 (0.400 sec/step)\n",
            "I0205 13:57:55.250901 140689526667136 learning.py:507] global step 5933: loss = 0.3526 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 5934: loss = 0.3186 (0.367 sec/step)\n",
            "I0205 13:57:55.619617 140689526667136 learning.py:507] global step 5934: loss = 0.3186 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 5935: loss = 0.0561 (0.388 sec/step)\n",
            "I0205 13:57:56.008914 140689526667136 learning.py:507] global step 5935: loss = 0.0561 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 5936: loss = 0.2765 (0.381 sec/step)\n",
            "I0205 13:57:56.391439 140689526667136 learning.py:507] global step 5936: loss = 0.2765 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 5937: loss = 0.1072 (0.383 sec/step)\n",
            "I0205 13:57:56.776095 140689526667136 learning.py:507] global step 5937: loss = 0.1072 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 5938: loss = 0.0604 (0.388 sec/step)\n",
            "I0205 13:57:57.165329 140689526667136 learning.py:507] global step 5938: loss = 0.0604 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 5939: loss = 0.2822 (0.384 sec/step)\n",
            "I0205 13:57:57.551551 140689526667136 learning.py:507] global step 5939: loss = 0.2822 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 5940: loss = 0.0571 (0.379 sec/step)\n",
            "I0205 13:57:57.932652 140689526667136 learning.py:507] global step 5940: loss = 0.0571 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5941: loss = 0.0953 (0.411 sec/step)\n",
            "I0205 13:57:58.345153 140689526667136 learning.py:507] global step 5941: loss = 0.0953 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 5942: loss = 0.1024 (0.378 sec/step)\n",
            "I0205 13:57:58.724875 140689526667136 learning.py:507] global step 5942: loss = 0.1024 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 5943: loss = 0.1457 (0.405 sec/step)\n",
            "I0205 13:57:59.131079 140689526667136 learning.py:507] global step 5943: loss = 0.1457 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 5944: loss = 0.0962 (0.408 sec/step)\n",
            "I0205 13:57:59.541023 140689526667136 learning.py:507] global step 5944: loss = 0.0962 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 5945: loss = 0.1467 (0.353 sec/step)\n",
            "I0205 13:57:59.895085 140689526667136 learning.py:507] global step 5945: loss = 0.1467 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 5946: loss = 0.0721 (0.369 sec/step)\n",
            "I0205 13:58:00.265780 140689526667136 learning.py:507] global step 5946: loss = 0.0721 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 5947: loss = 0.0254 (0.356 sec/step)\n",
            "I0205 13:58:00.623131 140689526667136 learning.py:507] global step 5947: loss = 0.0254 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 5948: loss = 0.3058 (0.373 sec/step)\n",
            "I0205 13:58:00.997466 140689526667136 learning.py:507] global step 5948: loss = 0.3058 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 5949: loss = 0.1752 (0.398 sec/step)\n",
            "I0205 13:58:01.397539 140689526667136 learning.py:507] global step 5949: loss = 0.1752 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 5950: loss = 0.1774 (0.382 sec/step)\n",
            "I0205 13:58:01.781026 140689526667136 learning.py:507] global step 5950: loss = 0.1774 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5951: loss = 0.1240 (0.394 sec/step)\n",
            "I0205 13:58:02.176628 140689526667136 learning.py:507] global step 5951: loss = 0.1240 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 5952: loss = 0.0571 (0.360 sec/step)\n",
            "I0205 13:58:02.537778 140689526667136 learning.py:507] global step 5952: loss = 0.0571 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 5953: loss = 0.3431 (0.393 sec/step)\n",
            "I0205 13:58:02.933271 140689526667136 learning.py:507] global step 5953: loss = 0.3431 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 5954: loss = 0.0261 (0.405 sec/step)\n",
            "I0205 13:58:03.340288 140689526667136 learning.py:507] global step 5954: loss = 0.0261 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 5955: loss = 0.0804 (0.373 sec/step)\n",
            "I0205 13:58:03.714943 140689526667136 learning.py:507] global step 5955: loss = 0.0804 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 5956: loss = 0.2787 (0.362 sec/step)\n",
            "I0205 13:58:04.078589 140689526667136 learning.py:507] global step 5956: loss = 0.2787 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 5957: loss = 0.1261 (0.381 sec/step)\n",
            "I0205 13:58:04.461566 140689526667136 learning.py:507] global step 5957: loss = 0.1261 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 5958: loss = 0.0901 (0.382 sec/step)\n",
            "I0205 13:58:04.845524 140689526667136 learning.py:507] global step 5958: loss = 0.0901 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5959: loss = 0.1166 (0.403 sec/step)\n",
            "I0205 13:58:05.250396 140689526667136 learning.py:507] global step 5959: loss = 0.1166 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 5960: loss = 0.4507 (0.374 sec/step)\n",
            "I0205 13:58:05.626478 140689526667136 learning.py:507] global step 5960: loss = 0.4507 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 5961: loss = 0.1310 (0.355 sec/step)\n",
            "I0205 13:58:05.983315 140689526667136 learning.py:507] global step 5961: loss = 0.1310 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 5962: loss = 0.1324 (0.376 sec/step)\n",
            "I0205 13:58:06.361002 140689526667136 learning.py:507] global step 5962: loss = 0.1324 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5963: loss = 0.3182 (0.365 sec/step)\n",
            "I0205 13:58:06.728023 140689526667136 learning.py:507] global step 5963: loss = 0.3182 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 5964: loss = 0.0533 (0.357 sec/step)\n",
            "I0205 13:58:07.086133 140689526667136 learning.py:507] global step 5964: loss = 0.0533 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 5965: loss = 0.0868 (0.391 sec/step)\n",
            "I0205 13:58:07.478244 140689526667136 learning.py:507] global step 5965: loss = 0.0868 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 5966: loss = 0.0521 (0.376 sec/step)\n",
            "I0205 13:58:07.855746 140689526667136 learning.py:507] global step 5966: loss = 0.0521 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 5967: loss = 0.3029 (0.369 sec/step)\n",
            "I0205 13:58:08.229973 140689526667136 learning.py:507] global step 5967: loss = 0.3029 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 5968: loss = 0.2854 (0.380 sec/step)\n",
            "I0205 13:58:08.612235 140689526667136 learning.py:507] global step 5968: loss = 0.2854 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 5969: loss = 0.1400 (0.404 sec/step)\n",
            "I0205 13:58:09.017556 140689526667136 learning.py:507] global step 5969: loss = 0.1400 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 5970: loss = 0.1311 (0.382 sec/step)\n",
            "I0205 13:58:09.401014 140689526667136 learning.py:507] global step 5970: loss = 0.1311 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5971: loss = 0.1491 (0.352 sec/step)\n",
            "I0205 13:58:09.754123 140689526667136 learning.py:507] global step 5971: loss = 0.1491 (0.352 sec/step)\n",
            "INFO:tensorflow:global step 5972: loss = 0.0874 (0.371 sec/step)\n",
            "I0205 13:58:10.126768 140689526667136 learning.py:507] global step 5972: loss = 0.0874 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 5973: loss = 0.1506 (0.379 sec/step)\n",
            "I0205 13:58:10.507493 140689526667136 learning.py:507] global step 5973: loss = 0.1506 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5974: loss = 0.0726 (0.380 sec/step)\n",
            "I0205 13:58:10.889649 140689526667136 learning.py:507] global step 5974: loss = 0.0726 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 5975: loss = 0.0340 (0.362 sec/step)\n",
            "I0205 13:58:11.253557 140689526667136 learning.py:507] global step 5975: loss = 0.0340 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 5976: loss = 0.0515 (0.365 sec/step)\n",
            "I0205 13:58:11.620545 140689526667136 learning.py:507] global step 5976: loss = 0.0515 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 5977: loss = 0.0445 (0.391 sec/step)\n",
            "I0205 13:58:12.012951 140689526667136 learning.py:507] global step 5977: loss = 0.0445 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 5978: loss = 0.1024 (0.401 sec/step)\n",
            "I0205 13:58:12.415142 140689526667136 learning.py:507] global step 5978: loss = 0.1024 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 5979: loss = 0.1150 (0.387 sec/step)\n",
            "I0205 13:58:12.803716 140689526667136 learning.py:507] global step 5979: loss = 0.1150 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 5980: loss = 0.1414 (0.354 sec/step)\n",
            "I0205 13:58:13.159353 140689526667136 learning.py:507] global step 5980: loss = 0.1414 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 5981: loss = 0.2823 (0.386 sec/step)\n",
            "I0205 13:58:13.547040 140689526667136 learning.py:507] global step 5981: loss = 0.2823 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 5982: loss = 0.0542 (0.412 sec/step)\n",
            "I0205 13:58:13.979392 140689526667136 learning.py:507] global step 5982: loss = 0.0542 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 5983: loss = 0.0459 (0.684 sec/step)\n",
            "I0205 13:58:14.810501 140689526667136 learning.py:507] global step 5983: loss = 0.0459 (0.684 sec/step)\n",
            "INFO:tensorflow:global step 5984: loss = 0.0428 (0.798 sec/step)\n",
            "I0205 13:58:15.821575 140689526667136 learning.py:507] global step 5984: loss = 0.0428 (0.798 sec/step)\n",
            "INFO:tensorflow:global step 5985: loss = 0.0730 (0.637 sec/step)\n",
            "I0205 13:58:16.497877 140689526667136 learning.py:507] global step 5985: loss = 0.0730 (0.637 sec/step)\n",
            "INFO:tensorflow:global step 5986: loss = 0.8834 (0.550 sec/step)\n",
            "I0205 13:58:17.053327 140689526667136 learning.py:507] global step 5986: loss = 0.8834 (0.550 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 5986.\n",
            "I0205 13:58:17.510725 140686026073856 supervisor.py:1050] Recording summary at step 5986.\n",
            "INFO:tensorflow:global step 5987: loss = 0.8206 (0.477 sec/step)\n",
            "I0205 13:58:17.534595 140689526667136 learning.py:507] global step 5987: loss = 0.8206 (0.477 sec/step)\n",
            "INFO:tensorflow:global step 5988: loss = 0.1449 (0.371 sec/step)\n",
            "I0205 13:58:17.906668 140689526667136 learning.py:507] global step 5988: loss = 0.1449 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 5989: loss = 0.3970 (0.365 sec/step)\n",
            "I0205 13:58:18.273247 140689526667136 learning.py:507] global step 5989: loss = 0.3970 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 5990: loss = 0.2436 (0.381 sec/step)\n",
            "I0205 13:58:18.656054 140689526667136 learning.py:507] global step 5990: loss = 0.2436 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 5991: loss = 0.0329 (0.389 sec/step)\n",
            "I0205 13:58:19.046403 140689526667136 learning.py:507] global step 5991: loss = 0.0329 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 5992: loss = 0.2468 (0.385 sec/step)\n",
            "I0205 13:58:19.432875 140689526667136 learning.py:507] global step 5992: loss = 0.2468 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 5993: loss = 0.3375 (0.396 sec/step)\n",
            "I0205 13:58:19.830899 140689526667136 learning.py:507] global step 5993: loss = 0.3375 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 5994: loss = 0.2438 (0.386 sec/step)\n",
            "I0205 13:58:20.218678 140689526667136 learning.py:507] global step 5994: loss = 0.2438 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 5995: loss = 0.2627 (0.379 sec/step)\n",
            "I0205 13:58:20.598915 140689526667136 learning.py:507] global step 5995: loss = 0.2627 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 5996: loss = 0.1412 (0.374 sec/step)\n",
            "I0205 13:58:20.974389 140689526667136 learning.py:507] global step 5996: loss = 0.1412 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 5997: loss = 0.0682 (0.403 sec/step)\n",
            "I0205 13:58:21.379182 140689526667136 learning.py:507] global step 5997: loss = 0.0682 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 5998: loss = 0.2413 (0.382 sec/step)\n",
            "I0205 13:58:21.763062 140689526667136 learning.py:507] global step 5998: loss = 0.2413 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 5999: loss = 0.0784 (0.344 sec/step)\n",
            "I0205 13:58:22.108791 140689526667136 learning.py:507] global step 5999: loss = 0.0784 (0.344 sec/step)\n",
            "INFO:tensorflow:global step 6000: loss = 0.2045 (0.403 sec/step)\n",
            "I0205 13:58:22.513492 140689526667136 learning.py:507] global step 6000: loss = 0.2045 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 6001: loss = 0.0349 (0.382 sec/step)\n",
            "I0205 13:58:22.896862 140689526667136 learning.py:507] global step 6001: loss = 0.0349 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 6002: loss = 0.3436 (0.408 sec/step)\n",
            "I0205 13:58:23.306195 140689526667136 learning.py:507] global step 6002: loss = 0.3436 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 6003: loss = 0.1895 (0.410 sec/step)\n",
            "I0205 13:58:23.717453 140689526667136 learning.py:507] global step 6003: loss = 0.1895 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 6004: loss = 0.1300 (0.425 sec/step)\n",
            "I0205 13:58:24.143886 140689526667136 learning.py:507] global step 6004: loss = 0.1300 (0.425 sec/step)\n",
            "INFO:tensorflow:global step 6005: loss = 0.1451 (0.408 sec/step)\n",
            "I0205 13:58:24.554250 140689526667136 learning.py:507] global step 6005: loss = 0.1451 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 6006: loss = 0.1253 (0.393 sec/step)\n",
            "I0205 13:58:24.949254 140689526667136 learning.py:507] global step 6006: loss = 0.1253 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 6007: loss = 0.0724 (0.414 sec/step)\n",
            "I0205 13:58:25.364948 140689526667136 learning.py:507] global step 6007: loss = 0.0724 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 6008: loss = 0.1634 (0.413 sec/step)\n",
            "I0205 13:58:25.779751 140689526667136 learning.py:507] global step 6008: loss = 0.1634 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 6009: loss = 0.1544 (0.389 sec/step)\n",
            "I0205 13:58:26.170822 140689526667136 learning.py:507] global step 6009: loss = 0.1544 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 6010: loss = 0.3945 (0.401 sec/step)\n",
            "I0205 13:58:26.574212 140689526667136 learning.py:507] global step 6010: loss = 0.3945 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 6011: loss = 0.4384 (0.394 sec/step)\n",
            "I0205 13:58:26.969947 140689526667136 learning.py:507] global step 6011: loss = 0.4384 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 6012: loss = 0.0457 (0.399 sec/step)\n",
            "I0205 13:58:27.370632 140689526667136 learning.py:507] global step 6012: loss = 0.0457 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 6013: loss = 0.1378 (0.400 sec/step)\n",
            "I0205 13:58:27.772082 140689526667136 learning.py:507] global step 6013: loss = 0.1378 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 6014: loss = 0.1998 (0.373 sec/step)\n",
            "I0205 13:58:28.146643 140689526667136 learning.py:507] global step 6014: loss = 0.1998 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 6015: loss = 0.1009 (0.379 sec/step)\n",
            "I0205 13:58:28.527120 140689526667136 learning.py:507] global step 6015: loss = 0.1009 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 6016: loss = 0.0581 (0.404 sec/step)\n",
            "I0205 13:58:28.932697 140689526667136 learning.py:507] global step 6016: loss = 0.0581 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 6017: loss = 0.1062 (0.398 sec/step)\n",
            "I0205 13:58:29.332210 140689526667136 learning.py:507] global step 6017: loss = 0.1062 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 6018: loss = 0.4995 (0.418 sec/step)\n",
            "I0205 13:58:29.751837 140689526667136 learning.py:507] global step 6018: loss = 0.4995 (0.418 sec/step)\n",
            "INFO:tensorflow:global step 6019: loss = 0.1093 (0.429 sec/step)\n",
            "I0205 13:58:30.182752 140689526667136 learning.py:507] global step 6019: loss = 0.1093 (0.429 sec/step)\n",
            "INFO:tensorflow:global step 6020: loss = 0.0651 (0.390 sec/step)\n",
            "I0205 13:58:30.574557 140689526667136 learning.py:507] global step 6020: loss = 0.0651 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 6021: loss = 0.2118 (0.397 sec/step)\n",
            "I0205 13:58:30.973727 140689526667136 learning.py:507] global step 6021: loss = 0.2118 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 6022: loss = 0.4149 (0.390 sec/step)\n",
            "I0205 13:58:31.365521 140689526667136 learning.py:507] global step 6022: loss = 0.4149 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 6023: loss = 0.1123 (0.376 sec/step)\n",
            "I0205 13:58:31.743134 140689526667136 learning.py:507] global step 6023: loss = 0.1123 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 6024: loss = 0.0841 (0.389 sec/step)\n",
            "I0205 13:58:32.133902 140689526667136 learning.py:507] global step 6024: loss = 0.0841 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 6025: loss = 0.0462 (0.387 sec/step)\n",
            "I0205 13:58:32.522375 140689526667136 learning.py:507] global step 6025: loss = 0.0462 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 6026: loss = 0.2051 (0.397 sec/step)\n",
            "I0205 13:58:32.921763 140689526667136 learning.py:507] global step 6026: loss = 0.2051 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 6027: loss = 0.2704 (0.391 sec/step)\n",
            "I0205 13:58:33.314601 140689526667136 learning.py:507] global step 6027: loss = 0.2704 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6028: loss = 0.0454 (0.391 sec/step)\n",
            "I0205 13:58:33.706856 140689526667136 learning.py:507] global step 6028: loss = 0.0454 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6029: loss = 0.1614 (0.393 sec/step)\n",
            "I0205 13:58:34.101601 140689526667136 learning.py:507] global step 6029: loss = 0.1614 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 6030: loss = 0.5796 (0.369 sec/step)\n",
            "I0205 13:58:34.472019 140689526667136 learning.py:507] global step 6030: loss = 0.5796 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 6031: loss = 0.1626 (0.369 sec/step)\n",
            "I0205 13:58:34.842315 140689526667136 learning.py:507] global step 6031: loss = 0.1626 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 6032: loss = 0.0980 (0.393 sec/step)\n",
            "I0205 13:58:35.236763 140689526667136 learning.py:507] global step 6032: loss = 0.0980 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 6033: loss = 0.2514 (0.379 sec/step)\n",
            "I0205 13:58:35.616927 140689526667136 learning.py:507] global step 6033: loss = 0.2514 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 6034: loss = 0.1181 (0.353 sec/step)\n",
            "I0205 13:58:35.971546 140689526667136 learning.py:507] global step 6034: loss = 0.1181 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 6035: loss = 0.1902 (0.385 sec/step)\n",
            "I0205 13:58:36.358460 140689526667136 learning.py:507] global step 6035: loss = 0.1902 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 6036: loss = 0.0589 (0.379 sec/step)\n",
            "I0205 13:58:36.738850 140689526667136 learning.py:507] global step 6036: loss = 0.0589 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 6037: loss = 0.2177 (0.373 sec/step)\n",
            "I0205 13:58:37.113883 140689526667136 learning.py:507] global step 6037: loss = 0.2177 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 6038: loss = 0.0657 (0.396 sec/step)\n",
            "I0205 13:58:37.512069 140689526667136 learning.py:507] global step 6038: loss = 0.0657 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 6039: loss = 0.1564 (0.398 sec/step)\n",
            "I0205 13:58:37.911253 140689526667136 learning.py:507] global step 6039: loss = 0.1564 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 6040: loss = 0.0633 (0.391 sec/step)\n",
            "I0205 13:58:38.303956 140689526667136 learning.py:507] global step 6040: loss = 0.0633 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6041: loss = 0.1496 (0.408 sec/step)\n",
            "I0205 13:58:38.713318 140689526667136 learning.py:507] global step 6041: loss = 0.1496 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 6042: loss = 0.1206 (0.387 sec/step)\n",
            "I0205 13:58:39.102309 140689526667136 learning.py:507] global step 6042: loss = 0.1206 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 6043: loss = 0.0530 (0.356 sec/step)\n",
            "I0205 13:58:39.459938 140689526667136 learning.py:507] global step 6043: loss = 0.0530 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 6044: loss = 0.2158 (0.369 sec/step)\n",
            "I0205 13:58:39.830579 140689526667136 learning.py:507] global step 6044: loss = 0.2158 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 6045: loss = 0.0625 (0.401 sec/step)\n",
            "I0205 13:58:40.233224 140689526667136 learning.py:507] global step 6045: loss = 0.0625 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 6046: loss = 0.6504 (0.369 sec/step)\n",
            "I0205 13:58:40.604228 140689526667136 learning.py:507] global step 6046: loss = 0.6504 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 6047: loss = 0.2442 (0.383 sec/step)\n",
            "I0205 13:58:40.989075 140689526667136 learning.py:507] global step 6047: loss = 0.2442 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 6048: loss = 0.9572 (0.384 sec/step)\n",
            "I0205 13:58:41.375019 140689526667136 learning.py:507] global step 6048: loss = 0.9572 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6049: loss = 0.1483 (0.390 sec/step)\n",
            "I0205 13:58:41.768674 140689526667136 learning.py:507] global step 6049: loss = 0.1483 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 6050: loss = 0.5235 (0.362 sec/step)\n",
            "I0205 13:58:42.133558 140689526667136 learning.py:507] global step 6050: loss = 0.5235 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 6051: loss = 0.6437 (0.382 sec/step)\n",
            "I0205 13:58:42.517596 140689526667136 learning.py:507] global step 6051: loss = 0.6437 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 6052: loss = 0.1622 (0.407 sec/step)\n",
            "I0205 13:58:42.926349 140689526667136 learning.py:507] global step 6052: loss = 0.1622 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 6053: loss = 0.0588 (0.403 sec/step)\n",
            "I0205 13:58:43.331094 140689526667136 learning.py:507] global step 6053: loss = 0.0588 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 6054: loss = 0.2432 (0.398 sec/step)\n",
            "I0205 13:58:43.730299 140689526667136 learning.py:507] global step 6054: loss = 0.2432 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 6055: loss = 0.0809 (0.392 sec/step)\n",
            "I0205 13:58:44.123828 140689526667136 learning.py:507] global step 6055: loss = 0.0809 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 6056: loss = 0.3104 (0.411 sec/step)\n",
            "I0205 13:58:44.536993 140689526667136 learning.py:507] global step 6056: loss = 0.3104 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 6057: loss = 0.1231 (0.407 sec/step)\n",
            "I0205 13:58:44.946069 140689526667136 learning.py:507] global step 6057: loss = 0.1231 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 6058: loss = 0.0925 (0.404 sec/step)\n",
            "I0205 13:58:45.352469 140689526667136 learning.py:507] global step 6058: loss = 0.0925 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 6059: loss = 0.3050 (0.407 sec/step)\n",
            "I0205 13:58:45.761432 140689526667136 learning.py:507] global step 6059: loss = 0.3050 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 6060: loss = 0.1536 (0.379 sec/step)\n",
            "I0205 13:58:46.141812 140689526667136 learning.py:507] global step 6060: loss = 0.1536 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 6061: loss = 0.0753 (0.417 sec/step)\n",
            "I0205 13:58:46.560307 140689526667136 learning.py:507] global step 6061: loss = 0.0753 (0.417 sec/step)\n",
            "INFO:tensorflow:global step 6062: loss = 0.0483 (0.405 sec/step)\n",
            "I0205 13:58:46.966835 140689526667136 learning.py:507] global step 6062: loss = 0.0483 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 6063: loss = 0.4003 (0.396 sec/step)\n",
            "I0205 13:58:47.364542 140689526667136 learning.py:507] global step 6063: loss = 0.4003 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 6064: loss = 0.9583 (0.416 sec/step)\n",
            "I0205 13:58:47.781905 140689526667136 learning.py:507] global step 6064: loss = 0.9583 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 6065: loss = 0.0869 (0.393 sec/step)\n",
            "I0205 13:58:48.176457 140689526667136 learning.py:507] global step 6065: loss = 0.0869 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 6066: loss = 0.1296 (0.478 sec/step)\n",
            "I0205 13:58:48.656314 140689526667136 learning.py:507] global step 6066: loss = 0.1296 (0.478 sec/step)\n",
            "INFO:tensorflow:global step 6067: loss = 0.0381 (0.378 sec/step)\n",
            "I0205 13:58:49.035926 140689526667136 learning.py:507] global step 6067: loss = 0.0381 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 6068: loss = 0.1430 (0.394 sec/step)\n",
            "I0205 13:58:49.431945 140689526667136 learning.py:507] global step 6068: loss = 0.1430 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 6069: loss = 0.1231 (0.404 sec/step)\n",
            "I0205 13:58:49.837440 140689526667136 learning.py:507] global step 6069: loss = 0.1231 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 6070: loss = 0.2100 (0.379 sec/step)\n",
            "I0205 13:58:50.217630 140689526667136 learning.py:507] global step 6070: loss = 0.2100 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 6071: loss = 0.1352 (0.396 sec/step)\n",
            "I0205 13:58:50.615250 140689526667136 learning.py:507] global step 6071: loss = 0.1352 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 6072: loss = 0.1170 (0.359 sec/step)\n",
            "I0205 13:58:50.975809 140689526667136 learning.py:507] global step 6072: loss = 0.1170 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 6073: loss = 0.0476 (0.372 sec/step)\n",
            "I0205 13:58:51.349372 140689526667136 learning.py:507] global step 6073: loss = 0.0476 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 6074: loss = 0.0897 (0.377 sec/step)\n",
            "I0205 13:58:51.727382 140689526667136 learning.py:507] global step 6074: loss = 0.0897 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 6075: loss = 0.1792 (0.385 sec/step)\n",
            "I0205 13:58:52.113809 140689526667136 learning.py:507] global step 6075: loss = 0.1792 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 6076: loss = 0.9792 (0.419 sec/step)\n",
            "I0205 13:58:52.534798 140689526667136 learning.py:507] global step 6076: loss = 0.9792 (0.419 sec/step)\n",
            "INFO:tensorflow:global step 6077: loss = 0.0939 (0.425 sec/step)\n",
            "I0205 13:58:52.961347 140689526667136 learning.py:507] global step 6077: loss = 0.0939 (0.425 sec/step)\n",
            "INFO:tensorflow:global step 6078: loss = 0.0300 (0.414 sec/step)\n",
            "I0205 13:58:53.376806 140689526667136 learning.py:507] global step 6078: loss = 0.0300 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 6079: loss = 0.1041 (0.372 sec/step)\n",
            "I0205 13:58:53.750447 140689526667136 learning.py:507] global step 6079: loss = 0.1041 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 6080: loss = 0.1349 (0.377 sec/step)\n",
            "I0205 13:58:54.129247 140689526667136 learning.py:507] global step 6080: loss = 0.1349 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 6081: loss = 0.1990 (0.403 sec/step)\n",
            "I0205 13:58:54.534180 140689526667136 learning.py:507] global step 6081: loss = 0.1990 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 6082: loss = 0.1201 (0.420 sec/step)\n",
            "I0205 13:58:54.955595 140689526667136 learning.py:507] global step 6082: loss = 0.1201 (0.420 sec/step)\n",
            "INFO:tensorflow:global step 6083: loss = 0.1265 (0.383 sec/step)\n",
            "I0205 13:58:55.340347 140689526667136 learning.py:507] global step 6083: loss = 0.1265 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 6084: loss = 0.1760 (0.395 sec/step)\n",
            "I0205 13:58:55.737282 140689526667136 learning.py:507] global step 6084: loss = 0.1760 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 6085: loss = 0.1278 (0.371 sec/step)\n",
            "I0205 13:58:56.109844 140689526667136 learning.py:507] global step 6085: loss = 0.1278 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 6086: loss = 0.1984 (0.382 sec/step)\n",
            "I0205 13:58:56.493126 140689526667136 learning.py:507] global step 6086: loss = 0.1984 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 6087: loss = 0.0876 (0.394 sec/step)\n",
            "I0205 13:58:56.888588 140689526667136 learning.py:507] global step 6087: loss = 0.0876 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 6088: loss = 0.0763 (0.378 sec/step)\n",
            "I0205 13:58:57.267815 140689526667136 learning.py:507] global step 6088: loss = 0.0763 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 6089: loss = 0.4234 (0.368 sec/step)\n",
            "I0205 13:58:57.637509 140689526667136 learning.py:507] global step 6089: loss = 0.4234 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 6090: loss = 0.1039 (0.368 sec/step)\n",
            "I0205 13:58:58.007238 140689526667136 learning.py:507] global step 6090: loss = 0.1039 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 6091: loss = 0.0985 (0.385 sec/step)\n",
            "I0205 13:58:58.393724 140689526667136 learning.py:507] global step 6091: loss = 0.0985 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 6092: loss = 0.0783 (0.377 sec/step)\n",
            "I0205 13:58:58.772887 140689526667136 learning.py:507] global step 6092: loss = 0.0783 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 6093: loss = 1.0807 (0.358 sec/step)\n",
            "I0205 13:58:59.132429 140689526667136 learning.py:507] global step 6093: loss = 1.0807 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 6094: loss = 0.0547 (0.366 sec/step)\n",
            "I0205 13:58:59.500186 140689526667136 learning.py:507] global step 6094: loss = 0.0547 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 6095: loss = 0.1229 (0.394 sec/step)\n",
            "I0205 13:58:59.896084 140689526667136 learning.py:507] global step 6095: loss = 0.1229 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 6096: loss = 0.1611 (0.380 sec/step)\n",
            "I0205 13:59:00.278110 140689526667136 learning.py:507] global step 6096: loss = 0.1611 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 6097: loss = 0.0892 (0.391 sec/step)\n",
            "I0205 13:59:00.671182 140689526667136 learning.py:507] global step 6097: loss = 0.0892 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6098: loss = 0.3692 (0.353 sec/step)\n",
            "I0205 13:59:01.026828 140689526667136 learning.py:507] global step 6098: loss = 0.3692 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 6099: loss = 0.0851 (0.385 sec/step)\n",
            "I0205 13:59:01.413135 140689526667136 learning.py:507] global step 6099: loss = 0.0851 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 6100: loss = 0.2010 (0.401 sec/step)\n",
            "I0205 13:59:01.815351 140689526667136 learning.py:507] global step 6100: loss = 0.2010 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 6101: loss = 0.3212 (0.399 sec/step)\n",
            "I0205 13:59:02.216254 140689526667136 learning.py:507] global step 6101: loss = 0.3212 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 6102: loss = 0.0529 (0.390 sec/step)\n",
            "I0205 13:59:02.607683 140689526667136 learning.py:507] global step 6102: loss = 0.0529 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 6103: loss = 0.1250 (0.403 sec/step)\n",
            "I0205 13:59:03.013391 140689526667136 learning.py:507] global step 6103: loss = 0.1250 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 6104: loss = 0.0904 (0.396 sec/step)\n",
            "I0205 13:59:03.410919 140689526667136 learning.py:507] global step 6104: loss = 0.0904 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 6105: loss = 0.1031 (0.371 sec/step)\n",
            "I0205 13:59:03.783142 140689526667136 learning.py:507] global step 6105: loss = 0.1031 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 6106: loss = 0.2105 (0.343 sec/step)\n",
            "I0205 13:59:04.127667 140689526667136 learning.py:507] global step 6106: loss = 0.2105 (0.343 sec/step)\n",
            "INFO:tensorflow:global step 6107: loss = 0.4225 (0.374 sec/step)\n",
            "I0205 13:59:04.502945 140689526667136 learning.py:507] global step 6107: loss = 0.4225 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 6108: loss = 0.0484 (0.391 sec/step)\n",
            "I0205 13:59:04.895238 140689526667136 learning.py:507] global step 6108: loss = 0.0484 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6109: loss = 0.1318 (0.371 sec/step)\n",
            "I0205 13:59:05.267452 140689526667136 learning.py:507] global step 6109: loss = 0.1318 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 6110: loss = 0.2625 (0.375 sec/step)\n",
            "I0205 13:59:05.643864 140689526667136 learning.py:507] global step 6110: loss = 0.2625 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 6111: loss = 0.0273 (0.377 sec/step)\n",
            "I0205 13:59:06.022028 140689526667136 learning.py:507] global step 6111: loss = 0.0273 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 6112: loss = 0.1791 (0.374 sec/step)\n",
            "I0205 13:59:06.397950 140689526667136 learning.py:507] global step 6112: loss = 0.1791 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 6113: loss = 0.1031 (0.402 sec/step)\n",
            "I0205 13:59:06.804802 140689526667136 learning.py:507] global step 6113: loss = 0.1031 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 6114: loss = 0.3240 (0.391 sec/step)\n",
            "I0205 13:59:07.197967 140689526667136 learning.py:507] global step 6114: loss = 0.3240 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6115: loss = 0.1213 (0.371 sec/step)\n",
            "I0205 13:59:07.570880 140689526667136 learning.py:507] global step 6115: loss = 0.1213 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 6116: loss = 1.1531 (0.411 sec/step)\n",
            "I0205 13:59:07.983933 140689526667136 learning.py:507] global step 6116: loss = 1.1531 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 6117: loss = 0.0495 (0.421 sec/step)\n",
            "I0205 13:59:08.407647 140689526667136 learning.py:507] global step 6117: loss = 0.0495 (0.421 sec/step)\n",
            "INFO:tensorflow:global step 6118: loss = 0.1533 (0.399 sec/step)\n",
            "I0205 13:59:08.809845 140689526667136 learning.py:507] global step 6118: loss = 0.1533 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 6119: loss = 0.0560 (0.376 sec/step)\n",
            "I0205 13:59:09.187156 140689526667136 learning.py:507] global step 6119: loss = 0.0560 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 6120: loss = 0.0554 (0.361 sec/step)\n",
            "I0205 13:59:09.550935 140689526667136 learning.py:507] global step 6120: loss = 0.0554 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 6121: loss = 0.1687 (0.370 sec/step)\n",
            "I0205 13:59:09.922379 140689526667136 learning.py:507] global step 6121: loss = 0.1687 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 6122: loss = 0.2412 (0.377 sec/step)\n",
            "I0205 13:59:10.301146 140689526667136 learning.py:507] global step 6122: loss = 0.2412 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 6123: loss = 0.1897 (0.374 sec/step)\n",
            "I0205 13:59:10.677320 140689526667136 learning.py:507] global step 6123: loss = 0.1897 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 6124: loss = 0.0326 (0.386 sec/step)\n",
            "I0205 13:59:11.065253 140689526667136 learning.py:507] global step 6124: loss = 0.0326 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 6125: loss = 0.0841 (0.370 sec/step)\n",
            "I0205 13:59:11.437239 140689526667136 learning.py:507] global step 6125: loss = 0.0841 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 6126: loss = 0.2511 (0.375 sec/step)\n",
            "I0205 13:59:11.813515 140689526667136 learning.py:507] global step 6126: loss = 0.2511 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 6127: loss = 0.0578 (0.389 sec/step)\n",
            "I0205 13:59:12.203640 140689526667136 learning.py:507] global step 6127: loss = 0.0578 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 6128: loss = 0.3886 (0.391 sec/step)\n",
            "I0205 13:59:12.596782 140689526667136 learning.py:507] global step 6128: loss = 0.3886 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6129: loss = 0.0224 (0.390 sec/step)\n",
            "I0205 13:59:12.988139 140689526667136 learning.py:507] global step 6129: loss = 0.0224 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 6130: loss = 0.0698 (0.363 sec/step)\n",
            "I0205 13:59:13.352907 140689526667136 learning.py:507] global step 6130: loss = 0.0698 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 6131: loss = 0.1774 (0.374 sec/step)\n",
            "I0205 13:59:13.728469 140689526667136 learning.py:507] global step 6131: loss = 0.1774 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 6132: loss = 0.4303 (0.519 sec/step)\n",
            "I0205 13:59:14.249233 140689526667136 learning.py:507] global step 6132: loss = 0.4303 (0.519 sec/step)\n",
            "INFO:tensorflow:global step 6133: loss = 0.2014 (0.339 sec/step)\n",
            "I0205 13:59:14.590060 140689526667136 learning.py:507] global step 6133: loss = 0.2014 (0.339 sec/step)\n",
            "INFO:tensorflow:global step 6134: loss = 0.0769 (0.371 sec/step)\n",
            "I0205 13:59:14.963068 140689526667136 learning.py:507] global step 6134: loss = 0.0769 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 6135: loss = 0.1194 (0.372 sec/step)\n",
            "I0205 13:59:15.336753 140689526667136 learning.py:507] global step 6135: loss = 0.1194 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 6136: loss = 0.2470 (0.375 sec/step)\n",
            "I0205 13:59:15.713360 140689526667136 learning.py:507] global step 6136: loss = 0.2470 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 6137: loss = 0.1608 (0.365 sec/step)\n",
            "I0205 13:59:16.079623 140689526667136 learning.py:507] global step 6137: loss = 0.1608 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 6138: loss = 0.1903 (0.385 sec/step)\n",
            "I0205 13:59:16.467103 140689526667136 learning.py:507] global step 6138: loss = 0.1903 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 6139: loss = 0.0614 (0.379 sec/step)\n",
            "I0205 13:59:16.848204 140689526667136 learning.py:507] global step 6139: loss = 0.0614 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 6140: loss = 0.0738 (0.376 sec/step)\n",
            "I0205 13:59:17.226076 140689526667136 learning.py:507] global step 6140: loss = 0.0738 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 6141: loss = 0.1595 (0.391 sec/step)\n",
            "I0205 13:59:17.618710 140689526667136 learning.py:507] global step 6141: loss = 0.1595 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6142: loss = 0.0429 (0.377 sec/step)\n",
            "I0205 13:59:17.997577 140689526667136 learning.py:507] global step 6142: loss = 0.0429 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 6143: loss = 0.1162 (0.406 sec/step)\n",
            "I0205 13:59:18.405376 140689526667136 learning.py:507] global step 6143: loss = 0.1162 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 6144: loss = 0.4325 (0.369 sec/step)\n",
            "I0205 13:59:18.776280 140689526667136 learning.py:507] global step 6144: loss = 0.4325 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 6145: loss = 0.0658 (0.401 sec/step)\n",
            "I0205 13:59:19.178669 140689526667136 learning.py:507] global step 6145: loss = 0.0658 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 6146: loss = 0.1963 (0.372 sec/step)\n",
            "I0205 13:59:19.552643 140689526667136 learning.py:507] global step 6146: loss = 0.1963 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 6147: loss = 1.2014 (0.362 sec/step)\n",
            "I0205 13:59:19.915824 140689526667136 learning.py:507] global step 6147: loss = 1.2014 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 6148: loss = 0.2805 (0.376 sec/step)\n",
            "I0205 13:59:20.292901 140689526667136 learning.py:507] global step 6148: loss = 0.2805 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 6149: loss = 0.7972 (0.369 sec/step)\n",
            "I0205 13:59:20.663148 140689526667136 learning.py:507] global step 6149: loss = 0.7972 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 6150: loss = 0.2602 (0.380 sec/step)\n",
            "I0205 13:59:21.045094 140689526667136 learning.py:507] global step 6150: loss = 0.2602 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 6151: loss = 0.3226 (0.392 sec/step)\n",
            "I0205 13:59:21.438586 140689526667136 learning.py:507] global step 6151: loss = 0.3226 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 6152: loss = 0.1399 (0.383 sec/step)\n",
            "I0205 13:59:21.822690 140689526667136 learning.py:507] global step 6152: loss = 0.1399 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 6153: loss = 0.3211 (0.397 sec/step)\n",
            "I0205 13:59:22.222715 140689526667136 learning.py:507] global step 6153: loss = 0.3211 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 6154: loss = 0.1248 (0.410 sec/step)\n",
            "I0205 13:59:22.634688 140689526667136 learning.py:507] global step 6154: loss = 0.1248 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 6155: loss = 0.4096 (0.416 sec/step)\n",
            "I0205 13:59:23.052719 140689526667136 learning.py:507] global step 6155: loss = 0.4096 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 6156: loss = 0.3159 (0.381 sec/step)\n",
            "I0205 13:59:23.434857 140689526667136 learning.py:507] global step 6156: loss = 0.3159 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 6157: loss = 0.0950 (0.389 sec/step)\n",
            "I0205 13:59:23.825759 140689526667136 learning.py:507] global step 6157: loss = 0.0950 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 6158: loss = 0.1355 (0.396 sec/step)\n",
            "I0205 13:59:24.223409 140689526667136 learning.py:507] global step 6158: loss = 0.1355 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 6159: loss = 0.1281 (0.376 sec/step)\n",
            "I0205 13:59:24.600932 140689526667136 learning.py:507] global step 6159: loss = 0.1281 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 6160: loss = 0.0618 (0.365 sec/step)\n",
            "I0205 13:59:24.967234 140689526667136 learning.py:507] global step 6160: loss = 0.0618 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 6161: loss = 0.5207 (0.364 sec/step)\n",
            "I0205 13:59:25.333018 140689526667136 learning.py:507] global step 6161: loss = 0.5207 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 6162: loss = 0.1876 (0.356 sec/step)\n",
            "I0205 13:59:25.690533 140689526667136 learning.py:507] global step 6162: loss = 0.1876 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 6163: loss = 0.0773 (0.361 sec/step)\n",
            "I0205 13:59:26.053440 140689526667136 learning.py:507] global step 6163: loss = 0.0773 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 6164: loss = 0.0389 (0.399 sec/step)\n",
            "I0205 13:59:26.453768 140689526667136 learning.py:507] global step 6164: loss = 0.0389 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 6165: loss = 0.2442 (0.357 sec/step)\n",
            "I0205 13:59:26.812986 140689526667136 learning.py:507] global step 6165: loss = 0.2442 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 6166: loss = 0.4571 (0.355 sec/step)\n",
            "I0205 13:59:27.169651 140689526667136 learning.py:507] global step 6166: loss = 0.4571 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 6167: loss = 0.0646 (0.347 sec/step)\n",
            "I0205 13:59:27.518129 140689526667136 learning.py:507] global step 6167: loss = 0.0646 (0.347 sec/step)\n",
            "INFO:tensorflow:global step 6168: loss = 0.4256 (0.388 sec/step)\n",
            "I0205 13:59:27.908717 140689526667136 learning.py:507] global step 6168: loss = 0.4256 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 6169: loss = 0.3128 (0.396 sec/step)\n",
            "I0205 13:59:28.306682 140689526667136 learning.py:507] global step 6169: loss = 0.3128 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 6170: loss = 0.1779 (0.373 sec/step)\n",
            "I0205 13:59:28.681457 140689526667136 learning.py:507] global step 6170: loss = 0.1779 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 6171: loss = 0.0999 (0.401 sec/step)\n",
            "I0205 13:59:29.083996 140689526667136 learning.py:507] global step 6171: loss = 0.0999 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 6172: loss = 0.1928 (0.382 sec/step)\n",
            "I0205 13:59:29.467288 140689526667136 learning.py:507] global step 6172: loss = 0.1928 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 6173: loss = 0.1088 (0.419 sec/step)\n",
            "I0205 13:59:29.890061 140689526667136 learning.py:507] global step 6173: loss = 0.1088 (0.419 sec/step)\n",
            "INFO:tensorflow:global step 6174: loss = 0.2395 (0.398 sec/step)\n",
            "I0205 13:59:30.290414 140689526667136 learning.py:507] global step 6174: loss = 0.2395 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 6175: loss = 0.1599 (0.367 sec/step)\n",
            "I0205 13:59:30.658553 140689526667136 learning.py:507] global step 6175: loss = 0.1599 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 6176: loss = 0.2441 (0.372 sec/step)\n",
            "I0205 13:59:31.031644 140689526667136 learning.py:507] global step 6176: loss = 0.2441 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 6177: loss = 0.3514 (0.406 sec/step)\n",
            "I0205 13:59:31.439232 140689526667136 learning.py:507] global step 6177: loss = 0.3514 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 6178: loss = 0.2107 (0.385 sec/step)\n",
            "I0205 13:59:31.825810 140689526667136 learning.py:507] global step 6178: loss = 0.2107 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 6179: loss = 0.1186 (0.380 sec/step)\n",
            "I0205 13:59:32.207555 140689526667136 learning.py:507] global step 6179: loss = 0.1186 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 6180: loss = 0.0467 (0.403 sec/step)\n",
            "I0205 13:59:32.612222 140689526667136 learning.py:507] global step 6180: loss = 0.0467 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 6181: loss = 0.2265 (0.388 sec/step)\n",
            "I0205 13:59:33.001940 140689526667136 learning.py:507] global step 6181: loss = 0.2265 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 6182: loss = 0.5471 (0.395 sec/step)\n",
            "I0205 13:59:33.398256 140689526667136 learning.py:507] global step 6182: loss = 0.5471 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 6183: loss = 0.1445 (0.390 sec/step)\n",
            "I0205 13:59:33.790149 140689526667136 learning.py:507] global step 6183: loss = 0.1445 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 6184: loss = 0.1636 (0.383 sec/step)\n",
            "I0205 13:59:34.174634 140689526667136 learning.py:507] global step 6184: loss = 0.1636 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 6185: loss = 0.0768 (0.379 sec/step)\n",
            "I0205 13:59:34.555727 140689526667136 learning.py:507] global step 6185: loss = 0.0768 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 6186: loss = 0.1977 (0.393 sec/step)\n",
            "I0205 13:59:34.951200 140689526667136 learning.py:507] global step 6186: loss = 0.1977 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 6187: loss = 0.3440 (0.360 sec/step)\n",
            "I0205 13:59:35.312356 140689526667136 learning.py:507] global step 6187: loss = 0.3440 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 6188: loss = 0.4870 (0.380 sec/step)\n",
            "I0205 13:59:35.694566 140689526667136 learning.py:507] global step 6188: loss = 0.4870 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 6189: loss = 0.0895 (0.369 sec/step)\n",
            "I0205 13:59:36.065305 140689526667136 learning.py:507] global step 6189: loss = 0.0895 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 6190: loss = 0.0840 (0.404 sec/step)\n",
            "I0205 13:59:36.471271 140689526667136 learning.py:507] global step 6190: loss = 0.0840 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 6191: loss = 0.1839 (0.403 sec/step)\n",
            "I0205 13:59:36.876121 140689526667136 learning.py:507] global step 6191: loss = 0.1839 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 6192: loss = 0.1161 (0.357 sec/step)\n",
            "I0205 13:59:37.234969 140689526667136 learning.py:507] global step 6192: loss = 0.1161 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 6193: loss = 0.0768 (0.395 sec/step)\n",
            "I0205 13:59:37.632106 140689526667136 learning.py:507] global step 6193: loss = 0.0768 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 6194: loss = 0.0881 (0.371 sec/step)\n",
            "I0205 13:59:38.005027 140689526667136 learning.py:507] global step 6194: loss = 0.0881 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 6195: loss = 0.0796 (0.362 sec/step)\n",
            "I0205 13:59:38.369061 140689526667136 learning.py:507] global step 6195: loss = 0.0796 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 6196: loss = 0.0775 (0.371 sec/step)\n",
            "I0205 13:59:38.741475 140689526667136 learning.py:507] global step 6196: loss = 0.0775 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 6197: loss = 0.1527 (0.368 sec/step)\n",
            "I0205 13:59:39.110759 140689526667136 learning.py:507] global step 6197: loss = 0.1527 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 6198: loss = 0.0417 (0.397 sec/step)\n",
            "I0205 13:59:39.509129 140689526667136 learning.py:507] global step 6198: loss = 0.0417 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 6199: loss = 0.1648 (0.385 sec/step)\n",
            "I0205 13:59:39.895901 140689526667136 learning.py:507] global step 6199: loss = 0.1648 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 6200: loss = 0.1260 (0.371 sec/step)\n",
            "I0205 13:59:40.268601 140689526667136 learning.py:507] global step 6200: loss = 0.1260 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 6201: loss = 0.0914 (0.391 sec/step)\n",
            "I0205 13:59:40.661695 140689526667136 learning.py:507] global step 6201: loss = 0.0914 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6202: loss = 0.2708 (0.399 sec/step)\n",
            "I0205 13:59:41.062336 140689526667136 learning.py:507] global step 6202: loss = 0.2708 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 6203: loss = 0.0747 (0.367 sec/step)\n",
            "I0205 13:59:41.431482 140689526667136 learning.py:507] global step 6203: loss = 0.0747 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 6204: loss = 0.7271 (0.382 sec/step)\n",
            "I0205 13:59:41.815460 140689526667136 learning.py:507] global step 6204: loss = 0.7271 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 6205: loss = 0.3680 (0.354 sec/step)\n",
            "I0205 13:59:42.171026 140689526667136 learning.py:507] global step 6205: loss = 0.3680 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 6206: loss = 0.1017 (0.396 sec/step)\n",
            "I0205 13:59:42.568780 140689526667136 learning.py:507] global step 6206: loss = 0.1017 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 6207: loss = 0.0662 (0.384 sec/step)\n",
            "I0205 13:59:42.954576 140689526667136 learning.py:507] global step 6207: loss = 0.0662 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6208: loss = 0.0407 (0.379 sec/step)\n",
            "I0205 13:59:43.335257 140689526667136 learning.py:507] global step 6208: loss = 0.0407 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 6209: loss = 0.0718 (0.370 sec/step)\n",
            "I0205 13:59:43.707003 140689526667136 learning.py:507] global step 6209: loss = 0.0718 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 6210: loss = 0.0312 (0.413 sec/step)\n",
            "I0205 13:59:44.120860 140689526667136 learning.py:507] global step 6210: loss = 0.0312 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 6211: loss = 0.7804 (0.371 sec/step)\n",
            "I0205 13:59:44.493108 140689526667136 learning.py:507] global step 6211: loss = 0.7804 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 6212: loss = 0.0999 (0.388 sec/step)\n",
            "I0205 13:59:44.882793 140689526667136 learning.py:507] global step 6212: loss = 0.0999 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 6213: loss = 0.0889 (0.386 sec/step)\n",
            "I0205 13:59:45.270263 140689526667136 learning.py:507] global step 6213: loss = 0.0889 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 6214: loss = 0.6231 (0.360 sec/step)\n",
            "I0205 13:59:45.631639 140689526667136 learning.py:507] global step 6214: loss = 0.6231 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 6215: loss = 0.1058 (0.384 sec/step)\n",
            "I0205 13:59:46.016779 140689526667136 learning.py:507] global step 6215: loss = 0.1058 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6216: loss = 0.1615 (0.377 sec/step)\n",
            "I0205 13:59:46.395464 140689526667136 learning.py:507] global step 6216: loss = 0.1615 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 6217: loss = 0.0456 (0.372 sec/step)\n",
            "I0205 13:59:46.768889 140689526667136 learning.py:507] global step 6217: loss = 0.0456 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 6218: loss = 0.0092 (0.373 sec/step)\n",
            "I0205 13:59:47.143497 140689526667136 learning.py:507] global step 6218: loss = 0.0092 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 6219: loss = 0.4762 (0.383 sec/step)\n",
            "I0205 13:59:47.528384 140689526667136 learning.py:507] global step 6219: loss = 0.4762 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 6220: loss = 0.2931 (0.362 sec/step)\n",
            "I0205 13:59:47.892389 140689526667136 learning.py:507] global step 6220: loss = 0.2931 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 6221: loss = 0.3658 (0.376 sec/step)\n",
            "I0205 13:59:48.272036 140689526667136 learning.py:507] global step 6221: loss = 0.3658 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 6222: loss = 0.0937 (0.397 sec/step)\n",
            "I0205 13:59:48.670851 140689526667136 learning.py:507] global step 6222: loss = 0.0937 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 6223: loss = 0.1536 (0.387 sec/step)\n",
            "I0205 13:59:49.059410 140689526667136 learning.py:507] global step 6223: loss = 0.1536 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 6224: loss = 0.1165 (0.365 sec/step)\n",
            "I0205 13:59:49.426308 140689526667136 learning.py:507] global step 6224: loss = 0.1165 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 6225: loss = 0.0911 (0.408 sec/step)\n",
            "I0205 13:59:49.836251 140689526667136 learning.py:507] global step 6225: loss = 0.0911 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 6226: loss = 0.1514 (0.380 sec/step)\n",
            "I0205 13:59:50.217388 140689526667136 learning.py:507] global step 6226: loss = 0.1514 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 6227: loss = 1.0392 (0.380 sec/step)\n",
            "I0205 13:59:50.599119 140689526667136 learning.py:507] global step 6227: loss = 1.0392 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 6228: loss = 0.1429 (0.361 sec/step)\n",
            "I0205 13:59:50.961802 140689526667136 learning.py:507] global step 6228: loss = 0.1429 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 6229: loss = 0.0942 (0.413 sec/step)\n",
            "I0205 13:59:51.376346 140689526667136 learning.py:507] global step 6229: loss = 0.0942 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 6230: loss = 0.1212 (0.361 sec/step)\n",
            "I0205 13:59:51.738798 140689526667136 learning.py:507] global step 6230: loss = 0.1212 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 6231: loss = 0.0413 (0.390 sec/step)\n",
            "I0205 13:59:52.130458 140689526667136 learning.py:507] global step 6231: loss = 0.0413 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 6232: loss = 0.9331 (0.390 sec/step)\n",
            "I0205 13:59:52.521512 140689526667136 learning.py:507] global step 6232: loss = 0.9331 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 6233: loss = 0.0872 (0.389 sec/step)\n",
            "I0205 13:59:52.912252 140689526667136 learning.py:507] global step 6233: loss = 0.0872 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 6234: loss = 0.0363 (0.394 sec/step)\n",
            "I0205 13:59:53.307848 140689526667136 learning.py:507] global step 6234: loss = 0.0363 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 6235: loss = 0.2107 (0.410 sec/step)\n",
            "I0205 13:59:53.719567 140689526667136 learning.py:507] global step 6235: loss = 0.2107 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 6236: loss = 0.1585 (0.409 sec/step)\n",
            "I0205 13:59:54.130204 140689526667136 learning.py:507] global step 6236: loss = 0.1585 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 6237: loss = 0.0430 (0.413 sec/step)\n",
            "I0205 13:59:54.544728 140689526667136 learning.py:507] global step 6237: loss = 0.0430 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 6238: loss = 0.1180 (0.372 sec/step)\n",
            "I0205 13:59:54.918153 140689526667136 learning.py:507] global step 6238: loss = 0.1180 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 6239: loss = 0.0533 (0.379 sec/step)\n",
            "I0205 13:59:55.298706 140689526667136 learning.py:507] global step 6239: loss = 0.0533 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 6240: loss = 0.3088 (0.381 sec/step)\n",
            "I0205 13:59:55.681324 140689526667136 learning.py:507] global step 6240: loss = 0.3088 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 6241: loss = 0.1649 (0.338 sec/step)\n",
            "I0205 13:59:56.021208 140689526667136 learning.py:507] global step 6241: loss = 0.1649 (0.338 sec/step)\n",
            "INFO:tensorflow:global step 6242: loss = 0.6333 (0.361 sec/step)\n",
            "I0205 13:59:56.383820 140689526667136 learning.py:507] global step 6242: loss = 0.6333 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 6243: loss = 0.1522 (0.378 sec/step)\n",
            "I0205 13:59:56.763875 140689526667136 learning.py:507] global step 6243: loss = 0.1522 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 6244: loss = 0.0830 (0.399 sec/step)\n",
            "I0205 13:59:57.165394 140689526667136 learning.py:507] global step 6244: loss = 0.0830 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 6245: loss = 0.1045 (0.393 sec/step)\n",
            "I0205 13:59:57.560251 140689526667136 learning.py:507] global step 6245: loss = 0.1045 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 6246: loss = 0.1613 (0.386 sec/step)\n",
            "I0205 13:59:57.947745 140689526667136 learning.py:507] global step 6246: loss = 0.1613 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 6247: loss = 0.1135 (0.366 sec/step)\n",
            "I0205 13:59:58.315094 140689526667136 learning.py:507] global step 6247: loss = 0.1135 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 6248: loss = 0.3683 (0.383 sec/step)\n",
            "I0205 13:59:58.699264 140689526667136 learning.py:507] global step 6248: loss = 0.3683 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 6249: loss = 0.0411 (0.406 sec/step)\n",
            "I0205 13:59:59.107475 140689526667136 learning.py:507] global step 6249: loss = 0.0411 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 6250: loss = 0.0614 (0.386 sec/step)\n",
            "I0205 13:59:59.495240 140689526667136 learning.py:507] global step 6250: loss = 0.0614 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 6251: loss = 0.2454 (0.381 sec/step)\n",
            "I0205 13:59:59.878268 140689526667136 learning.py:507] global step 6251: loss = 0.2454 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 6252: loss = 0.0661 (0.373 sec/step)\n",
            "I0205 14:00:00.252751 140689526667136 learning.py:507] global step 6252: loss = 0.0661 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 6253: loss = 0.0683 (0.369 sec/step)\n",
            "I0205 14:00:00.623070 140689526667136 learning.py:507] global step 6253: loss = 0.0683 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 6254: loss = 1.1101 (0.359 sec/step)\n",
            "I0205 14:00:00.983537 140689526667136 learning.py:507] global step 6254: loss = 1.1101 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 6255: loss = 0.0646 (0.407 sec/step)\n",
            "I0205 14:00:01.392610 140689526667136 learning.py:507] global step 6255: loss = 0.0646 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 6256: loss = 0.1284 (0.395 sec/step)\n",
            "I0205 14:00:01.789781 140689526667136 learning.py:507] global step 6256: loss = 0.1284 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 6257: loss = 0.0788 (0.372 sec/step)\n",
            "I0205 14:00:02.163688 140689526667136 learning.py:507] global step 6257: loss = 0.0788 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 6258: loss = 0.2188 (0.364 sec/step)\n",
            "I0205 14:00:02.528954 140689526667136 learning.py:507] global step 6258: loss = 0.2188 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 6259: loss = 0.2561 (0.368 sec/step)\n",
            "I0205 14:00:02.899077 140689526667136 learning.py:507] global step 6259: loss = 0.2561 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 6260: loss = 0.0571 (0.409 sec/step)\n",
            "I0205 14:00:03.309756 140689526667136 learning.py:507] global step 6260: loss = 0.0571 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 6261: loss = 0.0853 (0.404 sec/step)\n",
            "I0205 14:00:03.715491 140689526667136 learning.py:507] global step 6261: loss = 0.0853 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 6262: loss = 0.1386 (0.372 sec/step)\n",
            "I0205 14:00:04.088750 140689526667136 learning.py:507] global step 6262: loss = 0.1386 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 6263: loss = 0.0742 (0.396 sec/step)\n",
            "I0205 14:00:04.486573 140689526667136 learning.py:507] global step 6263: loss = 0.0742 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 6264: loss = 0.0841 (0.370 sec/step)\n",
            "I0205 14:00:04.857943 140689526667136 learning.py:507] global step 6264: loss = 0.0841 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 6265: loss = 0.0798 (0.399 sec/step)\n",
            "I0205 14:00:05.258651 140689526667136 learning.py:507] global step 6265: loss = 0.0798 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 6266: loss = 0.1068 (0.384 sec/step)\n",
            "I0205 14:00:05.644126 140689526667136 learning.py:507] global step 6266: loss = 0.1068 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6267: loss = 0.0571 (0.362 sec/step)\n",
            "I0205 14:00:06.008176 140689526667136 learning.py:507] global step 6267: loss = 0.0571 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 6268: loss = 0.1427 (0.390 sec/step)\n",
            "I0205 14:00:06.399790 140689526667136 learning.py:507] global step 6268: loss = 0.1427 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 6269: loss = 0.0625 (0.365 sec/step)\n",
            "I0205 14:00:06.766046 140689526667136 learning.py:507] global step 6269: loss = 0.0625 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 6270: loss = 0.0313 (0.387 sec/step)\n",
            "I0205 14:00:07.154576 140689526667136 learning.py:507] global step 6270: loss = 0.0313 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 6271: loss = 0.0540 (0.383 sec/step)\n",
            "I0205 14:00:07.539283 140689526667136 learning.py:507] global step 6271: loss = 0.0540 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 6272: loss = 0.0431 (0.384 sec/step)\n",
            "I0205 14:00:07.925061 140689526667136 learning.py:507] global step 6272: loss = 0.0431 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6273: loss = 0.0988 (0.409 sec/step)\n",
            "I0205 14:00:08.335344 140689526667136 learning.py:507] global step 6273: loss = 0.0988 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 6274: loss = 0.2105 (0.412 sec/step)\n",
            "I0205 14:00:08.749099 140689526667136 learning.py:507] global step 6274: loss = 0.2105 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 6275: loss = 0.2534 (0.412 sec/step)\n",
            "I0205 14:00:09.162501 140689526667136 learning.py:507] global step 6275: loss = 0.2534 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 6276: loss = 0.2283 (0.412 sec/step)\n",
            "I0205 14:00:09.576223 140689526667136 learning.py:507] global step 6276: loss = 0.2283 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 6277: loss = 0.1369 (0.363 sec/step)\n",
            "I0205 14:00:09.941287 140689526667136 learning.py:507] global step 6277: loss = 0.1369 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 6278: loss = 0.0722 (0.374 sec/step)\n",
            "I0205 14:00:10.316964 140689526667136 learning.py:507] global step 6278: loss = 0.0722 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 6279: loss = 0.0856 (0.381 sec/step)\n",
            "I0205 14:00:10.699257 140689526667136 learning.py:507] global step 6279: loss = 0.0856 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 6280: loss = 0.0218 (0.387 sec/step)\n",
            "I0205 14:00:11.088121 140689526667136 learning.py:507] global step 6280: loss = 0.0218 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 6281: loss = 0.0664 (0.375 sec/step)\n",
            "I0205 14:00:11.464413 140689526667136 learning.py:507] global step 6281: loss = 0.0664 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 6282: loss = 0.1763 (0.343 sec/step)\n",
            "I0205 14:00:11.808990 140689526667136 learning.py:507] global step 6282: loss = 0.1763 (0.343 sec/step)\n",
            "INFO:tensorflow:global step 6283: loss = 0.9248 (0.394 sec/step)\n",
            "I0205 14:00:12.204379 140689526667136 learning.py:507] global step 6283: loss = 0.9248 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 6284: loss = 0.1658 (0.376 sec/step)\n",
            "I0205 14:00:12.581588 140689526667136 learning.py:507] global step 6284: loss = 0.1658 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 6285: loss = 0.4311 (0.384 sec/step)\n",
            "I0205 14:00:12.967109 140689526667136 learning.py:507] global step 6285: loss = 0.4311 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6286: loss = 0.1385 (0.349 sec/step)\n",
            "I0205 14:00:13.318441 140689526667136 learning.py:507] global step 6286: loss = 0.1385 (0.349 sec/step)\n",
            "INFO:tensorflow:global step 6287: loss = 0.0519 (0.372 sec/step)\n",
            "I0205 14:00:13.692497 140689526667136 learning.py:507] global step 6287: loss = 0.0519 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 6288: loss = 0.3062 (0.984 sec/step)\n",
            "I0205 14:00:14.768656 140689526667136 learning.py:507] global step 6288: loss = 0.3062 (0.984 sec/step)\n",
            "INFO:tensorflow:global step 6289: loss = 0.0766 (0.948 sec/step)\n",
            "I0205 14:00:15.720120 140689526667136 learning.py:507] global step 6289: loss = 0.0766 (0.948 sec/step)\n",
            "INFO:tensorflow:global step 6290: loss = 0.2967 (0.680 sec/step)\n",
            "I0205 14:00:16.403474 140689526667136 learning.py:507] global step 6290: loss = 0.2967 (0.680 sec/step)\n",
            "INFO:tensorflow:global step 6291: loss = 0.1934 (0.609 sec/step)\n",
            "I0205 14:00:17.014082 140689526667136 learning.py:507] global step 6291: loss = 0.1934 (0.609 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 6291.\n",
            "I0205 14:00:17.241205 140686026073856 supervisor.py:1050] Recording summary at step 6291.\n",
            "INFO:tensorflow:global step 6292: loss = 0.0583 (0.429 sec/step)\n",
            "I0205 14:00:17.448990 140689526667136 learning.py:507] global step 6292: loss = 0.0583 (0.429 sec/step)\n",
            "INFO:tensorflow:global step 6293: loss = 0.1970 (0.363 sec/step)\n",
            "I0205 14:00:17.813070 140689526667136 learning.py:507] global step 6293: loss = 0.1970 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 6294: loss = 0.0690 (0.402 sec/step)\n",
            "I0205 14:00:18.216622 140689526667136 learning.py:507] global step 6294: loss = 0.0690 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 6295: loss = 0.1585 (0.406 sec/step)\n",
            "I0205 14:00:18.624682 140689526667136 learning.py:507] global step 6295: loss = 0.1585 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 6296: loss = 0.0675 (0.392 sec/step)\n",
            "I0205 14:00:19.018590 140689526667136 learning.py:507] global step 6296: loss = 0.0675 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 6297: loss = 0.3571 (0.363 sec/step)\n",
            "I0205 14:00:19.383482 140689526667136 learning.py:507] global step 6297: loss = 0.3571 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 6298: loss = 0.1868 (0.392 sec/step)\n",
            "I0205 14:00:19.777298 140689526667136 learning.py:507] global step 6298: loss = 0.1868 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 6299: loss = 0.0681 (0.367 sec/step)\n",
            "I0205 14:00:20.145149 140689526667136 learning.py:507] global step 6299: loss = 0.0681 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 6300: loss = 0.0840 (0.376 sec/step)\n",
            "I0205 14:00:20.522334 140689526667136 learning.py:507] global step 6300: loss = 0.0840 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 6301: loss = 0.2737 (0.386 sec/step)\n",
            "I0205 14:00:20.910007 140689526667136 learning.py:507] global step 6301: loss = 0.2737 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 6302: loss = 0.1284 (0.393 sec/step)\n",
            "I0205 14:00:21.304140 140689526667136 learning.py:507] global step 6302: loss = 0.1284 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 6303: loss = 0.1053 (0.395 sec/step)\n",
            "I0205 14:00:21.700253 140689526667136 learning.py:507] global step 6303: loss = 0.1053 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 6304: loss = 0.1491 (0.369 sec/step)\n",
            "I0205 14:00:22.071261 140689526667136 learning.py:507] global step 6304: loss = 0.1491 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 6305: loss = 0.0630 (0.365 sec/step)\n",
            "I0205 14:00:22.438111 140689526667136 learning.py:507] global step 6305: loss = 0.0630 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 6306: loss = 0.0557 (0.360 sec/step)\n",
            "I0205 14:00:22.799472 140689526667136 learning.py:507] global step 6306: loss = 0.0557 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 6307: loss = 0.2636 (0.391 sec/step)\n",
            "I0205 14:00:23.192056 140689526667136 learning.py:507] global step 6307: loss = 0.2636 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6308: loss = 0.0286 (0.405 sec/step)\n",
            "I0205 14:00:23.599052 140689526667136 learning.py:507] global step 6308: loss = 0.0286 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 6309: loss = 0.0442 (0.370 sec/step)\n",
            "I0205 14:00:23.970568 140689526667136 learning.py:507] global step 6309: loss = 0.0442 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 6310: loss = 0.0860 (0.395 sec/step)\n",
            "I0205 14:00:24.367838 140689526667136 learning.py:507] global step 6310: loss = 0.0860 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 6311: loss = 0.0395 (0.386 sec/step)\n",
            "I0205 14:00:24.755354 140689526667136 learning.py:507] global step 6311: loss = 0.0395 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 6312: loss = 0.1514 (0.394 sec/step)\n",
            "I0205 14:00:25.151124 140689526667136 learning.py:507] global step 6312: loss = 0.1514 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 6313: loss = 0.1917 (0.396 sec/step)\n",
            "I0205 14:00:25.549290 140689526667136 learning.py:507] global step 6313: loss = 0.1917 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 6314: loss = 0.0457 (0.372 sec/step)\n",
            "I0205 14:00:25.923094 140689526667136 learning.py:507] global step 6314: loss = 0.0457 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 6315: loss = 0.3731 (0.388 sec/step)\n",
            "I0205 14:00:26.313180 140689526667136 learning.py:507] global step 6315: loss = 0.3731 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 6316: loss = 0.0832 (0.348 sec/step)\n",
            "I0205 14:00:26.662884 140689526667136 learning.py:507] global step 6316: loss = 0.0832 (0.348 sec/step)\n",
            "INFO:tensorflow:global step 6317: loss = 0.2969 (0.380 sec/step)\n",
            "I0205 14:00:27.044743 140689526667136 learning.py:507] global step 6317: loss = 0.2969 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 6318: loss = 0.1073 (0.386 sec/step)\n",
            "I0205 14:00:27.432249 140689526667136 learning.py:507] global step 6318: loss = 0.1073 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 6319: loss = 0.5836 (0.382 sec/step)\n",
            "I0205 14:00:27.817010 140689526667136 learning.py:507] global step 6319: loss = 0.5836 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 6320: loss = 0.1822 (0.380 sec/step)\n",
            "I0205 14:00:28.199498 140689526667136 learning.py:507] global step 6320: loss = 0.1822 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 6321: loss = 0.0479 (0.358 sec/step)\n",
            "I0205 14:00:28.558691 140689526667136 learning.py:507] global step 6321: loss = 0.0479 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 6322: loss = 0.1522 (0.392 sec/step)\n",
            "I0205 14:00:28.952404 140689526667136 learning.py:507] global step 6322: loss = 0.1522 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 6323: loss = 0.4596 (0.415 sec/step)\n",
            "I0205 14:00:29.369124 140689526667136 learning.py:507] global step 6323: loss = 0.4596 (0.415 sec/step)\n",
            "INFO:tensorflow:global step 6324: loss = 0.1058 (0.419 sec/step)\n",
            "I0205 14:00:29.789257 140689526667136 learning.py:507] global step 6324: loss = 0.1058 (0.419 sec/step)\n",
            "INFO:tensorflow:global step 6325: loss = 0.3711 (0.413 sec/step)\n",
            "I0205 14:00:30.204031 140689526667136 learning.py:507] global step 6325: loss = 0.3711 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 6326: loss = 0.1244 (0.408 sec/step)\n",
            "I0205 14:00:30.614976 140689526667136 learning.py:507] global step 6326: loss = 0.1244 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 6327: loss = 0.0572 (0.434 sec/step)\n",
            "I0205 14:00:31.051572 140689526667136 learning.py:507] global step 6327: loss = 0.0572 (0.434 sec/step)\n",
            "INFO:tensorflow:global step 6328: loss = 0.0950 (0.384 sec/step)\n",
            "I0205 14:00:31.437930 140689526667136 learning.py:507] global step 6328: loss = 0.0950 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6329: loss = 0.0560 (0.401 sec/step)\n",
            "I0205 14:00:31.840233 140689526667136 learning.py:507] global step 6329: loss = 0.0560 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 6330: loss = 0.0717 (0.397 sec/step)\n",
            "I0205 14:00:32.238654 140689526667136 learning.py:507] global step 6330: loss = 0.0717 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 6331: loss = 0.0929 (0.389 sec/step)\n",
            "I0205 14:00:32.629076 140689526667136 learning.py:507] global step 6331: loss = 0.0929 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 6332: loss = 0.1105 (0.417 sec/step)\n",
            "I0205 14:00:33.047620 140689526667136 learning.py:507] global step 6332: loss = 0.1105 (0.417 sec/step)\n",
            "INFO:tensorflow:global step 6333: loss = 0.3245 (0.385 sec/step)\n",
            "I0205 14:00:33.435279 140689526667136 learning.py:507] global step 6333: loss = 0.3245 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 6334: loss = 0.0702 (0.397 sec/step)\n",
            "I0205 14:00:33.833507 140689526667136 learning.py:507] global step 6334: loss = 0.0702 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 6335: loss = 0.1646 (0.397 sec/step)\n",
            "I0205 14:00:34.231945 140689526667136 learning.py:507] global step 6335: loss = 0.1646 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 6336: loss = 0.0215 (0.371 sec/step)\n",
            "I0205 14:00:34.605243 140689526667136 learning.py:507] global step 6336: loss = 0.0215 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 6337: loss = 0.0360 (0.390 sec/step)\n",
            "I0205 14:00:34.996381 140689526667136 learning.py:507] global step 6337: loss = 0.0360 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 6338: loss = 0.2703 (0.394 sec/step)\n",
            "I0205 14:00:35.392454 140689526667136 learning.py:507] global step 6338: loss = 0.2703 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 6339: loss = 0.0556 (0.392 sec/step)\n",
            "I0205 14:00:35.785761 140689526667136 learning.py:507] global step 6339: loss = 0.0556 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 6340: loss = 0.0229 (0.409 sec/step)\n",
            "I0205 14:00:36.196611 140689526667136 learning.py:507] global step 6340: loss = 0.0229 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 6341: loss = 0.0319 (0.397 sec/step)\n",
            "I0205 14:00:36.595739 140689526667136 learning.py:507] global step 6341: loss = 0.0319 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 6342: loss = 0.1656 (0.392 sec/step)\n",
            "I0205 14:00:36.989491 140689526667136 learning.py:507] global step 6342: loss = 0.1656 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 6343: loss = 0.1408 (0.365 sec/step)\n",
            "I0205 14:00:37.355950 140689526667136 learning.py:507] global step 6343: loss = 0.1408 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 6344: loss = 0.1091 (0.389 sec/step)\n",
            "I0205 14:00:37.746416 140689526667136 learning.py:507] global step 6344: loss = 0.1091 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 6345: loss = 0.1195 (0.377 sec/step)\n",
            "I0205 14:00:38.125285 140689526667136 learning.py:507] global step 6345: loss = 0.1195 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 6346: loss = 0.6407 (0.389 sec/step)\n",
            "I0205 14:00:38.515974 140689526667136 learning.py:507] global step 6346: loss = 0.6407 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 6347: loss = 0.1191 (0.359 sec/step)\n",
            "I0205 14:00:38.876845 140689526667136 learning.py:507] global step 6347: loss = 0.1191 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 6348: loss = 0.0865 (0.377 sec/step)\n",
            "I0205 14:00:39.255756 140689526667136 learning.py:507] global step 6348: loss = 0.0865 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 6349: loss = 0.0537 (0.389 sec/step)\n",
            "I0205 14:00:39.646590 140689526667136 learning.py:507] global step 6349: loss = 0.0537 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 6350: loss = 0.1140 (0.394 sec/step)\n",
            "I0205 14:00:40.042482 140689526667136 learning.py:507] global step 6350: loss = 0.1140 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 6351: loss = 0.4739 (0.375 sec/step)\n",
            "I0205 14:00:40.419592 140689526667136 learning.py:507] global step 6351: loss = 0.4739 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 6352: loss = 0.2496 (0.391 sec/step)\n",
            "I0205 14:00:40.812144 140689526667136 learning.py:507] global step 6352: loss = 0.2496 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6353: loss = 0.2543 (0.382 sec/step)\n",
            "I0205 14:00:41.196054 140689526667136 learning.py:507] global step 6353: loss = 0.2543 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 6354: loss = 0.2457 (0.359 sec/step)\n",
            "I0205 14:00:41.556158 140689526667136 learning.py:507] global step 6354: loss = 0.2457 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 6355: loss = 0.0970 (0.365 sec/step)\n",
            "I0205 14:00:41.922663 140689526667136 learning.py:507] global step 6355: loss = 0.0970 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 6356: loss = 0.1797 (0.413 sec/step)\n",
            "I0205 14:00:42.337064 140689526667136 learning.py:507] global step 6356: loss = 0.1797 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 6357: loss = 0.2097 (0.373 sec/step)\n",
            "I0205 14:00:42.711245 140689526667136 learning.py:507] global step 6357: loss = 0.2097 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 6358: loss = 0.3993 (0.371 sec/step)\n",
            "I0205 14:00:43.084199 140689526667136 learning.py:507] global step 6358: loss = 0.3993 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 6359: loss = 0.2150 (0.393 sec/step)\n",
            "I0205 14:00:43.478320 140689526667136 learning.py:507] global step 6359: loss = 0.2150 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 6360: loss = 0.0620 (0.395 sec/step)\n",
            "I0205 14:00:43.874971 140689526667136 learning.py:507] global step 6360: loss = 0.0620 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 6361: loss = 0.0598 (0.376 sec/step)\n",
            "I0205 14:00:44.253117 140689526667136 learning.py:507] global step 6361: loss = 0.0598 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 6362: loss = 0.0885 (0.361 sec/step)\n",
            "I0205 14:00:44.615623 140689526667136 learning.py:507] global step 6362: loss = 0.0885 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 6363: loss = 0.1174 (0.383 sec/step)\n",
            "I0205 14:00:45.000319 140689526667136 learning.py:507] global step 6363: loss = 0.1174 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 6364: loss = 0.1862 (0.376 sec/step)\n",
            "I0205 14:00:45.382751 140689526667136 learning.py:507] global step 6364: loss = 0.1862 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 6365: loss = 0.6150 (0.386 sec/step)\n",
            "I0205 14:00:45.770478 140689526667136 learning.py:507] global step 6365: loss = 0.6150 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 6366: loss = 0.0989 (0.354 sec/step)\n",
            "I0205 14:00:46.126110 140689526667136 learning.py:507] global step 6366: loss = 0.0989 (0.354 sec/step)\n",
            "INFO:tensorflow:global step 6367: loss = 0.2566 (0.399 sec/step)\n",
            "I0205 14:00:46.527093 140689526667136 learning.py:507] global step 6367: loss = 0.2566 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 6368: loss = 0.2273 (0.365 sec/step)\n",
            "I0205 14:00:46.893616 140689526667136 learning.py:507] global step 6368: loss = 0.2273 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 6369: loss = 0.2140 (0.386 sec/step)\n",
            "I0205 14:00:47.281356 140689526667136 learning.py:507] global step 6369: loss = 0.2140 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 6370: loss = 0.1444 (0.402 sec/step)\n",
            "I0205 14:00:47.684974 140689526667136 learning.py:507] global step 6370: loss = 0.1444 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 6371: loss = 0.0869 (0.404 sec/step)\n",
            "I0205 14:00:48.089991 140689526667136 learning.py:507] global step 6371: loss = 0.0869 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 6372: loss = 0.0434 (0.391 sec/step)\n",
            "I0205 14:00:48.484243 140689526667136 learning.py:507] global step 6372: loss = 0.0434 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6373: loss = 0.0549 (0.383 sec/step)\n",
            "I0205 14:00:48.868877 140689526667136 learning.py:507] global step 6373: loss = 0.0549 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 6374: loss = 0.0865 (0.359 sec/step)\n",
            "I0205 14:00:49.229748 140689526667136 learning.py:507] global step 6374: loss = 0.0865 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 6375: loss = 0.0997 (0.416 sec/step)\n",
            "I0205 14:00:49.647529 140689526667136 learning.py:507] global step 6375: loss = 0.0997 (0.416 sec/step)\n",
            "INFO:tensorflow:global step 6376: loss = 0.2398 (0.388 sec/step)\n",
            "I0205 14:00:50.037442 140689526667136 learning.py:507] global step 6376: loss = 0.2398 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 6377: loss = 0.2342 (0.391 sec/step)\n",
            "I0205 14:00:50.429821 140689526667136 learning.py:507] global step 6377: loss = 0.2342 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6378: loss = 0.0364 (0.388 sec/step)\n",
            "I0205 14:00:50.819287 140689526667136 learning.py:507] global step 6378: loss = 0.0364 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 6379: loss = 0.1244 (0.388 sec/step)\n",
            "I0205 14:00:51.208977 140689526667136 learning.py:507] global step 6379: loss = 0.1244 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 6380: loss = 0.1354 (0.387 sec/step)\n",
            "I0205 14:00:51.598537 140689526667136 learning.py:507] global step 6380: loss = 0.1354 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 6381: loss = 0.6689 (0.367 sec/step)\n",
            "I0205 14:00:51.966907 140689526667136 learning.py:507] global step 6381: loss = 0.6689 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 6382: loss = 0.1352 (0.379 sec/step)\n",
            "I0205 14:00:52.348222 140689526667136 learning.py:507] global step 6382: loss = 0.1352 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 6383: loss = 0.1509 (0.400 sec/step)\n",
            "I0205 14:00:52.751041 140689526667136 learning.py:507] global step 6383: loss = 0.1509 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 6384: loss = 0.0369 (0.404 sec/step)\n",
            "I0205 14:00:53.157686 140689526667136 learning.py:507] global step 6384: loss = 0.0369 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 6385: loss = 0.1919 (0.407 sec/step)\n",
            "I0205 14:00:53.566401 140689526667136 learning.py:507] global step 6385: loss = 0.1919 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 6386: loss = 0.0767 (0.383 sec/step)\n",
            "I0205 14:00:53.951755 140689526667136 learning.py:507] global step 6386: loss = 0.0767 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 6387: loss = 0.1601 (0.376 sec/step)\n",
            "I0205 14:00:54.329084 140689526667136 learning.py:507] global step 6387: loss = 0.1601 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 6388: loss = 0.0442 (0.390 sec/step)\n",
            "I0205 14:00:54.720889 140689526667136 learning.py:507] global step 6388: loss = 0.0442 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 6389: loss = 0.1689 (0.380 sec/step)\n",
            "I0205 14:00:55.102967 140689526667136 learning.py:507] global step 6389: loss = 0.1689 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 6390: loss = 0.0900 (0.398 sec/step)\n",
            "I0205 14:00:55.502722 140689526667136 learning.py:507] global step 6390: loss = 0.0900 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 6391: loss = 0.1336 (0.403 sec/step)\n",
            "I0205 14:00:55.907666 140689526667136 learning.py:507] global step 6391: loss = 0.1336 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 6392: loss = 0.0739 (0.381 sec/step)\n",
            "I0205 14:00:56.290098 140689526667136 learning.py:507] global step 6392: loss = 0.0739 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 6393: loss = 0.4058 (0.385 sec/step)\n",
            "I0205 14:00:56.676302 140689526667136 learning.py:507] global step 6393: loss = 0.4058 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 6394: loss = 0.0237 (0.396 sec/step)\n",
            "I0205 14:00:57.074412 140689526667136 learning.py:507] global step 6394: loss = 0.0237 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 6395: loss = 0.1279 (0.381 sec/step)\n",
            "I0205 14:00:57.457361 140689526667136 learning.py:507] global step 6395: loss = 0.1279 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 6396: loss = 0.3533 (0.395 sec/step)\n",
            "I0205 14:00:57.853517 140689526667136 learning.py:507] global step 6396: loss = 0.3533 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 6397: loss = 0.8493 (0.390 sec/step)\n",
            "I0205 14:00:58.244781 140689526667136 learning.py:507] global step 6397: loss = 0.8493 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 6398: loss = 0.4554 (0.405 sec/step)\n",
            "I0205 14:00:58.651992 140689526667136 learning.py:507] global step 6398: loss = 0.4554 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 6399: loss = 0.1484 (0.383 sec/step)\n",
            "I0205 14:00:59.037028 140689526667136 learning.py:507] global step 6399: loss = 0.1484 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 6400: loss = 0.0910 (0.399 sec/step)\n",
            "I0205 14:00:59.437885 140689526667136 learning.py:507] global step 6400: loss = 0.0910 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 6401: loss = 0.1136 (0.409 sec/step)\n",
            "I0205 14:00:59.848927 140689526667136 learning.py:507] global step 6401: loss = 0.1136 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 6402: loss = 0.2064 (0.384 sec/step)\n",
            "I0205 14:01:00.234086 140689526667136 learning.py:507] global step 6402: loss = 0.2064 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6403: loss = 0.1553 (0.395 sec/step)\n",
            "I0205 14:01:00.630185 140689526667136 learning.py:507] global step 6403: loss = 0.1553 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 6404: loss = 0.1657 (0.390 sec/step)\n",
            "I0205 14:01:01.022244 140689526667136 learning.py:507] global step 6404: loss = 0.1657 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 6405: loss = 0.0843 (0.390 sec/step)\n",
            "I0205 14:01:01.413728 140689526667136 learning.py:507] global step 6405: loss = 0.0843 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 6406: loss = 0.0959 (0.395 sec/step)\n",
            "I0205 14:01:01.810899 140689526667136 learning.py:507] global step 6406: loss = 0.0959 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 6407: loss = 0.0579 (0.382 sec/step)\n",
            "I0205 14:01:02.194358 140689526667136 learning.py:507] global step 6407: loss = 0.0579 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 6408: loss = 0.0218 (0.398 sec/step)\n",
            "I0205 14:01:02.593632 140689526667136 learning.py:507] global step 6408: loss = 0.0218 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 6409: loss = 0.0994 (0.406 sec/step)\n",
            "I0205 14:01:03.001201 140689526667136 learning.py:507] global step 6409: loss = 0.0994 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 6410: loss = 0.1923 (0.389 sec/step)\n",
            "I0205 14:01:03.392301 140689526667136 learning.py:507] global step 6410: loss = 0.1923 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 6411: loss = 0.2429 (0.407 sec/step)\n",
            "I0205 14:01:03.801129 140689526667136 learning.py:507] global step 6411: loss = 0.2429 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 6412: loss = 0.2762 (0.396 sec/step)\n",
            "I0205 14:01:04.198448 140689526667136 learning.py:507] global step 6412: loss = 0.2762 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 6413: loss = 0.0962 (0.394 sec/step)\n",
            "I0205 14:01:04.594129 140689526667136 learning.py:507] global step 6413: loss = 0.0962 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 6414: loss = 0.0779 (0.377 sec/step)\n",
            "I0205 14:01:04.972531 140689526667136 learning.py:507] global step 6414: loss = 0.0779 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 6415: loss = 0.2123 (0.389 sec/step)\n",
            "I0205 14:01:05.363033 140689526667136 learning.py:507] global step 6415: loss = 0.2123 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 6416: loss = 0.1466 (0.401 sec/step)\n",
            "I0205 14:01:05.765800 140689526667136 learning.py:507] global step 6416: loss = 0.1466 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 6417: loss = 0.4115 (0.383 sec/step)\n",
            "I0205 14:01:06.150633 140689526667136 learning.py:507] global step 6417: loss = 0.4115 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 6418: loss = 0.0883 (0.393 sec/step)\n",
            "I0205 14:01:06.545328 140689526667136 learning.py:507] global step 6418: loss = 0.0883 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 6419: loss = 0.0038 (0.397 sec/step)\n",
            "I0205 14:01:06.944344 140689526667136 learning.py:507] global step 6419: loss = 0.0038 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 6420: loss = 0.1237 (0.389 sec/step)\n",
            "I0205 14:01:07.334729 140689526667136 learning.py:507] global step 6420: loss = 0.1237 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 6421: loss = 0.1187 (0.387 sec/step)\n",
            "I0205 14:01:07.723721 140689526667136 learning.py:507] global step 6421: loss = 0.1187 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 6422: loss = 0.0530 (0.441 sec/step)\n",
            "I0205 14:01:08.166583 140689526667136 learning.py:507] global step 6422: loss = 0.0530 (0.441 sec/step)\n",
            "INFO:tensorflow:global step 6423: loss = 0.0797 (0.406 sec/step)\n",
            "I0205 14:01:08.575197 140689526667136 learning.py:507] global step 6423: loss = 0.0797 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 6424: loss = 0.1356 (0.427 sec/step)\n",
            "I0205 14:01:09.003787 140689526667136 learning.py:507] global step 6424: loss = 0.1356 (0.427 sec/step)\n",
            "INFO:tensorflow:global step 6425: loss = 0.0423 (0.427 sec/step)\n",
            "I0205 14:01:09.432731 140689526667136 learning.py:507] global step 6425: loss = 0.0423 (0.427 sec/step)\n",
            "INFO:tensorflow:global step 6426: loss = 0.0586 (0.414 sec/step)\n",
            "I0205 14:01:09.848589 140689526667136 learning.py:507] global step 6426: loss = 0.0586 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 6427: loss = 0.0853 (0.392 sec/step)\n",
            "I0205 14:01:10.242347 140689526667136 learning.py:507] global step 6427: loss = 0.0853 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 6428: loss = 0.2008 (0.384 sec/step)\n",
            "I0205 14:01:10.627251 140689526667136 learning.py:507] global step 6428: loss = 0.2008 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6429: loss = 0.2965 (0.374 sec/step)\n",
            "I0205 14:01:11.002892 140689526667136 learning.py:507] global step 6429: loss = 0.2965 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 6430: loss = 0.0799 (0.341 sec/step)\n",
            "I0205 14:01:11.344993 140689526667136 learning.py:507] global step 6430: loss = 0.0799 (0.341 sec/step)\n",
            "INFO:tensorflow:global step 6431: loss = 0.0860 (0.388 sec/step)\n",
            "I0205 14:01:11.734528 140689526667136 learning.py:507] global step 6431: loss = 0.0860 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 6432: loss = 0.1723 (0.395 sec/step)\n",
            "I0205 14:01:12.132621 140689526667136 learning.py:507] global step 6432: loss = 0.1723 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 6433: loss = 0.1273 (0.363 sec/step)\n",
            "I0205 14:01:12.497956 140689526667136 learning.py:507] global step 6433: loss = 0.1273 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 6434: loss = 0.0369 (0.391 sec/step)\n",
            "I0205 14:01:12.890805 140689526667136 learning.py:507] global step 6434: loss = 0.0369 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6435: loss = 0.1489 (0.404 sec/step)\n",
            "I0205 14:01:13.297058 140689526667136 learning.py:507] global step 6435: loss = 0.1489 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 6436: loss = 0.2067 (0.397 sec/step)\n",
            "I0205 14:01:13.695552 140689526667136 learning.py:507] global step 6436: loss = 0.2067 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 6437: loss = 0.1528 (0.401 sec/step)\n",
            "I0205 14:01:14.098837 140689526667136 learning.py:507] global step 6437: loss = 0.1528 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 6438: loss = 0.1229 (0.383 sec/step)\n",
            "I0205 14:01:14.483364 140689526667136 learning.py:507] global step 6438: loss = 0.1229 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 6439: loss = 0.0386 (0.340 sec/step)\n",
            "I0205 14:01:14.824828 140689526667136 learning.py:507] global step 6439: loss = 0.0386 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 6440: loss = 0.1798 (0.376 sec/step)\n",
            "I0205 14:01:15.202765 140689526667136 learning.py:507] global step 6440: loss = 0.1798 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 6441: loss = 0.0757 (0.402 sec/step)\n",
            "I0205 14:01:15.606456 140689526667136 learning.py:507] global step 6441: loss = 0.0757 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 6442: loss = 0.0564 (0.383 sec/step)\n",
            "I0205 14:01:15.992245 140689526667136 learning.py:507] global step 6442: loss = 0.0564 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 6443: loss = 0.1105 (0.377 sec/step)\n",
            "I0205 14:01:16.370821 140689526667136 learning.py:507] global step 6443: loss = 0.1105 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 6444: loss = 0.1698 (0.373 sec/step)\n",
            "I0205 14:01:16.745497 140689526667136 learning.py:507] global step 6444: loss = 0.1698 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 6445: loss = 0.1863 (0.363 sec/step)\n",
            "I0205 14:01:17.110446 140689526667136 learning.py:507] global step 6445: loss = 0.1863 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 6446: loss = 0.0411 (0.381 sec/step)\n",
            "I0205 14:01:17.493639 140689526667136 learning.py:507] global step 6446: loss = 0.0411 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 6447: loss = 0.0499 (0.373 sec/step)\n",
            "I0205 14:01:17.868654 140689526667136 learning.py:507] global step 6447: loss = 0.0499 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 6448: loss = 0.1098 (0.353 sec/step)\n",
            "I0205 14:01:18.223512 140689526667136 learning.py:507] global step 6448: loss = 0.1098 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 6449: loss = 0.0823 (0.385 sec/step)\n",
            "I0205 14:01:18.610382 140689526667136 learning.py:507] global step 6449: loss = 0.0823 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 6450: loss = 0.0233 (0.394 sec/step)\n",
            "I0205 14:01:19.006265 140689526667136 learning.py:507] global step 6450: loss = 0.0233 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 6451: loss = 0.0200 (0.397 sec/step)\n",
            "I0205 14:01:19.405039 140689526667136 learning.py:507] global step 6451: loss = 0.0200 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 6452: loss = 0.1531 (0.384 sec/step)\n",
            "I0205 14:01:19.790090 140689526667136 learning.py:507] global step 6452: loss = 0.1531 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6453: loss = 0.0391 (0.376 sec/step)\n",
            "I0205 14:01:20.167650 140689526667136 learning.py:507] global step 6453: loss = 0.0391 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 6454: loss = 0.2781 (0.371 sec/step)\n",
            "I0205 14:01:20.540704 140689526667136 learning.py:507] global step 6454: loss = 0.2781 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 6455: loss = 0.2860 (0.391 sec/step)\n",
            "I0205 14:01:20.933833 140689526667136 learning.py:507] global step 6455: loss = 0.2860 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6456: loss = 0.0677 (0.406 sec/step)\n",
            "I0205 14:01:21.341134 140689526667136 learning.py:507] global step 6456: loss = 0.0677 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 6457: loss = 0.0304 (0.403 sec/step)\n",
            "I0205 14:01:21.745977 140689526667136 learning.py:507] global step 6457: loss = 0.0304 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 6458: loss = 0.0444 (0.402 sec/step)\n",
            "I0205 14:01:22.149595 140689526667136 learning.py:507] global step 6458: loss = 0.0444 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 6459: loss = 0.0313 (0.374 sec/step)\n",
            "I0205 14:01:22.525156 140689526667136 learning.py:507] global step 6459: loss = 0.0313 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 6460: loss = 0.1831 (0.397 sec/step)\n",
            "I0205 14:01:22.924378 140689526667136 learning.py:507] global step 6460: loss = 0.1831 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 6461: loss = 0.0277 (0.398 sec/step)\n",
            "I0205 14:01:23.323841 140689526667136 learning.py:507] global step 6461: loss = 0.0277 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 6462: loss = 0.0801 (0.392 sec/step)\n",
            "I0205 14:01:23.717438 140689526667136 learning.py:507] global step 6462: loss = 0.0801 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 6463: loss = 0.1501 (0.374 sec/step)\n",
            "I0205 14:01:24.092825 140689526667136 learning.py:507] global step 6463: loss = 0.1501 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 6464: loss = 0.2216 (0.394 sec/step)\n",
            "I0205 14:01:24.488852 140689526667136 learning.py:507] global step 6464: loss = 0.2216 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 6465: loss = 0.1963 (0.408 sec/step)\n",
            "I0205 14:01:24.898940 140689526667136 learning.py:507] global step 6465: loss = 0.1963 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 6466: loss = 0.3464 (0.380 sec/step)\n",
            "I0205 14:01:25.280767 140689526667136 learning.py:507] global step 6466: loss = 0.3464 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 6467: loss = 0.0255 (0.409 sec/step)\n",
            "I0205 14:01:25.691985 140689526667136 learning.py:507] global step 6467: loss = 0.0255 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 6468: loss = 0.1628 (0.414 sec/step)\n",
            "I0205 14:01:26.107947 140689526667136 learning.py:507] global step 6468: loss = 0.1628 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 6469: loss = 0.3801 (0.366 sec/step)\n",
            "I0205 14:01:26.475945 140689526667136 learning.py:507] global step 6469: loss = 0.3801 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 6470: loss = 0.2510 (0.379 sec/step)\n",
            "I0205 14:01:26.856226 140689526667136 learning.py:507] global step 6470: loss = 0.2510 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 6471: loss = 0.1809 (0.384 sec/step)\n",
            "I0205 14:01:27.241666 140689526667136 learning.py:507] global step 6471: loss = 0.1809 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6472: loss = 0.1293 (0.388 sec/step)\n",
            "I0205 14:01:27.631896 140689526667136 learning.py:507] global step 6472: loss = 0.1293 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 6473: loss = 0.1183 (0.381 sec/step)\n",
            "I0205 14:01:28.014377 140689526667136 learning.py:507] global step 6473: loss = 0.1183 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 6474: loss = 0.0461 (0.367 sec/step)\n",
            "I0205 14:01:28.383141 140689526667136 learning.py:507] global step 6474: loss = 0.0461 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 6475: loss = 0.0701 (0.366 sec/step)\n",
            "I0205 14:01:28.751109 140689526667136 learning.py:507] global step 6475: loss = 0.0701 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 6476: loss = 0.4092 (0.398 sec/step)\n",
            "I0205 14:01:29.150843 140689526667136 learning.py:507] global step 6476: loss = 0.4092 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 6477: loss = 0.2446 (0.396 sec/step)\n",
            "I0205 14:01:29.548853 140689526667136 learning.py:507] global step 6477: loss = 0.2446 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 6478: loss = 0.1106 (0.404 sec/step)\n",
            "I0205 14:01:29.955011 140689526667136 learning.py:507] global step 6478: loss = 0.1106 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 6479: loss = 0.0685 (0.413 sec/step)\n",
            "I0205 14:01:30.369329 140689526667136 learning.py:507] global step 6479: loss = 0.0685 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 6480: loss = 0.4701 (0.376 sec/step)\n",
            "I0205 14:01:30.746762 140689526667136 learning.py:507] global step 6480: loss = 0.4701 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 6481: loss = 0.2501 (0.390 sec/step)\n",
            "I0205 14:01:31.138144 140689526667136 learning.py:507] global step 6481: loss = 0.2501 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 6482: loss = 0.0527 (0.389 sec/step)\n",
            "I0205 14:01:31.529129 140689526667136 learning.py:507] global step 6482: loss = 0.0527 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 6483: loss = 0.1798 (0.394 sec/step)\n",
            "I0205 14:01:31.924633 140689526667136 learning.py:507] global step 6483: loss = 0.1798 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 6484: loss = 0.0797 (0.392 sec/step)\n",
            "I0205 14:01:32.318878 140689526667136 learning.py:507] global step 6484: loss = 0.0797 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 6485: loss = 0.1950 (0.382 sec/step)\n",
            "I0205 14:01:32.702995 140689526667136 learning.py:507] global step 6485: loss = 0.1950 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 6486: loss = 0.1266 (0.358 sec/step)\n",
            "I0205 14:01:33.062338 140689526667136 learning.py:507] global step 6486: loss = 0.1266 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 6487: loss = 0.2304 (0.395 sec/step)\n",
            "I0205 14:01:33.458964 140689526667136 learning.py:507] global step 6487: loss = 0.2304 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 6488: loss = 0.0400 (0.372 sec/step)\n",
            "I0205 14:01:33.832301 140689526667136 learning.py:507] global step 6488: loss = 0.0400 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 6489: loss = 0.2203 (0.381 sec/step)\n",
            "I0205 14:01:34.214934 140689526667136 learning.py:507] global step 6489: loss = 0.2203 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 6490: loss = 0.2070 (0.370 sec/step)\n",
            "I0205 14:01:34.586752 140689526667136 learning.py:507] global step 6490: loss = 0.2070 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 6491: loss = 0.0797 (0.384 sec/step)\n",
            "I0205 14:01:34.972749 140689526667136 learning.py:507] global step 6491: loss = 0.0797 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6492: loss = 0.2002 (0.376 sec/step)\n",
            "I0205 14:01:35.350573 140689526667136 learning.py:507] global step 6492: loss = 0.2002 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 6493: loss = 0.0751 (0.384 sec/step)\n",
            "I0205 14:01:35.736852 140689526667136 learning.py:507] global step 6493: loss = 0.0751 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6494: loss = 0.1595 (0.389 sec/step)\n",
            "I0205 14:01:36.127920 140689526667136 learning.py:507] global step 6494: loss = 0.1595 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 6495: loss = 0.2442 (0.372 sec/step)\n",
            "I0205 14:01:36.501740 140689526667136 learning.py:507] global step 6495: loss = 0.2442 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 6496: loss = 0.0804 (0.429 sec/step)\n",
            "I0205 14:01:36.932654 140689526667136 learning.py:507] global step 6496: loss = 0.0804 (0.429 sec/step)\n",
            "INFO:tensorflow:global step 6497: loss = 0.1683 (0.382 sec/step)\n",
            "I0205 14:01:37.316090 140689526667136 learning.py:507] global step 6497: loss = 0.1683 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 6498: loss = 0.1294 (0.406 sec/step)\n",
            "I0205 14:01:37.723283 140689526667136 learning.py:507] global step 6498: loss = 0.1294 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 6499: loss = 0.0757 (0.375 sec/step)\n",
            "I0205 14:01:38.099843 140689526667136 learning.py:507] global step 6499: loss = 0.0757 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 6500: loss = 0.0998 (0.346 sec/step)\n",
            "I0205 14:01:38.447325 140689526667136 learning.py:507] global step 6500: loss = 0.0998 (0.346 sec/step)\n",
            "INFO:tensorflow:global step 6501: loss = 0.3630 (0.379 sec/step)\n",
            "I0205 14:01:38.828357 140689526667136 learning.py:507] global step 6501: loss = 0.3630 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 6502: loss = 0.1016 (0.379 sec/step)\n",
            "I0205 14:01:39.212651 140689526667136 learning.py:507] global step 6502: loss = 0.1016 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 6503: loss = 0.1484 (0.376 sec/step)\n",
            "I0205 14:01:39.590088 140689526667136 learning.py:507] global step 6503: loss = 0.1484 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 6504: loss = 0.1146 (0.384 sec/step)\n",
            "I0205 14:01:39.975396 140689526667136 learning.py:507] global step 6504: loss = 0.1146 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6505: loss = 0.1623 (0.340 sec/step)\n",
            "I0205 14:01:40.316982 140689526667136 learning.py:507] global step 6505: loss = 0.1623 (0.340 sec/step)\n",
            "INFO:tensorflow:global step 6506: loss = 0.1146 (0.388 sec/step)\n",
            "I0205 14:01:40.707011 140689526667136 learning.py:507] global step 6506: loss = 0.1146 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 6507: loss = 0.1012 (0.361 sec/step)\n",
            "I0205 14:01:41.069615 140689526667136 learning.py:507] global step 6507: loss = 0.1012 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 6508: loss = 0.1624 (0.390 sec/step)\n",
            "I0205 14:01:41.462156 140689526667136 learning.py:507] global step 6508: loss = 0.1624 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 6509: loss = 0.0876 (0.382 sec/step)\n",
            "I0205 14:01:41.845522 140689526667136 learning.py:507] global step 6509: loss = 0.0876 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 6510: loss = 0.1775 (0.383 sec/step)\n",
            "I0205 14:01:42.229983 140689526667136 learning.py:507] global step 6510: loss = 0.1775 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 6511: loss = 0.2276 (0.371 sec/step)\n",
            "I0205 14:01:42.602945 140689526667136 learning.py:507] global step 6511: loss = 0.2276 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 6512: loss = 0.1200 (0.398 sec/step)\n",
            "I0205 14:01:43.002499 140689526667136 learning.py:507] global step 6512: loss = 0.1200 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 6513: loss = 0.0413 (0.379 sec/step)\n",
            "I0205 14:01:43.383513 140689526667136 learning.py:507] global step 6513: loss = 0.0413 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 6514: loss = 0.1054 (0.418 sec/step)\n",
            "I0205 14:01:43.802810 140689526667136 learning.py:507] global step 6514: loss = 0.1054 (0.418 sec/step)\n",
            "INFO:tensorflow:global step 6515: loss = 0.0786 (0.387 sec/step)\n",
            "I0205 14:01:44.191943 140689526667136 learning.py:507] global step 6515: loss = 0.0786 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 6516: loss = 0.0947 (0.377 sec/step)\n",
            "I0205 14:01:44.570725 140689526667136 learning.py:507] global step 6516: loss = 0.0947 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 6517: loss = 0.1133 (0.391 sec/step)\n",
            "I0205 14:01:44.962896 140689526667136 learning.py:507] global step 6517: loss = 0.1133 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6518: loss = 0.0491 (0.388 sec/step)\n",
            "I0205 14:01:45.352381 140689526667136 learning.py:507] global step 6518: loss = 0.0491 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 6519: loss = 0.1382 (0.353 sec/step)\n",
            "I0205 14:01:45.706653 140689526667136 learning.py:507] global step 6519: loss = 0.1382 (0.353 sec/step)\n",
            "INFO:tensorflow:global step 6520: loss = 0.1624 (0.402 sec/step)\n",
            "I0205 14:01:46.109915 140689526667136 learning.py:507] global step 6520: loss = 0.1624 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 6521: loss = 0.1387 (0.375 sec/step)\n",
            "I0205 14:01:46.486613 140689526667136 learning.py:507] global step 6521: loss = 0.1387 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 6522: loss = 0.0992 (0.364 sec/step)\n",
            "I0205 14:01:46.854538 140689526667136 learning.py:507] global step 6522: loss = 0.0992 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 6523: loss = 0.0248 (0.362 sec/step)\n",
            "I0205 14:01:47.217745 140689526667136 learning.py:507] global step 6523: loss = 0.0248 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 6524: loss = 0.0863 (0.371 sec/step)\n",
            "I0205 14:01:47.590401 140689526667136 learning.py:507] global step 6524: loss = 0.0863 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 6525: loss = 0.9352 (0.372 sec/step)\n",
            "I0205 14:01:47.963727 140689526667136 learning.py:507] global step 6525: loss = 0.9352 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 6526: loss = 0.0577 (0.399 sec/step)\n",
            "I0205 14:01:48.364339 140689526667136 learning.py:507] global step 6526: loss = 0.0577 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 6527: loss = 0.1687 (0.395 sec/step)\n",
            "I0205 14:01:48.760811 140689526667136 learning.py:507] global step 6527: loss = 0.1687 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 6528: loss = 0.0367 (0.405 sec/step)\n",
            "I0205 14:01:49.167575 140689526667136 learning.py:507] global step 6528: loss = 0.0367 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 6529: loss = 0.1182 (0.403 sec/step)\n",
            "I0205 14:01:49.572716 140689526667136 learning.py:507] global step 6529: loss = 0.1182 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 6530: loss = 0.0638 (0.377 sec/step)\n",
            "I0205 14:01:49.952013 140689526667136 learning.py:507] global step 6530: loss = 0.0638 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 6531: loss = 0.0873 (0.370 sec/step)\n",
            "I0205 14:01:50.324261 140689526667136 learning.py:507] global step 6531: loss = 0.0873 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 6532: loss = 0.0274 (0.415 sec/step)\n",
            "I0205 14:01:50.740389 140689526667136 learning.py:507] global step 6532: loss = 0.0274 (0.415 sec/step)\n",
            "INFO:tensorflow:global step 6533: loss = 0.0638 (0.398 sec/step)\n",
            "I0205 14:01:51.139834 140689526667136 learning.py:507] global step 6533: loss = 0.0638 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 6534: loss = 0.1067 (0.408 sec/step)\n",
            "I0205 14:01:51.549397 140689526667136 learning.py:507] global step 6534: loss = 0.1067 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 6535: loss = 0.4910 (0.412 sec/step)\n",
            "I0205 14:01:51.963142 140689526667136 learning.py:507] global step 6535: loss = 0.4910 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 6536: loss = 0.2242 (0.419 sec/step)\n",
            "I0205 14:01:52.384370 140689526667136 learning.py:507] global step 6536: loss = 0.2242 (0.419 sec/step)\n",
            "INFO:tensorflow:global step 6537: loss = 0.0141 (0.407 sec/step)\n",
            "I0205 14:01:52.793267 140689526667136 learning.py:507] global step 6537: loss = 0.0141 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 6538: loss = 0.3686 (0.414 sec/step)\n",
            "I0205 14:01:53.209258 140689526667136 learning.py:507] global step 6538: loss = 0.3686 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 6539: loss = 0.0720 (0.397 sec/step)\n",
            "I0205 14:01:53.609384 140689526667136 learning.py:507] global step 6539: loss = 0.0720 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 6540: loss = 0.2193 (0.376 sec/step)\n",
            "I0205 14:01:53.987537 140689526667136 learning.py:507] global step 6540: loss = 0.2193 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 6541: loss = 0.1667 (0.401 sec/step)\n",
            "I0205 14:01:54.390321 140689526667136 learning.py:507] global step 6541: loss = 0.1667 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 6542: loss = 0.0878 (0.396 sec/step)\n",
            "I0205 14:01:54.787805 140689526667136 learning.py:507] global step 6542: loss = 0.0878 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 6543: loss = 0.2296 (0.364 sec/step)\n",
            "I0205 14:01:55.153725 140689526667136 learning.py:507] global step 6543: loss = 0.2296 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 6544: loss = 0.1975 (0.415 sec/step)\n",
            "I0205 14:01:55.570575 140689526667136 learning.py:507] global step 6544: loss = 0.1975 (0.415 sec/step)\n",
            "INFO:tensorflow:global step 6545: loss = 0.0860 (0.384 sec/step)\n",
            "I0205 14:01:55.956509 140689526667136 learning.py:507] global step 6545: loss = 0.0860 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6546: loss = 0.2650 (0.389 sec/step)\n",
            "I0205 14:01:56.347409 140689526667136 learning.py:507] global step 6546: loss = 0.2650 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 6547: loss = 0.0694 (0.413 sec/step)\n",
            "I0205 14:01:56.761906 140689526667136 learning.py:507] global step 6547: loss = 0.0694 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 6548: loss = 0.1259 (0.367 sec/step)\n",
            "I0205 14:01:57.131066 140689526667136 learning.py:507] global step 6548: loss = 0.1259 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 6549: loss = 0.0784 (0.368 sec/step)\n",
            "I0205 14:01:57.500622 140689526667136 learning.py:507] global step 6549: loss = 0.0784 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 6550: loss = 0.1058 (0.384 sec/step)\n",
            "I0205 14:01:57.886093 140689526667136 learning.py:507] global step 6550: loss = 0.1058 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6551: loss = 0.1381 (0.379 sec/step)\n",
            "I0205 14:01:58.266530 140689526667136 learning.py:507] global step 6551: loss = 0.1381 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 6552: loss = 0.1160 (0.426 sec/step)\n",
            "I0205 14:01:58.694505 140689526667136 learning.py:507] global step 6552: loss = 0.1160 (0.426 sec/step)\n",
            "INFO:tensorflow:global step 6553: loss = 0.0367 (0.391 sec/step)\n",
            "I0205 14:01:59.086856 140689526667136 learning.py:507] global step 6553: loss = 0.0367 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6554: loss = 0.1610 (0.401 sec/step)\n",
            "I0205 14:01:59.489567 140689526667136 learning.py:507] global step 6554: loss = 0.1610 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 6555: loss = 0.0773 (0.417 sec/step)\n",
            "I0205 14:01:59.908113 140689526667136 learning.py:507] global step 6555: loss = 0.0773 (0.417 sec/step)\n",
            "INFO:tensorflow:global step 6556: loss = 0.0353 (0.382 sec/step)\n",
            "I0205 14:02:00.291642 140689526667136 learning.py:507] global step 6556: loss = 0.0353 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 6557: loss = 0.2007 (0.408 sec/step)\n",
            "I0205 14:02:00.701726 140689526667136 learning.py:507] global step 6557: loss = 0.2007 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 6558: loss = 0.0403 (0.382 sec/step)\n",
            "I0205 14:02:01.084735 140689526667136 learning.py:507] global step 6558: loss = 0.0403 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 6559: loss = 0.0745 (0.394 sec/step)\n",
            "I0205 14:02:01.480118 140689526667136 learning.py:507] global step 6559: loss = 0.0745 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 6560: loss = 0.0566 (0.400 sec/step)\n",
            "I0205 14:02:01.881635 140689526667136 learning.py:507] global step 6560: loss = 0.0566 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 6561: loss = 0.0972 (0.377 sec/step)\n",
            "I0205 14:02:02.260658 140689526667136 learning.py:507] global step 6561: loss = 0.0972 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 6562: loss = 0.0620 (0.383 sec/step)\n",
            "I0205 14:02:02.645603 140689526667136 learning.py:507] global step 6562: loss = 0.0620 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 6563: loss = 0.0572 (0.379 sec/step)\n",
            "I0205 14:02:03.025898 140689526667136 learning.py:507] global step 6563: loss = 0.0572 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 6564: loss = 0.1052 (0.387 sec/step)\n",
            "I0205 14:02:03.414112 140689526667136 learning.py:507] global step 6564: loss = 0.1052 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 6565: loss = 0.1027 (0.402 sec/step)\n",
            "I0205 14:02:03.817934 140689526667136 learning.py:507] global step 6565: loss = 0.1027 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 6566: loss = 0.4468 (0.381 sec/step)\n",
            "I0205 14:02:04.200043 140689526667136 learning.py:507] global step 6566: loss = 0.4468 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 6567: loss = 0.2244 (0.384 sec/step)\n",
            "I0205 14:02:04.585730 140689526667136 learning.py:507] global step 6567: loss = 0.2244 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6568: loss = 0.0504 (0.364 sec/step)\n",
            "I0205 14:02:04.951095 140689526667136 learning.py:507] global step 6568: loss = 0.0504 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 6569: loss = 0.2288 (0.400 sec/step)\n",
            "I0205 14:02:05.353246 140689526667136 learning.py:507] global step 6569: loss = 0.2288 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 6570: loss = 0.2187 (0.370 sec/step)\n",
            "I0205 14:02:05.724621 140689526667136 learning.py:507] global step 6570: loss = 0.2187 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 6571: loss = 0.1065 (0.396 sec/step)\n",
            "I0205 14:02:06.122194 140689526667136 learning.py:507] global step 6571: loss = 0.1065 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 6572: loss = 0.0689 (0.399 sec/step)\n",
            "I0205 14:02:06.522718 140689526667136 learning.py:507] global step 6572: loss = 0.0689 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 6573: loss = 0.0414 (0.413 sec/step)\n",
            "I0205 14:02:06.937842 140689526667136 learning.py:507] global step 6573: loss = 0.0414 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 6574: loss = 0.0718 (0.361 sec/step)\n",
            "I0205 14:02:07.300294 140689526667136 learning.py:507] global step 6574: loss = 0.0718 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 6575: loss = 0.0377 (0.403 sec/step)\n",
            "I0205 14:02:07.705342 140689526667136 learning.py:507] global step 6575: loss = 0.0377 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 6576: loss = 0.1626 (0.432 sec/step)\n",
            "I0205 14:02:08.139992 140689526667136 learning.py:507] global step 6576: loss = 0.1626 (0.432 sec/step)\n",
            "INFO:tensorflow:global step 6577: loss = 0.1953 (0.423 sec/step)\n",
            "I0205 14:02:08.565582 140689526667136 learning.py:507] global step 6577: loss = 0.1953 (0.423 sec/step)\n",
            "INFO:tensorflow:global step 6578: loss = 0.1126 (0.433 sec/step)\n",
            "I0205 14:02:09.001206 140689526667136 learning.py:507] global step 6578: loss = 0.1126 (0.433 sec/step)\n",
            "INFO:tensorflow:global step 6579: loss = 0.3379 (0.410 sec/step)\n",
            "I0205 14:02:09.413038 140689526667136 learning.py:507] global step 6579: loss = 0.3379 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 6580: loss = 0.0747 (0.365 sec/step)\n",
            "I0205 14:02:09.779977 140689526667136 learning.py:507] global step 6580: loss = 0.0747 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 6581: loss = 0.1012 (0.373 sec/step)\n",
            "I0205 14:02:10.154670 140689526667136 learning.py:507] global step 6581: loss = 0.1012 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 6582: loss = 0.1369 (0.370 sec/step)\n",
            "I0205 14:02:10.526276 140689526667136 learning.py:507] global step 6582: loss = 0.1369 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 6583: loss = 0.2986 (0.366 sec/step)\n",
            "I0205 14:02:10.894384 140689526667136 learning.py:507] global step 6583: loss = 0.2986 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 6584: loss = 0.1299 (0.395 sec/step)\n",
            "I0205 14:02:11.291444 140689526667136 learning.py:507] global step 6584: loss = 0.1299 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 6585: loss = 0.1069 (0.378 sec/step)\n",
            "I0205 14:02:11.670862 140689526667136 learning.py:507] global step 6585: loss = 0.1069 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 6586: loss = 0.1505 (0.399 sec/step)\n",
            "I0205 14:02:12.071585 140689526667136 learning.py:507] global step 6586: loss = 0.1505 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 6587: loss = 0.2490 (0.395 sec/step)\n",
            "I0205 14:02:12.468303 140689526667136 learning.py:507] global step 6587: loss = 0.2490 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 6588: loss = 0.0547 (0.401 sec/step)\n",
            "I0205 14:02:12.871210 140689526667136 learning.py:507] global step 6588: loss = 0.0547 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 6589: loss = 0.2063 (0.370 sec/step)\n",
            "I0205 14:02:13.242930 140689526667136 learning.py:507] global step 6589: loss = 0.2063 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 6590: loss = 0.3364 (0.405 sec/step)\n",
            "I0205 14:02:13.650055 140689526667136 learning.py:507] global step 6590: loss = 0.3364 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 6591: loss = 0.0856 (1.002 sec/step)\n",
            "I0205 14:02:14.718681 140689526667136 learning.py:507] global step 6591: loss = 0.0856 (1.002 sec/step)\n",
            "INFO:tensorflow:global step 6592: loss = 0.2948 (0.831 sec/step)\n",
            "I0205 14:02:15.588184 140689526667136 learning.py:507] global step 6592: loss = 0.2948 (0.831 sec/step)\n",
            "INFO:tensorflow:global step 6593: loss = 0.0501 (0.579 sec/step)\n",
            "I0205 14:02:16.188528 140689526667136 learning.py:507] global step 6593: loss = 0.0501 (0.579 sec/step)\n",
            "INFO:tensorflow:global step 6594: loss = 0.1863 (0.582 sec/step)\n",
            "I0205 14:02:16.795830 140689526667136 learning.py:507] global step 6594: loss = 0.1863 (0.582 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 6594.\n",
            "I0205 14:02:17.465366 140686026073856 supervisor.py:1050] Recording summary at step 6594.\n",
            "INFO:tensorflow:global step 6595: loss = 0.1342 (0.687 sec/step)\n",
            "I0205 14:02:17.488953 140689526667136 learning.py:507] global step 6595: loss = 0.1342 (0.687 sec/step)\n",
            "INFO:tensorflow:global step 6596: loss = 0.4383 (0.397 sec/step)\n",
            "I0205 14:02:17.888345 140689526667136 learning.py:507] global step 6596: loss = 0.4383 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 6597: loss = 0.0944 (0.384 sec/step)\n",
            "I0205 14:02:18.275136 140689526667136 learning.py:507] global step 6597: loss = 0.0944 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6598: loss = 0.1040 (0.363 sec/step)\n",
            "I0205 14:02:18.639894 140689526667136 learning.py:507] global step 6598: loss = 0.1040 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 6599: loss = 0.2215 (0.396 sec/step)\n",
            "I0205 14:02:19.037928 140689526667136 learning.py:507] global step 6599: loss = 0.2215 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 6600: loss = 0.1425 (0.372 sec/step)\n",
            "I0205 14:02:19.411275 140689526667136 learning.py:507] global step 6600: loss = 0.1425 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 6601: loss = 0.0565 (0.375 sec/step)\n",
            "I0205 14:02:19.788138 140689526667136 learning.py:507] global step 6601: loss = 0.0565 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 6602: loss = 0.0890 (0.376 sec/step)\n",
            "I0205 14:02:20.165894 140689526667136 learning.py:507] global step 6602: loss = 0.0890 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 6603: loss = 0.2014 (0.375 sec/step)\n",
            "I0205 14:02:20.542492 140689526667136 learning.py:507] global step 6603: loss = 0.2014 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 6604: loss = 0.0869 (0.389 sec/step)\n",
            "I0205 14:02:20.933236 140689526667136 learning.py:507] global step 6604: loss = 0.0869 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 6605: loss = 0.1135 (0.373 sec/step)\n",
            "I0205 14:02:21.308062 140689526667136 learning.py:507] global step 6605: loss = 0.1135 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 6606: loss = 0.0406 (0.389 sec/step)\n",
            "I0205 14:02:21.698160 140689526667136 learning.py:507] global step 6606: loss = 0.0406 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 6607: loss = 0.2168 (0.411 sec/step)\n",
            "I0205 14:02:22.110476 140689526667136 learning.py:507] global step 6607: loss = 0.2168 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 6608: loss = 0.1416 (0.378 sec/step)\n",
            "I0205 14:02:22.490051 140689526667136 learning.py:507] global step 6608: loss = 0.1416 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 6609: loss = 0.0681 (0.380 sec/step)\n",
            "I0205 14:02:22.872080 140689526667136 learning.py:507] global step 6609: loss = 0.0681 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 6610: loss = 0.1483 (0.390 sec/step)\n",
            "I0205 14:02:23.263459 140689526667136 learning.py:507] global step 6610: loss = 0.1483 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 6611: loss = 0.1469 (0.384 sec/step)\n",
            "I0205 14:02:23.648998 140689526667136 learning.py:507] global step 6611: loss = 0.1469 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6612: loss = 0.1063 (0.388 sec/step)\n",
            "I0205 14:02:24.039232 140689526667136 learning.py:507] global step 6612: loss = 0.1063 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 6613: loss = 0.4061 (0.402 sec/step)\n",
            "I0205 14:02:24.442697 140689526667136 learning.py:507] global step 6613: loss = 0.4061 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 6614: loss = 0.1245 (0.401 sec/step)\n",
            "I0205 14:02:24.845314 140689526667136 learning.py:507] global step 6614: loss = 0.1245 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 6615: loss = 0.2917 (0.399 sec/step)\n",
            "I0205 14:02:25.245884 140689526667136 learning.py:507] global step 6615: loss = 0.2917 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 6616: loss = 0.5570 (0.385 sec/step)\n",
            "I0205 14:02:25.632819 140689526667136 learning.py:507] global step 6616: loss = 0.5570 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 6617: loss = 0.0622 (0.427 sec/step)\n",
            "I0205 14:02:26.061610 140689526667136 learning.py:507] global step 6617: loss = 0.0622 (0.427 sec/step)\n",
            "INFO:tensorflow:global step 6618: loss = 0.0588 (0.388 sec/step)\n",
            "I0205 14:02:26.451144 140689526667136 learning.py:507] global step 6618: loss = 0.0588 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 6619: loss = 0.2270 (0.380 sec/step)\n",
            "I0205 14:02:26.832938 140689526667136 learning.py:507] global step 6619: loss = 0.2270 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 6620: loss = 0.6992 (0.408 sec/step)\n",
            "I0205 14:02:27.242706 140689526667136 learning.py:507] global step 6620: loss = 0.6992 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 6621: loss = 0.1903 (0.378 sec/step)\n",
            "I0205 14:02:27.623029 140689526667136 learning.py:507] global step 6621: loss = 0.1903 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 6622: loss = 0.6106 (0.403 sec/step)\n",
            "I0205 14:02:28.027375 140689526667136 learning.py:507] global step 6622: loss = 0.6106 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 6623: loss = 0.4344 (0.423 sec/step)\n",
            "I0205 14:02:28.451810 140689526667136 learning.py:507] global step 6623: loss = 0.4344 (0.423 sec/step)\n",
            "INFO:tensorflow:global step 6624: loss = 0.1643 (0.398 sec/step)\n",
            "I0205 14:02:28.851745 140689526667136 learning.py:507] global step 6624: loss = 0.1643 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 6625: loss = 0.0962 (0.396 sec/step)\n",
            "I0205 14:02:29.249619 140689526667136 learning.py:507] global step 6625: loss = 0.0962 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 6626: loss = 0.0821 (0.408 sec/step)\n",
            "I0205 14:02:29.659805 140689526667136 learning.py:507] global step 6626: loss = 0.0821 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 6627: loss = 0.0424 (0.424 sec/step)\n",
            "I0205 14:02:30.085963 140689526667136 learning.py:507] global step 6627: loss = 0.0424 (0.424 sec/step)\n",
            "INFO:tensorflow:global step 6628: loss = 0.0673 (0.392 sec/step)\n",
            "I0205 14:02:30.480577 140689526667136 learning.py:507] global step 6628: loss = 0.0673 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 6629: loss = 0.1552 (0.370 sec/step)\n",
            "I0205 14:02:30.852220 140689526667136 learning.py:507] global step 6629: loss = 0.1552 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 6630: loss = 0.2555 (0.373 sec/step)\n",
            "I0205 14:02:31.227334 140689526667136 learning.py:507] global step 6630: loss = 0.2555 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 6631: loss = 0.3582 (0.425 sec/step)\n",
            "I0205 14:02:31.653781 140689526667136 learning.py:507] global step 6631: loss = 0.3582 (0.425 sec/step)\n",
            "INFO:tensorflow:global step 6632: loss = 0.1492 (0.383 sec/step)\n",
            "I0205 14:02:32.038569 140689526667136 learning.py:507] global step 6632: loss = 0.1492 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 6633: loss = 0.1179 (0.398 sec/step)\n",
            "I0205 14:02:32.438312 140689526667136 learning.py:507] global step 6633: loss = 0.1179 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 6634: loss = 0.0560 (0.363 sec/step)\n",
            "I0205 14:02:32.803018 140689526667136 learning.py:507] global step 6634: loss = 0.0560 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 6635: loss = 0.1136 (0.399 sec/step)\n",
            "I0205 14:02:33.203437 140689526667136 learning.py:507] global step 6635: loss = 0.1136 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 6636: loss = 0.2689 (0.409 sec/step)\n",
            "I0205 14:02:33.614113 140689526667136 learning.py:507] global step 6636: loss = 0.2689 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 6637: loss = 0.0441 (0.385 sec/step)\n",
            "I0205 14:02:34.000717 140689526667136 learning.py:507] global step 6637: loss = 0.0441 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 6638: loss = 0.2497 (0.385 sec/step)\n",
            "I0205 14:02:34.387693 140689526667136 learning.py:507] global step 6638: loss = 0.2497 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 6639: loss = 0.2409 (0.397 sec/step)\n",
            "I0205 14:02:34.786582 140689526667136 learning.py:507] global step 6639: loss = 0.2409 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 6640: loss = 0.3850 (0.379 sec/step)\n",
            "I0205 14:02:35.167222 140689526667136 learning.py:507] global step 6640: loss = 0.3850 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 6641: loss = 0.1297 (0.374 sec/step)\n",
            "I0205 14:02:35.542739 140689526667136 learning.py:507] global step 6641: loss = 0.1297 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 6642: loss = 0.1945 (0.397 sec/step)\n",
            "I0205 14:02:35.941670 140689526667136 learning.py:507] global step 6642: loss = 0.1945 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 6643: loss = 0.1829 (0.384 sec/step)\n",
            "I0205 14:02:36.327216 140689526667136 learning.py:507] global step 6643: loss = 0.1829 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6644: loss = 0.1524 (0.375 sec/step)\n",
            "I0205 14:02:36.703137 140689526667136 learning.py:507] global step 6644: loss = 0.1524 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 6645: loss = 0.0962 (0.366 sec/step)\n",
            "I0205 14:02:37.071206 140689526667136 learning.py:507] global step 6645: loss = 0.0962 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 6646: loss = 0.0832 (0.394 sec/step)\n",
            "I0205 14:02:37.466941 140689526667136 learning.py:507] global step 6646: loss = 0.0832 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 6647: loss = 0.1161 (0.383 sec/step)\n",
            "I0205 14:02:37.852153 140689526667136 learning.py:507] global step 6647: loss = 0.1161 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 6648: loss = 0.0503 (0.362 sec/step)\n",
            "I0205 14:02:38.215927 140689526667136 learning.py:507] global step 6648: loss = 0.0503 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 6649: loss = 0.1347 (0.370 sec/step)\n",
            "I0205 14:02:38.587310 140689526667136 learning.py:507] global step 6649: loss = 0.1347 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 6650: loss = 0.0742 (0.382 sec/step)\n",
            "I0205 14:02:38.971151 140689526667136 learning.py:507] global step 6650: loss = 0.0742 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 6651: loss = 0.0200 (0.368 sec/step)\n",
            "I0205 14:02:39.340767 140689526667136 learning.py:507] global step 6651: loss = 0.0200 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 6652: loss = 0.1489 (0.398 sec/step)\n",
            "I0205 14:02:39.740613 140689526667136 learning.py:507] global step 6652: loss = 0.1489 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 6653: loss = 0.4508 (0.379 sec/step)\n",
            "I0205 14:02:40.121472 140689526667136 learning.py:507] global step 6653: loss = 0.4508 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 6654: loss = 0.0598 (0.390 sec/step)\n",
            "I0205 14:02:40.512767 140689526667136 learning.py:507] global step 6654: loss = 0.0598 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 6655: loss = 0.0515 (0.376 sec/step)\n",
            "I0205 14:02:40.890218 140689526667136 learning.py:507] global step 6655: loss = 0.0515 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 6656: loss = 0.0799 (0.384 sec/step)\n",
            "I0205 14:02:41.275538 140689526667136 learning.py:507] global step 6656: loss = 0.0799 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6657: loss = 0.1451 (0.395 sec/step)\n",
            "I0205 14:02:41.672116 140689526667136 learning.py:507] global step 6657: loss = 0.1451 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 6658: loss = 0.0509 (0.379 sec/step)\n",
            "I0205 14:02:42.052522 140689526667136 learning.py:507] global step 6658: loss = 0.0509 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 6659: loss = 0.2616 (0.398 sec/step)\n",
            "I0205 14:02:42.452581 140689526667136 learning.py:507] global step 6659: loss = 0.2616 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 6660: loss = 0.1338 (0.378 sec/step)\n",
            "I0205 14:02:42.831872 140689526667136 learning.py:507] global step 6660: loss = 0.1338 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 6661: loss = 0.4326 (0.399 sec/step)\n",
            "I0205 14:02:43.232792 140689526667136 learning.py:507] global step 6661: loss = 0.4326 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 6662: loss = 0.1373 (0.365 sec/step)\n",
            "I0205 14:02:43.599588 140689526667136 learning.py:507] global step 6662: loss = 0.1373 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 6663: loss = 0.1342 (0.403 sec/step)\n",
            "I0205 14:02:44.004092 140689526667136 learning.py:507] global step 6663: loss = 0.1342 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 6664: loss = 0.6172 (0.407 sec/step)\n",
            "I0205 14:02:44.412661 140689526667136 learning.py:507] global step 6664: loss = 0.6172 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 6665: loss = 0.1182 (0.393 sec/step)\n",
            "I0205 14:02:44.807001 140689526667136 learning.py:507] global step 6665: loss = 0.1182 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 6666: loss = 0.6676 (0.355 sec/step)\n",
            "I0205 14:02:45.163512 140689526667136 learning.py:507] global step 6666: loss = 0.6676 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 6667: loss = 0.4447 (0.391 sec/step)\n",
            "I0205 14:02:45.556216 140689526667136 learning.py:507] global step 6667: loss = 0.4447 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6668: loss = 0.1721 (0.392 sec/step)\n",
            "I0205 14:02:45.951447 140689526667136 learning.py:507] global step 6668: loss = 0.1721 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 6669: loss = 0.1405 (0.401 sec/step)\n",
            "I0205 14:02:46.354002 140689526667136 learning.py:507] global step 6669: loss = 0.1405 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 6670: loss = 0.1205 (0.440 sec/step)\n",
            "I0205 14:02:46.795191 140689526667136 learning.py:507] global step 6670: loss = 0.1205 (0.440 sec/step)\n",
            "INFO:tensorflow:global step 6671: loss = 0.5181 (0.369 sec/step)\n",
            "I0205 14:02:47.166249 140689526667136 learning.py:507] global step 6671: loss = 0.5181 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 6672: loss = 0.1506 (0.415 sec/step)\n",
            "I0205 14:02:47.582854 140689526667136 learning.py:507] global step 6672: loss = 0.1506 (0.415 sec/step)\n",
            "INFO:tensorflow:global step 6673: loss = 0.1492 (0.396 sec/step)\n",
            "I0205 14:02:47.981099 140689526667136 learning.py:507] global step 6673: loss = 0.1492 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 6674: loss = 0.3651 (0.401 sec/step)\n",
            "I0205 14:02:48.383566 140689526667136 learning.py:507] global step 6674: loss = 0.3651 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 6675: loss = 0.0441 (0.368 sec/step)\n",
            "I0205 14:02:48.753120 140689526667136 learning.py:507] global step 6675: loss = 0.0441 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 6676: loss = 0.4836 (0.388 sec/step)\n",
            "I0205 14:02:49.143483 140689526667136 learning.py:507] global step 6676: loss = 0.4836 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 6677: loss = 0.0639 (0.412 sec/step)\n",
            "I0205 14:02:49.557863 140689526667136 learning.py:507] global step 6677: loss = 0.0639 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 6678: loss = 0.0832 (0.373 sec/step)\n",
            "I0205 14:02:49.932683 140689526667136 learning.py:507] global step 6678: loss = 0.0832 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 6679: loss = 0.1650 (0.370 sec/step)\n",
            "I0205 14:02:50.304591 140689526667136 learning.py:507] global step 6679: loss = 0.1650 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 6680: loss = 0.2568 (0.393 sec/step)\n",
            "I0205 14:02:50.699877 140689526667136 learning.py:507] global step 6680: loss = 0.2568 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 6681: loss = 0.4870 (0.400 sec/step)\n",
            "I0205 14:02:51.101435 140689526667136 learning.py:507] global step 6681: loss = 0.4870 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 6682: loss = 0.1143 (0.355 sec/step)\n",
            "I0205 14:02:51.458532 140689526667136 learning.py:507] global step 6682: loss = 0.1143 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 6683: loss = 0.0710 (0.386 sec/step)\n",
            "I0205 14:02:51.846074 140689526667136 learning.py:507] global step 6683: loss = 0.0710 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 6684: loss = 0.1257 (0.396 sec/step)\n",
            "I0205 14:02:52.243243 140689526667136 learning.py:507] global step 6684: loss = 0.1257 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 6685: loss = 0.1279 (0.417 sec/step)\n",
            "I0205 14:02:52.662076 140689526667136 learning.py:507] global step 6685: loss = 0.1279 (0.417 sec/step)\n",
            "INFO:tensorflow:global step 6686: loss = 0.1654 (0.444 sec/step)\n",
            "I0205 14:02:53.107713 140689526667136 learning.py:507] global step 6686: loss = 0.1654 (0.444 sec/step)\n",
            "INFO:tensorflow:global step 6687: loss = 0.1299 (0.437 sec/step)\n",
            "I0205 14:02:53.547281 140689526667136 learning.py:507] global step 6687: loss = 0.1299 (0.437 sec/step)\n",
            "INFO:tensorflow:global step 6688: loss = 0.2101 (0.426 sec/step)\n",
            "I0205 14:02:53.975316 140689526667136 learning.py:507] global step 6688: loss = 0.2101 (0.426 sec/step)\n",
            "INFO:tensorflow:global step 6689: loss = 0.4535 (0.385 sec/step)\n",
            "I0205 14:02:54.362574 140689526667136 learning.py:507] global step 6689: loss = 0.4535 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 6690: loss = 0.0599 (0.379 sec/step)\n",
            "I0205 14:02:54.743891 140689526667136 learning.py:507] global step 6690: loss = 0.0599 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 6691: loss = 0.1577 (0.372 sec/step)\n",
            "I0205 14:02:55.117855 140689526667136 learning.py:507] global step 6691: loss = 0.1577 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 6692: loss = 0.0477 (0.388 sec/step)\n",
            "I0205 14:02:55.507103 140689526667136 learning.py:507] global step 6692: loss = 0.0477 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 6693: loss = 0.1310 (0.385 sec/step)\n",
            "I0205 14:02:55.893625 140689526667136 learning.py:507] global step 6693: loss = 0.1310 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 6694: loss = 0.2134 (0.379 sec/step)\n",
            "I0205 14:02:56.274693 140689526667136 learning.py:507] global step 6694: loss = 0.2134 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 6695: loss = 0.0164 (0.374 sec/step)\n",
            "I0205 14:02:56.650450 140689526667136 learning.py:507] global step 6695: loss = 0.0164 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 6696: loss = 0.0798 (0.377 sec/step)\n",
            "I0205 14:02:57.029631 140689526667136 learning.py:507] global step 6696: loss = 0.0798 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 6697: loss = 0.0653 (0.384 sec/step)\n",
            "I0205 14:02:57.415067 140689526667136 learning.py:507] global step 6697: loss = 0.0653 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6698: loss = 0.0669 (0.376 sec/step)\n",
            "I0205 14:02:57.792879 140689526667136 learning.py:507] global step 6698: loss = 0.0669 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 6699: loss = 0.2668 (0.386 sec/step)\n",
            "I0205 14:02:58.180430 140689526667136 learning.py:507] global step 6699: loss = 0.2668 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 6700: loss = 0.0556 (0.379 sec/step)\n",
            "I0205 14:02:58.560773 140689526667136 learning.py:507] global step 6700: loss = 0.0556 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 6701: loss = 0.1182 (0.366 sec/step)\n",
            "I0205 14:02:58.928417 140689526667136 learning.py:507] global step 6701: loss = 0.1182 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 6702: loss = 0.2537 (0.399 sec/step)\n",
            "I0205 14:02:59.329010 140689526667136 learning.py:507] global step 6702: loss = 0.2537 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 6703: loss = 0.2180 (0.384 sec/step)\n",
            "I0205 14:02:59.715179 140689526667136 learning.py:507] global step 6703: loss = 0.2180 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6704: loss = 0.0320 (0.382 sec/step)\n",
            "I0205 14:03:00.099048 140689526667136 learning.py:507] global step 6704: loss = 0.0320 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 6705: loss = 0.1272 (0.377 sec/step)\n",
            "I0205 14:03:00.478258 140689526667136 learning.py:507] global step 6705: loss = 0.1272 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 6706: loss = 0.1058 (0.384 sec/step)\n",
            "I0205 14:03:00.863757 140689526667136 learning.py:507] global step 6706: loss = 0.1058 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6707: loss = 0.0342 (0.364 sec/step)\n",
            "I0205 14:03:01.228811 140689526667136 learning.py:507] global step 6707: loss = 0.0342 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 6708: loss = 0.0200 (0.389 sec/step)\n",
            "I0205 14:03:01.619272 140689526667136 learning.py:507] global step 6708: loss = 0.0200 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 6709: loss = 0.0389 (0.378 sec/step)\n",
            "I0205 14:03:01.998978 140689526667136 learning.py:507] global step 6709: loss = 0.0389 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 6710: loss = 0.0818 (0.417 sec/step)\n",
            "I0205 14:03:02.417346 140689526667136 learning.py:507] global step 6710: loss = 0.0818 (0.417 sec/step)\n",
            "INFO:tensorflow:global step 6711: loss = 0.0210 (0.387 sec/step)\n",
            "I0205 14:03:02.806563 140689526667136 learning.py:507] global step 6711: loss = 0.0210 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 6712: loss = 0.0575 (0.420 sec/step)\n",
            "I0205 14:03:03.228144 140689526667136 learning.py:507] global step 6712: loss = 0.0575 (0.420 sec/step)\n",
            "INFO:tensorflow:global step 6713: loss = 0.1648 (0.400 sec/step)\n",
            "I0205 14:03:03.630117 140689526667136 learning.py:507] global step 6713: loss = 0.1648 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 6714: loss = 0.2541 (0.384 sec/step)\n",
            "I0205 14:03:04.015550 140689526667136 learning.py:507] global step 6714: loss = 0.2541 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6715: loss = 0.2175 (0.394 sec/step)\n",
            "I0205 14:03:04.411709 140689526667136 learning.py:507] global step 6715: loss = 0.2175 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 6716: loss = 0.3226 (0.391 sec/step)\n",
            "I0205 14:03:04.804129 140689526667136 learning.py:507] global step 6716: loss = 0.3226 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6717: loss = 0.0715 (0.384 sec/step)\n",
            "I0205 14:03:05.189900 140689526667136 learning.py:507] global step 6717: loss = 0.0715 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6718: loss = 0.0688 (0.382 sec/step)\n",
            "I0205 14:03:05.573708 140689526667136 learning.py:507] global step 6718: loss = 0.0688 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 6719: loss = 0.1403 (0.402 sec/step)\n",
            "I0205 14:03:05.977506 140689526667136 learning.py:507] global step 6719: loss = 0.1403 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 6720: loss = 0.6470 (0.382 sec/step)\n",
            "I0205 14:03:06.361782 140689526667136 learning.py:507] global step 6720: loss = 0.6470 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 6721: loss = 0.0524 (0.370 sec/step)\n",
            "I0205 14:03:06.733116 140689526667136 learning.py:507] global step 6721: loss = 0.0524 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 6722: loss = 0.2743 (0.362 sec/step)\n",
            "I0205 14:03:07.097207 140689526667136 learning.py:507] global step 6722: loss = 0.2743 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 6723: loss = 0.0366 (0.387 sec/step)\n",
            "I0205 14:03:07.485414 140689526667136 learning.py:507] global step 6723: loss = 0.0366 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 6724: loss = 0.1256 (0.425 sec/step)\n",
            "I0205 14:03:07.911654 140689526667136 learning.py:507] global step 6724: loss = 0.1256 (0.425 sec/step)\n",
            "INFO:tensorflow:global step 6725: loss = 0.1144 (0.421 sec/step)\n",
            "I0205 14:03:08.334768 140689526667136 learning.py:507] global step 6725: loss = 0.1144 (0.421 sec/step)\n",
            "INFO:tensorflow:global step 6726: loss = 0.0546 (0.433 sec/step)\n",
            "I0205 14:03:08.769282 140689526667136 learning.py:507] global step 6726: loss = 0.0546 (0.433 sec/step)\n",
            "INFO:tensorflow:global step 6727: loss = 0.0634 (0.422 sec/step)\n",
            "I0205 14:03:09.193001 140689526667136 learning.py:507] global step 6727: loss = 0.0634 (0.422 sec/step)\n",
            "INFO:tensorflow:global step 6728: loss = 0.0580 (0.376 sec/step)\n",
            "I0205 14:03:09.570440 140689526667136 learning.py:507] global step 6728: loss = 0.0580 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 6729: loss = 0.4239 (0.385 sec/step)\n",
            "I0205 14:03:09.957500 140689526667136 learning.py:507] global step 6729: loss = 0.4239 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 6730: loss = 0.1473 (0.388 sec/step)\n",
            "I0205 14:03:10.346847 140689526667136 learning.py:507] global step 6730: loss = 0.1473 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 6731: loss = 0.1995 (0.385 sec/step)\n",
            "I0205 14:03:10.732868 140689526667136 learning.py:507] global step 6731: loss = 0.1995 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 6732: loss = 0.1637 (0.381 sec/step)\n",
            "I0205 14:03:11.115270 140689526667136 learning.py:507] global step 6732: loss = 0.1637 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 6733: loss = 0.1395 (0.373 sec/step)\n",
            "I0205 14:03:11.489912 140689526667136 learning.py:507] global step 6733: loss = 0.1395 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 6734: loss = 0.1110 (0.392 sec/step)\n",
            "I0205 14:03:11.883990 140689526667136 learning.py:507] global step 6734: loss = 0.1110 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 6735: loss = 0.0570 (0.370 sec/step)\n",
            "I0205 14:03:12.255336 140689526667136 learning.py:507] global step 6735: loss = 0.0570 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 6736: loss = 0.1280 (0.394 sec/step)\n",
            "I0205 14:03:12.650941 140689526667136 learning.py:507] global step 6736: loss = 0.1280 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 6737: loss = 0.0210 (0.370 sec/step)\n",
            "I0205 14:03:13.023047 140689526667136 learning.py:507] global step 6737: loss = 0.0210 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 6738: loss = 0.1807 (0.396 sec/step)\n",
            "I0205 14:03:13.420947 140689526667136 learning.py:507] global step 6738: loss = 0.1807 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 6739: loss = 0.4235 (0.390 sec/step)\n",
            "I0205 14:03:13.812272 140689526667136 learning.py:507] global step 6739: loss = 0.4235 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 6740: loss = 0.2334 (0.422 sec/step)\n",
            "I0205 14:03:14.236051 140689526667136 learning.py:507] global step 6740: loss = 0.2334 (0.422 sec/step)\n",
            "INFO:tensorflow:global step 6741: loss = 0.0747 (0.407 sec/step)\n",
            "I0205 14:03:14.644329 140689526667136 learning.py:507] global step 6741: loss = 0.0747 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 6742: loss = 0.1941 (0.393 sec/step)\n",
            "I0205 14:03:15.038890 140689526667136 learning.py:507] global step 6742: loss = 0.1941 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 6743: loss = 0.0737 (0.393 sec/step)\n",
            "I0205 14:03:15.433921 140689526667136 learning.py:507] global step 6743: loss = 0.0737 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 6744: loss = 0.0765 (0.385 sec/step)\n",
            "I0205 14:03:15.820326 140689526667136 learning.py:507] global step 6744: loss = 0.0765 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 6745: loss = 0.0372 (0.380 sec/step)\n",
            "I0205 14:03:16.202033 140689526667136 learning.py:507] global step 6745: loss = 0.0372 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 6746: loss = 0.0516 (0.378 sec/step)\n",
            "I0205 14:03:16.581830 140689526667136 learning.py:507] global step 6746: loss = 0.0516 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 6747: loss = 0.0882 (0.387 sec/step)\n",
            "I0205 14:03:16.970324 140689526667136 learning.py:507] global step 6747: loss = 0.0882 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 6748: loss = 0.0387 (0.394 sec/step)\n",
            "I0205 14:03:17.365810 140689526667136 learning.py:507] global step 6748: loss = 0.0387 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 6749: loss = 0.0649 (0.395 sec/step)\n",
            "I0205 14:03:17.762669 140689526667136 learning.py:507] global step 6749: loss = 0.0649 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 6750: loss = 0.2072 (0.381 sec/step)\n",
            "I0205 14:03:18.144992 140689526667136 learning.py:507] global step 6750: loss = 0.2072 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 6751: loss = 0.3184 (0.410 sec/step)\n",
            "I0205 14:03:18.556640 140689526667136 learning.py:507] global step 6751: loss = 0.3184 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 6752: loss = 0.0547 (0.384 sec/step)\n",
            "I0205 14:03:18.943063 140689526667136 learning.py:507] global step 6752: loss = 0.0547 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6753: loss = 0.1527 (0.368 sec/step)\n",
            "I0205 14:03:19.313148 140689526667136 learning.py:507] global step 6753: loss = 0.1527 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 6754: loss = 0.0548 (0.382 sec/step)\n",
            "I0205 14:03:19.697112 140689526667136 learning.py:507] global step 6754: loss = 0.0548 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 6755: loss = 0.1497 (0.378 sec/step)\n",
            "I0205 14:03:20.077128 140689526667136 learning.py:507] global step 6755: loss = 0.1497 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 6756: loss = 0.1242 (0.389 sec/step)\n",
            "I0205 14:03:20.467376 140689526667136 learning.py:507] global step 6756: loss = 0.1242 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 6757: loss = 0.1325 (0.422 sec/step)\n",
            "I0205 14:03:20.891049 140689526667136 learning.py:507] global step 6757: loss = 0.1325 (0.422 sec/step)\n",
            "INFO:tensorflow:global step 6758: loss = 1.9702 (0.368 sec/step)\n",
            "I0205 14:03:21.260559 140689526667136 learning.py:507] global step 6758: loss = 1.9702 (0.368 sec/step)\n",
            "INFO:tensorflow:global step 6759: loss = 0.0855 (0.403 sec/step)\n",
            "I0205 14:03:21.665335 140689526667136 learning.py:507] global step 6759: loss = 0.0855 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 6760: loss = 0.2665 (0.400 sec/step)\n",
            "I0205 14:03:22.066663 140689526667136 learning.py:507] global step 6760: loss = 0.2665 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 6761: loss = 0.1036 (0.365 sec/step)\n",
            "I0205 14:03:22.433104 140689526667136 learning.py:507] global step 6761: loss = 0.1036 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 6762: loss = 0.0921 (0.371 sec/step)\n",
            "I0205 14:03:22.805785 140689526667136 learning.py:507] global step 6762: loss = 0.0921 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 6763: loss = 0.1528 (0.372 sec/step)\n",
            "I0205 14:03:23.179688 140689526667136 learning.py:507] global step 6763: loss = 0.1528 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 6764: loss = 0.0938 (0.397 sec/step)\n",
            "I0205 14:03:23.578716 140689526667136 learning.py:507] global step 6764: loss = 0.0938 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 6765: loss = 0.1692 (0.370 sec/step)\n",
            "I0205 14:03:23.950809 140689526667136 learning.py:507] global step 6765: loss = 0.1692 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 6766: loss = 0.0489 (0.385 sec/step)\n",
            "I0205 14:03:24.342554 140689526667136 learning.py:507] global step 6766: loss = 0.0489 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 6767: loss = 0.0714 (0.426 sec/step)\n",
            "I0205 14:03:24.770540 140689526667136 learning.py:507] global step 6767: loss = 0.0714 (0.426 sec/step)\n",
            "INFO:tensorflow:global step 6768: loss = 0.0735 (0.370 sec/step)\n",
            "I0205 14:03:25.142703 140689526667136 learning.py:507] global step 6768: loss = 0.0735 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 6769: loss = 0.4153 (0.395 sec/step)\n",
            "I0205 14:03:25.539721 140689526667136 learning.py:507] global step 6769: loss = 0.4153 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 6770: loss = 0.0786 (0.383 sec/step)\n",
            "I0205 14:03:25.924799 140689526667136 learning.py:507] global step 6770: loss = 0.0786 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 6771: loss = 0.2255 (0.371 sec/step)\n",
            "I0205 14:03:26.297626 140689526667136 learning.py:507] global step 6771: loss = 0.2255 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 6772: loss = 0.0948 (0.400 sec/step)\n",
            "I0205 14:03:26.700685 140689526667136 learning.py:507] global step 6772: loss = 0.0948 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 6773: loss = 0.7569 (0.373 sec/step)\n",
            "I0205 14:03:27.075188 140689526667136 learning.py:507] global step 6773: loss = 0.7569 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 6774: loss = 0.0042 (0.361 sec/step)\n",
            "I0205 14:03:27.437350 140689526667136 learning.py:507] global step 6774: loss = 0.0042 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 6775: loss = 0.4154 (0.413 sec/step)\n",
            "I0205 14:03:27.851861 140689526667136 learning.py:507] global step 6775: loss = 0.4154 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 6776: loss = 0.4259 (0.391 sec/step)\n",
            "I0205 14:03:28.244253 140689526667136 learning.py:507] global step 6776: loss = 0.4259 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6777: loss = 0.0298 (0.374 sec/step)\n",
            "I0205 14:03:28.620093 140689526667136 learning.py:507] global step 6777: loss = 0.0298 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 6778: loss = 0.1055 (0.408 sec/step)\n",
            "I0205 14:03:29.029289 140689526667136 learning.py:507] global step 6778: loss = 0.1055 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 6779: loss = 0.0535 (0.387 sec/step)\n",
            "I0205 14:03:29.418472 140689526667136 learning.py:507] global step 6779: loss = 0.0535 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 6780: loss = 0.1767 (0.437 sec/step)\n",
            "I0205 14:03:29.857883 140689526667136 learning.py:507] global step 6780: loss = 0.1767 (0.437 sec/step)\n",
            "INFO:tensorflow:global step 6781: loss = 0.0795 (0.442 sec/step)\n",
            "I0205 14:03:30.301256 140689526667136 learning.py:507] global step 6781: loss = 0.0795 (0.442 sec/step)\n",
            "INFO:tensorflow:global step 6782: loss = 0.1812 (0.409 sec/step)\n",
            "I0205 14:03:30.712407 140689526667136 learning.py:507] global step 6782: loss = 0.1812 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 6783: loss = 0.1872 (0.372 sec/step)\n",
            "I0205 14:03:31.086316 140689526667136 learning.py:507] global step 6783: loss = 0.1872 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 6784: loss = 0.1455 (0.366 sec/step)\n",
            "I0205 14:03:31.454258 140689526667136 learning.py:507] global step 6784: loss = 0.1455 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 6785: loss = 0.0413 (0.394 sec/step)\n",
            "I0205 14:03:31.850432 140689526667136 learning.py:507] global step 6785: loss = 0.0413 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 6786: loss = 0.1759 (0.358 sec/step)\n",
            "I0205 14:03:32.209852 140689526667136 learning.py:507] global step 6786: loss = 0.1759 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 6787: loss = 0.0235 (0.351 sec/step)\n",
            "I0205 14:03:32.563032 140689526667136 learning.py:507] global step 6787: loss = 0.0235 (0.351 sec/step)\n",
            "INFO:tensorflow:global step 6788: loss = 0.8327 (0.419 sec/step)\n",
            "I0205 14:03:32.983988 140689526667136 learning.py:507] global step 6788: loss = 0.8327 (0.419 sec/step)\n",
            "INFO:tensorflow:global step 6789: loss = 0.7872 (0.408 sec/step)\n",
            "I0205 14:03:33.393567 140689526667136 learning.py:507] global step 6789: loss = 0.7872 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 6790: loss = 0.2080 (0.384 sec/step)\n",
            "I0205 14:03:33.780023 140689526667136 learning.py:507] global step 6790: loss = 0.2080 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6791: loss = 0.3155 (0.371 sec/step)\n",
            "I0205 14:03:34.153105 140689526667136 learning.py:507] global step 6791: loss = 0.3155 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 6792: loss = 0.1351 (0.359 sec/step)\n",
            "I0205 14:03:34.514159 140689526667136 learning.py:507] global step 6792: loss = 0.1351 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 6793: loss = 0.0618 (0.410 sec/step)\n",
            "I0205 14:03:34.925648 140689526667136 learning.py:507] global step 6793: loss = 0.0618 (0.410 sec/step)\n",
            "INFO:tensorflow:global step 6794: loss = 0.1869 (0.393 sec/step)\n",
            "I0205 14:03:35.319960 140689526667136 learning.py:507] global step 6794: loss = 0.1869 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 6795: loss = 0.0559 (0.391 sec/step)\n",
            "I0205 14:03:35.712720 140689526667136 learning.py:507] global step 6795: loss = 0.0559 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6796: loss = 0.0865 (0.395 sec/step)\n",
            "I0205 14:03:36.109444 140689526667136 learning.py:507] global step 6796: loss = 0.0865 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 6797: loss = 0.9973 (0.390 sec/step)\n",
            "I0205 14:03:36.501194 140689526667136 learning.py:507] global step 6797: loss = 0.9973 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 6798: loss = 0.1055 (0.386 sec/step)\n",
            "I0205 14:03:36.888531 140689526667136 learning.py:507] global step 6798: loss = 0.1055 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 6799: loss = 0.2092 (0.387 sec/step)\n",
            "I0205 14:03:37.277254 140689526667136 learning.py:507] global step 6799: loss = 0.2092 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 6800: loss = 0.1330 (0.398 sec/step)\n",
            "I0205 14:03:37.676411 140689526667136 learning.py:507] global step 6800: loss = 0.1330 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 6801: loss = 0.1205 (0.385 sec/step)\n",
            "I0205 14:03:38.062612 140689526667136 learning.py:507] global step 6801: loss = 0.1205 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 6802: loss = 0.1240 (0.381 sec/step)\n",
            "I0205 14:03:38.445471 140689526667136 learning.py:507] global step 6802: loss = 0.1240 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 6803: loss = 0.1705 (0.387 sec/step)\n",
            "I0205 14:03:38.834320 140689526667136 learning.py:507] global step 6803: loss = 0.1705 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 6804: loss = 0.0389 (0.377 sec/step)\n",
            "I0205 14:03:39.212863 140689526667136 learning.py:507] global step 6804: loss = 0.0389 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 6805: loss = 0.0676 (0.374 sec/step)\n",
            "I0205 14:03:39.588511 140689526667136 learning.py:507] global step 6805: loss = 0.0676 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 6806: loss = 0.0906 (0.388 sec/step)\n",
            "I0205 14:03:39.978047 140689526667136 learning.py:507] global step 6806: loss = 0.0906 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 6807: loss = 0.2574 (0.377 sec/step)\n",
            "I0205 14:03:40.356603 140689526667136 learning.py:507] global step 6807: loss = 0.2574 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 6808: loss = 0.0731 (0.352 sec/step)\n",
            "I0205 14:03:40.710342 140689526667136 learning.py:507] global step 6808: loss = 0.0731 (0.352 sec/step)\n",
            "INFO:tensorflow:global step 6809: loss = 0.1618 (0.379 sec/step)\n",
            "I0205 14:03:41.090632 140689526667136 learning.py:507] global step 6809: loss = 0.1618 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 6810: loss = 0.1908 (0.352 sec/step)\n",
            "I0205 14:03:41.443719 140689526667136 learning.py:507] global step 6810: loss = 0.1908 (0.352 sec/step)\n",
            "INFO:tensorflow:global step 6811: loss = 0.0499 (0.367 sec/step)\n",
            "I0205 14:03:41.812870 140689526667136 learning.py:507] global step 6811: loss = 0.0499 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 6812: loss = 0.0956 (0.387 sec/step)\n",
            "I0205 14:03:42.201771 140689526667136 learning.py:507] global step 6812: loss = 0.0956 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 6813: loss = 0.1399 (0.389 sec/step)\n",
            "I0205 14:03:42.592035 140689526667136 learning.py:507] global step 6813: loss = 0.1399 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 6814: loss = 0.1753 (0.390 sec/step)\n",
            "I0205 14:03:42.983591 140689526667136 learning.py:507] global step 6814: loss = 0.1753 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 6815: loss = 0.0695 (0.390 sec/step)\n",
            "I0205 14:03:43.375931 140689526667136 learning.py:507] global step 6815: loss = 0.0695 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 6816: loss = 0.1224 (0.387 sec/step)\n",
            "I0205 14:03:43.764659 140689526667136 learning.py:507] global step 6816: loss = 0.1224 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 6817: loss = 0.1472 (0.377 sec/step)\n",
            "I0205 14:03:44.142934 140689526667136 learning.py:507] global step 6817: loss = 0.1472 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 6818: loss = 0.1715 (0.393 sec/step)\n",
            "I0205 14:03:44.537630 140689526667136 learning.py:507] global step 6818: loss = 0.1715 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 6819: loss = 0.1380 (0.383 sec/step)\n",
            "I0205 14:03:44.922142 140689526667136 learning.py:507] global step 6819: loss = 0.1380 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 6820: loss = 0.0676 (0.411 sec/step)\n",
            "I0205 14:03:45.334522 140689526667136 learning.py:507] global step 6820: loss = 0.0676 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 6821: loss = 0.0739 (0.380 sec/step)\n",
            "I0205 14:03:45.715758 140689526667136 learning.py:507] global step 6821: loss = 0.0739 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 6822: loss = 0.0713 (0.391 sec/step)\n",
            "I0205 14:03:46.108703 140689526667136 learning.py:507] global step 6822: loss = 0.0713 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6823: loss = 0.0613 (0.386 sec/step)\n",
            "I0205 14:03:46.496513 140689526667136 learning.py:507] global step 6823: loss = 0.0613 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 6824: loss = 0.0840 (0.358 sec/step)\n",
            "I0205 14:03:46.856195 140689526667136 learning.py:507] global step 6824: loss = 0.0840 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 6825: loss = 0.3195 (0.413 sec/step)\n",
            "I0205 14:03:47.270455 140689526667136 learning.py:507] global step 6825: loss = 0.3195 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 6826: loss = 0.0955 (0.386 sec/step)\n",
            "I0205 14:03:47.658292 140689526667136 learning.py:507] global step 6826: loss = 0.0955 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 6827: loss = 0.2730 (0.379 sec/step)\n",
            "I0205 14:03:48.038545 140689526667136 learning.py:507] global step 6827: loss = 0.2730 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 6828: loss = 0.1985 (0.393 sec/step)\n",
            "I0205 14:03:48.433138 140689526667136 learning.py:507] global step 6828: loss = 0.1985 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 6829: loss = 0.0201 (0.412 sec/step)\n",
            "I0205 14:03:48.847137 140689526667136 learning.py:507] global step 6829: loss = 0.0201 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 6830: loss = 0.0506 (0.359 sec/step)\n",
            "I0205 14:03:49.208035 140689526667136 learning.py:507] global step 6830: loss = 0.0506 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 6831: loss = 0.0684 (0.412 sec/step)\n",
            "I0205 14:03:49.621749 140689526667136 learning.py:507] global step 6831: loss = 0.0684 (0.412 sec/step)\n",
            "INFO:tensorflow:global step 6832: loss = 0.1406 (0.393 sec/step)\n",
            "I0205 14:03:50.016552 140689526667136 learning.py:507] global step 6832: loss = 0.1406 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 6833: loss = 0.2073 (0.385 sec/step)\n",
            "I0205 14:03:50.402959 140689526667136 learning.py:507] global step 6833: loss = 0.2073 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 6834: loss = 0.0791 (0.388 sec/step)\n",
            "I0205 14:03:50.792319 140689526667136 learning.py:507] global step 6834: loss = 0.0791 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 6835: loss = 0.0297 (0.405 sec/step)\n",
            "I0205 14:03:51.199004 140689526667136 learning.py:507] global step 6835: loss = 0.0297 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 6836: loss = 0.0453 (0.392 sec/step)\n",
            "I0205 14:03:51.592663 140689526667136 learning.py:507] global step 6836: loss = 0.0453 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 6837: loss = 0.2298 (0.395 sec/step)\n",
            "I0205 14:03:51.989770 140689526667136 learning.py:507] global step 6837: loss = 0.2298 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 6838: loss = 0.0624 (0.409 sec/step)\n",
            "I0205 14:03:52.400551 140689526667136 learning.py:507] global step 6838: loss = 0.0624 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 6839: loss = 0.0577 (0.387 sec/step)\n",
            "I0205 14:03:52.789567 140689526667136 learning.py:507] global step 6839: loss = 0.0577 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 6840: loss = 0.1025 (0.404 sec/step)\n",
            "I0205 14:03:53.195362 140689526667136 learning.py:507] global step 6840: loss = 0.1025 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 6841: loss = 0.1765 (0.409 sec/step)\n",
            "I0205 14:03:53.605715 140689526667136 learning.py:507] global step 6841: loss = 0.1765 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 6842: loss = 0.3295 (0.388 sec/step)\n",
            "I0205 14:03:53.995391 140689526667136 learning.py:507] global step 6842: loss = 0.3295 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 6843: loss = 0.6368 (0.372 sec/step)\n",
            "I0205 14:03:54.369186 140689526667136 learning.py:507] global step 6843: loss = 0.6368 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 6844: loss = 0.3270 (0.386 sec/step)\n",
            "I0205 14:03:54.756720 140689526667136 learning.py:507] global step 6844: loss = 0.3270 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 6845: loss = 0.1190 (0.373 sec/step)\n",
            "I0205 14:03:55.131948 140689526667136 learning.py:507] global step 6845: loss = 0.1190 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 6846: loss = 0.0439 (0.372 sec/step)\n",
            "I0205 14:03:55.505153 140689526667136 learning.py:507] global step 6846: loss = 0.0439 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 6847: loss = 0.0680 (0.378 sec/step)\n",
            "I0205 14:03:55.885116 140689526667136 learning.py:507] global step 6847: loss = 0.0680 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 6848: loss = 0.0939 (0.376 sec/step)\n",
            "I0205 14:03:56.262563 140689526667136 learning.py:507] global step 6848: loss = 0.0939 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 6849: loss = 0.1582 (0.413 sec/step)\n",
            "I0205 14:03:56.677265 140689526667136 learning.py:507] global step 6849: loss = 0.1582 (0.413 sec/step)\n",
            "INFO:tensorflow:global step 6850: loss = 0.0371 (0.383 sec/step)\n",
            "I0205 14:03:57.061935 140689526667136 learning.py:507] global step 6850: loss = 0.0371 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 6851: loss = 0.0278 (0.358 sec/step)\n",
            "I0205 14:03:57.421394 140689526667136 learning.py:507] global step 6851: loss = 0.0278 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 6852: loss = 0.0833 (0.373 sec/step)\n",
            "I0205 14:03:57.796145 140689526667136 learning.py:507] global step 6852: loss = 0.0833 (0.373 sec/step)\n",
            "INFO:tensorflow:global step 6853: loss = 0.8584 (0.350 sec/step)\n",
            "I0205 14:03:58.147813 140689526667136 learning.py:507] global step 6853: loss = 0.8584 (0.350 sec/step)\n",
            "INFO:tensorflow:global step 6854: loss = 0.1401 (0.407 sec/step)\n",
            "I0205 14:03:58.557038 140689526667136 learning.py:507] global step 6854: loss = 0.1401 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 6855: loss = 0.0351 (0.406 sec/step)\n",
            "I0205 14:03:58.965805 140689526667136 learning.py:507] global step 6855: loss = 0.0351 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 6856: loss = 0.0673 (0.378 sec/step)\n",
            "I0205 14:03:59.345736 140689526667136 learning.py:507] global step 6856: loss = 0.0673 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 6857: loss = 0.1469 (0.415 sec/step)\n",
            "I0205 14:03:59.762212 140689526667136 learning.py:507] global step 6857: loss = 0.1469 (0.415 sec/step)\n",
            "INFO:tensorflow:global step 6858: loss = 0.0323 (0.388 sec/step)\n",
            "I0205 14:04:00.151911 140689526667136 learning.py:507] global step 6858: loss = 0.0323 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 6859: loss = 0.4570 (0.371 sec/step)\n",
            "I0205 14:04:00.524811 140689526667136 learning.py:507] global step 6859: loss = 0.4570 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 6860: loss = 0.1391 (0.401 sec/step)\n",
            "I0205 14:04:00.927413 140689526667136 learning.py:507] global step 6860: loss = 0.1391 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 6861: loss = 0.1824 (0.392 sec/step)\n",
            "I0205 14:04:01.321287 140689526667136 learning.py:507] global step 6861: loss = 0.1824 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 6862: loss = 0.1294 (0.385 sec/step)\n",
            "I0205 14:04:01.707553 140689526667136 learning.py:507] global step 6862: loss = 0.1294 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 6863: loss = 0.2214 (0.377 sec/step)\n",
            "I0205 14:04:02.086120 140689526667136 learning.py:507] global step 6863: loss = 0.2214 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 6864: loss = 0.0369 (0.379 sec/step)\n",
            "I0205 14:04:02.467036 140689526667136 learning.py:507] global step 6864: loss = 0.0369 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 6865: loss = 0.0377 (0.409 sec/step)\n",
            "I0205 14:04:02.877133 140689526667136 learning.py:507] global step 6865: loss = 0.0377 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 6866: loss = 0.3412 (0.382 sec/step)\n",
            "I0205 14:04:03.260262 140689526667136 learning.py:507] global step 6866: loss = 0.3412 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 6867: loss = 0.0951 (0.386 sec/step)\n",
            "I0205 14:04:03.648345 140689526667136 learning.py:507] global step 6867: loss = 0.0951 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 6868: loss = 0.0628 (0.387 sec/step)\n",
            "I0205 14:04:04.037070 140689526667136 learning.py:507] global step 6868: loss = 0.0628 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 6869: loss = 0.1789 (0.376 sec/step)\n",
            "I0205 14:04:04.414963 140689526667136 learning.py:507] global step 6869: loss = 0.1789 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 6870: loss = 0.1530 (0.389 sec/step)\n",
            "I0205 14:04:04.805188 140689526667136 learning.py:507] global step 6870: loss = 0.1530 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 6871: loss = 0.4050 (0.403 sec/step)\n",
            "I0205 14:04:05.210454 140689526667136 learning.py:507] global step 6871: loss = 0.4050 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 6872: loss = 0.1064 (0.386 sec/step)\n",
            "I0205 14:04:05.598497 140689526667136 learning.py:507] global step 6872: loss = 0.1064 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 6873: loss = 0.0351 (0.372 sec/step)\n",
            "I0205 14:04:05.972648 140689526667136 learning.py:507] global step 6873: loss = 0.0351 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 6874: loss = 0.1316 (0.397 sec/step)\n",
            "I0205 14:04:06.371148 140689526667136 learning.py:507] global step 6874: loss = 0.1316 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 6875: loss = 0.0367 (0.385 sec/step)\n",
            "I0205 14:04:06.759003 140689526667136 learning.py:507] global step 6875: loss = 0.0367 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 6876: loss = 0.2450 (0.391 sec/step)\n",
            "I0205 14:04:07.153158 140689526667136 learning.py:507] global step 6876: loss = 0.2450 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6877: loss = 0.1531 (0.391 sec/step)\n",
            "I0205 14:04:07.547362 140689526667136 learning.py:507] global step 6877: loss = 0.1531 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6878: loss = 1.0384 (0.421 sec/step)\n",
            "I0205 14:04:07.969639 140689526667136 learning.py:507] global step 6878: loss = 1.0384 (0.421 sec/step)\n",
            "INFO:tensorflow:global step 6879: loss = 0.0792 (0.430 sec/step)\n",
            "I0205 14:04:08.401878 140689526667136 learning.py:507] global step 6879: loss = 0.0792 (0.430 sec/step)\n",
            "INFO:tensorflow:global step 6880: loss = 0.3208 (0.415 sec/step)\n",
            "I0205 14:04:08.819047 140689526667136 learning.py:507] global step 6880: loss = 0.3208 (0.415 sec/step)\n",
            "INFO:tensorflow:global step 6881: loss = 0.1573 (0.391 sec/step)\n",
            "I0205 14:04:09.212066 140689526667136 learning.py:507] global step 6881: loss = 0.1573 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6882: loss = 0.0862 (0.400 sec/step)\n",
            "I0205 14:04:09.613949 140689526667136 learning.py:507] global step 6882: loss = 0.0862 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 6883: loss = 0.7438 (0.397 sec/step)\n",
            "I0205 14:04:10.012969 140689526667136 learning.py:507] global step 6883: loss = 0.7438 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 6884: loss = 0.1436 (0.385 sec/step)\n",
            "I0205 14:04:10.400070 140689526667136 learning.py:507] global step 6884: loss = 0.1436 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 6885: loss = 0.1981 (0.375 sec/step)\n",
            "I0205 14:04:10.776915 140689526667136 learning.py:507] global step 6885: loss = 0.1981 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 6886: loss = 0.1178 (0.388 sec/step)\n",
            "I0205 14:04:11.166276 140689526667136 learning.py:507] global step 6886: loss = 0.1178 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 6887: loss = 0.1746 (0.359 sec/step)\n",
            "I0205 14:04:11.526998 140689526667136 learning.py:507] global step 6887: loss = 0.1746 (0.359 sec/step)\n",
            "INFO:tensorflow:global step 6888: loss = 0.1760 (0.396 sec/step)\n",
            "I0205 14:04:11.924758 140689526667136 learning.py:507] global step 6888: loss = 0.1760 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 6889: loss = 0.1581 (0.384 sec/step)\n",
            "I0205 14:04:12.310280 140689526667136 learning.py:507] global step 6889: loss = 0.1581 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6890: loss = 0.3290 (0.366 sec/step)\n",
            "I0205 14:04:12.677824 140689526667136 learning.py:507] global step 6890: loss = 0.3290 (0.366 sec/step)\n",
            "INFO:tensorflow:global step 6891: loss = 0.1810 (0.399 sec/step)\n",
            "I0205 14:04:13.078534 140689526667136 learning.py:507] global step 6891: loss = 0.1810 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 6892: loss = 0.1129 (0.362 sec/step)\n",
            "I0205 14:04:13.441852 140689526667136 learning.py:507] global step 6892: loss = 0.1129 (0.362 sec/step)\n",
            "INFO:tensorflow:Saving checkpoint to path ../training/model.ckpt\n",
            "I0205 14:04:13.746461 140686000895744 supervisor.py:1117] Saving checkpoint to path ../training/model.ckpt\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W0205 14:04:15.019730 140686000895744 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:global step 6893: loss = 0.2916 (1.648 sec/step)\n",
            "I0205 14:04:15.163095 140689526667136 learning.py:507] global step 6893: loss = 0.2916 (1.648 sec/step)\n",
            "INFO:tensorflow:global step 6894: loss = 0.0969 (1.786 sec/step)\n",
            "I0205 14:04:17.246736 140689526667136 learning.py:507] global step 6894: loss = 0.0969 (1.786 sec/step)\n",
            "INFO:tensorflow:Recording summary at step 6895.\n",
            "I0205 14:04:18.206656 140686026073856 supervisor.py:1050] Recording summary at step 6895.\n",
            "INFO:tensorflow:global step 6895: loss = 0.2218 (0.923 sec/step)\n",
            "I0205 14:04:18.209935 140689526667136 learning.py:507] global step 6895: loss = 0.2218 (0.923 sec/step)\n",
            "INFO:tensorflow:global step 6896: loss = 0.3265 (0.360 sec/step)\n",
            "I0205 14:04:18.734752 140689526667136 learning.py:507] global step 6896: loss = 0.3265 (0.360 sec/step)\n",
            "INFO:tensorflow:global step 6897: loss = 0.2657 (0.400 sec/step)\n",
            "I0205 14:04:19.137439 140689526667136 learning.py:507] global step 6897: loss = 0.2657 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 6898: loss = 0.0976 (0.374 sec/step)\n",
            "I0205 14:04:19.515544 140689526667136 learning.py:507] global step 6898: loss = 0.0976 (0.374 sec/step)\n",
            "INFO:tensorflow:global step 6899: loss = 0.2079 (0.401 sec/step)\n",
            "I0205 14:04:19.917712 140689526667136 learning.py:507] global step 6899: loss = 0.2079 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 6900: loss = 0.2722 (0.370 sec/step)\n",
            "I0205 14:04:20.289093 140689526667136 learning.py:507] global step 6900: loss = 0.2722 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 6901: loss = 0.2475 (0.369 sec/step)\n",
            "I0205 14:04:20.659875 140689526667136 learning.py:507] global step 6901: loss = 0.2475 (0.369 sec/step)\n",
            "INFO:tensorflow:global step 6902: loss = 0.0892 (0.364 sec/step)\n",
            "I0205 14:04:21.025570 140689526667136 learning.py:507] global step 6902: loss = 0.0892 (0.364 sec/step)\n",
            "INFO:tensorflow:global step 6903: loss = 0.1519 (0.393 sec/step)\n",
            "I0205 14:04:21.421284 140689526667136 learning.py:507] global step 6903: loss = 0.1519 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 6904: loss = 0.1336 (0.365 sec/step)\n",
            "I0205 14:04:21.788052 140689526667136 learning.py:507] global step 6904: loss = 0.1336 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 6905: loss = 0.0703 (0.378 sec/step)\n",
            "I0205 14:04:22.167334 140689526667136 learning.py:507] global step 6905: loss = 0.0703 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 6906: loss = 0.0602 (0.387 sec/step)\n",
            "I0205 14:04:22.556150 140689526667136 learning.py:507] global step 6906: loss = 0.0602 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 6907: loss = 0.0623 (0.345 sec/step)\n",
            "I0205 14:04:22.902477 140689526667136 learning.py:507] global step 6907: loss = 0.0623 (0.345 sec/step)\n",
            "INFO:tensorflow:global step 6908: loss = 0.0262 (0.380 sec/step)\n",
            "I0205 14:04:23.285189 140689526667136 learning.py:507] global step 6908: loss = 0.0262 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 6909: loss = 0.1234 (0.357 sec/step)\n",
            "I0205 14:04:23.643782 140689526667136 learning.py:507] global step 6909: loss = 0.1234 (0.357 sec/step)\n",
            "INFO:tensorflow:global step 6910: loss = 0.7265 (0.387 sec/step)\n",
            "I0205 14:04:24.032125 140689526667136 learning.py:507] global step 6910: loss = 0.7265 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 6911: loss = 0.1349 (0.394 sec/step)\n",
            "I0205 14:04:24.427525 140689526667136 learning.py:507] global step 6911: loss = 0.1349 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 6912: loss = 0.1881 (0.391 sec/step)\n",
            "I0205 14:04:24.820629 140689526667136 learning.py:507] global step 6912: loss = 0.1881 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6913: loss = 0.0455 (0.391 sec/step)\n",
            "I0205 14:04:25.213501 140689526667136 learning.py:507] global step 6913: loss = 0.0455 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6914: loss = 0.0906 (0.365 sec/step)\n",
            "I0205 14:04:25.580588 140689526667136 learning.py:507] global step 6914: loss = 0.0906 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 6915: loss = 0.0966 (0.382 sec/step)\n",
            "I0205 14:04:25.963900 140689526667136 learning.py:507] global step 6915: loss = 0.0966 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 6916: loss = 0.2186 (0.385 sec/step)\n",
            "I0205 14:04:26.350565 140689526667136 learning.py:507] global step 6916: loss = 0.2186 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 6917: loss = 0.1147 (0.398 sec/step)\n",
            "I0205 14:04:26.750690 140689526667136 learning.py:507] global step 6917: loss = 0.1147 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 6918: loss = 0.1027 (0.376 sec/step)\n",
            "I0205 14:04:27.128845 140689526667136 learning.py:507] global step 6918: loss = 0.1027 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 6919: loss = 0.8244 (0.391 sec/step)\n",
            "I0205 14:04:27.521744 140689526667136 learning.py:507] global step 6919: loss = 0.8244 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6920: loss = 0.3778 (0.393 sec/step)\n",
            "I0205 14:04:27.916143 140689526667136 learning.py:507] global step 6920: loss = 0.3778 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 6921: loss = 0.1955 (0.394 sec/step)\n",
            "I0205 14:04:28.311543 140689526667136 learning.py:507] global step 6921: loss = 0.1955 (0.394 sec/step)\n",
            "INFO:tensorflow:global step 6922: loss = 0.0781 (0.429 sec/step)\n",
            "I0205 14:04:28.742237 140689526667136 learning.py:507] global step 6922: loss = 0.0781 (0.429 sec/step)\n",
            "INFO:tensorflow:global step 6923: loss = 0.2285 (0.408 sec/step)\n",
            "I0205 14:04:29.152546 140689526667136 learning.py:507] global step 6923: loss = 0.2285 (0.408 sec/step)\n",
            "INFO:tensorflow:global step 6924: loss = 0.0667 (0.411 sec/step)\n",
            "I0205 14:04:29.566097 140689526667136 learning.py:507] global step 6924: loss = 0.0667 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 6925: loss = 0.5103 (0.431 sec/step)\n",
            "I0205 14:04:29.998618 140689526667136 learning.py:507] global step 6925: loss = 0.5103 (0.431 sec/step)\n",
            "INFO:tensorflow:global step 6926: loss = 0.0996 (0.411 sec/step)\n",
            "I0205 14:04:30.411648 140689526667136 learning.py:507] global step 6926: loss = 0.0996 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 6927: loss = 0.1017 (0.422 sec/step)\n",
            "I0205 14:04:30.835697 140689526667136 learning.py:507] global step 6927: loss = 0.1017 (0.422 sec/step)\n",
            "INFO:tensorflow:global step 6928: loss = 0.1069 (0.384 sec/step)\n",
            "I0205 14:04:31.220964 140689526667136 learning.py:507] global step 6928: loss = 0.1069 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6929: loss = 0.1715 (0.403 sec/step)\n",
            "I0205 14:04:31.625533 140689526667136 learning.py:507] global step 6929: loss = 0.1715 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 6930: loss = 0.4478 (0.382 sec/step)\n",
            "I0205 14:04:32.008873 140689526667136 learning.py:507] global step 6930: loss = 0.4478 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 6931: loss = 0.1267 (0.391 sec/step)\n",
            "I0205 14:04:32.401763 140689526667136 learning.py:507] global step 6931: loss = 0.1267 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6932: loss = 0.1398 (0.384 sec/step)\n",
            "I0205 14:04:32.787861 140689526667136 learning.py:507] global step 6932: loss = 0.1398 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6933: loss = 0.1825 (0.399 sec/step)\n",
            "I0205 14:04:33.187911 140689526667136 learning.py:507] global step 6933: loss = 0.1825 (0.399 sec/step)\n",
            "INFO:tensorflow:global step 6934: loss = 0.5381 (0.367 sec/step)\n",
            "I0205 14:04:33.556198 140689526667136 learning.py:507] global step 6934: loss = 0.5381 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 6935: loss = 0.1598 (0.386 sec/step)\n",
            "I0205 14:04:33.943643 140689526667136 learning.py:507] global step 6935: loss = 0.1598 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 6936: loss = 0.3193 (0.371 sec/step)\n",
            "I0205 14:04:34.315975 140689526667136 learning.py:507] global step 6936: loss = 0.3193 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 6937: loss = 0.1320 (0.385 sec/step)\n",
            "I0205 14:04:34.702565 140689526667136 learning.py:507] global step 6937: loss = 0.1320 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 6938: loss = 0.0279 (0.371 sec/step)\n",
            "I0205 14:04:35.075790 140689526667136 learning.py:507] global step 6938: loss = 0.0279 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 6939: loss = 0.2719 (0.356 sec/step)\n",
            "I0205 14:04:35.433129 140689526667136 learning.py:507] global step 6939: loss = 0.2719 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 6940: loss = 0.1180 (0.379 sec/step)\n",
            "I0205 14:04:35.813357 140689526667136 learning.py:507] global step 6940: loss = 0.1180 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 6941: loss = 0.3894 (0.381 sec/step)\n",
            "I0205 14:04:36.195931 140689526667136 learning.py:507] global step 6941: loss = 0.3894 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 6942: loss = 0.2240 (0.365 sec/step)\n",
            "I0205 14:04:36.562913 140689526667136 learning.py:507] global step 6942: loss = 0.2240 (0.365 sec/step)\n",
            "INFO:tensorflow:global step 6943: loss = 0.2009 (0.371 sec/step)\n",
            "I0205 14:04:36.935334 140689526667136 learning.py:507] global step 6943: loss = 0.2009 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 6944: loss = 0.0839 (0.385 sec/step)\n",
            "I0205 14:04:37.322134 140689526667136 learning.py:507] global step 6944: loss = 0.0839 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 6945: loss = 0.2027 (0.355 sec/step)\n",
            "I0205 14:04:37.678421 140689526667136 learning.py:507] global step 6945: loss = 0.2027 (0.355 sec/step)\n",
            "INFO:tensorflow:global step 6946: loss = 0.8273 (0.382 sec/step)\n",
            "I0205 14:04:38.062016 140689526667136 learning.py:507] global step 6946: loss = 0.8273 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 6947: loss = 0.1043 (0.388 sec/step)\n",
            "I0205 14:04:38.451298 140689526667136 learning.py:507] global step 6947: loss = 0.1043 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 6948: loss = 0.0797 (0.395 sec/step)\n",
            "I0205 14:04:38.847920 140689526667136 learning.py:507] global step 6948: loss = 0.0797 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 6949: loss = 0.0702 (0.376 sec/step)\n",
            "I0205 14:04:39.226049 140689526667136 learning.py:507] global step 6949: loss = 0.0702 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 6950: loss = 0.1345 (0.389 sec/step)\n",
            "I0205 14:04:39.616249 140689526667136 learning.py:507] global step 6950: loss = 0.1345 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 6951: loss = 0.1642 (0.409 sec/step)\n",
            "I0205 14:04:40.027225 140689526667136 learning.py:507] global step 6951: loss = 0.1642 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 6952: loss = 0.5179 (0.388 sec/step)\n",
            "I0205 14:04:40.417238 140689526667136 learning.py:507] global step 6952: loss = 0.5179 (0.388 sec/step)\n",
            "INFO:tensorflow:global step 6953: loss = 0.1193 (0.396 sec/step)\n",
            "I0205 14:04:40.815179 140689526667136 learning.py:507] global step 6953: loss = 0.1193 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 6954: loss = 0.1327 (0.381 sec/step)\n",
            "I0205 14:04:41.198237 140689526667136 learning.py:507] global step 6954: loss = 0.1327 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 6955: loss = 0.7197 (0.367 sec/step)\n",
            "I0205 14:04:41.567062 140689526667136 learning.py:507] global step 6955: loss = 0.7197 (0.367 sec/step)\n",
            "INFO:tensorflow:global step 6956: loss = 0.0954 (0.403 sec/step)\n",
            "I0205 14:04:41.971432 140689526667136 learning.py:507] global step 6956: loss = 0.0954 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 6957: loss = 0.0866 (0.361 sec/step)\n",
            "I0205 14:04:42.334026 140689526667136 learning.py:507] global step 6957: loss = 0.0866 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 6958: loss = 0.4679 (0.391 sec/step)\n",
            "I0205 14:04:42.728337 140689526667136 learning.py:507] global step 6958: loss = 0.4679 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 6959: loss = 0.2038 (0.384 sec/step)\n",
            "I0205 14:04:43.113930 140689526667136 learning.py:507] global step 6959: loss = 0.2038 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 6960: loss = 0.1338 (0.398 sec/step)\n",
            "I0205 14:04:43.513911 140689526667136 learning.py:507] global step 6960: loss = 0.1338 (0.398 sec/step)\n",
            "INFO:tensorflow:global step 6961: loss = 0.1544 (0.396 sec/step)\n",
            "I0205 14:04:43.911973 140689526667136 learning.py:507] global step 6961: loss = 0.1544 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 6962: loss = 0.0920 (0.389 sec/step)\n",
            "I0205 14:04:44.303231 140689526667136 learning.py:507] global step 6962: loss = 0.0920 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 6963: loss = 0.0841 (0.362 sec/step)\n",
            "I0205 14:04:44.667086 140689526667136 learning.py:507] global step 6963: loss = 0.0841 (0.362 sec/step)\n",
            "INFO:tensorflow:global step 6964: loss = 0.0535 (0.375 sec/step)\n",
            "I0205 14:04:45.043885 140689526667136 learning.py:507] global step 6964: loss = 0.0535 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 6965: loss = 0.0906 (0.371 sec/step)\n",
            "I0205 14:04:45.416271 140689526667136 learning.py:507] global step 6965: loss = 0.0906 (0.371 sec/step)\n",
            "INFO:tensorflow:global step 6966: loss = 0.1061 (0.411 sec/step)\n",
            "I0205 14:04:45.833225 140689526667136 learning.py:507] global step 6966: loss = 0.1061 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 6967: loss = 0.0369 (0.378 sec/step)\n",
            "I0205 14:04:46.214949 140689526667136 learning.py:507] global step 6967: loss = 0.0369 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 6968: loss = 0.2074 (0.400 sec/step)\n",
            "I0205 14:04:46.616068 140689526667136 learning.py:507] global step 6968: loss = 0.2074 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 6969: loss = 0.2016 (0.386 sec/step)\n",
            "I0205 14:04:47.004119 140689526667136 learning.py:507] global step 6969: loss = 0.2016 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 6970: loss = 0.1379 (0.392 sec/step)\n",
            "I0205 14:04:47.398158 140689526667136 learning.py:507] global step 6970: loss = 0.1379 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 6971: loss = 0.2062 (0.389 sec/step)\n",
            "I0205 14:04:47.788958 140689526667136 learning.py:507] global step 6971: loss = 0.2062 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 6972: loss = 0.0503 (0.363 sec/step)\n",
            "I0205 14:04:48.153551 140689526667136 learning.py:507] global step 6972: loss = 0.0503 (0.363 sec/step)\n",
            "INFO:tensorflow:global step 6973: loss = 0.1315 (0.376 sec/step)\n",
            "I0205 14:04:48.530901 140689526667136 learning.py:507] global step 6973: loss = 0.1315 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 6974: loss = 0.1786 (0.400 sec/step)\n",
            "I0205 14:04:48.932895 140689526667136 learning.py:507] global step 6974: loss = 0.1786 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 6975: loss = 0.0951 (0.372 sec/step)\n",
            "I0205 14:04:49.306748 140689526667136 learning.py:507] global step 6975: loss = 0.0951 (0.372 sec/step)\n",
            "INFO:tensorflow:global step 6976: loss = 0.0385 (0.402 sec/step)\n",
            "I0205 14:04:49.710061 140689526667136 learning.py:507] global step 6976: loss = 0.0385 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 6977: loss = 0.0587 (0.381 sec/step)\n",
            "I0205 14:04:50.093105 140689526667136 learning.py:507] global step 6977: loss = 0.0587 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 6978: loss = 0.1406 (0.370 sec/step)\n",
            "I0205 14:04:50.465130 140689526667136 learning.py:507] global step 6978: loss = 0.1406 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 6979: loss = 0.0400 (0.390 sec/step)\n",
            "I0205 14:04:50.856707 140689526667136 learning.py:507] global step 6979: loss = 0.0400 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 6980: loss = 0.2034 (0.386 sec/step)\n",
            "I0205 14:04:51.244370 140689526667136 learning.py:507] global step 6980: loss = 0.2034 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 6981: loss = 0.3424 (0.405 sec/step)\n",
            "I0205 14:04:51.650575 140689526667136 learning.py:507] global step 6981: loss = 0.3424 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 6982: loss = 0.1049 (0.370 sec/step)\n",
            "I0205 14:04:52.022124 140689526667136 learning.py:507] global step 6982: loss = 0.1049 (0.370 sec/step)\n",
            "INFO:tensorflow:global step 6983: loss = 0.1861 (0.407 sec/step)\n",
            "I0205 14:04:52.431030 140689526667136 learning.py:507] global step 6983: loss = 0.1861 (0.407 sec/step)\n",
            "INFO:tensorflow:global step 6984: loss = 0.1044 (0.421 sec/step)\n",
            "I0205 14:04:52.854378 140689526667136 learning.py:507] global step 6984: loss = 0.1044 (0.421 sec/step)\n",
            "INFO:tensorflow:global step 6985: loss = 0.1459 (0.404 sec/step)\n",
            "I0205 14:04:53.259812 140689526667136 learning.py:507] global step 6985: loss = 0.1459 (0.404 sec/step)\n",
            "INFO:tensorflow:global step 6986: loss = 0.1185 (0.383 sec/step)\n",
            "I0205 14:04:53.644225 140689526667136 learning.py:507] global step 6986: loss = 0.1185 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 6987: loss = 0.2469 (0.380 sec/step)\n",
            "I0205 14:04:54.026129 140689526667136 learning.py:507] global step 6987: loss = 0.2469 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 6988: loss = 0.0468 (0.376 sec/step)\n",
            "I0205 14:04:54.403672 140689526667136 learning.py:507] global step 6988: loss = 0.0468 (0.376 sec/step)\n",
            "INFO:tensorflow:global step 6989: loss = 0.3031 (0.361 sec/step)\n",
            "I0205 14:04:54.766641 140689526667136 learning.py:507] global step 6989: loss = 0.3031 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 6990: loss = 0.1613 (0.393 sec/step)\n",
            "I0205 14:04:55.161754 140689526667136 learning.py:507] global step 6990: loss = 0.1613 (0.393 sec/step)\n",
            "INFO:tensorflow:global step 6991: loss = 0.0857 (0.406 sec/step)\n",
            "I0205 14:04:55.569424 140689526667136 learning.py:507] global step 6991: loss = 0.0857 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 6992: loss = 0.0438 (0.378 sec/step)\n",
            "I0205 14:04:55.949235 140689526667136 learning.py:507] global step 6992: loss = 0.0438 (0.378 sec/step)\n",
            "INFO:tensorflow:global step 6993: loss = 0.2518 (0.397 sec/step)\n",
            "I0205 14:04:56.347554 140689526667136 learning.py:507] global step 6993: loss = 0.2518 (0.397 sec/step)\n",
            "INFO:tensorflow:global step 6994: loss = 0.1918 (0.381 sec/step)\n",
            "I0205 14:04:56.730213 140689526667136 learning.py:507] global step 6994: loss = 0.1918 (0.381 sec/step)\n",
            "INFO:tensorflow:global step 6995: loss = 0.3822 (0.361 sec/step)\n",
            "I0205 14:04:57.092985 140689526667136 learning.py:507] global step 6995: loss = 0.3822 (0.361 sec/step)\n",
            "INFO:tensorflow:global step 6996: loss = 0.1933 (0.402 sec/step)\n",
            "I0205 14:04:57.496369 140689526667136 learning.py:507] global step 6996: loss = 0.1933 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 6997: loss = 0.1908 (0.386 sec/step)\n",
            "I0205 14:04:57.883745 140689526667136 learning.py:507] global step 6997: loss = 0.1908 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 6998: loss = 0.1046 (0.377 sec/step)\n",
            "I0205 14:04:58.261916 140689526667136 learning.py:507] global step 6998: loss = 0.1046 (0.377 sec/step)\n",
            "INFO:tensorflow:global step 6999: loss = 0.1563 (0.356 sec/step)\n",
            "I0205 14:04:58.619546 140689526667136 learning.py:507] global step 6999: loss = 0.1563 (0.356 sec/step)\n",
            "INFO:tensorflow:global step 7000: loss = 0.1073 (0.400 sec/step)\n",
            "I0205 14:04:59.020768 140689526667136 learning.py:507] global step 7000: loss = 0.1073 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 7001: loss = 0.2076 (0.390 sec/step)\n",
            "I0205 14:04:59.412187 140689526667136 learning.py:507] global step 7001: loss = 0.2076 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 7002: loss = 0.0641 (0.422 sec/step)\n",
            "I0205 14:04:59.835786 140689526667136 learning.py:507] global step 7002: loss = 0.0641 (0.422 sec/step)\n",
            "INFO:tensorflow:global step 7003: loss = 0.6584 (0.395 sec/step)\n",
            "I0205 14:05:00.232636 140689526667136 learning.py:507] global step 7003: loss = 0.6584 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 7004: loss = 0.0259 (0.401 sec/step)\n",
            "I0205 14:05:00.635259 140689526667136 learning.py:507] global step 7004: loss = 0.0259 (0.401 sec/step)\n",
            "INFO:tensorflow:global step 7005: loss = 0.1792 (0.383 sec/step)\n",
            "I0205 14:05:01.020328 140689526667136 learning.py:507] global step 7005: loss = 0.1792 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 7006: loss = 0.0142 (0.406 sec/step)\n",
            "I0205 14:05:01.428012 140689526667136 learning.py:507] global step 7006: loss = 0.0142 (0.406 sec/step)\n",
            "INFO:tensorflow:global step 7007: loss = 0.0624 (0.383 sec/step)\n",
            "I0205 14:05:01.812894 140689526667136 learning.py:507] global step 7007: loss = 0.0624 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 7008: loss = 0.2383 (0.380 sec/step)\n",
            "I0205 14:05:02.194216 140689526667136 learning.py:507] global step 7008: loss = 0.2383 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 7009: loss = 0.5153 (0.383 sec/step)\n",
            "I0205 14:05:02.578773 140689526667136 learning.py:507] global step 7009: loss = 0.5153 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 7010: loss = 0.2524 (0.396 sec/step)\n",
            "I0205 14:05:02.977291 140689526667136 learning.py:507] global step 7010: loss = 0.2524 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 7011: loss = 0.1797 (0.403 sec/step)\n",
            "I0205 14:05:03.382280 140689526667136 learning.py:507] global step 7011: loss = 0.1797 (0.403 sec/step)\n",
            "INFO:tensorflow:global step 7012: loss = 0.2109 (0.409 sec/step)\n",
            "I0205 14:05:03.793430 140689526667136 learning.py:507] global step 7012: loss = 0.2109 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 7013: loss = 0.1920 (0.400 sec/step)\n",
            "I0205 14:05:04.194679 140689526667136 learning.py:507] global step 7013: loss = 0.1920 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 7014: loss = 0.0764 (0.386 sec/step)\n",
            "I0205 14:05:04.583014 140689526667136 learning.py:507] global step 7014: loss = 0.0764 (0.386 sec/step)\n",
            "INFO:tensorflow:global step 7015: loss = 0.1327 (0.385 sec/step)\n",
            "I0205 14:05:04.969606 140689526667136 learning.py:507] global step 7015: loss = 0.1327 (0.385 sec/step)\n",
            "INFO:tensorflow:global step 7016: loss = 0.0760 (0.409 sec/step)\n",
            "I0205 14:05:05.380608 140689526667136 learning.py:507] global step 7016: loss = 0.0760 (0.409 sec/step)\n",
            "INFO:tensorflow:global step 7017: loss = 0.0877 (0.375 sec/step)\n",
            "I0205 14:05:05.756837 140689526667136 learning.py:507] global step 7017: loss = 0.0877 (0.375 sec/step)\n",
            "INFO:tensorflow:global step 7018: loss = 0.0418 (0.390 sec/step)\n",
            "I0205 14:05:06.148526 140689526667136 learning.py:507] global step 7018: loss = 0.0418 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 7019: loss = 0.4345 (0.382 sec/step)\n",
            "I0205 14:05:06.532304 140689526667136 learning.py:507] global step 7019: loss = 0.4345 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 7020: loss = 0.1343 (0.402 sec/step)\n",
            "I0205 14:05:06.935529 140689526667136 learning.py:507] global step 7020: loss = 0.1343 (0.402 sec/step)\n",
            "INFO:tensorflow:global step 7021: loss = 0.0111 (0.382 sec/step)\n",
            "I0205 14:05:07.319593 140689526667136 learning.py:507] global step 7021: loss = 0.0111 (0.382 sec/step)\n",
            "INFO:tensorflow:global step 7022: loss = 0.4409 (0.380 sec/step)\n",
            "I0205 14:05:07.701178 140689526667136 learning.py:507] global step 7022: loss = 0.4409 (0.380 sec/step)\n",
            "INFO:tensorflow:global step 7023: loss = 0.4076 (0.419 sec/step)\n",
            "I0205 14:05:08.122234 140689526667136 learning.py:507] global step 7023: loss = 0.4076 (0.419 sec/step)\n",
            "INFO:tensorflow:global step 7024: loss = 0.6759 (0.417 sec/step)\n",
            "I0205 14:05:08.541391 140689526667136 learning.py:507] global step 7024: loss = 0.6759 (0.417 sec/step)\n",
            "INFO:tensorflow:global step 7025: loss = 0.1787 (0.387 sec/step)\n",
            "I0205 14:05:08.930611 140689526667136 learning.py:507] global step 7025: loss = 0.1787 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 7026: loss = 0.4572 (0.389 sec/step)\n",
            "I0205 14:05:09.321687 140689526667136 learning.py:507] global step 7026: loss = 0.4572 (0.389 sec/step)\n",
            "INFO:tensorflow:global step 7027: loss = 0.0385 (0.358 sec/step)\n",
            "I0205 14:05:09.680708 140689526667136 learning.py:507] global step 7027: loss = 0.0385 (0.358 sec/step)\n",
            "INFO:tensorflow:global step 7028: loss = 0.0825 (0.392 sec/step)\n",
            "I0205 14:05:10.074032 140689526667136 learning.py:507] global step 7028: loss = 0.0825 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 7029: loss = 0.1524 (0.379 sec/step)\n",
            "I0205 14:05:10.455513 140689526667136 learning.py:507] global step 7029: loss = 0.1524 (0.379 sec/step)\n",
            "INFO:tensorflow:global step 7030: loss = 0.1913 (0.411 sec/step)\n",
            "I0205 14:05:10.868127 140689526667136 learning.py:507] global step 7030: loss = 0.1913 (0.411 sec/step)\n",
            "INFO:tensorflow:global step 7031: loss = 0.1165 (0.395 sec/step)\n",
            "I0205 14:05:11.264762 140689526667136 learning.py:507] global step 7031: loss = 0.1165 (0.395 sec/step)\n",
            "INFO:tensorflow:global step 7032: loss = 0.2332 (0.384 sec/step)\n",
            "I0205 14:05:11.650561 140689526667136 learning.py:507] global step 7032: loss = 0.2332 (0.384 sec/step)\n",
            "INFO:tensorflow:global step 7033: loss = 0.3957 (0.391 sec/step)\n",
            "I0205 14:05:12.043056 140689526667136 learning.py:507] global step 7033: loss = 0.3957 (0.391 sec/step)\n",
            "INFO:tensorflow:global step 7034: loss = 0.1863 (0.423 sec/step)\n",
            "I0205 14:05:12.468371 140689526667136 learning.py:507] global step 7034: loss = 0.1863 (0.423 sec/step)\n",
            "INFO:tensorflow:global step 7035: loss = 0.0864 (0.392 sec/step)\n",
            "I0205 14:05:12.862058 140689526667136 learning.py:507] global step 7035: loss = 0.0864 (0.392 sec/step)\n",
            "INFO:tensorflow:global step 7036: loss = 0.2406 (0.390 sec/step)\n",
            "I0205 14:05:13.254534 140689526667136 learning.py:507] global step 7036: loss = 0.2406 (0.390 sec/step)\n",
            "INFO:tensorflow:global step 7037: loss = 0.2716 (0.431 sec/step)\n",
            "I0205 14:05:13.687265 140689526667136 learning.py:507] global step 7037: loss = 0.2716 (0.431 sec/step)\n",
            "INFO:tensorflow:global step 7038: loss = 0.5082 (0.405 sec/step)\n",
            "I0205 14:05:14.093797 140689526667136 learning.py:507] global step 7038: loss = 0.5082 (0.405 sec/step)\n",
            "INFO:tensorflow:global step 7039: loss = 0.0782 (0.421 sec/step)\n",
            "I0205 14:05:14.516805 140689526667136 learning.py:507] global step 7039: loss = 0.0782 (0.421 sec/step)\n",
            "INFO:tensorflow:global step 7040: loss = 0.0922 (0.387 sec/step)\n",
            "I0205 14:05:14.905827 140689526667136 learning.py:507] global step 7040: loss = 0.0922 (0.387 sec/step)\n",
            "INFO:tensorflow:global step 7041: loss = 0.0941 (0.400 sec/step)\n",
            "I0205 14:05:15.307980 140689526667136 learning.py:507] global step 7041: loss = 0.0941 (0.400 sec/step)\n",
            "INFO:tensorflow:global step 7042: loss = 0.1633 (0.414 sec/step)\n",
            "I0205 14:05:15.724038 140689526667136 learning.py:507] global step 7042: loss = 0.1633 (0.414 sec/step)\n",
            "INFO:tensorflow:global step 7043: loss = 0.0830 (0.383 sec/step)\n",
            "I0205 14:05:16.108370 140689526667136 learning.py:507] global step 7043: loss = 0.0830 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 7044: loss = 0.1207 (0.383 sec/step)\n",
            "I0205 14:05:16.493121 140689526667136 learning.py:507] global step 7044: loss = 0.1207 (0.383 sec/step)\n",
            "INFO:tensorflow:global step 7045: loss = 0.1380 (0.396 sec/step)\n",
            "I0205 14:05:16.890361 140689526667136 learning.py:507] global step 7045: loss = 0.1380 (0.396 sec/step)\n",
            "INFO:tensorflow:global step 7046: loss = 0.0985 (0.390 sec/step)\n",
            "I0205 14:05:17.281701 140689526667136 learning.py:507] global step 7046: loss = 0.0985 (0.390 sec/step)\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 185, in <module>\n",
            "    tf.app.run()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"train.py\", line 181, in main\n",
            "    graph_hook_fn=graph_rewriter_fn)\n",
            "  File \"/content/models/research/object_detection/legacy/trainer.py\", line 417, in train\n",
            "    saver=saver)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/slim/python/slim/learning.py\", line 775, in train\n",
            "    train_step_kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/slim/python/slim/learning.py\", line 490, in train_step\n",
            "    run_metadata=run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n",
            "    target_list, run_metadata)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "KeyboardInterrupt\n",
            "/content/models/research/object_detection\n",
            "/content/models/research\n",
            "/content/models\n",
            "/content\n",
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEC5ZhAd4LyV",
        "colab_type": "code",
        "outputId": "f27eaac8-b6e9-4f4a-f9ab-27cd19e67ec7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "%ls"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mbin\u001b[0m/                                       ngrok-stable-linux-amd64.zip\n",
            "\u001b[01;34mboot\u001b[0m/                                      ngrok-stable-linux-amd64.zip.1\n",
            "\u001b[01;34mbuild\u001b[0m/                                     \u001b[01;34mobject_detection.egg-info\u001b[0m/\n",
            "\u001b[01;34mcontent\u001b[0m/                                   \u001b[01;34mopt\u001b[0m/\n",
            "\u001b[01;34mdatalab\u001b[0m/                                   \u001b[01;34mproc\u001b[0m/\n",
            "\u001b[01;34mdev\u001b[0m/                                       \u001b[01;34mroot\u001b[0m/\n",
            "\u001b[01;34mdist\u001b[0m/                                      \u001b[01;34mrun\u001b[0m/\n",
            "dlib-19.18.0-cp27-cp27mu-linux_x86_64.whl  \u001b[01;34msbin\u001b[0m/\n",
            "dlib-19.18.0-cp36-cp36m-linux_x86_64.whl   \u001b[01;34msrv\u001b[0m/\n",
            "\u001b[01;34metc\u001b[0m/                                       \u001b[01;34mswift\u001b[0m/\n",
            "\u001b[01;34mhome\u001b[0m/                                      \u001b[01;34msys\u001b[0m/\n",
            "\u001b[01;34mlib\u001b[0m/                                       \u001b[01;34mtensorflow-2.1.0\u001b[0m/\n",
            "\u001b[01;34mlib32\u001b[0m/                                     \u001b[30;42mtmp\u001b[0m/\n",
            "\u001b[01;34mlib64\u001b[0m/                                     \u001b[01;34mtools\u001b[0m/\n",
            "\u001b[01;34mmedia\u001b[0m/                                     \u001b[01;34musr\u001b[0m/\n",
            "\u001b[01;34mmnt\u001b[0m/                                       \u001b[01;34mvar\u001b[0m/\n",
            "\u001b[01;32mngrok\u001b[0m*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbgHogus2vUd",
        "colab_type": "code",
        "outputId": "90ea7b0c-7491-41e8-cc11-92485d0e4ca7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python3 /content/models/research/object_detection/export_inference_graph.py --input_type image_tensor --pipeline_config_path  /content/models/research/object_detection/training/faster_rcnn_resnet101_coco.config --trained_checkpoint_prefix  /content/models/research/object_detection/training/model.ckpt-6892 --output_directory /content/models/research/object_detection/inference-graph\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_inference_graph.py:162: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0205 14:13:14.623876 140123216222080 module_wrapper.py:139] From /content/models/research/object_detection/export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0205 14:13:14.629961 140123216222080 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0205 14:13:14.630271 140123216222080 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/preprocessor.py:2689: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0205 14:13:14.669111 140123216222080 module_wrapper.py:139] From /content/models/research/object_detection/core/preprocessor.py:2689: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:168: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0205 14:13:14.727416 140123216222080 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:168: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0205 14:13:14.737279 140123216222080 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0205 14:13:14.739608 140123216222080 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "W0205 14:13:17.790503 140123216222080 module_wrapper.py:139] From /content/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0205 14:13:17.797826 140123216222080 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:558: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "W0205 14:13:17.798192 140123216222080 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:558: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
            "\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0205 14:13:17.811499 140123216222080 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0205 14:13:17.811841 140123216222080 module_wrapper.py:139] From /content/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0205 14:13:17.811961 140123216222080 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/core/box_list_ops.py:141: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0205 14:13:17.868608 140123216222080 deprecation.py:323] From /content/models/research/object_detection/core/box_list_ops.py:141: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/spatial_transform_ops.py:419: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "W0205 14:13:18.427899 140123216222080 deprecation.py:506] From /content/models/research/object_detection/utils/spatial_transform_ops.py:419: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "box_ind is deprecated, use box_indices instead\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:191: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0205 14:13:18.444834 140123216222080 module_wrapper.py:139] From /content/models/research/object_detection/meta_architectures/faster_rcnn_meta_arch.py:191: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0205 14:13:18.445159 140123216222080 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "W0205 14:13:18.712992 140123216222080 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0205 14:13:18.717880 140123216222080 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0205 14:13:18.736468 140123216222080 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "W0205 14:13:19.436267 140123216222080 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/dispatch.py:180: batch_gather (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2017-10-25.\n",
            "Instructions for updating:\n",
            "`tf.batch_gather` is deprecated, please use `tf.gather` with `batch_dims=-1` instead.\n",
            "INFO:tensorflow:Scale of 0 disables regularizer.\n",
            "I0205 14:13:19.558136 140123216222080 regularizers.py:98] Scale of 0 disables regularizer.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "W0205 14:13:19.674148 140123216222080 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0205 14:13:19.674394 140123216222080 deprecation.py:323] From /content/models/research/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:415: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0205 14:13:19.677335 140123216222080 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:415: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W0205 14:13:19.677514 140123216222080 deprecation.py:323] From /content/models/research/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W0205 14:13:19.678564 140123216222080 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "262 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/62.15m params)\n",
            "  Conv (--/4.72m params)\n",
            "    Conv/biases (512, 512/512 params)\n",
            "    Conv/weights (3x3x1024x512, 4.72m/4.72m params)\n",
            "  FirstStageBoxPredictor (--/36.94k params)\n",
            "    FirstStageBoxPredictor/BoxEncodingPredictor (--/24.62k params)\n",
            "      FirstStageBoxPredictor/BoxEncodingPredictor/biases (48, 48/48 params)\n",
            "      FirstStageBoxPredictor/BoxEncodingPredictor/weights (1x1x512x48, 24.58k/24.58k params)\n",
            "    FirstStageBoxPredictor/ClassPredictor (--/12.31k params)\n",
            "      FirstStageBoxPredictor/ClassPredictor/biases (24, 24/24 params)\n",
            "      FirstStageBoxPredictor/ClassPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n",
            "  FirstStageFeatureExtractor (--/42.39m params)\n",
            "    FirstStageFeatureExtractor/resnet_v1_101 (--/42.39m params)\n",
            "      FirstStageFeatureExtractor/resnet_v1_101/block1 (--/212.99k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1 (--/73.73k params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1 (--/73.73k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv1 (--/4.10k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv1/weights (1x1x64x64, 4.10k/4.10k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv2 (--/36.86k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv2/weights (3x3x64x64, 36.86k/36.86k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv3 (--/16.38k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/conv3/weights (1x1x64x256, 16.38k/16.38k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut (--/16.38k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_1/bottleneck_v1/shortcut/weights (1x1x64x256, 16.38k/16.38k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2 (--/69.63k params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1 (--/69.63k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1 (--/16.38k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv2 (--/36.86k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv2/weights (3x3x64x64, 36.86k/36.86k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv3 (--/16.38k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_2/bottleneck_v1/conv3/weights (1x1x64x256, 16.38k/16.38k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3 (--/69.63k params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1 (--/69.63k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv1 (--/16.38k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv2 (--/36.86k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv2/weights (3x3x64x64, 36.86k/36.86k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv3 (--/16.38k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block1/unit_3/bottleneck_v1/conv3/weights (1x1x64x256, 16.38k/16.38k params)\n",
            "      FirstStageFeatureExtractor/resnet_v1_101/block2 (--/1.21m params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1 (--/376.83k params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1 (--/376.83k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv1 (--/32.77k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv1/weights (1x1x256x128, 32.77k/32.77k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv2 (--/147.46k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv2/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv3 (--/65.54k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/conv3/weights (1x1x128x512, 65.54k/65.54k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut (--/131.07k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_1/bottleneck_v1/shortcut/weights (1x1x256x512, 131.07k/131.07k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2 (--/278.53k params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1 (--/278.53k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv1 (--/65.54k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv1/weights (1x1x512x128, 65.54k/65.54k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv2 (--/147.46k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv2/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv3 (--/65.54k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_2/bottleneck_v1/conv3/weights (1x1x128x512, 65.54k/65.54k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3 (--/278.53k params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1 (--/278.53k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv1 (--/65.54k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv1/weights (1x1x512x128, 65.54k/65.54k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv2 (--/147.46k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv2/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv3 (--/65.54k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_3/bottleneck_v1/conv3/weights (1x1x128x512, 65.54k/65.54k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4 (--/278.53k params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1 (--/278.53k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv1 (--/65.54k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv1/weights (1x1x512x128, 65.54k/65.54k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv2 (--/147.46k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv2/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv3 (--/65.54k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block2/unit_4/bottleneck_v1/conv3/weights (1x1x128x512, 65.54k/65.54k params)\n",
            "      FirstStageFeatureExtractor/resnet_v1_101/block3 (--/26.02m params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1 (--/1.51m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1 (--/1.51m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv1 (--/131.07k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv1/weights (1x1x512x256, 131.07k/131.07k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut (--/524.29k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_1/bottleneck_v1/shortcut/weights (1x1x512x1024, 524.29k/524.29k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_10/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_11/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_12/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_13/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_14/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_15/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_16/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_17/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_18/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_19/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_2/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_20/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_21/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_22/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_23/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_3/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_4/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_5/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_6/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_7/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_8/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9 (--/1.11m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1 (--/1.11m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block3/unit_9/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "      FirstStageFeatureExtractor/resnet_v1_101/block4 (--/14.94m params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1 (--/6.03m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1 (--/6.03m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1 (--/524.29k params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/weights (1x1x1024x512, 524.29k/524.29k params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2 (--/2.36m params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3 (--/1.05m params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut (--/2.10m params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/weights (1x1x1024x2048, 2.10m/2.10m params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2 (--/4.46m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1 (--/4.46m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1 (--/1.05m params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/weights (1x1x2048x512, 1.05m/1.05m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2 (--/2.36m params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3 (--/1.05m params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3 (--/4.46m params)\n",
            "          FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1 (--/4.46m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1 (--/1.05m params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/weights (1x1x2048x512, 1.05m/1.05m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2 (--/2.36m params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n",
            "            FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3 (--/1.05m params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FirstStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n",
            "      FirstStageFeatureExtractor/resnet_v1_101/conv1 (--/9.41k params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/conv1/BatchNorm (--/0 params)\n",
            "        FirstStageFeatureExtractor/resnet_v1_101/conv1/weights (7x7x3x64, 9.41k/9.41k params)\n",
            "  SecondStageBoxPredictor (--/53.27k params)\n",
            "    SecondStageBoxPredictor/BoxEncodingPredictor (--/40.98k params)\n",
            "      SecondStageBoxPredictor/BoxEncodingPredictor/biases (20, 20/20 params)\n",
            "      SecondStageBoxPredictor/BoxEncodingPredictor/weights (2048x20, 40.96k/40.96k params)\n",
            "    SecondStageBoxPredictor/ClassPredictor (--/12.29k params)\n",
            "      SecondStageBoxPredictor/ClassPredictor/biases (6, 6/6 params)\n",
            "      SecondStageBoxPredictor/ClassPredictor/weights (2048x6, 12.29k/12.29k params)\n",
            "  SecondStageFeatureExtractor (--/14.94m params)\n",
            "    SecondStageFeatureExtractor/resnet_v1_101 (--/14.94m params)\n",
            "      SecondStageFeatureExtractor/resnet_v1_101/block4 (--/14.94m params)\n",
            "        SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1 (--/6.03m params)\n",
            "          SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1 (--/6.03m params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1 (--/524.29k params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv1/weights (1x1x1024x512, 524.29k/524.29k params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2 (--/2.36m params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3 (--/1.05m params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut (--/2.10m params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_1/bottleneck_v1/shortcut/weights (1x1x1024x2048, 2.10m/2.10m params)\n",
            "        SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2 (--/4.46m params)\n",
            "          SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1 (--/4.46m params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1 (--/1.05m params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv1/weights (1x1x2048x512, 1.05m/1.05m params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2 (--/2.36m params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3 (--/1.05m params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_2/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n",
            "        SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3 (--/4.46m params)\n",
            "          SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1 (--/4.46m params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1 (--/1.05m params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv1/weights (1x1x2048x512, 1.05m/1.05m params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2 (--/2.36m params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n",
            "            SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3 (--/1.05m params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              SecondStageFeatureExtractor/resnet_v1_101/block4/unit_3/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n",
            "\n",
            "======================End of Report==========================\n",
            "262 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/6.18k flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/Scale/mul_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_2 (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_1 (300/300 flops)\n",
            "  map/while/ToNormalizedCoordinates/Scale/mul_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Minimum (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_3 (300/300 flops)\n",
            "  map_2/while/mul_3 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_2 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum_1 (300/300 flops)\n",
            "  SecondStagePostprocessor/map/while/ClipToWindow/Maximum (300/300 flops)\n",
            "  map_2/while/mul_2 (300/300 flops)\n",
            "  map_2/while/mul_1 (300/300 flops)\n",
            "  map_2/while/mul (300/300 flops)\n",
            "  GridAnchorGenerator/mul (12/12 flops)\n",
            "  GridAnchorGenerator/truediv (12/12 flops)\n",
            "  GridAnchorGenerator/mul_1 (12/12 flops)\n",
            "  GridAnchorGenerator/mul_2 (12/12 flops)\n",
            "  FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block4/unit_1/bottleneck_v1/conv2/required_space_to_batch_paddings/sub (2/2 flops)\n",
            "  FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block4/unit_3/bottleneck_v1/conv2/required_space_to_batch_paddings/sub (2/2 flops)\n",
            "  FirstStageFeatureExtractor/resnet_v1_101/resnet_v1_101/block4/unit_2/bottleneck_v1/conv2/required_space_to_batch_paddings/sub (2/2 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_9 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/Less_1 (1/1 flops)\n",
            "  mul (1/1 flops)\n",
            "  map_2/while/Less_1 (1/1 flops)\n",
            "  map_2/while/Less (1/1 flops)\n",
            "  map_1/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  map_1/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  map_1/while/Less_1 (1/1 flops)\n",
            "  map_1/while/Less (1/1 flops)\n",
            "  map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  map/while/Less_1 (1/1 flops)\n",
            "  map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  SecondStagePostprocessor/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  FirstStageFeatureExtractor/GreaterEqual (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  SecondStageDetectionFeaturesExtract/mul (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchGather/mul (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchGather/mul_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_3 (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_4 (1/1 flops)\n",
            "  BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/Minimum (1/1 flops)\n",
            "  FirstStageFeatureExtractor/GreaterEqual_1 (1/1 flops)\n",
            "  GridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
            "  GridAnchorGenerator/mul_7 (1/1 flops)\n",
            "  GridAnchorGenerator/mul_8 (1/1 flops)\n",
            "  GridAnchorGenerator/zeros/Less (1/1 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/Less (1/1 flops)\n",
            "  SecondStagePostprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/mul (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/mul_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/truediv (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize/truediv_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/Minimum (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/mul_1 (1/1 flops)\n",
            "  Preprocessor/map/while/ResizeToRange/cond/resize_1/truediv (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0205 14:13:21.319272 140123216222080 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:342: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0205 14:13:22.419411 140123216222080 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:342: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-02-05 14:13:22.442814: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-02-05 14:13:22.482801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-05 14:13:22.483375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-02-05 14:13:22.486441: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-05 14:13:22.501301: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-02-05 14:13:22.508991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-02-05 14:13:22.514745: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-02-05 14:13:22.534433: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-02-05 14:13:22.548316: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-02-05 14:13:22.597793: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-02-05 14:13:22.597946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-05 14:13:22.598556: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-05 14:13:22.599042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-02-05 14:13:22.606783: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-02-05 14:13:22.606961: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x18a8f40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-02-05 14:13:22.606987: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-02-05 14:13:22.722365: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-05 14:13:22.722978: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x18a9480 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-02-05 14:13:22.723001: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-02-05 14:13:22.723200: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-05 14:13:22.723683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-02-05 14:13:22.723739: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-05 14:13:22.723755: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-02-05 14:13:22.723768: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-02-05 14:13:22.723780: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-02-05 14:13:22.723792: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-02-05 14:13:22.723805: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-02-05 14:13:22.723825: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-02-05 14:13:22.723900: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-05 14:13:22.724458: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-05 14:13:22.724920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-02-05 14:13:22.724977: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-05 14:13:22.726089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-02-05 14:13:22.726112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-02-05 14:13:22.726121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-02-05 14:13:22.726261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-05 14:13:22.726805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-05 14:13:22.727314: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-02-05 14:13:22.727350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from /content/models/research/object_detection/training/model.ckpt-6892\n",
            "I0205 14:13:22.728944 140123216222080 saver.py:1284] Restoring parameters from /content/models/research/object_detection/training/model.ckpt-6892\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0205 14:13:26.029213 140123216222080 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2020-02-05 14:13:26.787765: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-05 14:13:26.788342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-02-05 14:13:26.788439: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-05 14:13:26.788456: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-02-05 14:13:26.788472: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-02-05 14:13:26.788485: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-02-05 14:13:26.788498: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-02-05 14:13:26.788513: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-02-05 14:13:26.788528: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-02-05 14:13:26.788622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-05 14:13:26.789134: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-05 14:13:26.789605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-02-05 14:13:26.789641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-02-05 14:13:26.789651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-02-05 14:13:26.789659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-02-05 14:13:26.789771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-05 14:13:26.790300: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-05 14:13:26.790761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "INFO:tensorflow:Restoring parameters from /content/models/research/object_detection/training/model.ckpt-6892\n",
            "I0205 14:13:26.791915 140123216222080 saver.py:1284] Restoring parameters from /content/models/research/object_detection/training/model.ckpt-6892\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0205 14:13:27.987768 140123216222080 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0205 14:13:27.988028 140123216222080 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 530 variables.\n",
            "I0205 14:13:28.558185 140123216222080 graph_util_impl.py:334] Froze 530 variables.\n",
            "INFO:tensorflow:Converted 530 variables to const ops.\n",
            "I0205 14:13:28.831413 140123216222080 graph_util_impl.py:394] Converted 530 variables to const ops.\n",
            "2020-02-05 14:13:29.484196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-05 14:13:29.484844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-02-05 14:13:29.484938: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-02-05 14:13:29.484962: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-02-05 14:13:29.484982: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-02-05 14:13:29.485004: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-02-05 14:13:29.485039: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-02-05 14:13:29.485067: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-02-05 14:13:29.485095: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-02-05 14:13:29.485759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-05 14:13:29.486591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-05 14:13:29.487146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n",
            "2020-02-05 14:13:29.487202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-02-05 14:13:29.487219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n",
            "2020-02-05 14:13:29.487236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n",
            "2020-02-05 14:13:29.487367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-05 14:13:29.488039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-02-05 14:13:29.488695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14221 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "W0205 14:13:30.592963 140123216222080 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:309: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0205 14:13:30.593450 140123216222080 deprecation.py:323] From /content/models/research/object_detection/exporter.py:309: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:315: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
            "\n",
            "W0205 14:13:30.593918 140123216222080 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:315: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:318: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
            "\n",
            "W0205 14:13:30.594107 140123216222080 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:318: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:323: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
            "\n",
            "W0205 14:13:30.594358 140123216222080 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:323: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/exporter.py:325: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
            "\n",
            "W0205 14:13:30.594510 140123216222080 module_wrapper.py:139] From /content/models/research/object_detection/exporter.py:325: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
            "\n",
            "INFO:tensorflow:No assets to save.\n",
            "I0205 14:13:30.594787 140123216222080 builder_impl.py:640] No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0205 14:13:30.594892 140123216222080 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /content/models/research/object_detection/inference-graph/saved_model/saved_model.pb\n",
            "I0205 14:13:31.481141 140123216222080 builder_impl.py:425] SavedModel written to: /content/models/research/object_detection/inference-graph/saved_model/saved_model.pb\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0205 14:13:31.632516 140123216222080 module_wrapper.py:139] From /content/models/research/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "INFO:tensorflow:Writing pipeline config file to /content/models/research/object_detection/inference-graph/pipeline.config\n",
            "I0205 14:13:31.632813 140123216222080 config_util.py:190] Writing pipeline config file to /content/models/research/object_detection/inference-graph/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhwYDcfs7Jza",
        "colab_type": "code",
        "outputId": "ccc07e14-62a3-4959-ff47-cc56a71869dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "source": [
        "%cd /content/models/research/object_detection\n",
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from distutils.version import StrictVersion\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# This is needed since the notebook is stored in the object_detection folder.\n",
        "sys.path.append(\"..\")\n",
        "from object_detection.utils import ops as utils_ops\n",
        "\n",
        "if StrictVersion(tf.__version__) < StrictVersion('1.12.0'):\n",
        "  raise ImportError('Please upgrade your TensorFlow installation to v1.12.*.')\n",
        "%ls"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34manchor_generators\u001b[0m/                      \u001b[01;34mlegacy\u001b[0m/\n",
            "\u001b[01;34mbox_coders\u001b[0m/                             \u001b[01;34mmatchers\u001b[0m/\n",
            "\u001b[01;34mbuilders\u001b[0m/                               \u001b[01;34mmeta_architectures\u001b[0m/\n",
            "CONTRIBUTING.md                         \u001b[01;34mmetrics\u001b[0m/\n",
            "\u001b[01;34mcore\u001b[0m/                                   model_hparams.py\n",
            "\u001b[01;34mdata\u001b[0m/                                   model_lib.py\n",
            "\u001b[01;34mdata_decoders\u001b[0m/                          model_lib_test.py\n",
            "\u001b[01;34mdataset_tools\u001b[0m/                          model_lib_v2.py\n",
            "\u001b[01;34mdockerfiles\u001b[0m/                            model_lib_v2_test.py\n",
            "eval_util.py                            model_main.py\n",
            "eval_util_test.py                       \u001b[01;34mmodels\u001b[0m/\n",
            "exporter.py                             model_tpu_main.py\n",
            "exporter_test.py                        object_detection_tutorial.ipynb\n",
            "export_inference_graph.py               \u001b[01;34mpredictors\u001b[0m/\n",
            "export_tflite_ssd_graph_lib.py          \u001b[01;34mprotos\u001b[0m/\n",
            "export_tflite_ssd_graph_lib_test.py     \u001b[01;34m__pycache__\u001b[0m/\n",
            "export_tflite_ssd_graph.py              README.md\n",
            "\u001b[01;34mfaster_rcnn_resnet101_coco_2018_01_28\u001b[0m/  \u001b[01;34msamples\u001b[0m/\n",
            "\u001b[01;34mg3doc\u001b[0m/                                  \u001b[01;34mtest_ckpt\u001b[0m/\n",
            "\u001b[01;34mimages\u001b[0m/                                 \u001b[01;34mtest_data\u001b[0m/\n",
            "\u001b[01;34minference\u001b[0m/                              \u001b[01;34mtest_images\u001b[0m/\n",
            "\u001b[01;34minference-graph\u001b[0m/                        \u001b[01;34mtpu_exporters\u001b[0m/\n",
            "__init__.py                             \u001b[01;34mtraining\u001b[0m/\n",
            "inputs.py                               \u001b[01;34mutils\u001b[0m/\n",
            "inputs_test.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLNdZvQr7L6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is needed to display the images.\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x76oR1-t7Ra7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from utils import label_map_util\n",
        "\n",
        "from utils import visualization_utils as vis_util"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf9Osdp77TzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_NAME = 'inference-graph'\n",
        "PATH_TO_FROZEN_GRAPH = MODEL_NAME + '/frozen_inference_graph.pb'\n",
        "PATH_TO_LABELS = 'training/labelmap.pbtxt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Vt5UMPQ7X9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeZINcyH7Z8I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRGgAY5W7chX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmzoQJGt7fZi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# For the sake of simplicity we will use only 2 images:\n",
        "# image1.jpg\n",
        "# image2.jpg\n",
        "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
        "PATH_TO_TEST_IMAGES_DIR = 'test_images'\n",
        "TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, 'image{}.jpg'.format(i)) for i in range(1, 12) ]\n",
        "\n",
        "# Size, in inches, of the output images.\n",
        "IMAGE_SIZE = (10, 6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOerx-Wd7hqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_inference_for_single_image(image, graph):\n",
        "  with graph.as_default():\n",
        "    with tf.Session() as sess:\n",
        "      # Get handles to input and output tensors\n",
        "      ops = tf.get_default_graph().get_operations()\n",
        "      all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "      tensor_dict = {}\n",
        "      for key in [\n",
        "          'num_detections', 'detection_boxes', 'detection_scores',\n",
        "          'detection_classes', 'detection_masks'\n",
        "      ]:\n",
        "        tensor_name = key + ':0'\n",
        "        if tensor_name in all_tensor_names:\n",
        "          tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
        "              tensor_name)\n",
        "      if 'detection_masks' in tensor_dict:\n",
        "        # The following processing is only for single image\n",
        "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
        "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
        "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
        "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
        "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
        "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
        "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "            detection_masks, detection_boxes, image.shape[1], image.shape[2])\n",
        "        detection_masks_reframed = tf.cast(\n",
        "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
        "        # Follow the convention by adding back the batch dimension\n",
        "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
        "            detection_masks_reframed, 0)\n",
        "      image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
        "\n",
        "      # Run inference\n",
        "      output_dict = sess.run(tensor_dict,\n",
        "                             feed_dict={image_tensor: image})\n",
        "\n",
        "      # all outputs are float32 numpy arrays, so convert types as appropriate\n",
        "      output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
        "      output_dict['detection_classes'] = output_dict[\n",
        "          'detection_classes'][0].astype(np.int64)\n",
        "      output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
        "      output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
        "      if 'detection_masks' in output_dict:\n",
        "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
        "  return output_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcq4sMFP7tGG",
        "colab_type": "code",
        "outputId": "9dd1653f-4bf9-4f79-c006-0c845f0eadbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for image_path in TEST_IMAGE_PATHS:\n",
        "  image = Image.open(image_path)\n",
        "  # the array based representation of the image will be used later in order to prepare the\n",
        "  # result image with boxes and labels on it.\n",
        "  image_np = load_image_into_numpy_array(image)\n",
        "  # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "  image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "  # Actual detection.\n",
        "  output_dict = run_inference_for_single_image(image_np_expanded, detection_graph)\n",
        "  # Visualization of the results of a detection.\n",
        "  vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "      image_np,\n",
        "      output_dict['detection_boxes'],\n",
        "      output_dict['detection_classes'],\n",
        "      output_dict['detection_scores'],\n",
        "      category_index,\n",
        "      instance_masks=output_dict.get('detection_masks'),\n",
        "      use_normalized_coordinates=True,\n",
        "      line_thickness=2)\n",
        "  plt.figure(figsize=IMAGE_SIZE)\n",
        "  # print(image_np)\n",
        "  plt.imshow(image_np)\n",
        "  # plt.show()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAFoCAYAAABpHuNkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeUAAAFoCAYAAABpHuNkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgEAAAFoCAYAAADO9ShuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nD5EH88uZwgxHAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAFoCAYAAAB3+xGSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAFoCAYAAABwo3AzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFoCAYAAAAWz/GVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nb5AgQYIECXKH5f8HKgAvtoj8K2cAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl0AAADQCAYAAAA9M9QEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc4AAAFoCAYAAADeoxtDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nOy9aYxlyXUm9kXc5W25Z2XtVV1VXd3s\nbm5NscVFHGkkeQQYGkgDjy1BAjwDYzCQYWAAGxAM2APDMDCABwa8/DA8Y8u2/MvwYDBjaOGIGlIS\nRYlsbmqS3WKv7KX2ysrK/eVb7hbhH+eciHjv3cyqrO4my8A9RDNf3TVu3LgRZ/nOd5S1Fo000kgj\njTTSyMOJ/kk3oJFGGmmkkUb+/yTNwtlII4000kgjx5Bm4WykkUYaaaSRY0izcDbSSCONNNLIMaRZ\nOBtppJFGGmnkGNIsnI000kgjjTRyDPnQFk6l1L+rlHpTKfW2Uuq/+LDu00gjjTTSSCM/TlEfRh6n\nUioC8BaAXwJwC8B3Afymtfa1D/xmjTTSSCONNPJjlA/L4vwMgLette9aa3MA/wLA3/mQ7tVII400\n0kgjPzaJP6TrngNwM/j3LQCfDQ9QSv0WgN8CgKjd+fTCxUuANYiVAgBUWQYA2L55AyqmZqqqAgBo\nWGjwcVUFpWn9t3wulIbV9NuUFd/RIj19EgAwNz9PWywQ8bVLPi6KYpjK8BlWTgVfzmka1lTut1JA\nVRQAgK37GwCA1ADGVHwsXUfJxYJtVi4QtN9WJVbPnQcAxO02tc9a6DSlZ+Zzi6pEKg3zl36w1Bw3\ns0k9xDEPPuXwY4+62BEXsof9g88JPSgT3hQZGv6HewcTt1azN6/bdlx5WM/OYXdSD9m75qEHwfuX\nsE3BaJ4QO7Xt0NYd0ewoOGT6MNoWflm8Pehv5f7671lNXUkBMA/RpLr3qPWk/VHXC7PXmb12OM7C\ncVq33z/K0e87HA/TY0gd8vvI+UEdeshknyr/XqaPmmifMa7/tMx/1sJN5cp92K7vFf/VWvu5k69r\nrIXh/XS8u9DM3eU6KnigvXfe2rTWrtU0fEI+rIXzgWKt/R0AvwMAyx951v7i//p/oacVWvkYANAZ\nDQEA/8d/90+R3bgBAJircgBAPBxiqdsFAAz6B0jn5gAAZZQAALbHOcZDOh+LCwCApz/9Ap74B78G\nALhy9Sk6bmcPUUwL0/7BiO7bXYAsj7GmT9ZWFWzG+3nGn2tF6MX80kYD/NW3XgQAfOfb3wQAnLy7\nhWH/gNq4twsAKMZjxPyGYkX3KK1BYfml9uiZ8r19nP/FXwIA/Mrf//sAgC1rUc7Rgr/HC3I/y3BS\n8yCyNR+18cPEfdpWo2IFxO+enkZk39SE0Ao/7FkJF0Mtv4PFSR9y7Mx1gg/ITi2INviAZKKz1sIY\n+peK9MxCV1qDghWbsizd307amrifUsr9lo853Ba267hS1WzT4TxT13eyD0A0PekpVduH42h6+n+w\nPGq4JjKR+03jhe5t5K8CrGXlkZsv74mOk4kQkNHh2mL983YVX89aVNwPJR9fQaG0kfstw03GuIKF\ntnS+fHvaGsTcRs1/lQWy6QUwHGvGt2G6v+I0mTinmlYWas4xwYBwC4fWE+NOtsnvKPL9bScWBxz6\nexj555MxFP6N+BQxRJQF1JRCaZR/HaWoSAozz5lGJWC122+8aUHboGHVZB/P9+Yw5Lla8bvottow\nFX2v48EAAJDEGitLy9SG7W1qfxKj4uuNSmpLDgvE9D5MnKKy3sCStsj3pfidRgaIeYz8wa/8wnU8\nhHxYC+dtABeCf5/nbYeIhbUVdBRjOKaF89TSIgDgypNP4odvUGjUdmmRqyKF7YN92mYMypIW1II7\nZGwrIKVHu/DRZwEAf+fX/31snicrLhx08tJi7uyiKNBu0wKW8LayKqET+q3lIzYV+gNaTFU2wp17\n6wCAE2ukrGy8/DpGgz4AIFU04BcXF2ELauv+Di2mWmssrq4CAHZH9OxYWMDbb7wOABj16TmrOIHh\n9rS5LSWUe/kWGm45M7MfkLeP7cSCOSuHe+/1IZaXm8BVMOk7479m8cbRC2c4uU5PEIdNFDLh1Fkd\ntqzchyMLaFVV0O0OtSXU9I+wLqcn0WOJnu1XE/SXTEzKeoXG7cOEDgSArDB7eFN/LKKClxjBT6S+\nDyvnqnFNnRgPPKEGD6dcR/j7VKI86QjGTlqXxvi+sdZfX/M3R1+FLB48UUK7xVSsjkhZJKIo1yhp\n7t3XbJsek2IFHur9AKCUnlHIwuMmlEc73a8PVnbctW3w72mFzIYWnT9ONpngVcgzReIRtNb9luMi\no3keouv5a8tiqmfasL2+geUFmut73R5dL88wZEOmxd9ar5WixV7BTknb9nd3YWJ6Z0tLS3RulGJr\neMD3K9GbJ8NpVM2+E6X9nFjVzoWHy4cV4/wugKeUUpeVUimA3wDwBx/SvRpppJFGGmnkxyYfisVp\nrS2VUv8IwL8FKaO/a6199eizDIbDAWJ2arHCiINhH8gp3mkXyBI0SYQ2W5SR0hiyBrI3IrMeOgLm\nSYs5cfY0AGDl5Enscjyzz65TWHIBAMAiayz7B2PEkWi17NI0Bi228qR9w8EAKifrsZtEWD1J8dNr\n75CVefnJK7hxjaz+Pluj21mGpbke34/crkVRYMjWsxIXcaeNrE/XURndY7E7hz5bq2O2ysnyFE2p\nTrv1VqjfpoL4ikSmvP5kREWdMN1o/7S70EloIQWWk+yb1s5UcFwoYmFVoTYtWn2NFi/WgoF3Y1VV\nhbyadMuGFmLKcWKl1ITry13zIeKZH5TFqTBrSYZHmaljQ6nU8WLKH4bowIVHcSkxW/iP9Y10hqRR\nbjw5CQaEePLC91x5I8b1iesbrTAxWHlHzJaIsj62p91fW2uuxzWuWnnXdRanSF4WM9cCjnbth3HR\nujEXWrOy37sbD7/XYb+1DdyxU1bm9DY75SUI2zARehVLU65h9UQcVbn3HLxA3iZHaZ0AY+q/0XDM\nbS2x3CVv0HyHvIyD/h7u3H4HAPCxpRMAgEsXn4BlL8Gd7R0AwF7ex1qP5tgxFDbu3wcAdBYXuQna\neUbc42sFMz0mHyAfWozTWvtHAP7ow7p+I4000kgjjfwk5CcGDgqFAvglRsMDPLFKAWBryFq4desW\nsEAaBCIOoseRs5JyYzBki9Rp9UkKdAj40WX/OeIISUSPm4/p+Fa7A8Nd0ErIEon1GKjo3gVbLDpS\nyBm0JKaUjiJ0F8hq7MYan/n85wAAu7uk+dz+5neRtqkNi6fIGs36B06TnJtnQFNeYHN7i+7NsdXR\n9n1EbBntrt8FAFw5fZo0ZQAjjo+mSYxS1KZQYwosyon4D29z2mwQ9xQRLXHSpvLa7zRwpeawiZ96\ncvPMcRObxditiw1NWZ7hPgUgYxS2tdZp5nKs1hoxexvkb6jxHxUvqgN2PIpYNRvXDf8pGnhogR5m\nfQIOJEjHvf/mPZIo7SNDBhZKzEXZqDBpoQCA9lOOgFAI6CReHn5nwQMa7S9o5Tg+10wZnNNxQ7KM\n5PyY22qgMWn5VDAzMc7wOiGic3o86ADpUxfjVErNxjihjvRu1H0D4fXq4qN115OxoQNL0IFjguuE\nMc5aUZN/I8yOSW29N8Eo70Hz+/2/BcM21+mhYCCo9GM7jlHuk8ft/gZlKcz3uvj45asAgL/9iU8C\nALoLPcwzLotXALw3An74I7JM375zBws8rxuOcRYwbqqUHp4GOT2MPB4Lp7VIqxKwFRY7ZKLv36Zs\nlnLQx9wJAtwoCfpCY8xuy8FgBMNvs8uL7tBYQg0AaHM6R6vVwhyb/Tu8gCZRjKygxXFwQC+qzDMo\nJS4+al+700Ze0qvRWs5NkeUUwC6yAh995iMAgJ9n8Mm//urXMTwg17EMoJUTq0h48GcyWGBxnkFL\n65vkVlBJCpPR/q98kULDn89G+Pjnfoae5cQK9dFwhH0riD6PQPWLjAdbhLB04w/0L2FqEa37fFR5\ndLKDBWbcsgZHLxju7nYSJYup3+EiaaYmJsC7r6MoQsJudfkbIm1D19u0q7YODDL9G5hNP3gYqVAP\n5qnzjIuEi6icOw2+Ajx45tALfUgSgoOUsg6bbWT9DFy1xi1U/hyt3U6ffhAugvx77J7PuI4Q0Flk\nrF+cjUf0hukcvo+DxVZCGO6GGunUojHhopQ21fTD9DhSU+OzXhGcHUN1Slr4b4ccr0F/h+hbOYae\nKlgwnTJxuKvWTp0TPFT4B0Z5F61rH7T3tQcSLphT3nwM9/vo8neasnu9HA3cYrq6ROCeT378o3ju\n6UsAgEt8bh8AB+ccar2/s4ObN64BAO7cWUfJBkhnmQFKWsPyAK3c8Dv+R9Nw1TbSSCONNNLIMeSx\nsDg1FOa1hk1bGG9uAgDe+N73aKcxSNlFWzAcOdEROnPkgjWFQclal1iXw70+wDmHKadwbG9uoVqi\n/YoJDiILaDbhJe0jjlNAYOvillAWCWuVMYOJqrJEn3OMImtw5x65FFZOngIA/Of/5T/GH/ze7wMA\nvvG1PwMAZKMBVhgc5MEGFQy7pUXTW1tewsYBWdfXv/0tal82Ro+D3peeoRSbdDRGxDlkYc6js1Ss\nd2zqcJ+QL0wollOupBolzJNJHC5iNcr5Wusj9TmxoCaAMGEemZ1sq7XWbQvdhG3WLKG1szTFEtBa\n+5zBwPUWTWnHxnrd07pt1v1D3lkdqOhBcljPhWkoM/tqjncpAod51H6sbtspl2aICONtxqN9/HGy\n351r3DiQFAcao5I+4t+Zdaklsk1BS8qVVd4KKv24mbYajYUnSwmH2jE7T8aDuP9lm1KT++ssyaq0\nE+ccdu3DLE6XflVzj0kiBfhzprwVE+ktwTic8YwoD/mRe4RWqWvDtLUZuG2ByZCC/Gx3OjAMstwf\n0Jw332rhky/8FADgpz5JnrwVAJyZj33+Owbw8mtvAAC+9iLNk1uDEc5cvgwAuHj5Im5vUhhMwjeV\ntaj4PYcgoeNanY3F2UgjjTTSSCPHkMfC4owVsKIVVBrj3nViCXr9uy8BANLCoJA0k4zih+20hXLE\nYJAKzoLKBxwiLgzOrp0BAFw8fZaOG+fYYe1jzJpNp9V2lHUVA4G6aeIACC4toiydhiEgFJgSXU7Y\nnet28L0fvAKAMmEA4JdOnscLX6CYpICEXv/eS9jbJMu0x1pqGsUYjShWGsXSlhwY0raYffw7t+/i\nm1/5Ct16TBrauScuIYq8Zu10psCilPQSNqJJG1aitdfBTzhmUmcBVQ+fhnFYHHNaHvaKqsZKdtq4\nAhYWqJ+MMcgDdiA5TjT0yHkOktn41UMmmD9KjPNBTxo+11GGz4P04sPhJh+8TPRXzfYJL0JgjThw\ninh2rHLAkEiICYLjiqmUEACwVWhp0f1iowLPBKeSQbuYq1iZSnkvyKR1NQkEqot511mPURRNbTs8\nxilialJLDhtzR8VKHwRc0/4TmYkvosYanwAMBffy5072Ubgtn7FUJ9tggcAap79JHAHM/HR69RwA\n4GNPP42PnCccxzxfagQPAHr5HuFfXn3tDbzDKX+GPW8rJ87iwNA6UQz7aC/SFfojmjON8ZamB04+\niLhwVh6LhVMbi/YoQ6IVvviVP6GNTFd35fQZbFx7DwBw9hQtgvub25Bx14lTVJz0yWBYfPRjH8fy\nSVo4X2IT/unnnsNBSefHLXLrDXf3oYN8LwA42N6GjiddfUYp5OxOkOmg1+kibdN1tnZ2sM9AoGvX\n3qU2Zq9gjUE8V54j1+qpU6fw3b/8KgDg9jv0TFG3hYyBTq0WLbB5UWCBEbtGS/sM+vcIPHTrrTcB\nAPNxgujSvGvVPgOc5PkQaRwwgjhlYFScJkgZHDX50emJfpj+DQBFDbfrg6Qscvf7YXlgBegT7q+j\nxXP5ZkohY9alcCKUqdoEqEZZTIHZBTBsS7jQTrfxqHy6wyTsy6Mm4VpEZ7ioPgBFGT/CO3pULt4s\ny/xCpTydWuVm2QhGTSoMVV7gwlmaILfW7wGgXD1h8ilZqTVFiSVGnh/s07ZER+6bTAN0tCiF1io3\nKWY5vedWr4uM39ed+3S/pdUTyFgJjCU/O01QDAd8nSNcpzXbqjyfzDt9COag0FVbJ3Wo2XBfHQ3k\ndM4pUA8oCq9jp65Twec6h+7YikGUwrxlrXXziAPj9VpunhznpaMzjFKee+LYr5gF58PnY7Q5/HXA\n2REvv/U63r7OoJ4k4r+xe/evvPcDuobVMCs0RiQ7og/rQD+VUrCCsNfyLXkE9wQH8jGR842rtpFG\nGmmkkUaOIY+FxVnlOQ5u3cbiwhz271De4oCtq+29PSSsHQ4jCgtnB0MXkLfQaCWUwtJiftvIaGyt\nE8jIJHTc/uY2ttoMGGLrq9frIW3Ruc7yjGKolDU3Nv+TNPXVVqwPyotinaYtrHDKjLh3t15+Fd/6\nN8T/0Jsnl+5TF87h0jPPAYBzz967cR2XzpIlLFq3tRZDZgw6YEsqH48w3KZneveHxN27efM2rv5t\n0rhWVlagWBssGGwUtVIoNsOFIxexrnUaKsfd6bdNw9LrtKwH8aWG+Xh12nqdy0nXWJeo2TZteR7a\nBtQ7Sl11hMB/NJH/J3+njnsU/E1dC5VSkyCkw86d8IM+ws0/JLHhu7UBECgk9+bvRba02x1naWpm\n3OlEHdy9dgsAcPEUfUdRGiMb7AEArpwgppiQW1Vc96aqUBZsrVYl2IOLnI/bvncPMYPqzq3Qdda3\nttBbptS1Dud7r29sYoV/H1emuZWngSb1ucDHf5FHeQYOy+2MarY9yMMgc5MUuYgizxkmua5lWaJg\n6zLn8FVWDoI2RG58jAtmBKq81Rgz4DNpt1wKUc79VpUFxsw/rh2/sHUfQr8ly5b2RPJWtilYsSWt\nhtiV1nqQWjRVUEDh+N90Y3E20kgjjTTSyDHksbA422mKZy+ex6kTa/gEQ4m3O6Qlvv3aazh5krRD\n8YujXcAENS5F3+uy9Tg8GGCT4yIrzCHb39tHv8unM8mCykuUHdKWoph86lGawKSk7SQcc1Rl6dlo\nWPXKbAVT+VQQAackHF88l/awdoEKxEjs5M2Xv4d95mDssMZrbt92HLsp6zGtOHLxg0UuJZZ2uogS\nspT3tqiszntvvgl1+Rm63sc/4TTdMXO1duZ6DiRRci8lSQSDnJ/FV5AQi84wkiIKqimIxRMlNXqW\nneVbndgdarcuBWc2HhNq5GG6x4wWHUDxw2OcxTaRXhAcU9e4aVaYGoaX8N7vh0Eo5Pl1wBRrXcgH\nNdZs3d1cMv/jYHla7QEWSntWH2fBq4ChR0p7xbAgL8gcp48VBwMspRzL4sSda2+9ha//5dfo9811\nd0v5Lnod+phPrKzg1ClKAVtdW8P8InFOn2Avzokzp3GfeZ+HGVk+8602lrgU4Q5jE9rx8VOMRIwx\nk3HFhyBA0Or4U2+d1VgX+5+I1dcQEvghp7wnJmij4AAqRe8irjzrmqTlRVrDFJMgPJOP0eI5OG3F\nbpBmnMZWljmUYsIWSR9TkfPiFewdy6oSEGAfe89sWbi+Gy2JZ0AHH4JgNPx9tY0dANIG5RcFPBmF\n37U5Hm7hsVg4hwd9/NXX/wLnzpxFn+nnFE/+aRyhxWCdnMnc0zTFgAEkJtIYsVsz5rzKQWUw5m0d\nrttZVRYRB+Q1X8dmmavXZmMeLJlGxS7aYsSE4HEEJW4Ldv1Ca4y11AGcBdn0K4sFRvSKS6qqKlgu\nNda2TCl48zru75BLap4D4WkUu3qdcr2qtEhadI7UFVydm8N7b1Ae0+Xz5x16NxtLqbTIzbSlkcEd\no7AeMAAARkUztfoQUIK57LjI1x0Mpc7z4xZTU1NT05jahdPlxfHHWTcZUL7g7LaqbuA/YJH5IKj0\nHlbioBG+tLqfxOryWY+iAiPyci/vZyF91H4wUM4FZpUvKSXMLOSK5nckk+hg6Ai8o5JBYMMBLp2m\nxe/bX6Wc5++++HXc/sH3af8iFWrAaIwx5zePmVlmSym8yYow5hYQ87U//ws/DwD41Od/BnNck1fG\nS9xtw/KkD3Y3Ls31nMvx2P1wiKv2KHDQo7jcj1okH+SqBTD7Hda1C/DUpQJ+qioXthFXbRrFzjUv\ni6o1GSIeyLGtAFkk2S1rtAcj+ZrAnrzPZYvGsUtP0OByjmh7MJYWwKF2oQAZX6SqSYlB7Wn/JJMg\n+C3Pp2Hdwvqw0rhqG2mkkUYaaeQY8lhYnP39ffzZl7+M0ydPYYvzHNts3czNdTFk3taKXbW5Ndgb\n0LZWt4eRWFMc1DZxjB5rmT1O6yitQcFAG82memKVYxGqhPMxjmALstxswhBs63MxAXbzRhpZRZpP\nVhYOXu4YatIWDFtB+3tkUZ44fxHFPrlZLywTkKkaj/FXX/8LbgODl9ptLHEB1oitvf29A+xsEDhI\niLLn5uZw/y65sUb7e9Cc9VSNqR+q0QEqhnobwwT3WeTBCwLc0NppmUrct1bB8U4yd6+NaooxT/17\n2vKprHdj1bH/1LmzJvLNajTzOmXdWWx1x9tDLLLp1A1V81vN3vBRjLvQDRzzFQyOBiVMuP/EU33Y\n9X98xrMTiyjIhQvGiwNfaFeYQPhKqyxHzqMm69N3cWF1AfevXwMAfPWP/hAAsH9vHcunCcxT7HLZ\nLqVhu+RiVeyqtZVx47kaj2HYavzL/+dfAAC+/+1v45d//dcAAE9+ktho9qzB5h59h8tLlDI2yHwK\n1OMqdaXIDrM4nXUdjIuZ/MWaggkhP28kKVlKO6CQZes6K0rHJCYpHxEyVJz+VkAB7ClMWuSSj6IU\nFYeOMnGXJh6Q5duvvdHLLm0N40MmjsFMe1esXMNq5wVRNgi9GAmFGO+JknNw/EIOj8XCqbVCr9eC\njgwuXboIAMg5YbXT6WBrgxC2VSToK4N+xqQB83Nocb6X4Yk97rbRZYTtWBCmRmO4S6hcw+4cbSzA\nLyESQvAkdnEBmQcipd1iq8XFqJSbeKu8wpBdxwUv7lWcOCSr5Hi20wQZH5f2KJftb/3yL+OF54nt\n/5/90/8WADDY3MJmSi7rtWX6sNutLpY5fiMDqNXqQPE9ykEfpsUuTiEAyMawRmI31K5i5MmNZZGM\nlYZyOaviekuChZPdK9rnQNYtROEiKvvLspxdzPQhLlg5N/yIxZUe5GzqKVeSDRYldVjMtcZtWxtD\nfIh45qPkPUYT9OYkGv5dODq/YGkM1/UAp0r71AcHsH1UV20VVMOA8hWLPEo5eGb+bpIodkqxVLHM\n+wf403/zRTqXleSTS3Ow7EY1fRp3Cp6aD0JwYIxz+ylj4J2tdODBD1/DV1q0GEtO8yf+xt9AYWky\nl5xhU2RUVekRRGs9GSeviXF+EHHyo2KcIcn7hKtW8hdBlJJAMG5qCB4MrMvZTDgGnSapU8wqDoFV\n49y9U/keF5MEY87FHI5zVIqP5TlRpwYFf4CF0J72YjduBIdBIYxqol21GAirA4VRQgIhobwK9vN4\nsRYyU1nJYkAFa+trqh4mjau2kUYaaaSRRo4hj4XFWZkK/QNy24g2sX6P8zn3+xhyZXDLpsR4nKHF\nuZGdxXkkjMDdHTINcJw4S/P+Lrlkzp67gBZrGi12dbZ0jJg1Mq0EpWsctZy4ceM4gmGAT841jmwU\nuZyxqqqcpSmUfO3FJWzcobqZC0uEoNXtFBEDGb764osAgKVY4dmLVFbsP/nt3wYA3H77bbz7xlsA\nPIK2LArErKmXDG7a3d3FwhqBKsosg2W2FPbOwhS5y2kSUFOZj53LVSzOSmlotkwN9z8ZExKgZy2x\nqNfKQivOTG3L89xZizpwh4flkOSvYy9hjXfC/RRYnjNk1lNo2CPdnzW/66yBoyyER7E4CcwzdU2l\nEE25jYzyOZ2h+3mKPx36MPfzj1FsMH1YeEYWcaRF8O9NnqWdttBlBG1rhb6Lb/zxF/GjV/8aAHCe\nQxhFfwc379wGAJxN6PswZY4yZ6Ad5/kpUyGWMRJHDh3b5mvvFAV2/proML/EIYx0YQFnuAxgxRZn\nrDU8x9XxZLq26zSBWy1D1MOzVzp5JFRtQAYfs51U1ADpQkDTjBVqjJtbSp4Duu02TnJ+7YmVVQDA\n6XaGwYD6eGtvH9t75Gnb53l5VBQOlxOzC9aWFSphjRLydWODewt1ot+2ELXreof+31rvBZlwRYun\n0Dg2K9lmVIHq0DIM9dJYnI000kgjjTRyDHksLE5jLAajEdI0xf4BreV31sni3Nq4jw4DAuKIYhBZ\nWeDkKeKi7SwuOV/8NmuUWZnDHLDVMiYN9Mozz7i0FuGEbbUT6GgypcTAuvhJVUmsU7kUUtF4bRQ5\ni6ysfJxFcpqu3byFhC2tFqfEvPitF/HJJy8DAM5y8eo7P3odf/pnfw4AuHiCNDddlIg5JUaC5+U4\nc1pqxVrfeDBG9yJD8SsDK0TZfG5pKmelC19QVhZQXPxaCUQ7ilwxcB/XrOA0NuEgPYSjtc7iFCnL\n0sHR/UE+TlkXo6lqYkNei67RrGt4OA+TujzIunJMddvej+jQKg6YiqatXsA65iQHgTgkbnsUIOrH\nJ/7d+naIlQNM2/+x0hhwSsnKIn3X33nxG457dpfZsYabGzjF30Oyy+9Cx3B12yXFwRhXlq+wcJiF\n/iZ5avR8F+D5wd65AwD4vX/5L/F3/+E/BABceOppAMCN9TtAUp9u9cAeeECMsy4/uHqfnMJHcdlO\n7MfEQJ8855AmyLcp32Ge566ohlxt8cRJfPSjHwUAfGSZ5uWTIDJ2ALg7HOLt68QG9d5N8hxs7O57\nbwqnsOR5gcrhKoLnEy+VcBKH7cseZO+FoDqxXOXCxuWnShm5yhrHXvSw8lgsnK1WgqeePIPxcASU\nZNY/dYXAMycWetjYIKBMzAn4585dQsrEANuDAW5sE3goE1LhxWWcOEc5lGvnaIG1y/Non7s8cd/Q\nNTPh3vCzGV03IHEWN25VVROosjaf00ppoSuyA0c+sLtJyNcLVy5hh8/fYz+vOv8U5s89BQB46zYp\nC3k2xJDzWBHz9BnFfsJtkzsLyzHE1zdvC6BFH363N8f92nKu4zKj406vncb2Nk0qjv5Kx9BS1oUl\nMyWGhQdgAICK84mFDuDBHgQ858IAACAASURBVBCoi+JQ8iK+vLwc1JAUcIKFEkKJij/IoP8Tt76E\nEwW3z8wukkbpADCkUc/AN30OHMtzSLPnludg4pHJp3YyYjkyZw/AKBm63y5n1vj6keIObwWkAlrS\nzRRQ8ORS8gmlUmC9DpXyisDfvE3fTQ6Dgaa+PYhpLA2TEuOUaRkjQaqWiMR1xYC7teUl7G4Qur1k\nsIfWGisrBFQ74BzK9bgPONd+gs48jcv9AV27LBSWFmjx29ul/GXVmUfEi8brXAlpdH8fI64GtMrA\nvS4WkY54Ma3ofiUUSp5wSwGzWZ/LF5sSLa6MEY1pcV6IMqQcZtHzBK7bevUVjN+i/OfOWVJgV6MU\njFmvXYyOUqBIoQwAOU4JDS8wdZL2U2+Yr2v5XcgCY4J3a3lhN7BujMhxVZAVTMo/7V+uaqZ4FaJl\npUINh6WMRcoo+nJnBwCQFDmucp7tC88R4cpHL1/G4tT6dQPAjW268Xe+/xqu3aIqJoKijjotqDa1\np2KyAx0pt4CJuzgCHJmG6y7rv6uqMxtGOapwAjCZa+u6gf/GiHHcpbBx1TbSSCONNNLIMeSxsDiL\nqsLt3T62N7eQMdx5kbXDTqeL+dPkCjCsn5ftFq4zGfzYWOeKWT1P2vaFp5/GGrtCYyZuLqwBjqDV\nmiY0B7yW2Yk6M65YWwBlLi7dytNUCSMGAC1WEluedL3DXTRrTA9YjEYYcp7agKnBitHQWbtRYPUt\nnCVS7MXlZaRtyZeaZd4RLSyrYUex1s64YcNtoq3FUTqzzQT9FMcxuuyWVpEHJUjf1lVZrwfh+G0P\nC9Lx+ytP6Dz5RBPXVhaw0ftPEZi9f/31rLW+LuEUIAiAI6u28DR8ntkpcGnz8TE88EYpf60bKVla\nuS2QMcS+Yq+ESi2E+Cph96bOcyyxa19XTHu3NUBnSO93aY6+w7IsofeZZSejMbC02IYpqA25AWxJ\nY+sEj3ujE6gDsiQHnF7WGu2gxxbPD17+PrcrxkJK4xwMJNGw2OSc7pRDNYBxxQic90VZh7QJ37pz\n+5c+/8+BYrTC+n2yL5/jbfp9UO49iju/Ck7xoLHKhRJcoYOAljEqBMwSWFjO6z8L6gGAMjraBSkh\nHNet1mDI4aiLF4ky9LlLl/ARnltPpb6X9/gcIXv/8qs3cX+LvIN372+4773FRTWigES/EEYz2MB1\nPAvOU2Z226PIBxVyEWkszkYaaaSRRho5hjwWFmfS7eHs8y8gf+dd7HBA+WDIltFBDrC26tASSR9g\nMoClU6dx+oknAACrHNdsLy0BXdJyKlaxozSGLacStAOJjtBI4jhGJGwVrF2V1sCWrMnCIGcNXjhT\nVeQjYa7slQksLMHgwJsLC0zaUM11MT/PLEBsgZd5AcNxz5BW8cQF4vFcWFhwoKcJK03KobG1Oh6P\nZ6y4wlSO5DiEoE9bl4WZTQXRWkNLMeA4dkVtJf0lyzKvCQfBx7qUkqOF+5UKDE2IshYTRuaUNn6Y\nTMc9Qgt9mki+ts2H7J/+DQCq9EAg+UUjRMZk2BYpCA3/HLxfhwneEhMKnAX3TrKVaQpX2Z2zP9BR\nQJefuT3mQgBZjqURE1tsU/pUuXOAHqdptJgU4N69e67clPTrkx+/isVVinu2unPY2qX0g6FA/+MU\nY76fWB1VUSLh83/vm18HAFxe7KHLHoobmwTgSeIYOhLiA7YKoVBx/E27clE28BX5PlQ6IA7nMVlK\n/piO8N4Niq9KQWuddOApGT58mRxDUjrLg4wcYYcNUpGERALh+OJnNvUWZ9aWb+FoG0ks+coa9MRr\nxPFm1e1AsaUpQ20bwN1b1Iebd6lM3Mtv30XFqXIFDBTPAZL+llel6++M04nidqsGIIcZr8v0cx1X\nwsIRH4Q8Fgtn2pvDxc/+LNpPPI3Fu+SC3WFU3O72Dkbs7kkYYdqbX8QC5w6tnTuLtXPkRqi4c+73\n+zhgSr42uzoX5jqYmxo7h4EApunLLAAj2BMGJyBOHHAnig2cR4QRW5GufCUEN4NXboEQF4SufLVI\nAXvoNHVV2CMe8LHSQW1LmUSB+RXPJuSI06VWITmMg6cA8rx0LEHu46zMxIIJMPhpiojdlCNXB1Xa\nl6apZ11SyoODpGJCsMyJa9HoWRfyxAcSgHFm988uTkpZV9Ul7B95aYeSvJuZAeHejwnuW4finbnW\ndJ7e9Ec+QQMkqFkL6xBA4Z9Z9KOnIZRFBDPjFACuaQKitSKNDif0tniySooKPXazrvEaccpoZNcJ\n9dgZ8kKbl1hsU250l0MG/VMJfvDaDwEAX/wS1Zkdfu00XvjMZwEAz33uM3hmgc6J+ZsznQTru+S6\nG3GIYGtvF8OcKTSvvw0AeP7zn3UL9ODWewCA8XCApXm69zjj8AgUIlYcBC1JYQBRqizct8FDvCqM\n6+9cXLUqws4u5Y2PRdGNY1e79rjyKG7AeALs6sFEzlXrL+4V8CpY2GU8Gb9YulBAkJM4cLpE5VHP\ndva7cMxA1jqF6y1Gw966fRuvsFJ/aonmG13m2Oa5+t46jbno5CXHuhbBumISOYeqitIQ8hmTrvEQ\nnCeigz5xx+HRpXHVNtJII4000shPUB4Li9PoCP3uAjpXFnD1MjF6SL5kf38f4wG5jcQN2O7OuTyo\nUllssy6SsfaYdbuIF0jrFVftnlZYPAIAUJcjJTIej531VYobSitocQMrIE3ptwPN5KMZ14mysa/7\nJtuM9Zy3omSF7k+2DtM4dtZnKJLnlOe5By4F1pJYiGJlVlWFqIYZZAb0M1UqCQDiNHUujwm2FAFO\n1ZQLi9Nk1rq0CmYqZ2Si/wOgzHRuibWlT02pAQ5N5jR6y7OWW7eatOweVK5JZJoppu73tGhjXZ6a\neASs8qAMaR+1v5hog7Ze2xbPRhRYoVFAQ7PaJRfYfJpiUWpXjml/J8+wmtPvS5qsuUudNna5/NPp\nE+R27capS1l65VVi3UkW5/HEBUpJuHSZQiLmpev40Ta5Z3dffg1Rl66zzIC1p55/Dl0OmezsUsrY\nvTs3MWLLabkgT9LFuQ7WON1BDT5G933lFWzvketYayktpZyLNrLsqoVy35K2xoFd5B2ZSDvgla89\nCSh2R5ZSF/N9GCSPYs1MgBGDcaxnxnvl2hYS/jhPhaNttq5GMeA9Na6eJQIeaukJO/tdVAAWOK3I\ncCpSno1xe4/SiTb7BD7raIWUvQQLFyhU1leJ+3a1ApRY8zyxaWXR5lx6mbeG45FP93J9g8k6vvSA\nDxHO+fFJY3E20kgjjTTSyDHksbE4x71F0pKk/EvK6lXSQTJPGqphy2YIoNXmdI3BAfZHA74Ondue\n7yFmTdewSjUuC9gatdJZQ7JBz1axyEzprTNJ1o0UFGurUayhp6y4UvkYZxiHUG7bpOUJAImzYLUD\nN0hQv1AUcAcmwUEpXycPKqTLM5VV6dJCRDs0sI4b0lmX5Ww8E8AMu89ct+djoHYWbKS1dpqkWKa2\nMhOgILnedNWTMPUEAVBGmcD6BNgClb7z1VuslfiUrmHSMbXxTjsRUTwEHBTEPd3VDqHqOSwNBaDq\nPHI/Fy/XCpWWgr7S/OAabBFH1jhOWy3bDBA769PH2JeHFG9KjEE5JOtz6z7FGc3GNnb69C0NeOzu\nRD1gh6yJvR4B0q5evYqzlyid68XXXwIAfP0b34JeJi9Ov0ttWEgTDPpUcShJFHpLFOO8MyZrdWEh\nwvJpwiJ898+/AgDYzwYwnP5yfo4wC/nWBuZPk5X6/NPE5NPf2sbuJqWM2JQ6J4JyVqNS0jfe4lTA\nTDpHHMfIZYwJPiGvcPEykY4Y9uyMy0cHnjxSjDOYi9yYVMqx9cg3YKEdQUIVfCsyL3jGs4mpxPGw\n6sJvlN6z0xY4/DxjFbC9T+Mh4bmjlaSw0WQ6XmYsegnzAjPpSzbOoaLAYyNYCnH0mco9nxAgUN+p\nicMmGMNkW9hWHF8+6KL1j8XCabVG2e6izAuMmb1EaOWUBWJ+MSFrT84dXyYxYkWLZAmPEq243Ja4\nKKNEw06lMIb5cSK1rDBKuwXTuduUr2YOrV2dOpE4bQeuSVk4q4lF1O0TqjxBxcK4j6ByC7uCdoPS\nL2guZ1FHSMQtKwvnaOSI6J17E8YTJwuFn/WAHFkkIqXd4id/jQlqa1bi7plEtDookp1dAGopfQJ3\nqQN8hK5QAX44UJUO7hcgbYM8TuUAJBM3kgvyX+1otuomPseWdAxX7ZHbqnBW43tY44AhRlxvAcDF\nyjdggFj6m9sVlbQ4AkBS+fX2NBdLONjexdZtQqju36HFtLq/g+0BfQSbPKFeKyyevXIVABzR+pe+\n+hV86ue+AABYz2hh3LYjFCN2+Z5kQNrFErfvELLy9s4AqxHVkD0YEOPMiafW8Mx5WgjLihG3gx2k\nltCazz5JLr4kAgpG8WYZPfPq/CKWOrSQ75d97pkIkbgt2VWrgrGr4PMS5TtOkgS5fAOijJoSH/kE\n0cVFDHIbjnIkyfEXwEeVWHkEbVgYQdDV7rtXQMXbSlnwtPWLqTANAW480z46f2lfEEPa0WqKy9ZA\nzyyiFhpVOfmtaK3R4X5qsTteK4uSQT8HPDZNK3ahB2OqCfYjaoJy7mRhXQsXzkmRk2bBg3iERdAc\nQhf6qNK4ahtppJFGGmnkGPJYWJxVVWGvfzBRUBmVpFZUDpBTSq5kmbl0CNG1+GD+Y6A4xzKJ5W8C\nk8+yaEi6hHfZBmAPKZ6cxs4V61yalT/XmIA7Uoq7hkAkZ2VGMOxS1KH7lrWrKgB5aGd9sQUYx0iC\nFBCALUEu3aOiCMlUHudwPPaE6aLAKd/uOn5HZ9lF2j1DxNj+wWDgrE8BaiVJEvDWhv3jC4Q7bVGe\nOVDXQuCQT7mYfQf+BOvVY+e6qtwDsh7Oh9ZZniJVcD//N/w9sy1gc/ENrNF+67YZ5V3QAUpFuEmV\nuM2t8VaV8Hkag4jz41r8t11al2YSGw8Qym8Q287u7du48847AIC9+wTMSYoSc9wnOZthe+MMB0y6\n/vRVAubtbm3gqy9SjmXWpbFWxcp5LQwz2MTPXMRmn6zZ/v4mUualLVoURknPncDyFQISbY7IEi4T\noNejcfrMx56lXlApVExeozffeg8Alw5skWUalbvcrZ5Fx6U5We9tiCzcdyrgmySKYLlMnQMMKeDs\neWLFAYNVMjNE8mO0I4yCDwG4z8MDYKzzcBln3rgwgvLzjfs8Zh0aAIAWH2hgnWXu+G2Vctsq+G+4\nv0/jQcIuZZIg47kg5sEZRZFLqZF+TbsRMim/mHsm8DB1TYqYy7P0+/2ZviFP2uQzv19X6wftqn3k\nkaKUuqCU+qpS6jWl1KtKqf+Ut/83SqnbSqkf8H+//ME1t5FGGmmkkUZ+svJ+LM4SwG9ba7+nlJoH\n8JJS6iu873+y1v73D3shBWLlt7Z02nxkxc/uUxxitiTiKAK4CkJLK7TazFYjHK2RhoongS1KeTab\nuuLJ7qGsT82QuKWOIhcUF75LC+uuB1gXkxXmjCorZuOnSiES+DurLJHyicuSOhJp38ZYSVs94EEq\nj5SmwhKn3aRVhSqf1PaSlueWPRj66hxiDUr7osSnuoTpJtPgoK7q+IcRRqIgBUUpNQNvj1QI6BCz\nN4hqqKl98MCPifiHGBghAiSwPK3jAw6ZhYSRhaJfAIJKLQoZx9PrUk+OGiOPItZGLp7pWIKs8V4S\nF8utHLCjzQOjBQMzIM28x1bYQhrj4C6Bfu6tr2NrnSzNk4pihXub226cLK5SweFOEgMjjiXuUuzS\n2BIFV6gZvv0mP3OMvQ0C+BTcDysXzqJlyHLYvUPW48bpNkYLXFQ4XcFGRePu8z/z0wCA127fwJNc\nHnDIb2Vufh4f/zTt3+MC9dduvYekReN4yAWTk84coOl+589ShaNxUaLg2CaYDKWykSsiH1uFbuLT\nswBgc3cPaUzX2eMUm+d/8z/EEifyj9p0nU7RhS2ZGekBceujrJe6MVSX5lRUNddQJrAkfWqJAL96\nTAixv78LyzFhxudAx9p9h1EUORaxbLjrtsXcZ4qtx8pqjDnWWGZ0vXFVYoXTUURCblxJ4TKmQDlV\nGm1nNJrAX7jyZCNOE8wy57VwPMwmJGnxfQhbs41F5uLjyAdNgPDIC6e19i6Au/y7r5R6HcC5R7mW\nApCiAqwN0J3cOcHE7MjSrZ0IGou7QvAVkYJz9U4MXnC9Pee31O5Fu9I+dhZtCR35cj/Ob4KghiUC\nFJzkeWp3vsvZ0oBx7j53cXdthzCdqCfHt7Bqxq2sAAy4HJPWHombtGgy03GFghf0UqgCyxJt2R+4\nQ9xCAf/RTw+2KJ51UISL5QT7T3DqJHfR1PmBu3R60SV03RQtntHefTu9gPI/fB7o5HYgeGZESKZK\nqU0s3g7caGeu9CgfIV3FK13UBgMtJOPMOKWMQcRjP+UFoRMAhqIBLXjD4QjqgNz0pzop5lYImNNL\nlul6aYp0nhajgyG53vr9PfRzOqcyNB7SBIg5hDFmkvZurDyWisE6yaDCXIvdvHuMiDwToZXSQl5k\nY8cK02cAUjftIOcB3JqndpXWImbS9js3yZX8wzd/hF0OOSysUKGDdqeHit2CvY6EICIombid+9+g\nFISmCb6/TNqQYIfdgaeuXgEA/PRPfQopI3vXt0n5qHSMeIpmsY44/bCyVXUuxbrfclwe1KjVwTfg\ncnMdYto6N/zwOoG9FlsplphmLO/Tgrc8P4erV54EAJw5teYU4DtX6D2vr6/jJpctFBandjfF4hwt\nkkKFNxiNncLl5x4PNjLBPDmNNqfQDs8fh5Xek/mdt9Wyt6F+rhCJaq79IPlgHbUfEDhIKXUJwKcA\nfJs3/SOl1CtKqd9VSi1/EPdopJFGGmmkkcdB3jc4SCk1B+BfA/jPrLX7Sql/DuCfgBb5fwLgfwDw\nD2rO+y0AvwUA7bU1JJwrKa5aB2Wmsq0AMOOCo+sYxGzW68DNq41YUKLpefegnnKbhL8PY4+xU9ts\nENy3KrAWXc6Y17nkXB3oUspF9ZUDsTg3aWDkOE0XcLmPHlSg4Oo7W+tcy5IqEuZDCXCo3W57K1zg\n5oE6VqcpikSBllxrddWkm4Rctdptq5dpsI48w+T9DDS76xzoR1mf+qn8HdSReqFxrvHpe4W/6xiU\n6gjgHyRKezi8T0WqXBFpSUmKTYmYPStxTt6EThyjLYihAW3bvXsLHW7u6uoJdAp2o26Tdbm/1cd9\ntqaGGbnpM1NgzJfJJVSAyuXjlcxVGyXKAdE0s/tElUWHx2lHPGX9ERZ5AFa5RcL9frBBrtz502vY\nY2ahHhdfT9ttXGJ2sDv36bj23CL271LOZjJPFtIgL9BikvE253FWpYLhvnEpJpWBKqQounWsTPOc\n571x67or0v4LP/uzAIAnLp7H3T7deyRgq+VVZ+WF7z4MQ4T7wt/TnMp1Y2f6eymSwOLkwxLrQV4J\nP0dSAS0eOqfmiNmp2j9Ah9mUnr5MVuYnnn0G508w8AYAp7bjbUqPRavVwl6fNo45P9aUlUsLEQ+d\nqirE4kYNHDqSKqacNy4Au7HEcexBPRaOj9vNg8YAU+7dKI59elbNlGKmprzwej9JeV8Wp1IqAS2a\n/7e19v8FAGvtPWttZSlQ878D+Ezdudba37HWvmCtfSFZWKw7pJFGGmmkkUYeO3lki1ORCvV/Anjd\nWvs/BtvPcPwTAP49AD984LW4IRZBnEtg+rA+7SMoYhs5C9BbVT5OR/+T33Qd5dQWD+v22xxrhVLO\n6rI1VqiDtMMSigcUA5jeX0U+xuksU6iJArWuLRLXEHBTwF/rcCTWEEIoaL8K2misReViwV4TjAVG\nztZVrCMYDq6LhWetddqhqwpiZ0EQoaU1HW/lk2esTmVnY5cagRaKWbFB4W8Xr5zQ6CfTTaxW7mGU\nDQFKYTL8bNxToPX+vgGbkuvDIKbl+D8Ps5kPl7CgsMCltKkQcb9HDHaLTYUWxx8jBnvNK2CJ038K\njjOPyhwptzHKBxhscqWKd4h84N7mOrZ2CQyT872jbuJSn2Q8JEohkhJdDI6JWhHSNqeh8D1UqqHE\nSuI8hG6W4VRC8XKrIhgG9uzeIqBS2yj84FsvAwDWb5OV8+nPfgYpA4GWl8gcOnfuHHaZA7WCAEnG\nWF7jMns5xfHKokCRSdUdtnRL66qaRFYhdVy2/B5zgxc+81N0709+AgCwvbeLpYuX6R10yKq9tr2D\nOa4E86DycXXl6OrkKECR0SHViqQk+blH5qMEBi0594A8B5dW1vD802S1f+JJskI7CsioC1EOLJb5\nHX3z5nsAgP29A4ylLCEDqEpTAezViBhA1ev1MBgNJ9qglHWWpiMzsIEHhSepWAcWpwlTrfi7qXw6\nkevjAGbgqrvUdOcEZuIDBvo8irwfV+0XAPw9AH+tlPoBb/vHAH5TKfU8aI66BuA/fpiLEZLS+yid\na0Qr+Gk2GGpuUdNBHiH/jSJYWWSCxUaXU4HrYEGUYR1Z5a8dAGWmEaY6ZA7CFEUbABUnHgAU+BEd\nobFcx1rXnjhKuS2Fc90Zx9ADtyBKyR2tFUY8qRBqjifDyDMIOdc3u2SKwlPzuWXQBCWJ3OIwC4Ko\natg3QrJ2pZRPqVW+XwKA4IwcBRyi+3u0rGwL3bYAA4ZCt63kdE7cb9J9q1A/4U276X076vc9rBTK\n5406UnZroDk3OeH30zIFWrwQdPk+i0pjmYsI6HmitTPzPeTMErR37zbefoMWqOiAIAWdSmGtQ8dm\nXMPyIM+QVwIAov5cmJ9H0aeJ0uUtqwpaFltOl86Q46BgV5+mCXilHCNlP+MojbDPxRh27tPCmWUj\nvPraGwCA7T4t6D/zcz+Pt94kUNDGBi2mg/0+WjzR77ELdWluDqeWaFHbvM7HjXOMOCcTSvK4tSN+\nb8cRuswy1mM374n5HipGjP5v/+x/AQDcT1v4j/6r/5qOWyZXZ7eV1L7Xabd8HZNU6J4FJoFE09vc\nOZgEBR0lMnt84WeJzens0jJOE6kSxGue838AcO3uTbz91o8AAN+L6d0mSQsx56xGDLYyeYViSlFM\ntBX93AMmlXWMTFZAbLD++xLlCn7OhPV5oxM0nk7nEAPCP+eRC2a4cD4G4KD3g6r9Ourf+R89enMa\naaSRRhpp5PGWx4I5iFSVCKHFKZaMgXK8jSYIyU4Ad5y1JzmSkbM0q8BSjJ215924oiF5vkgVEHp4\nl2jkik0LaMm669ig0rBLn4h8Uom4wshFN2n1aigPahJidGOdy8oF0611vLTiNtEKiDm1hNyaDKII\nQD/uWQXYoy3yMZP2Oo03ZOoQSx0zYm01q20bO0HU7nccTysMb3e0+zaa1d6PdasARTSNRgjYi6Lg\n3U6XenoUGcFCi+vKeQ4qRJXkINLftKzQYutzmS2DlTTBggN5kdVQLnRxd5csu/U7N3DrGlkYp+c/\nDgDIizHEHonZmpuLYxRcskw+/E5ROpewEMnHWQar2RLm48pRHztsrRbs6r+T3XO+tlGeYVjQ/jFb\n0cVogLs7zFu7QrmkS6sncOcesQ25fDxb4cwqWcoXmAf30qWLKEuyoe78iHmpsxwVk7Hr2OcsJpqe\nppu2MN8mSzPjNK3VxUX0WmSdqj1K5fnM5z6Hi2eJ0ejlG9cAAFWcAK3ZsoMu1zma3ScybVlOF0yo\nS2tpGRUUrRbvk0+1sIHVl/OB93LyxXajBXR5TtnkaeLaO9dw6xo9y8H+rssFThZW3HM4jlo+R+vK\ncShLTmZZ5jDCiQ0/12Eit5pCRy5DWz7e0s9vMNZt9k5p7cJbIsoGACDpQxwCFJJzHgNXbcNV20gj\njTTSSCPHkMfD4oSC0XpCW6vEetIKpuL0g8hrbVr7OJ5YnFZ7i1O2RQGTRVv88yFkWqyJABTj4n2i\nCdalqNA/3BNoTO6fiJ86zTL26TGBj1+C3S5Wq7UzNH0ZMgs1lT+iLdBhcENVVV6DZyumCp4/4rhn\nHMcostw/Az+f3Fs03kjVMOaUOaYlPKau2kyYjuLASA9QGEMNfvp6ZPVKEWO/TeJcIbOQT9+pv890\nzLYuPaku9eRReC9LVbnYpnAbaRgIqYezPE2FhGOcK10CxyymMRK25hK25loayIdcDmznvis6vDEi\npphhNnR8p50eeSXarQSJ2JDsdVDjAvMcR+9KdZ2icikeMVtrWZYhG5DFk7AlvJ7dc+83itvoWwY1\ndSm2WsYRDAOKrnz0GQDA2cuXMeD0mMVFAgnt76xDMzjqU58g/tonL13Al7/yx9QGjs3FsUEs348U\neI9StPi777Ra6LTZA8MkEsPxCLuclhMxwOriubPY3aFtO1vE47t08QmMpsZDSAJSxyQVst+EFuV0\nMfjp/QAQB+Q30yAhAKg4GGg0HLHEi29S9Zqv/fW30WXw1vIyZyRYg62CnmlsDpAwwUMm1VaqyrGa\nybeSxrGrPJUE6TZDxzIWgOICDAFtC8FB/Gy554zWataijrTGtK1WweMrqiNinCFw9HGwOB+LhVNM\ncws4N4E1kqCoYBioUIU2vQ6om9wiKmV3Irdfi89RKWC6RFXwAgSla8PgfwAKqQUO8N+q5ppWBQha\nSLOV+4dM6irY7ydp5UsAyRYTuEsCOqqcmYG01o54XXHemzLW5XTKoloWngpQ2hcF4Cdh04nULCCq\nOiQD000ganZbzqTPxxH5kEKqrw/jY5lGR9ZNiiGr0mHnPZzMAqus9ZOGaEo6AGrNcS7lXBKh4MXG\nMAOUKXKMmBGoGI/RYTL2+xW5KON2gk5XFkxWPPMM+ZAAPkIQ34li9BhRucSUbGU1cvmSXUbN7puR\nK9XX7dC2ZLmF0ZAWYN3SyJj8vc0MQ1lZIOcxM8+u2NWTa1hfZ7QsUx6OBkPkA5r0T698HgBwankR\n6+8RIrTdJiRMZTyCU2mh2YwRa68Uprz4S55nmsaI2X27z+9tf2cXC3ukYJw7Qy7b3SxDpSaLJBxG\nwejQ7/JdVNXEwlg3qQaIrwAAIABJREFUVo9aON0xwWkOvRpEFDL+1lsLbezxeLq9eQsAUJYFWh16\nj8laD0NInV5G0EO5OrDias9GOWA88xhAFJ9e+efGKAWENJEQIJkbvPT/xtfZBZSbj6PwW5JZU8I7\nZVm7YD7u0rhqG2mkkUYaaeQY8lhYnMpSYV5AzdQ8ttDeGmQjlLQ6OrCqSudClPJXqUqRCFAoKH5d\nsjUr1pcpjAO2JAnD25WCYe1KoNp5WTp+USm1paz11dqD7S12iZo4w26fwAiW7ze/0MHqPGnPO0x+\nvdabg9kjl9v5ZdJ+7965hQurlON2wOfG823EbEEI+GJrZw/b80LyTiwjAJAYrw85K5C7I62AWFIy\n+LgCQMb7c670blA5MJWkIO6uDNFlA3KhoOft5j4dII80RgxEybmvO60laObTTPbobydXSNiFV7I1\ntBdVOGAwy/35U3RcNcaJiiytZZf7GGNsyRXYZ17WorOAcUnWV8vsYq4g8MlcScCUuMqhNfWTSan0\nlUnmEQlriljSgVGo3D8C4Af3ZRJF7rezPbWeAK/5AUzb5qIWKk6laLFHYK4bIR4zq88muQwxzNCW\nscsvpRPPYcBjZHn+NADgYLyLV96lbWOzjPuavoENdtEtdTpoM4F5jy2uYmMDa5yr2B7T8fNKocvv\nWZiIbKuD4ZD257vMXhS10E7YBTugA5+On8S93Xt0ThphMSZLsmQTYn1/Gwv8/IMtAjJdf+8tV6z+\na3/2p+AT8PSTnwIArJ6hAtMvfucVHGT0fnNXesrg5Apv429gYW4eJZPFL8YJyvtkSXZzJriP51EV\n1I/VkMbDK7//r7AwT/tPPU8uZFuOsLX2PPUN9xeqBFUmbmx69jhtYX9A96gYaJV0NQrxZkWAYgu4\nGFE/HOwVgKX5pdumcaiTEUQc+X9QkD2qmZrjRNrlLdflhPrcxp41yY79mJVSaXS8hDP4uMjChrRh\nLFLo3ouCTCCK/9ZZXGywu/uJUV0G26Z5w0pVwX14jpK8Po1HuXOCG03JYSlAQnr/sIXnHySPxcIJ\nFcT3HNVesCgFSf7ApAvFBlRzoTtl2r1G151GhlnI6wg77yhUnMQ1qymknJ0KpJlhhp50L1OaxXmF\nfJcnAXZxzfeW0OVqBLffIGTkuz98HQfLhEJ89hn6sGMd4drb5LrqLhGh91Kksc/aRAT/MsMnn/aC\nKAWfy8g7tfbkdLFMntpXZRA8Ya/ouvp+ko9llA5ivdohMxM5t/Rv0qactK4NFC+wVSJI08ohS+e5\nMa0yR1qOuV1c8UUnbhzonK5RlLlrkDWZq2MpPREnHRjN1SJ4chmPMyw4kveaOGyQw+ZEYjHWuN8T\n00DgYnY970LU1q2lEncejUbYuXkDALB9jd7tMiyiJVrch8u0SKiFBcyzwiUvajAYYDAgt2sRtFEq\n5ByUJZZ5EV3k3M+nn/wsfvULRDv33T+hQkZ3f/QOujxxJ/x3PBgj45zMgnMg40ShPUeKW8TX3TeV\nC4kUeeWQoEXhe0VqMe7uUH7mN77xDfdtZqy4qNLg9Tcp3zNhN+i9u+sYcdy2xTHtTqsNJTVI+bjK\nAHMrhBzd39nD6gnqs4jRt09fvYrf/9KXAAAnn3yC22/x/T+jeqO/+gRtu7A4j3WuHGMyqd+ZAoae\nVUgB4iL3BSSEhD5pwVjq9+FohDErQ2lEY+78yhosX2fE93jYyfpBx9XljB7n/Pd7/GEyndt61Lbp\nez8oLFN3zoOOqwuvPGzFmzppXLWNNNJII400cgx5LCxOhVmLU1R1GyK6atCWtH8ygB9F0QywBQDU\njAvCX7LO4qwCsnRPtj5rhRpYTCssnVxB9BLBJxEQg7p8jt1enXGJHltB7Yg0+jv9ITbvvQUA6F64\nRMdBY/sN2hZfIJfuR555DvfF4rT+ZYYK2wzdnQ5I7h3qDUicNeQtJbHH5PjOuDvD2mF1yOIER/Sd\niKlVWLe/krJUbe3c5q7cV5C/mDL1W1KM0MvJ3d0pyVJPkwRpvMTPxhpqVWIsCINq7HL9xjJGEg3L\n+WMDdguNqhyduG74S45lsElNvlztyg4AzmNhjAdJQUMZAYkxY5NRSNidb1ye4xA7nOd47x65PPfH\nI2CLqPIidlH2jMFqj1x8kp+XFbkbf1kxwphBQ90ueSM+8/zz+I1f/RUAwBJ3zdluF+uvvUb3uU/3\neOvlV/DCcx8DACxyua+Vzhw6MY3FDW7fKK9gjZSoo/bnAZhqnGeI+JycEa1KKXSZwefuXQpN6FaC\nhQVqY8xgNsQWd28QyGX00vfoOSuDxXk6rrVPlmcFoGLQoGYmpaTdQhGJ2z/B3EVyZc+36Puy3Tmc\ne+oKvwPqr3RcIt0hq/DNP/wLAMDf/Y1fx484J3rMbt6qqKCYjUusX5uNkWrxulCf37h1HedOkZfg\nwtIyCtB1+gOxYPuIEnaRc43RvSqoj3tMy+dhrEv/e9Y6e5C78tGBePXWZN2166zLhzl+Wo5qa92c\nfti1GouzkUYaaaSRRj5EeSwsToIuT6Zu6EDT8IV/vUxYqBLzCnlpJcY5VRYoFKOUO9cEBVYlNi15\nfhTS9paFa5ezQtWMNrek2jCiefO2rkoQjUhLHXOsM4sGOMesKr15sqQOTpzCe6+/CQDov3cNALB4\n8QI6A9JS++9QPGzpylV04wXXN0GlMifVlGqkLBwjSFjGS5g/Q+ppsT5desR4DiWboVlCG/MIKLXk\nJwKJsOIYAViNYaX0VIeul8V+4MViZSJ2ZasKtnLm4zGWLD1z21J/xblBbsfcWLJMrV1AOyJrqbKA\nZiCG4vc3MgYFg57G3O4iVijsbNxDODknfBNTyqiqiZdMxF1qlGBj4TqyquRvgXmOP+I0FXAe3LmN\nG7fJ+jq4RYWLO6bC5TMEmJL46NbWFhRbWtr4VKRT58gb8Zu/9h/g3/ns5wAAPQYlfe9P/gS/+z//\ncwDAWbYEVzs9DO4TF+zqGYrJnTixjB6npmgeJBu7++iPqL8zjqPm7Z4D11VV5fOHpSxanKLN5b3u\n3KJnKnADvXnalktqjTG4u07vvA0uLxYDq6tkxT3bI6CcgUUnJWvOMIOSQYw9Luh99uIFRCuEF4gY\nhLPRP8CnvvAzAICXvvldAEC5sY8nFikueuvPycLVz/8cVs6RZbrPHo9BWUIz2M86MCIQS0H3IY2D\np06exZjzQe/fXEeHi3v3OtSGUpWouKyc5tQf2z7aynzQtqMspONcr277o1qcE56uB1iNdXnSdVZo\nrWVa84E9KD76sNb2w8pjsnCSHEqU/IHl+UyuLOH9XGURaLdgFlVA8yYfTtAuWWCtNTOdH2kNbR1h\nGV0vy7B+5yYA4P677wIAzvS6+NTpcwCA8TYhDy+fOokxTzTrb9ECema+g0vLtEi++sbrAID929fR\nYzSiVX7CDnPAnOc1cDcKOb0sDpE1iPnk2LFoBdUs+RpLlcJY9BG+Xp4ElIewiJmsIuZGqCp2i2zB\ngKAysa7qhmbX25xK0HMuMHLPnp9bwtl5moRavGLn2R72OKfx7gFNvMPBPpIWuejQWkTaIoCIiai/\nRlUGIxMXT4RREsNks4QOdRmaU57a2uHoHfMhItdLDI1E6MY4t9UagxVOYD/H6OjdThvrGbkFD+6S\n+/b1N97Axs3rfA5de3N7y1HSWUV1VgHg1CotCC984hPYuUeTeYvBPF/94z9GRygYx9SGS2tnkO8S\ncCeS/shGAC+OYOKFyOZIpaYoo4LzsoJih77WsVMuo4gJCzqJc8dKTyuloHh/2qW/VVVheYW+EQET\noTIY8Td5j9HpFy5ccMpOmyusXLtzC8tnSOm4cuUq7mzQM4/Yxb+ysIicAUyXrhCh+81xBbtPi+MZ\nHiOvfvmbiD5NLuseo2LHReGUAZ3IQl0i5TEkSvfo/hYYpItLpy7iI09R5ZITTOu3Oy7x7johvde3\nCJF7P9+GyHEn88PmyQ9qsX2UerN8FffrsMVvug11C+dh7XLXruPje1DLHrAoN67aRhpppJFGGvkQ\n5TGxOK2jpRKN3wQgHClv42BD00FfB9LxlqSr3B5qZEIcX+dSkFJU1jiLU/7qWLscKeOupyaAQmbK\nn7efFw4Eohiq3tL+3kIfeOfeHbxz/W0AwBNzpP1e/chlVPvEpPLyd78NANi8ewPLc+TiisH0ajff\nRefyTwMASk3/AXBpAVb7zEJpXaUtzBTRcgTNebR+QCQTdS1JWtEYJR/ARgN0ohyKyNqAjchVQ9Oo\nxNLkFILSGoBTFtKKLjivUiyxtXH5HLklnzjdxYUVslXaFadoDG/jPru5k5vk3hts72Fjh99VxwCL\n5PpuL3DuXbsLHbEFZanvRigmSqJNi+shq2f6obYc2VRC0vQxnThGhy2/gkd5CYuEwScrbHEuqYtY\n5jH2GpOS39+8h717km4j7lBD/QjgYHCAkt/wqWXqp26cYmGNrPXvfOnfAgDuXbuJq+cvUhvWybtR\n9AfOTQ92nVbDoWOkskzsrk0JycwzDBLKCo2Ynyltt1GwK7rNdHCtXg9DDld0+N3vbO85Jp9uj0uk\noUTC+aUJj4E8zx31242MLOLzi8/igN34HbaIdze28dOf/gwAYLm1gHd2yJOTsgt8OC4wZhDP2mny\nSuT9Efo36PkVf0vX37mG1nu3AQCnr16lfogt9iXnmwfEaDRES6xenhMunzqNZ0/QmP3IuXNYXabn\nE174tV6M+dXzdO1dskL/+rt/Kb3+SO7Dh3fVznrXHpTC8qiu2qgGiMQX9Numrn2YxTmd/jchD+Ls\nrJGj2JweRRqLs5FGGmmkkUaOIY+FxWmtt+4qZz0G1pxYaTXBZWOMA+yIxlNVlU+bcKklFaJoVk8w\nwtohhMwISZr5XtaichYp3HEuHcX6slwi+2WBiC0t4YtNOi2sXaR45sIcadZvf+dbeONHlPy9zGQH\n3fkzOH2GLIebq5T4vrFxA6dj0phPrDLw4d51nGXzMgdQieXnSrcH8TmJdWqg5LQQV2y6BFKXRuIJ\nDlzMlC2zoj2UfHCAmX90rCQHHspqVHxsxOkhSmvHf+v6OgN0zsxDYnEmc1jhFJ0zbIl0qxyjbU7y\nz/f4thWW+T2e4Nc5n41x4wbFjg7MAYqUACa9NQKVLJ5fQXqCwC5zHG9V5Qg66mJCAivb1uiUwhFs\nlYIOivfSPrjOnqWypjijZStJsWXXiiO0nbVO4z+JNVaY13Vhgd7z/c1Nl24iZNztbguJYgu2KJyn\n5hc/T0AYm+VgTm986ff/kH7kJba3yIr9yBpZSKbfx3hnl9vtS2el3McSc1TZCBnz3O4wE1TRihEz\naXy323VlxdrCTtTt4WCPYnnLiwR829jZQsbxVcQMlMsylFK4XcqFtVpoc7rQmFNBrvV3oDk+vHmP\nMAAXz5zH6XmK6x7c3UaL3S49ZtkZDMdocfx3h8kcWidWcGKZnv/tH/wQAPHA3vn2SwCAJ89dAACc\n6vVQspVdBkXtJZ3mwim6xk+dfwLnGbR0oh2BP3sMOO55fXeE77xD5CY/fJeKeFtmQArlUdJE3i8B\nwvT+nyQBQggiOjIN5QHgobptDyrWcNznfiwWToSL1SMsnNPIWGOMo81DsE3I4MWXSZOjVDbnXcYv\nknI9qpdZg8q1/uVOd/w4slhZZLYXwxRRkUXSojYstakN95YXXKWKl77/HQDA6U6MKic31ck1mhSu\nvfsW+vvs1lukSeGNt97AZb5vpbyL1rj5TzmGH6EoNBFQCmuPkn1wiFZX9EB7wn1e49DvlA5VK4u0\nipSbKKxSsMIk43JqNWJuY1Rwv44KxCNq2AJP0IsR1YsEgN0N2rc5uo+Dnde4Q8mdvbZc4MQyTczF\nDk3kau8A5j65bze3drExpEm1c5JAI5fyK7iQ0CLam+c6k9UQBx1ZOAN3UVg7EOxad3VQvVgr1ItC\nOq58nc0JhYXdelphry9KAL3bhW4bc20GnTAL0GDQh2ZKuqUlWmw2tUXBBOtSNSdtJ0jZTdpqtdDu\n0rP80t/8BWpDWeEvv/JlAMDOBikSZxYWce82AY7KVXJnj0dj9OZonMbsYrUqQqHku5B8VCBjRiYh\nizPGwDAQqtvuYMxu3Q4jXtsB088i56HmZeGoB3c5X3WQjRGxy7rD95tfWkSHadIiHsQ/unUDT6zQ\nO715lxiX/tbn/x6Q0/6Ne+vocj/IpLG4sow7WxT2kMnzzNIqOpzv2tmmxW8rG+HNv/gGAODnP/8F\nAMDcpTbmRUFkFHJrrourVwl9+8k1WvzOA5BlMAGwc0B98vK7NGZfuv4u1it6f/EazwkBfuz9gIMe\n9pzjXPOR8zinQXQPyMGcvtfDMgdNOKIfMvfzYdG7DyuNq7aRRhpppJFGjiGPhcWplEKSJGSiiwVl\nA+tRStnUQK/DPE6pYm6MQcWQcSkzFEWR45sMq7pLiaDSVUL34CDjfJmxa5ezMo2BDdpYBRYy4NMD\nQslGIwxIKUeXyc3/P/beq1my7LwSW/v49Devv1V1y3VVV7U3ABoYECQBkCAIkhInOMMZjWZiJhQT\nmgcpQq9S6EG/QBF6FiU9cMRQiIzhUOQMODBD0AA08Gi0N+Xr1r11bfqTedzWw7f2zrymbFc3qhn5\nPVTeSnPOPvuYvdfa61vfZ155BWpHEMHr3/oWAOCvvvlN/PKnRfCwwnSFN3Z3sLoo9K1mGkJJF7j2\nnrgJLTx1FnOLgqp2iGiyeISqqadIsUeMDJoONvRph5sBuYGQBrVqIOHfQ1PmtFxFlhj3GKG9nFSj\nxPqMCQoMcxq6G5ecXKFBOs9l+gi6AwTsh7PLTMdYrmN9XfIWd64Lyt7cWEd7R9CjHopwY6bUxflT\nFMBEQukGiYuAqKO/3katIQKM3VsiAHl72ELeF5r7qeflda7u4iZRTn9g/EMVXGP2b1JjlAtFFG2K\nA0RRZD1hrdOQAnLjqJOMEBF11Sn6qcBFzvy/Uk3anyYxblwRMcv1t4Wun/V9+H3BdDfeFrTda7Wx\nQBcdg2rjOLa0pe96WJwXBHn5bUlfOrd6CrfXpD9n6tLHra1t1I2vK/OJB8MEfWJIVTKpIH1EDUFu\nmoUF+u0cDVLfmukhu60EeY8lqrIRKjxWs0ySDPqYrcp7A/bdwA+Rsz/3tiRFIwUwZ7ZNBmJrawsR\nUV5MtI04QWtXKPsvfeHLcmyzTRQ8F2G5gowpLm0ivGIYo00k7LMU2U4WI+nJfbry9JMAgObxY2j9\n1d8BAP76P3wVAPCb/8N/hxYR82gk+1g6fsw+Pzb7rJta8dDpyec7N27gJgs4rHWFAt9ROYZlljsj\nFe07/nipZ5IpO1DLc/JZZ54pk+LHyW0cVf/TD2kM/wBxsE7t/ccdxEb7/j6AJgt95Pfu+H1gIv1t\n4r0jaNc7edVOnYOmMY1pTGMa0/iI47FAnPcb9+S+74RI+XrQv1YpNUaVE0Wux1VW+EmeW7GI3Z6a\nmA25LtdBx5+HykFGr0qfazT1Uhl1pqH4XMfykgw1CgvOHRPhUPfKVWy8JyKCkIjm1MwcSimrhzRk\nFr+hHRRDWRsrBw6u3boq7aaopOR7iAxo5jGPXAdDx6x3yjHlev9alnk1qSdDCoL6bgU+Z8xeJigz\nzDOA65XwCjjGVYUinOGgg5qWDS0R3Z9cmUHdkWMuh1xvTW5h0Lkix7Uj7b91O0Z7j/2aSiP2nBxp\nIikJyzOcdWc+OpuCRIatLnxX+jYnMu+OdrDhy2+OlWUttHq8hiKS9a3IeJ1OuB+4pjwcFBK6GzlG\n5FRoKM8UWidDkmUWpYahjzwXBLK1JQn5t7f27NqYSUHxSz5W6lJGa0CUEmU5XKKzE8dXAABr/QF2\n6EwTetIPzz73HK5cuwoA6HW6+Pw/+0UAwKeefUH2u76By+9TiELTA79UtgKna7cFjf+Lf/rb+Ntv\ni19rzgLVT5w/ix+//lMAQMeUPXNdy+iUZmRFbynyxsWctUZKVqPFEmnadeATsVa4njwMS9CsFpTQ\nvWers4fbt+T4Ddapz87g5InVfcdUDSLUPLryuIKOs3iEjW05lt1hjJDuWznXa2NPI+b91xoIUu72\nezg9J6zE8rwg3SzLMM814+GerIluX76M2vkz3Lbcy7dvXMfaDTExmSHTcskL4MVyH+aDAQapfLfH\n+2xQCpCw0HhGsZXbObwmN1lIfdIZ7X7Q0FEim4eNh3YO+oj2dVRvHCUsMv+/23cfth2PzcB50HLP\nDEpKqfEAda8DPQKu23xOpayjif0OxvZzJsdTFS4UL3jXNQ5CGpq39P4q7YbOO9yWauEiZQ5bZMoi\nFQ76fADu3hYabbUU4QIdRuZO0dlkt4vhttA8DdJfK+UGdm/Jb4+xDFlNK1zfFAqzGr6EiGXvq6TZ\nil4MZ8A28IlUqXgYsE+GtrXOob9ypawoyFC1Q91ASPVQXZk8vyEyUsMq1Ig8cx6Zw1okaHCQOVkV\navVTx05inpZo3a4MeJc2bmI4EMHHxs4pAMDNnR5aezL4KSqZ3LRAa5f5mwtyHAuNOTQbQn9Wy7k9\nL0YZqvIM8W2hBUfr3E5pDsmc1PCs1+Vhmzq2YhRCUrbDVEOb0mYUqxR6TEWbSy5DOlai+j7ivvRP\nuy1tvfK972O5Kfsxlm0zzSrOXTgvx0/HnyjLUWLZuISm49fffMcanv/Wf/mbAIBms2mN01Ve4Lf/\n4W/J37zG/+QP/whrN4TmPrUs19ftvTZy0rs7VJhuFwUcUvzr7Ne6Bt7n30akd/HZF/DjV38ifWev\n9wyKg7I3IU6bpPsDLoEYa8WK4yIsy3WwyEFrUKRo087P0Nmrp0/h3AVx4DnpiaBGaaDTkcFvbU9E\nTsM0w0DxWpstw52TfjKuRFeuX0GXwqvFWblGolxhxAlBty33Weg4ePEZUbX/9Po1AMDG1St47jmZ\n2OxRMZwUGiMqnHVJBvGduA+PwinHd5F6cp0MqRDrAWhz4B3x9biu42Dsswo9IqwF6CPOv3xU8VHt\n/27q4oOD5oN890FiStVOYxrTmMY0pvEA8ZggzrHJO46YDUxSqybMzGxyIdzEJL0xiTg9d//h6onf\nan3E/ogq8ng0pgeMaMRx97frQBsj7cJh+kvA6YlKM8QtmTG36SNaK5cwoBH2Yllm1vncAja2hC4q\nN4lEKnUMWzI7NjRVWLgY0d+2c/smZk/O8cBkdjyK+2homf1GpIOR5egQBRiG1dUThacp4y8cxzoR\njYg802EAvzDnh0KSQiM3tLPjIiQyLDhDr7oRTszIMZysyutCo4GZQNpl0CqKBEUi22nHgnYGeYoe\nXeqzhPsbhhixGLCrY37WQ8B0B3hb6CeCJB0Ko0qeh5zCsMGWIJW4lGIwK+kQs3Rscl0PBO2IiNyy\nPLN5uEZINjmTVbwOfd+Ho8y1phGw7FVjRs7pxdOnEJhr27jRxEOEJv2C6EXFA8ywvJciU9He2UaN\nIo86Uftff/s72GWaxcmV41hi6s0eUeaNq9cwy+IBnYH009ruDrr0pY1Iy/7d+++hz89vkvK8+eoQ\nO4aCJsr5/JNPYe8HP2b7BbWWvQIJlw90rm3/lImUHcdBSqSZdIQin2024RK5+/xeySmhTDchl/0Q\neQHWrwkDEe8wzaVehSlRboRtpbkZlOln3C4yxHTFHVHwVfIClBtyLo7xXqo4Pvqbci+1tqUP5xoz\nqNcochvK9fPWqz/G01/8vBwLr4FqtQpd8tiHci76eW5znR03sGlexlnMQwHr6W6EjsPDaGiSqp18\nNX8bKhw4jJAm0eoHTS15WOR4FPP2YURxj/3cb1rLB4kp4pzGNKYxjWlM4wHi8UCc6jCqtGudSu37\nGwf+nkR7mDRNsE5A4/C9/cYGWmtb3NYWr95XMsoYJRxoLCS/+sB8cd/nw3yELDc1ITjzDBzMzDOV\nwnzWaeESRR6lJVnzKVUqSIkKg4iz81KEJ2moYBxltHIRslLIuz/6Hs4t/gIAoNURJFVJFOa4nqTo\n1vLuxg2ULojoYshj9wqNgEjTN+YPUFZUYjJVQp3DNf69Zk3YGyfBRxqIuHA6aMu6Ui0KMMtST3ok\nKO7qjV2E3F+P60+7WwUGbfm8F99iH8dIjMCCyNNVVbhcT9rsyG+T0bYtX9UrYuiKIJnmouy3FNTQ\n3djisUr7vFGKFo0BlhckRaVcq9v1dGq4pKoJ0xjMq3aUFf8o67ATQvG9okhQIjJcWJDzfXp+1Rar\nNiYYUeDbSinLC4IOuxubqDENY3ND2rc4N486Efr3vyvexT/+4Q8wR/efl196CT/4W3n/W7/3R9Jf\ng4Fdt2+zj/1GAyldeIxv8Nu724i5vtjmuV3b2kajJtfaoCfo6731LYxYqNqYDAR5G2kqHZUWCQqT\n0kUmQGllS6hlxvs2CjEg+u9SELQXxwBTYeZWRBDV73Ww0xLm4dk58detz88i5Lltc925k8bIugnb\nkNu0sCER5wtnnkDOqi9ba7I/lOuY5X0x4rEXRYbco3sTU0dubW+g4Jqkp+S9snYRE312iKKHaQI9\nwTZYT2xjqeX5KPHvkjI6iw4eNO7XSGDf2t0D7+UDIM6HqKryME5FR6WofNTxeAycOIKOnYTb96Bv\nD3a91uManpOU7UH6NssKZHwIj3M3NQq13xrddV2rOjVRTGxbw7EUjIl2kcCntZ0yNSwdjXJVbvy6\nJ9Ra1CihxAdbi/lqJ48t4/zLzwEASlQl9lotVCli2aWSNg19eKSVOrdvocJpQsqBrKFddK5eBQDc\nooH1m+s38fIZljHzTD1HIGDzffKzmRobx5kjq+kOTIk0qyoNRlA+jdjdECHzA7s0YM9LFXRYU7M1\nEJqwu9eFQ6WtwwGx106wdVMGh3ZH2jwqPCQ06Da0so8IKpeHrMe6ib6f4ea6KB0Tx0Njnobpx9nH\naoRhS7ZtaMRapYKWKUF1XGi7eqUO4x+oSUG62kHEQWuSni2KMWUvbVDWLihLU0vV1jnZWYkCbNyU\nNjqcwIVuiCEcZTRQAAAgAElEQVRrSc5U5Hud9CY6LTnmn/5ILODmmrOYZz7ku2++bd/rU1jVbbXx\np1+V3MPX/04G0Gq9gZTtWTklYitkCVYouGkN5Lr54eUrOH36NPubOaL9gb0H/KpMPr7/1ntQZU6A\nmKPa3bxqRVSVUmQnG3mSsx8yuJyclb2xM1CFdKypIeoGPqqzcm3PH5drs1yvIqENHzg460aIHiec\nm325vkZ5YbcT+QFmAhnUz9RkElptjXDjKkv5XRHVdumJM5g/K8dsRH95oKxI7OR56a/1N9+3E5uI\n+xjkGQLeFyMWKvCiCAmFgFmej0U8pKm9xLWTLjO2ZEcMTkVR3HXQutfAedRv84cYOT/KgbMoint/\n6UBMDpyPgpa9k4jobjGlaqcxjWlMYxrTeIB4bBCniTFVezgdRR31vYmZ1uTk6ihx0EFXjrTIrRvM\nJOI0fquTDkM2z9GiTA1thDR6UmTE18iF9vYjziwfIWaR4jrrblXn6phblLy4lE4v1eOLOPuE0FM3\n3xVnoF5nD0PSU9s9QUhJKUCNCDGMfMR7gqDqFEEsOiVcuSROMu9+X/LyhqGHMqehfWPErpWlagNS\ntQnUuEwQZ5JNtYcByzC5nEEjLOClBnF68PYo218TurjnZbi2JxTZLeZa7vUSlEtyzBF9fHW3QGeL\n9Fn6hrS1iJAWNBln/mJR+IhjaVedaHx5dR7dTFBtGAZImEa0N5R+8osROn1BWCOa7eaZRmdb2tjZ\nle8tL52AT0enmNSi44YIKczJrHuUtqlNyjEpAoWlbSM3grkaW0yfyFHFEv1hW0SKOsvRZZmsIRHg\n3s4OblMEduKElKKaC0tok2oOKaxZWFjA5auCoJQGyGjj17/yawCA199+GzduS79vMi/xxs42VufE\nKadBhNe7ehV95lWmzLXsxyOEFJM5vHh3+n0EpsDzQM73oufAD1y2y7fF0HOyErlWY+9jItjdrU2U\nGoJcjXG65yjkQ9nmLaJCFUWY49JFXJW+7qcd+5uAucwL1RpC47PcHiKkm88i++PqG69h55bcV2B+\n5WhmBsVJ6VtF9LyXxtAU5I3Icux19tBiOpFuyHU42Osg47KAIuUeDxMrpCtQwKGPsc/XQIUIeR17\nZFpaTg8mJp8dBx2BjspJB45GWEcxcg8B6B46PiohkhkPjkKK90pBedh9Howp4pzGNKYxjWlM4wHi\nsUCcCofXNu/5m/t1EZr4/hiFynv5xHpENunPqPbPJ1zPGxfYNj+eTHk5AnGqio8B/VxHFBOUHA2H\n1TDSkcyMu1kC1mBGjeufsVOguiSikv67TKyulaBYrWRI1xFdCrAS0nu0UsLrP5F0gfPPidPKheNP\nImQHBFxrOre6agUyrqnmUbi28LRBLm5xuDhW2RkgASuSuJHtVzfgWg4KOKx8kZpyYK6L2zJpx6V1\nGhcgwhzRV5DIJajaGbK2IDunJOhRF4VN9whLsgZYjHKMjHcn0wFWz57GzLJ8fnvQw82u/L7HteAS\ncov+A65xel6AUSxocNTn/vICnilNxzVO5QIB0a5hJ4pCw/dtLTX7WRgYoZCHlPve3RUUs5n30JwX\nlL3DFCKdBWMfUq6j1ut19Jlu02AS/2ypjPdfE99an6Ke1u6uLdXlaODKJfG8bS6KiUY5iixSfu11\n+e38yVXsdZmqw3O/eOIErm9Je5p1aV+iFCpN+dsIqEpeiG5P+sklsnzqqacwMFVdWh2bJjS5Pmyd\nlaglKIcRfKLYlGuYgetbsdkWU2xyV6HJNhRMNeqrHCMyNi7v0XIaoUQU5+cF6oX8ffm7YtbQvrWJ\nBXr1mnShnZvrWLogLk7estw/G9dv4b3LwnT4kVxLrc6ebf8MjUja3XhcP4fXZjIaIbM30ERFIrNE\nmw2huVZqjDzUojr0zLiXV+1RaXlHxc/KCOGj3u+dKqvczS1o8rsfJB6LgROQHKSiKMZlwAx1WhTW\nqcTjzaI8x95AynVs/pgZ+rI0HTv80N7M8X30kgPmxZ4Pnw/F/Z5C+yNJEnuzmIpdDtT4P3APnYxe\nEqAJeUg3eCOVkwwZTdCHtJzbrDrYpJCkYugsx8eNG/JAGrRkz/OjEHlbBD7zQ1Hz5ck2Gqsi9mik\nMZzXpYxRdE3EELNf+ALKWn7T0ZLf98onvoKAR5ulFKQEEdabsp+RS7WvEwNK+nixkJt+LTuFBQpb\n6nxIZv4Au6FQixsqQSng8fVYP7MVQ9dE/ak5aOnGDN7bJS1Nya4zTOCXjas8lZqtdcyQMkyLqwCA\ndreDuRl5EF6+LQ/Z5Ac9/PpXvgQAmElivEJ7s1d/IKbdb73+EyzTjSdlv6+lEUrvCFWbHOcDtRyh\nd0I+v7QhffjSsQZW2xwQLklfPn/8DC6xj5Ml6cP2TITLLWmP7/pYYNmqWVK6656DRMng6DWFgtze\n3kB/VyjYpylW6dcb+O5P3wIAvPglOaZ333oXf/OO2OctMC+07jmoU3zmDneh9uT8vnpJqP3l5WU8\ntyjfPVMWWrLdbiHZkGPWnMDNBR52PBkQS3yv0yywc10mYYHDOqalGhQrdqU0PO+eehbzdONxd3ag\nqUBtUS27fXMNVU4ITL6kpzTKnGilnGQVqkCDubRLofTNza0tvPbmq/K9NRF5vfzSC6hCttckrXys\nMoN12lPeunINOwO2bV0UzDNRBDeTY57jrLDpeOh9/2+lvynqcQY9XNylzeKsXJMDp4KyK9u7rWVy\nEZ+cQZcqqCGn02oUokyRW5Q5JtUbZjZahEDO0TQjtV9k++qKyXb02CDfiM7uRDEeyl0vJgSRE+97\n+jCpWNxlfNMT2z7qe5OWo4fes4WA7z8OurlNbu9O791r4LsXjf0w2zwYU6p2GtOYxjSmMY0HiA+M\nOJVSVwF0IYAv01p/Uik1C+D3AZwGcBXAP9Fa791pG4UuMBwO4Thj9OhQvl4UhaXI7GuaoERJe5yM\nrKOGkaXX63Wbj9ljHtre3h7mmssPe4x3/fyoBWm3mMh15EeFmviP/cydyEPl93JgSGonZ3900yEq\nFIZEjtBGUbeMLsUns/WKdYoZxjQyrzcwZA5bjYIhLwys+AmuMbN3xv68hqZWzliUxellFgJaG8cm\nnic/gE8UV/IcNOp0ipmji1EvxjbFKR3SdYUDOJnsb8T80qIfoxQwTaGQfSzMLeKZZ8Qr9KevvwYA\naFRr2NoWNFFlKkRvexvf/853AABf/IXPYtSTPvnyL31RtlMt4b23XgcAPHvxKQDAN7/+NeSQNs40\nBe14DpAwPeT8qoiz0lYX/bYc00pNqOHvfOevsEeh1tmVT0sbhrEtg+Vqx5ahqzJfsJxnKJhD6fN0\nJ0ojZnHr996VNJNzqyfxY9LAP/nhjwAAw8HI3hf1urR1oVLC+lVhGM4cW7KpFJ2tHtsARGRbXDoR\nIS/Qo6PTyCw+ZCkC7k+ZEk9FhoAuWybdxHXdMQXLa+SdN95E8xU5fqQ5SkQPi2fPyfHttbFNwZvP\nObrnu1B00ze+uUXhoLsnrEWP12vJ93Ds+BkAwLeuCKK8eXsNZ5fEd7fCdKidGzexe1OYgFG7i22a\n6ldppt5Hgl5i6HTZn5f5VtCWkS52+n3MHBev2jcoqmqeXkbIfFaT0wytEMekiyssUK/GbJjjOHa5\nw4ZTIDepGub2yotDFOxk3C/1eK/vPUyMKeH9bdm3XxyNhD9IPIpyXx/VPh4V4vyC1vpFrfUn+f//\nCcCfaa3PA/gz/n8a05jGNKYxjY99fFhrnL8J4PP8+3cB/AWA//FeP9onvZ54Dwf+1hMljKIoQpXJ\n4UOzxtJq2QoGBoUaocHDxJ0487vN9gIFuBSOGOo/V+PEZ1OwVysFl4ultgBwUSCmeMOtCIrZ20pR\npRuNz7VaNygh7nG9sxJZscLCIpF1EGCP4o2YCLwVx5ghwnBcU7zagakGZtsMB45tl7zXC3KMiPpD\nrg1BKeTKbC9AlXXMFP1pt999D1EqG18iIkt9B9tDmbUP+BoPEzisKuFmRLhZZh1bTh8Xt6PzTz6B\n26wKss51yCuX3sH3viNFwIOkh//iK1LkuEWnntWlJVxYFaTy59/6z9KfG9uImuJSAx7LQq2BIpK/\nPaZejAZDzFGY9Pp3/hoA8L0//zZWLgiqeoLpK8MsRsDr0EmBZEBkRzehvN/BHM0QHPZhyXXx7e/J\nWltnU9r6+Z//HL759a9Je+Zkve/ksZMos4SVMSs4d+I4domM0ixHpyvXgfHYVbqwyCc06NFzkRPN\nmyu6cByYk28MEJAVCInoKvS09bRCRpTqG6ZipHH9HUG9XqHhEZ11M0G9tbCE+qqYCXR2TdpNjIKV\ndXKee+15CGvSRs1121wBEdvw5HOyjr92/Qa8ASudnJaqMp3rN7F7+SoAIOBxA4BbYXUbpZESXSqy\nPL7nosp1fo9r7DN5bv15WzzOT7/yGQQUYMU023A8H4psiTE1yJ0cLkVJrjpEIKFwAOWatDgDOdUh\n1DgZdyqTZeJ+E/+Pctm5f4B4eB+PorLIvj3cJwL8IOuRD7vPu8WjGDg1gG8opTSA/11r/TsAlrTW\n9LfCBoClgz9SSv0bAP8GAEqLSwiCAEVR2AExnRAHHaxRF/qezWeLkxH6HByMQtb3fQT83HRInudw\nvUfniHGvum+hduAZQG/yOB2F3NjYUeHnOA5cDjzmIs8djYzV3oN5GYAG6wFSmpaDOYtxCjSM4rDV\nwfWbIhB54RMvAgB+8OpruG5EGVWZOMyuHkfKAbOgStdxx1SasSxztQOfakWTjJdHQxh91cgqchVG\nVAoOdSFPCQBlT9qatvdw4YwoPZ8/L6/vxQlGXT70CxlEhkphxAeXQyrPhcY6RR5nTovApRKGeO5p\nyUU8eUyO6RdfeQE3rskD/Fvf/Ab+XUuEHL/2KyKuWVmYR4l999zT4sgU9/q4UdCInpRb2SkQ0vAc\nNK5fLdew5MiA8CevSi7s5auXcfEXX2GfmKKtHsAHvVsA+UiuyUvvy+Ae9VtY/Qefkv3QMrHciPAf\nqWgtWM9xb2MDAR/cu6yZOVtr7HPHAYBGo4HjdNnp9PrY3BEBzMWAJbjyAilVsAX7WA8TqMzcI9Lu\nWuBDYb/dpF8UcEnzlkl56iRHAXPNynE2whI6m8xzHI2QBEK3Kt7DC/UqlhZlwnKTLjtrnR4CHkPK\n6147LiKK9AIObsMsR8HcznPPysCZ7u4i4wRhlzUxhxu3EXDCXK1WUJoVKrvLXMzE0chd417EwdIJ\nUOajr8Lr2VUOvronfbj41NPSl5/7OQwpbhqS4lbKtyIqUxjCVd4EVTu2a8zHqx72GaA4MVWOc2gQ\nOipn834HqDsNsA8zcN7XoHzERw9VW/MhBs6HiUc9GD+KgfNzWus1pdQigG8qpd4+0DitzNWy//3f\nAfA7ANB88sKjJbKnMY1pTGMa0/iQ4gMPnFpLvoPWelMp9UcAXgFwWym1orVeV0qtANi86zYwnm0d\ncuA5amFaa7Tbku6QYzzTMijU9307rUpI2aZp+kg9GI8qZTYZoR6X2dGucVRxkBmKll/3HBe+LQbM\nGTgK5DTS9nwR/Kj5WQwKpkXsyjH14gReIrPk0WhkBVNBRSjdn7z7HvaYOnDmOclbCxoz6DtjOsyE\nQR3MFICnHfhso6IgKAzz8ee5YQF8aFKPaaZQcBZuaLayp3FhVSjH2XOCkNZ+/BNkbUGSkSupJWkU\noMMUI52ODbOvronwY+mYbKM/7GN1dY79JYiqXgkQ+iLmOXvyn+OP/79/DwB4+x1BiH7wHGLmNM4v\nC/nx9PMvYPt9uSxfeu4puz+fYrIKzfUbULj8lqRm7KxLW5RX4MkXBJX0iFr9WhkxhSbVKILH/b1K\nr+D25Tdxmg5R51eFIu72Wog7gthKPBdbazexzEIABSGL77koMjnn79JJatBrQxH57bQ7cIkMc6Z4\nJIPY0vO+ccJKU2giJ01mQDuAS07XiJYi10VBSOEbxkZruNyeEQftrm3h7Gnp937esk5MS1wWUTmw\ncUP6LB0ZdykfnmNoYObtRhF80sltOigVykG9Kuj5+nXpwydXj6HUk+u5dUlKjulWB/NMNXIcoJPz\n+EwBMtezAqcSc4/9zAVPG4zMI/AjeGfkvDzzpV8GAHjLK7gdS3sSlyXH4hRgCTSdsD8Kz6JM+vVw\n2+NXrfaneHgTiNPEnVyCTEzmdt73s+whIMlBcdDRX7p/uvhu8VBU7UPv7S7b/CjTUZRSFaVUzfwN\n4FcAvA7gTwD8K37tXwH44w+yn2lMYxrTmMY0Hpf4oIhzCcAfccbhAfh/tNZfU0p9H8AfKKX+NYBr\nAP7J3Taii8PpKGqiaPChdJQix2DApO1qxSItE8Ph0K7XRFwrrFarGPRSPExMIs47rT0cnHX52Vgl\nkLOXM+UgK0xFEs7qHMcKYFwKUrI8RWZEEpGgx2BlEb01mWXnI/qjOr6V9vu+j2Oc/W+yWPaNnT0k\nRD5zZwRxtvMciW2PcSzJxgYPXGd0i8K6CblUN1VVggrnWg2HaCEoYQhzTDmUb0ozySx/YbGOiNVT\n0sGGtO/K6xhsCdKKZll5BC76LAWVKa7J5Sn2BvI95zVxgnn6/CoaTR5ALtfA9o09KKJxz3HwL//1\nvwAAXLp0BQDwV9/7G7zyKUmbePddWQu9fOUawPXAtRuS7jAfruKpFUm272yLY47fH2D7snwe09Rh\nfnkBS6dl7e71mIYCYQkpBUGuV8E803FCnlPEQ2zTM/WFM7JeGxcZnnlCzsvuxi3uo4VqxHVFPe5X\nIxy7yXXs9Zs3sbokbES/N0DTlAG7SVeiNLNFsst0WHI837r7jLiGmyYj5FzPDJluoz0fsanwQWEN\nsgKmDpFhJ3SaIeGa8Gx91nrG9ujFmw9jW7R7b1f6qdGoYzBkAXLZMlZWjmF2Wfo9X5drZK/bQ2oK\niO/KuqZXKTDaEwTYo4fsTOjDL7Hgd7tt19482qF4jmNNTsw91x9lGA5l24kvzE6zWsdLv/mb0p4X\nZB38xnCEba4Jawq/+oMExpjWFKr3lDMujqRh14KNjiHTBXLjoMRHiX9ENZM7Ic6HQXZ3+839bmby\ne4e2d9Qa50OU+7pTdZS7Mnof4lrq/cYHGji11pcBvHDE+zsAfukBt7XvwsFdFsy11lhaEsqtFw+w\nR6NsM8BVKhWUSVeaE9Pv9+HQueVB4yjz5IMU8iFVLZSlQjNTn891kPLmZek/KO1a9apR6Q3yEYYc\nrHoc3MLZObRvXpPfcnu15hzqFPDs9vu4TseWt1i+aiPL8eRnPwcAqC4JDRXMzGBvQGqV1GIBtS+H\nDwDcvIBrHlw8tmB3G2FMIY2h8rwaOryMcqWgyVnpirQ/mo+w0ZJ253RfaW1ftdZjxVAG+SQtrB2J\nyTGsVMumObh8QwbBGzfewruXZBB98RlRVp48PodKSEWr0li7LfTg3JJQhs+UXsDNLXkgf/v74iak\ntUISyQP+3/2/vwsAePZTL+PLXxZFrtuWB3TDK6HG/q6zFuTCk2egqKY1BjC5zqygLc5ilCtCH64s\ni8L5xncHtkzYPAVFF04uYWlOxF95V4Q1/XYbPvfX7bFWZA54pL4DQ8kmCXZpBl8vl+CGtPVhZFmG\nLOFEMTKCL2UpRTcbK767XTkHMxw43TBAQtvCLIltf5nRwTwgm80mrl+TgXx5YR4lDsDtDg3M61XM\n0+Vpl6KeYZEjJS2bMK93VGiUG9IPKzRQT9duYpcK2uMctG5cuo4+73VDIbuVEnq0thwM+1iYkwHY\noWDQ0yE8uh8VLvN+gxSjiAKn1dMAgOrZs4g+Jdl0XQrJbu/tALTr02bwVRlyXqfa9KEDaPZNocUJ\nCZio8asKWyAgN6I6Z/wsul9V7WTBioO/vdNE/oOoau/2PY0j6OIPyKE+SuXs3bb9IJ/dKabOQdOY\nxjSmMY1pPEA8Fl61SjkIw/Ce6SiGxnV9zzoCuYGP2dnZfdtL09SmqJhwHAcPUWeV7XsI5yCNcfFr\nQ9k6xUR5Mn5UjCkbg5jTIseASMbR0h9z5RApUaERVzQaTbz/QxGutOIBru4wNYDijIWz5/CpL0hK\nRss1/rQaCRFNZvmlDJ5pD1GmygurZDBo1NvYRjASirbEGXjoNBHSzbrvpkhIs8Ye00zCEVp7gvZ8\nRVToxahR/NQn4kzjBOWyUI+pQeCuQsYixseI3Ha2rmFzQ5D1D2I53u31BXzx84Ks52ZnACKZd955\nDwDw41ffwCqdgJaIvAeDAYakwzsdoRF/+Bd/joipDZ96+nnpy1ID65eEqjVW/6unVxHzvATMc2wV\nGVLut9vvIgvn2B45plI5tCKXv0wEfZ367X+IHaaj5BnLsY1iODC5lix/lyRWZ1IhkxLMNNBryfHP\nLy5Bc98BnYqQpba4wJCiK0cDmu8FdOaKoghbpD1NWTDf9dHhtRHT7chRPhybY22YCo0BxUavv/82\nZinmWaEAqxqVbeHp+ZOSh3v9xg3MLYrQCxQyrXXa8JkKMr8s52dWuWgRCac7IiRLW32UfbpL8dYa\nxCP4RGKhH6HEZY/Vk5Jn65eq8Oi2NOKSzpYqkDclP/MsU7cufuIlfCtlIXWWoEvLFdTn5fz16NBV\nqVeQsUBDFhPRFwUKcy9NIE6z5JBpbQtLGBr3YB74wTgqR/xObNed3jPteRTxYTkV3e82HjUCPbjN\nn0U6ygcOrQskSbKv8dZ674jRrtDaKmgLNc7fNOE4DvyjlLDFnSmRu71n2vIgEcJBzgHF1vxUua1w\n4pPW8nIPDteGjAK4UqmgMUPqjWt8g50de8wtUnQLjRnErMLR6nahAxnMYm7v9OppzNA4YGdPHtYp\npNYmAJSqpMUGQwxIpYWkykqlEt5/UzKL/u7bkvhfy9/H8wtMPM+Fwjr/ys/j2HkZlC4PuogaMpA0\nqXx959UYjWV5YCVgjcuoQIk0V4e1RUPVhM7lWBwmmxfDPupVJrKzykgFDj71gqwOPPmErBVurF/H\n7/4f/xcA4Fe//CU8/dSzAICvvS1GAnowwrW3ZPB74glp/6XdK/DYxYtNGhMUGjfflAoZak0GNDcF\nbjGXdH1HJgCr3T24rEOpadbgaKBSkomBn+bYbQkNfJ45gc1//Nv4g9/7twCAuSWZBFy+cmXCetFc\nFy4aDem7NBP7uMGosOv4KW3vtra2LM0bBAE0F886vIYiz0XI89yj0YCnC7F4BBB4Rv+pbA7l7qbs\nr7GyPK6SY3KLswTNGWlXh1TssMhQMqYOgQujINihKUecp/be0VQFZ6UIMfc3x2uz0mxixCf8W7TP\nu7W5hZ096cNTvMb73SFWFmQgm2U9zqzdw4kFGYj1YIQazd9vrsm5mj0RIJiV/d3mpLw7W8PJV2TA\nTFkl5Rub17FXlzxjzb7OoHF7TwZMY1yCeGSXGexEXgGqMM+bAjhgtq4KbQlTs07cHXRh4qjawgc/\nAx7d4HG39T49sc977e1eVO29Mg8e9r27AZk7DYb3+v1R48zdYkrVTmMa05jGNKbxAPFYIE4T+ymG\nO1MCP6t6cw8ShaPsBMzkc7qFg4JiH1N6SCllF/ALinXKUYScCtOAaFUNU2Qjea/ZIPU0iuGyCr32\nHCjmmhXMM5s9cRIdAwOIhnLXhxeMKWFAZmMlUo4RS39FQQlPXBDTa4M0uj/5KpIrQqnt0almuzqP\n5QVBHc2Kgu+SqtWCSsL5MuZoMJ/T2i59403EsSCQuYrkdqokRzIUVLlKJNzu7CCKhdqaYbv29tp4\n6weSn5kR1a0sNXHxjLT13Z++hxvviDiqty2fN8ISdrcFuY925L1zC8fwZiIqZY9ilaoXoEy6MjV5\nwtqBy5JQJdredbpde01W2NepUtCpcWJSyIn6Bzx/Z556GstnTgMA1ihUOndyGbe2BM1aC0NHoc/c\nQYsyixF6rKMZkRHwHBc9Cnj81RC/8pVfAwBcokXc9ctXsE2xWIMuTkvNps0ZbrV4/na2LWpMWd5u\nOIitYnTIEna+FyKOhQkw999mp4WEwpwsyyz961Dk5voOQlNKjr+JSmUkRJy3aKif9ocYkLbt8Lpv\n9wcYMp93pSbHVKvPIiPV3N6RtiyENVS00NMrJ09hSGq5ToP4K90WNqmImnlemIjFp88jWZRr8gbz\nqnv1OmJvP47QE7WzjGm/LFsYkZQJxxay1fowUlPKsbS7S2TqukfTs3dDaR+H556J+0XHd3q+3897\nP8uYIs5pTGMa05jGNB4gHhPEeQS3f/evP/aROUpMYAE49Hr1tbIiD99CzgKabxpRQeg6SCh+8uiE\nkvW6CI0HaE0QZ2fvCkDDdgSeRZwRUcfyqXNoU8jgVmVNcgQFj76no1gQi0IBn8h1yP0NWzFKvmzv\nGIssO8nzeH/tewCAZETE8u678JelPfUXV62zUL8rn2cqRZd5p8p4ufoOFuYpJJmTdcor6wOojuz7\nGFM9ylEAbfqEqMmv1LDblm1fe1/SXEb9AU6ckLzK06tNVInK/EJ+s7e5DZRYPoqCjrSfwDGG7rz2\nKpGHEsuldTZ3ud8QLvurVJHtbu3uICeSjJgG4ucFMubUOsqDZt8NCSTLcwt4/tOfBQB85+t/AgB4\n49JldPqCsGYoVCqHEVKmkbR5DSSJsnnLIfNyy+WyFXJVq1V88pOSSvFzL4qo6T9/9av4y6+LoX1v\nS5C86vZAt2Ob27hy7ATWWYA753WYFDlqzEM16S9eEGLE3BuztueVAxQmpXY0QkJE0KYYaVAUUK60\n23g0Kz9EQq1BzL5JCoXEpHgQ/cON4FBA9g5FYMerDdSITCOmcwROGe+9IalKnaUe9mgJ5Bxnib2l\nGVSeEW/j+qdfknafPI4tige36Icb1ZvQyQEtQ6Et82XWfNVEgsf4kVVYlJmrCQGg/aaGS6GdYZw8\nzzsyzW7SHci8mr897zF5XN8h7oQI73fN8oFETz/jeDzOhDrcKc5Exx38rHhkpksfXuSusjeOMRBw\nCm0HffumtfcAACAASURBVHOLOlDQvCs9Gm/rbISIA6xDIYbb6qLMBewSqcPtuIcR1Z255yDh54tG\ndDG3iFukahXzPVNouLkxPpDteK4Lj2KllLUGu3EPbQ6sfSoGz544jtVnxZ7OiURIsr1+G9dfk7qR\nn3iyjoDnpt8XqlNlI1y5JJShT9quWa1j9cQT/Fvy7ja338VsRRpbYbuay03s9YUq3O6IiEi7ChFV\nkl0ao791/RZaFM2Ubq6jWZdBeYZCkVpzHjlpvyGT70PPR8kz50cexk6eWdvDEbftVl2oQNoNDqqb\nm5uIO9I34ICuMo2CdR9d5UMZc3RObNZabZx/6WUAwO1NMTv49p/+e6zWaQDB3MGgFAF9OQdByMHe\nAfxFmhMYU3LfQZLSSCBN8c5bIuSKqrK9Zz/7WTTmZPD49n/6uvThlWuYIW1ubPhu3b6FkP3UpbI3\nywqMOED5HKjzAsgowlOkcav1CkYj0rOeiz77ts8lhaTft4NkagZGx0fmsM9YDQdBGQ6vDTcwVpMl\nKA6iMc9T248wImWtOCOpKYU8lPO9nSuMmHd5ifmen/jVX8SJL/wcAKBTlWPZiUdoZ8acpMx2lcYi\nHavqmfjbGNyryS/wE2c8uBWTlKIZbPU4n9LjAOr47qGBM8/zQzmbR9G3H3ZMCoXu+J0H2M6d/n8w\n7ncAfRxiStVOYxrTmMY0pvEA8VggToWxHNjmCZnPjlgUdpS6o1XT4xKJ54Is43iWqRWUyZwxaQiO\nCIkAoERKMO320ORMK6V9ntcbYIH032BLEEs67KObCDLKHM+im2Nnz9r3jIw+IyLLHKDAgfQdF1Cc\n1UcU5ijPR8KUkYQz/51SGfVzpwAATeZkBirDpT2hTOvDLgqKM5pmBg4Pu32a0vfktRqUUSa6TvuC\nDJLeOjzFck0B645Wy2MbQtqcZUGAwuO+HUFPzZk6BkzDOHPxAholQTSbN0T8s7vVwcwC67EO5bOd\nrR1U2N8Z0zXSeICClKmh1IJyhCHPT0IxVXu7hX6LohmKriIvHKctOb51qYlNP6Q5lmaFQn/5c5Jz\n+vYbP0J3W9IvZg1y9QMkmqIfotBur4PmjKDHTkvOt8oKmyqyMDePAWndHbC+KQCPuYonLwpLkCc5\nuhRUhZ5cnPPLK0h5rDGt8hKdocuSZGUiuE6vj4LHl/Dei/t9ex9mOjPGTyhIyxbOWBTkmtqVboiA\nZuuadncqLEN5RLb83ih3UVBI41Uk3SRRLrya/LarpB82/QgrT0re6Hp7Cxk/f/GLYlx26hc/BxwX\nGn9zTyjpbgb4JTku31xzqQsXxiDeOC2N00ecCYw1Nmw3zkDiHgTw+WVXYcxSjRbaFxNI5Q5pcJOp\nKR/HeND0kvut9bnvvUfT1A8UU8Q5jWlMYxrTmMYDxGOBOAEcmmndlef+GEzGMk/Z0lsGcfqFshNN\nI3XPlbLTF88zpt4FIq4nuVxzLGugyrnWNmfOo34LPTq3jJRCmb6gJ8+Ka8owLaBcmhwY41zlWCm8\n5tpenqcYjsZm8QDgVCK7NptS9HKjGmCxJigoqkhbZ+frSFxZYyonPaQjQWIlCly2d7qYdQVB7lLg\noosC231JyVBEkp6OQe0N+qEcU7/YA2bltxdekCLQpaVl7LKadsbSX6tnz2NxRUwFdJpgnqh5hukV\nP/3bv8Y3WGpsc0e8VU8sL8KHICzHrGsOBsi57ubRTMIvRWhR7JKYBUYFFFwDNOe2HlTsb+NE2zW9\nlGtjzcVl7HQFXZ+gP+qv/dY/wn/4vf9Tti1bRgKNPo3YQ26v3evCo/DLCJCQ5iizjUtLSzh9UpiA\nH3akX7s7W5jj+uQnfl7W+M6dPoMf0czi5pXLAMSHuD9iYXTjbRt6ANFlk+ukThhiwHYZV67RMIZi\nOocLZUuDZZ5hGzQUEaRm+52wipxrnNquL4YoXBZq4PcLeHZd0DACtwcDnJgR5qByTERlazubuDGQ\n9e82RnjhBREAPfHLXwAA9Eo+9nZYYJttqNdqSKlqykwKEVx4kONTE6yXY59DPKYJRGlhx1jzJwhb\n70eXSo+NJIwbV36EB/ck4nQnilx8bNY477Gm+fdpjfMxGTj//qlqc8eFkxvKhxZyeQHHuAmZO00p\nFEayx9daqYT8tjjXlPm9uSAESKWlrFkY99o2FzNxcpw6JnZli3xdS2EVob43dlpyDdXE3RZaI+Og\nYEyYskIj4eWhSb1thIBXlvfmWZGiyAdYnpMBO9/bgpvJwyde2+LrbUQ0PM87MjyUogAJhUcF64VW\nSw40n523edDNpSZWzoki8tjFZ6SL5hfRpA1f7AktV5mbx62O9E1QKWNE9e42HYgWPvksfmVOvvuT\nv/kOAOAH3/07PE9hlU+1YjrxkHKMM5DvIibVbGopnjhzDrM0Jc/p2KNyZSv6AIVVh7qB9LsOXKR9\neW/Ajj/71DN46dOfAQCsvSHG9UmhoUi5VymCWlhYwKAjxxKRxtYFEFKAdOX9S2jWhDIuVklf12cA\n5kRepUVhmKZ46dNSJebUyZP87XtY2+QkxtgHDocyQGBsxF6uVBFzwqKN+5DrWaW047jW8T7jdZ8V\nOTRlcJpWeEmSjgVVpk6oX4JPqtYMsDk8mKHHy6Rdu1mOHunbTYrZNkOFkVzieOUrv4wv/Ff/SI6B\nk4Gd3gAZtxmygkyaetCmyADp1FQD0oOAecAondvBz+ZkY1zH1ix4FAqWptZ6/GWrMVIKqjBCNOzr\n14NxcMlqMg46pD3OMc3jnMY0pjGNaUxjGjYeD8SpDkPyuy4QfywQ50SuJsOdQNamvqLkzlFMUZhy\nWiUkVwRhzHAG2gjL2F5nuSbOVofDATT9a3NdYI4+nlUKOrCXwaG5e8iUiqRIkTKNQTMX0fddlMtG\nnEERTpJbCtNjTdBt1caJOvMWZ2R+vtveQ2NBfjvY3UGFdPP2dXHvcZIcDg3fk64goPn6IjTR3m6f\nJudIkI7oZ7oo+7j4medx4WWhaDdJJV9u7WDAEmIFqciNzg5MRdF6GGBYyLY72yKiemJhFsssQfZi\nWb7XwQjpXwr6rFBQkihnTD0SPRYKGGakMPnZhQsXMD8reY7bzAsdxkNLh6dawa/R85f5s62tdTSZ\nX9tuyTGPhj18niKWP7j0Ds9JikpNftNnWbFqrY6tdakPWo0EhYbVEPMU/7z73tvImAriQNxxECdY\nLgnCurgs7kyzykfvtjgV1ery2+defAkLNJpvMQXnBz/9CTo0NR9cvgoAmFtetIUVbOpFnsK3ntLK\npriYfENPK7ikZUFhW68ztIxHSFTuBSGUa1ySiADTHBnp8AaVN8cWjiNnntYa25fWypgjer74xV/A\nRi7XmE9Hp3pQQqGkDR3WS23HMcpNuVdc5vyub22jXjVQ0VCtCpgwbwdAUU8+/tN+OBaVuQeWnRyt\nLOVrHW0nxI1HlS00yHPys48D4vwg3rMP897PKqaIcxrTmMY0pjGNB4jHAnFmSmG75AGFHhfaNQYA\nE+85hSmsDASUkducD0zMhDFec8gnUi+GarKCAX+OwwjXfG4W9F3PhWZF5f0L+jQQcNxD1VyC3iZc\nmg64Wma8aRAi59pZEXL25GWo0O3kJMUJ1Svvw7nxPgDgmbqIIfq9Dr73miS5v70n6GPbn8OwLKKY\noFJFdEr8Ws3anld3keby3UEi7YpKVRQGQAUyK3e0QsY6ZgQNqCkF5fCLsbjofHo9xAyTyHurgorU\nr4b46+8Jcpvv50g7sraZzQkq7FeAnEnr5XkKi/pt3HpX0jA8OtQUMw2sZYJ4duY+Idv73D/Hj5hS\nUmMqR32hwEKFq1FcCxyORuj2aUgwLKC4pjzfFJOFbgowEwbOgpgQfOafvYw/Wydq4Uw+VVvYuy3t\nP01RTCXXqBBVxrx+XvnkpzHi2nGPHZaXK+iayiR+gEDJMWf0vD0enMAWy6uBa8K3dIqna3L8n3hW\nRC073/g2hqwzkj8p5/aHr7+O5QVZuxzRI3i4WMftXERiF5sNfJ7nvsOSXq2tHXz3238FAPg+U0uW\nZ+fxDFNTmstyXTm+h/mTku4xQ3RVvXAaG2uC1rssVdffa6Pg/TDg9qrlEhKuUSNXcHg/DOlw5SuF\nnEKhTirnVgcuiojpPbyFY53AgHpQzBbUK6hGcp7jK3Ld1yvHsTuSa7tLj9zZpeP4r//lfw8ACGsV\nK8bqGqETxs8AxfXmWgnIwHOfyetsEyhSI4rR5pCk9AkO6l4Mopb/qWwSCU4+R8zDTIOXJMzKZnjE\no3dfNQ9byWn8nqsPf++o3+77vx8ces+wXXdy5THvP2hNKO1mmDz+I9uk92O1okgBW0ZvMiaUVwf3\now+/Z0Ld4T+27BtwtLLpAUHsYzFwKmj4zBk8oJOBowEa5cBlp6ti4kLV4wwrk5+o1VjIofWdQbXC\n4XwppZTdt4miKOydM+noodT4vaPETfbSt0mphW2PuaacogCMwIfqzfZeC0+yVNKoIw+c999/35Yd\nS5JsYnukvcolVKvyoBlxO6pUsfVN/WgsfZg8VmmrnjASG1NKB6+lMIrgMbdQk+4NohCNhgwEw5st\n5IkR0owN5IescTlXFpqxdbODCn+zy0Er0bk1+j51+rQcR5rA8Y1AiRSWcqz9XGEeaoeO7P7iy1/5\nCgDgO98UZx3X93HslNB+DoU13X4PLqlHo6QdDAZYNEIg2t7leb6v/Jy5TowDlu8H1r4uc4wiF1ZQ\n8/STFwAAP/qL72PAfd+6IQpgTzlIqCw1hR19z7Nl5i4+9TQcinQGO6ZMm4uv/NKXxvsB8M4bb+LP\nvv4NAMDGhgzir3z2H+D4GVHkVozj0mwTMzMyUUkGcp63b23g/Tfetn0CiBMUdUBIi8IK1UyEYYiC\nxzzk5CN3XCiTw2wmtUVq61Vq3rhaOfYeaVa4FNDahV8WWv2ZJ0U09tTPfcrW490b9q17kb1OVWG3\nUxzxvDX3eq4enAL8MMt8HRV3y/E8WELLfMe4PT0IhfowZRQ/yngcclynVO00pjGNaUxjGg8QjwXi\ndLRCyHw+ZZGYyaXSLOUz/kzBGVOmE1StXaDHJNozLh+AGkO/iX/5zhEL9CYEcRbjvyEzM4N1C+cO\nXrvGd1Kbqu/jmYo2vp/QcEgDxywAHAz6WDh+GgCwcVVENm+99RZiCh+MiEZ7CppbbDbn0GCOmzHj\nzqGtoCA0qEnrsajhCMrD0NNKqYkOItorleDQ8SejWKdSLmFpUdJf3nvnTXhEZZrlxfIsw4h0XhqS\nAssLK1bKiFL2khRBUxDpxaeFTuwPY+ueY2fHrkKf5agMgnADH0pNzAEPHJ/W42tncpJ94uwZAMAX\nfuXLAIDL3/sebv30NQDALJ1/ykGIrDUuOgwAu7u7OE9hi1JynFmWwWcZMFVo5BRweTRTb3VbyPR+\nA29fOcjpeXt6SdxtLperiDN5r7vFsmD1Ohw65djrWmuLllZPncTWW0KtbpKijPwApfkFdocgiOfP\nX8TZFcl//E9fF5TdbrUwPxR6d8Tr0An8sZG7uR6iACWen7AlyHQ0ylAYEYvjWlcsI44JSiVkhvtn\nCbTI92DFNbm0NSscuLwODGvk6gIuCw7ooSDc2kwTy2eFEVi8KDT8E+fPYET3rFE6hFeiQxEpW60m\nz/nkUo153phlmaPjQXMR7zcexhD9KCR4LySZpNl9fW8yHhbR/ewlO3eOR41Sp4hzGtOYxjSmMY0H\niMcCcSoNhLm82tQTgy4LhUMLxGrCbVU79mOzqK8nEpJNIree3KZzePYxlo6bb0/MUgo93vZkuZ+J\n9w66gBSOaxfhx8hHw5S3sEInJPCYFpJTdDFTrUBTLXFrXUQ0W7s70ExQd8zM3gUU002Wj59AWJa0\nkSF3OxqNDpUiUkrZItou2+VOgEub8bMPcVLQ5DoYmSK+RAt+GKDcFKSbJRki4/ZCOBj3hxixksV2\nT4Qms1EFuy0WQGYR5YFf4DRdX5ZYIqzT6SAkihtmCdvqj9eq2Ng8z+H64+McO7ZMzAvNuZ+YFo/Y\nEc98UsRITjzAtddeBzB2/JmpVRHQocjlObm9uW5FYAah53mO0AiFdG6rmChfPu/2ewgbRP1EqRXl\nQw2kT3obIvSpOD58kihNpgEFpQrcGsudDUwqUoqhKzvZabewc02cgH703ptyuEmGOaa/GFehZmPG\nppm0Kfo5dfYszpwWb+OdgSDrbtxHj+vSZvFRQ8OlI1PItdD27V3bD3BdFNkYfQOAm+eWCaAmDoXO\nAZpkmPvCd3IoFjxzeIJUruEaP6VUXp85u4qlJ+RYwLSoXrcFj0K7LHQR0X5qRMctafvhsMzWBEs1\nKRoEDq8bfthxr/3Zvn6A307+5kFQ59+3eNSI87EZOL3s3pTIeHBSE0/48eVujLnHetcJqhZjocZR\nfWgtsSY+s3lDR9x6So+/e5Q5s3IdyyWO9XGFtfNySKH6eQafD+SAr6tLS1h/9xIA4MYtGThdz8OI\nv4mohs11gREHlpXjJwCTd2nVpimimjw8Yz7MPN+baLehw9UEVWXecy2NZcqejZAiN1ZzZmRwfHtz\nhp5v6z1qDnSD3gg9lsky6sNqqYYBH1gxB5vGyZO4+HPiouPQSi6DRom2eTHLi0WuA9/WiKQh+Gh0\npAm0mqTkrVjMfg1+Q6jHm8xjRBji1AUR6cRrIsxJUaDaEGGVS8P9zc1NaG1y+biPYizIUBpQBxxg\nwmqEqCztHmgZOCqOg3nmL268IwPfTBThOmuorlBJ2xmlqJZkEE0CoSXboxH6pDdfe+ttZJtC6x6n\nGfxTFy5intR9oyoD3fr6OjZJcx9fFMXuwvz82EKPBv1+GKI0I33jceBzlYNylW0wZvc7XVugQDmO\nddRJeB0Xwz4ittsUMBgOhwCtHl3XCJ1SRDR8D+w4rKF4PTdXRHn87OnjGFLKmnLSMEz6mKnJUsEw\nHyFOOSFzzBKNYyea+ydUPH9j4etD5SB+kHgUhugmJp11Jr9nLDQf5Dge+vg+ojF4Kg6axjSmMY1p\nTONjFo8F4rShJ/0ID+camZSEfd6QmNC47P/pvvccTM5UxjMzW9n9qDI/5reuaylfKzJxxukojuPA\nI8Iw6Ct3ChSG/jVTcV1YKOwxo8svUkSkomoUnFRDH69euwIA2N6VvEIvCDEgIiiHNG4fjVChn+nM\n/AJSc/wsxaWdzMryc6Y4eH5hKWRDUzkYoyU7K58QN5n+zBwpmixt5XHmGdptQYOVUhV+IkKOLhMn\nR6MUw6H8XaEgaLc/gEt3nBFTKs5/8mXMnhNz+h0epxP4FsVk7OtMafj0Og3420wXUEfMAZ0Jqvao\nOWqXAh7jDdvLMzE4B7BMNxoMYlxbXx/3CYDWzu7Y5J0pMa4GdD4W/xgfWc3vub6LmBTlgD6qM0GG\n40wTusa0o9WFFdxuSe5t5tIBaTiAQ04giljwOenbe+PKtauoEwGvOIIuT6ycwBJzUcvGRafawMWL\nTwMAdong11rbePtNcS3aS6RdbiVCqSJI0QhSGrUaFA2WTYFpBIGlZX3PR5WUvSniPUqHSJh3aYza\nS44P0DXKZX+VHI0qH0Vl7s9V4+WPlZpQ9yuNEjaZhOzU5JjiWoQwkvOcdFPrEpRP6GhM/qnJDXcB\nOMXh3MGD7rEfJlV7LwR4d8bt3ujR5my63h2/c6f3Pg4ORQ8aU3HQNKYxjWlMYxo/w3gsEKdWGomj\nAeh94g1g/5pUcQT63B/jlBaLJI1YR00IgMZqoiMNEGwb+JHjOHBo/VFMIGF3AnFasQhnzJmT2/QX\nbbO7pYwTAHicOQdpgoAobpYIKt7dw/Y2q4vQzCAbZbbqRFgR1OEnGdy6rINFlToSHkvCtUSzvjQZ\nOi/siqZyDIpWtk/2gUzbNzy2wEWWyG+CiDP73gA7twWRlaMS8iEFJm065wxTRCHXxnIjRnIQhXIM\n9ROrAICTzz+PPlM3YiLUoBzZpPqQwijP82xSt2/SOnwfeXbEbHqf4Otw7MSChi4clzZ0bqyhS1HM\nCr1ocw20u3JM2mcR5W4bGcu5eVxv9jxlZ+paKwRE170hS5cVI4zoEBUQ4bqDPjQrr7gd2W8Qhpgl\ni7DZpz+tHyLryzVSovjF1wmoO0Kr30UUCtLsserMH//pf8TK/CIA4Mnz4tPrKQeNWUGFBT2FT50+\njRNU7myw7FmCwqYJGbOJalhCdcbsm4KnzhBra7IGHycj6/RTZRUSJ1YYsRSZS5anGvlQBoUTcZZV\nhhrdkipj5xIUptoK3aiCZIB6yax/M3UmctHnNaed3Kan5ROYwCahWFGc/WjMKmmpjnM/8VGgz6Pi\nbkjwTohzf7re4e9+HMVBj8Ma52MxcBYARqRWxvl2R5zQiWtg3HeToHlMp1pS1t4YjhW53E1Ve3Dg\nBgDXcQ61RxXaDjyTA+eRrh5mf4WGwwdSQNqrnOUoM/dupiKD0d7mOpKRUHc5k+Pagx4US4NFFE34\nCKDLdATyPFvKakj6rNQso8eHz2S5IvfAgDKpK7SCGqWstZVROgaBB01qMvSMTDJDa1ceuMddDzHv\n7ZgG5Wmao9GUQWiXRuWN5gI6bNe505JLWVlexuUkZhukH/woRJeDlqFlHcdBPCSlaHINwwB5drhM\n050GTBOlGZl0tDjYlJuzlqJtrYsZerK3ax16BtxHmiRWJOUwN9VXrhVvwfGsmjnPzUTDgxNI381R\nbOS930L7PcnT7a3J/tZdhWEh7TGOWXO1BjY6ImCKqGwNRj4cTriyPEfMB+TLn/t5AMDrP30Nt9py\nXt762tfkN76P3/iN35Bjp5pZZTl6pFONI1W5VrWikpIjxz5TrqFKU/00lO8/9dzzaDH3eOPSJfRH\nFD2VxueqViPly3aL0lb6xGWZshJyVKigjTjJVGmOnJR90hLFcT7owPVke5vMcS0vVlFQjOQHHnZj\nmbC5LGWHCRGfpe41rGvReIKNI+PDHFg+iBjpYWjX+/3N3dS705CY9tA0pjGNaUxjGg8QjwXi1AoY\nOTmyLLMzoIAz3jAM4bMqvJk9ZUlmaRyl8/35epBZ5MH3ACA9kIu5j5Y1M69JByG+JkkyniUbYY3j\n7EOcdjt0OXI8Bzln8Ea4MhrGmKOfbIOV55OtdazMS8pIk7kct3a20WqJmbcmpVaeqSNmDl+PLizl\nUhUnnntOfhREKFPQ0WOh694gBkzqhjchXjI+qgZdFuNZpz2MvBiryzlp7e7tYZEpCXUiz93N27ak\nVb/bgzIFernNKBr7mZZrQhMOsgJdpqssn5Ucwhgu+vxelWi2O+jbUl65OXd5jpJx6DFisTSz4qx9\ncRefYgCIjTiIlGGz3rCuS1WWm2oN1hAQPdZIv251+7h1U8znV14Q03gEJWwz1cPxPGzvCEqanWPB\n6/YIUV1+f/OKpBp9rjaDJm/BaE5cft5/6zU0L4q7z/qeILhOPERMNNdYEvq1mlexvSloz/V9tIey\n7w2e+xPPXLSUamuLiG2UICJVOyAlvb25BTDlp9IUwVa300OdKSxV0uxlN0JvV9JxakyhGUXAc8+/\nKO0vl3D1qgjaOvS3LfkeRhQCpTThb4QhVlgOrWDe8mK1hoJ951I45WQZZnmvXDf5pbub8MsiFNIj\nObZyEGBgDLwLPUZLvP40FI7CB+P0Mf4f4oN8p3gY1Lcv5/vAdx8mvzI7glW5V9wLMR/FkE2WPHug\nfeHwsR9qy4dMc9/peB81ip4izmlMYxrTmMY0HiAeD8SpC6TFEFE5QkixhZn1DAYDjGJBJ8bAIHAD\neEycF9REF54JibkpcTSJPE2hobHn7TjUEUhz8jNTiHZyfdQiNn34R55ykRsBA2dinu9a9xlnaApV\nK8wTYUVM3k46LfSJHEY5fWndAC6Rlss1wDzRUBSs5Mrh7BrWP1TcdM3aq+mPCXHURDgH+qSAmugo\nebeiAEWk6BDN3Lx8GSHXaD3XsUjGrqkq16aUmDXYNAMypswEXIsaKSBn2SedTLTriLbebT36TnHU\nVwsyGcaHWPk5FNtl1ihLpRJcIpGUqE8BGBFBGYOAPE33XUPGozbnWnbgKPhE/VU6EWWtDga3aL7Q\nk20fP34cn/n1XwMALNy6CgD4t7//B6gRpZmUoyiKUCsZVNzDiOkob926BgD4xMsv2zVSn+esqly0\niOiMfZT2XVRpBKF4HYZhaNc4TRpJL+0C9Bz2KOwKSh6On5Qi2aunVxFTbHXlqpg5XHn/Pbumv8RU\nlWfOPWHLzL3z4x8DAJJBH5r3g2sEPKpAQQGWb9bue12EZm2S6/zZMEZAFsRXDjxbfWhCHKT3vx4p\nLVHjCkcPWq3koxLYPJQo5uOn/flYxEMPnEqpCwB+f+KtswD+FwAzAP5bAFt8/3/WWv/p3bblKIWS\ncpDFMbqsMm+EH6EfotKgOpQ3Q1EAma2352BshVPs+57EmHZw7IV35wtQXF/2f+5o2MHDKnOV2mdP\nd9A5yHMcZHrCuQZA2ffhmHZTrTjr+Vhknl28KZRaa3ML3a6oMc0YohzfCmS8gpOLRMNjTmemnTF9\nYA3IJ1JbTWO1/WfiQaIO3ZTyfzX+CQA/TRGwPzM+jHfXb+Eccx9DnWOLlm4ZKTp4gCV9aYuXpoDi\ng7nOB+rtXNkHsqboZbK0mZ2kYEIJuU/kdATlNFkb8IhTXvDyV3Sj8XPA4cAZsi2NWh0bHByTPh/u\nnoc9UrFGOJWMRnBpf1hgXNbKuOioeAiWW0WNEyBvuwuvL29qkw9ZDXD6WTG5X3hRXv/vP/xDS6PG\n+Zj+Cx3miuYFXLoSvXb5PQDAc698EnXmynq2DmUZ3V0pO2ZKnI2KHP09WRYwtLjruobphOZg6UZl\ne40MqJQtKmXUqQCOosjSyX4o/XDu3DnUy8wh5Wvn9m0MeaX6vJ6H/T58DtpW1JdrDDiYhnS/2m3t\noFYIte+yHu+gFyNY5rKO4yOgdNaKrLVjJ8/jiVax7++DcZRDz0c9SD6qeJjB9uN2jPcTj/qYHnrg\nMJN++QAAIABJREFU1Fq/A+BFAFDijbUG4I8A/DcA/jet9f/6SFo4jWlMYxrTmMZjFI+Kqv0lAJe0\n1tceZobjQWHRC4CJBdyRKRo8HCFlmSVF+svzfZsPKUEkamTnKMbzyLss+O8XB43fO4jIoJQ1q3Ym\nkKU5VMdxxl635piUi8z8ht6cJT+AItIEBRTztRrq3NDtDZHY721tIMmEpkpZwb3AWMYfsB8qURkB\njd1zZ0zVGrqxUIVFWkb4oPPCutCYcDExG3f2o8zJ8OM+yp4INnZuiDim5rtYJCJw1jcwYDqAQaTa\nD2w5LZ+IptAaNdKDtbr8dj3X8FjKy5TqmkSX43Jn45QZdwKFHoU4DZ2s1WFcoRVsP5jLLgw9uKQA\nTR+7pbJFuwmRll+rY3tD0ke0KeGWZnB8QVB5oeARUZui1FWt0GfqRkSEqwYJygTmQzawN4zRZV7i\nkLmrjYU53KZYrNIUN6CsW9jSe77rWreeTi7X1ebOLhbnREjkRMauykdunHmMwCpx4BLtGQGWH0UY\nUohn/IDDRgMe0a7ph5l6Df8/e+8ZJFl2nYl999n0Wb6ruqq9GYsZDGYGJDwGhgAIUgJBEiQlLblc\nGmljtQr9W60UWjK0oVhJEVIENySRBB2oBRe7pAiScCScMCABgeMxDmO6e9p3+cpK+14+d/XjfPdm\ndXd1z3TPAGyu8kR0ZHXa9+67795zvvOd76RsRXbh4nmsrRNk4hyampjEgJC3qQfNo6GNgKfYSi32\nQ4SMuB1GrV6eIyc60/HlWFvtNvbyfUrJ2Ax6fdSU/IavPARmXchN6ckI7L8SsgWAgnj2tUqXrow0\nd2rC/qDtP0SodieydcUr1/zMzZzSG33N3ihy0M8C+MyO//+XSqlnlFK/r5Sa3O0DSqlfVUo9rpR6\nfNjefoMOY2xjG9vYxja276+97ohTKRUA+I8A/HM+9ZsA/iXEMfiXAP5XAP/oys9prT8J4JMAMHv0\nmG72hkjSHAlLBKr0ghuVCnSJnRWYL4qyzJIkdkYTJrrK4exwWHbmOM3pXk0u2enNXdkpRSkFZchG\nJq/mODZScXF1jtN1HHim8SzLUkLPh05IrmFx90Q4BcXc2dpZFsO3t+GSJZFyHJK8sG2byiV5bWFh\nESFLUDQcm9dRriFIjM591OkFI41dE43rHVU4O0QRTOcLMw5110WTpKznXn4ZADA/0USdub2NQXc0\nJoxUUmTIcpM749d5LhbmhVRSZo5W6b4l2tixHP20jTKdHeQmb2cOeZckptU2xtX+a4FRPtOSaFwH\nHm8J0oYkAk1JSDHKTa6H5YvSODqhspOjXPt7SikUhjTEAW2USuiT/FVQNSrebmPQEpEC0zqrNF22\n8/3kRSnvuO1Nd+GRP/5TAMCdc9J02vd9VCmI0XZDtCniMDcrZS1nXjmN/fMS0TkkKKWDGD6JSZ5p\nleYCMaNGI+BQrpWQkxQ0IAmqfemsPX/Trmz1udOIef5u4KNJQQmjcwvXQcDIdmZCrnceRfAYpWve\nFy0/QIXf7ZhxABAPpERl0JPx6qaJVdJSilrHgxgEKBAGHlzeI4FBN+Td8t07BFKMoo4lwylt55ix\nnVHKzsjzysjvViYH3USM+h+k3TI5zh32EQBPaq1XAcA8AoBS6ncAfOHVvqDiBbh/Zh863S42OhJ9\ndtlPL0sHKEJD4hgxaQdkEWaj7l3QykC2hf17Z2Af7lKetDspRl/1nHPloq5GrbiUUlfVCbkFEHJh\nTkF5NkdZkfSAtYN1x0NvYwUAsHZBWlkl8QCOz3OhPliuHCBh10BuEnsXlxCVd7R6MpsHyUG6yEcw\nlWMWkp2yXcYZcK+AqsE77vJzmi1V4HLh2r4ksPLhpUUM2kII6my3UKIUX0gHKBv2EJEZ7FEFyQ9L\nOHjwoPwM4UbX8dh79Rob547jc6yi0Q4HaDfFph3w7pXOlYvRxlmYXp+BD9ewgYdyrOkwsczSgKzY\n3HOxyj6pvY7AquHsHkTmGFzHygLaeZGl8HgSFToVJQ1krMn1OB+WDh9EfU6UlpYoXv6+ch2fe/ib\ncjw8k0qlAo/KO9UsxqW+XAPXl984f/oMNg+L1N7+RakL1WlmReIHhEQ78QAdKjaFDYHhF48fRp2y\neZ1tIak99ejj2FoTKHbyAEXXg1mUOf8qjaaVeDT10lGc2NrDTSpANUoVJBS7j3kxesPcbuim3R6K\nAq0BnRKS5xRGNaKm72uea2RDI7jvQNGj9mz6RtlrPpLSHNUo61EB9lV1v9ciCf39gmpvcaz2B2S3\nIlT7c9gB0yqlFna89hMAnnsDfmNsYxvb2MY2tlvCXlfEqZSqAvgggP98x9P/i1LqzZAY5swVr+1q\nFS/Am+f2ITxQQkTY6CQbOD9z6mVcuMQglnqXtZlpJCQPFaqAlYLl9wlRhi2e7GuOjTh3bSF2RVut\nnebg8tITwMCzo+eu+k6tLVRrqfGFhmYkZmDJ0FFYW5GIs7tFhZcsRcHIwUQYfjmE1oyQeFKTM7PI\nWTYxjAf2/A1Ui8IZeds7zm/UVoyv6dHfO/2yy6NPoJTn2GTUUTLfl2UYdFg6Ew/gekYliQ2FiwwM\njJC5RpUnxMEDB+T8TARecm3bqp22M/oEAFerESloF7LHTtv5bTvkgq15hO7zVKIYJ1SWMGS0b+PB\nwLbGKpHUkvk+Lm7ItRqQ8DO97wAio2alFIaE5E1ZVT6MQD6LJR6VgxApCTDm/PYs7bUC7G6FNbqe\nwu333A0AOH1GUIl6adLW6PquZ/V0+9tCziqGKS6eFuj/yOJB+b1a1dbZdroCg0bI8QqF2g/UpK2b\nX68jmBAodJb1o/7Jk1g5LfWZ9Q2pPb1nsoEmNW+DUmibSOckWFXqNWSpXIVuW+bIdreH0FxTkqky\nx0NMqDaNOB9QYJuoU6kiRLKg4qDP50Kbl1FIWOetQ0AZWN0zc8S5SuhcgA2uD+bJHaQzY9eKUv6u\nRMZv7ndv7YjzZshBN3NKtxRUq7XuA5i+4rl/cKPfkycJtl45iwwKqixQ3+KMcIqOfOBD6BMTPd9p\n2cc2ZcsuY8ip0WaZGxbpjlznlf04X82uN1F3QrqXiSeYRaEo7MbJ8j05Vq7cnmUAK/RJjkpYt6YK\njZwOREb1gEoYIs/YoYUbUblchsPayCLSV9Wc7XYuWutd5+TOHOi1LBlE2FiVTb5JOTRdZNDZSLHA\nCFd0WM9ZlDwrdG4kEz3Pw/S0TBsjnO44JdtFxt1x/M4u8PqVxyzs2x2wmoVjCeftuDfVLp83x6z0\n6Dkj4p7EqWV3BiZ357jI+rIRxNyIgiCATsn+dkadUky9ZLVcQZ8nY74vjYeI+rLRmf6s1VoNffbF\n/MY3HwYAvPTSaUzNyHh997kXAAD767MjCcosg8cepT6heL9axYVzsnGaTcufmESbf+dMdTRnJjCb\nCvt26aA4M+VmHZs9uX5TU5K3nNq7B84LstEtU3T9WOBax6fSaKJcb3D8HTs21Zo8t7AgOc725hYm\nKuIANw2024+QE8pNCMWGpSqmZuVaGAg88AMMmQM1sKpSLjJ6Zp7W0NkojwkwVw9+5DprcYHrw2//\nf6rjHNur21hyb2xjG9vYxja2G7BbQnIvSXtYXvs2fN+H15VD6m8Y6bMAFQpO3zEjjMEHpifx0wdE\nXHul08YrhDpPrcnjancbfSOjRgUXJ/TR80V1xPEM47NATKICSDwKKmXkjAxMNOE5o8gnMDFZoRAS\n1isXDgKyTT0SXF6aKMNtide+l1KAk+0uOqzVnJ8XCOyVrRM4qcSDP53J+8v1JhYH8juzKcdjHYgm\nxHtvTwmMtnbvPLpKIha/4UBpMhwzgeEqjrbRaU4mZ+L5CGvy+c0Oa0qDEdSXU5Kt7DqosQ1WanpU\nNjSePP0MAOAwGZQNrfDShpxTlMW2DZjKKByuq3AZYazyWCbvOIyTM0L4cGokq/RTLAZSo7hWCGNV\nKQUooyhDj1+NOBwFDKqgUKSXAbPysKNGt7jyNQArbAl2aEZ+N9nqoebJsUasKT3n57g0I5FRSIm+\nIorhs/7y5HdlPI68423oQMauGGSYSuW4F6lwc2ZhA3Pr8vqPVCT6eun8WfSmSHwjIWjy2HFcOC1R\n4YO3v12OpR1iiwSlev0lOXadImdXgPnKFIJzAuGeIhzsewoblyTiXDn1vBzjW9+KCs/lDElN3cBB\ni0zc/u13AQCeKteBQO65tZQphYXbsWdOrnOT5DMUQKUk78uGGXKOZ1iV17O4j5g9RTcSQYuatToG\nfUm9RJHM+8mJKnLWe5qa4CLOEPny3TFrU0VJiqmSROb4wlQFSVfO3WsUKIdsw5fI7xZhyU6YIJff\nmAnqqKZsfjCQC6mHBZYdOR69KGjXWQwsYjDLW2VuK8N8Ve6fk5Gc06WpABty+8AbAnMtOcbprqGR\nO9isyfdsVuW1cirjD1yO8owi2l1Qo51KWK+1rdgugu2v9tmbjVKVLu34jt3ecPVTNyMof3lq5oov\nveaxv7F9SccR59jGNraxjW1sN2C3RMSpHNEp9RxXSiMA5KkpB4iQRMw38THY7GBIDyFsNnCM+ZM7\njt0GAOgVOZZb4nGeXxXvdnO7hTV64EYNpVyvocFGu0Yku7+9BeXLMUxTPHqYprau0kSerqugmbuL\n8wwJIzpTXjH0C0zQNQpMfiRNrXpOk/mgzUtrWF4WT940vE4TbfN9I/KCQsZznp6VCMnx3JGIOwo7\ndrD1m8VVDpijgYFp+8TSBMcNkbGutKA2aalRwaArEXCNJSbnT5yxgueTDYkGWmcv2DyX4zgomHcz\npBh4nlUOMsfnh6FtDdbjZ93At6ULto52h+rLLn9cfl6XlQNd7g8WtrHbZZ+wAuRGy9TB1W3mXCgE\nzuV1owUUKiQKPf/k0wCAh3o9TLJsQvtAY8hfYQmRM0hQtCVKWl0/AwC4cOIVNJmbNCUvwzjGzLRE\nPH/+ta8DAM5eWEFIpSXjoQdBgGE0qhU1HrPPuV3khR3jrS1RHYriIRxec3+Hlu7O75TfgM0VmlKv\nwPNQ5ZztUiEor5bsNRumKbQr56fNNNTaav5W2Nw6TVNLvDK/qxVG7C2j8u44cIgC+RyjZJiMyqr4\n2bg/AFjKUvJc1IkmBTy/U5eWbc2wpjxT4Dk48bxE4fG6zHE9THH0nfcAAFpGT9rNwNsaRWbYZTm+\n+93vAgDm7pX1Ru1QRb6s8YBj5stO/sXlql1X2mvJpb6WaPPvWy7278KuV5v7anZLbJyO46Fcm4Sn\nRoLMmuSMdJhYGC5uC16S9lJbYD/oDTHcFGjLQIKlRg2Hyfa783YpGPeCEi4RNnvl7BkAwMkzZ9Fh\nJ3krzu650IQZ3R2SZrmZiI5ZFRRgBBU8x4or2AsQtVBy5YYOWb+Y9HqWGDFF0e7l00P0uiPYBgDS\nPENhmlhyISmUA1OVuf/gIfktP4AypfqqGBFkzCKkR3WcpupUKReaNYMON3FfuXAM1Gyg0WGKnMzL\ngP0az546iakq+zRykzi9sYXUSNEpZRc0011EeYElRJmxmZycRmj6XXZkE/cq5ZEgujva5tQVj+5O\nQf0dm6ip8ZXzvqKm9hpi7wFXeI8Qsg9vVC9qupoohQohWlNnGg0i1H05/vMvyAI8bLUwuTQvfw9T\nlAwJjEzbfUEVdx2SuXhkVc75+U4fTTogDkXQ3aJAwo3ltmPHAQDNmT3Q3AQfeVYW7VIlRNYzc9ZB\nQGH1gKIIRdpDuSIEruVVYcGubW5gbt8++Qyh+WSY2s2xzG4r3aywXV00pQOdIMQEIe0Lrwi71qlX\n4Jvfk2fkO7nxJPnQ4mrWoYKG5uuZ6ZmpYFMlivNQaWVrOhUdL53ECCgOYTbQbq8Pj4RCpKllRZsN\n/cwL38Ozjz4BAPjZj/8UACDeamGRzudffO3/AQD0W23M3SkbbGVSriOiGJ4R5KfIwvnTp/HIw98C\nAPzIYalndSuVUW0xRmY3S8e7LjFpt81yt+dupifo2MR22xivR6Z8NRtDtWMb29jGNrax3YDdEhGn\n6/mozy1KGYIptKMcVxYNkVEo28BZOsuxfUngIt/3EVIMGxXx5IftHvJV8Uz7O6KXLU88wNv3ikbD\nW9/+IPpDobcvU0R7o93DNiOoNuHLVi8CWHOGwESZPjL6HVGaocsSgpTU+JnZEBVGzU0eQt7vYJaR\nsCbhptveRr/f5xHKG7NcwwScphehdj04jLL3H2JrpbAEmGgIBXRxeSSmd/pFto4zQIU9T7t9KrOE\nCg1GIEVIWcPNdUwQjow32HYqSrB//34AwGCLZQ2DAfKYMoLOqA4y4LHmni99xAC4hNz2Li3aqNhG\nl8q1EJ596rLockcUegV/4irlpisiTvH2L68HBYBQG5UZEk6cUWs2nROyVh4aFNrPWGOY6xyhiXC7\nch1XXj6JIyRtFcMUZdbc7puTyKY2NYV3TYuCj8qF/FTPHQxWZWxvPypkt9rkFC4NBD5cWJAI1SlX\n0WZvStM6T+sCfsDWewhQYc2nz99NHc+2PGtvy/edv7SM6X1y/QpGdsMiRsCykIAogI6TEeIRGORA\nYWJOylZ6hPP7gwEm2BYuLJes2pVZVYZZgphzI2avznqlCp0ZBSxGnK4HFZj5aRAUB9qoCJmGAa6D\nEiNzj7WuOh7a1mdFP4YK2duWEfiJp57BKutP54mSfOxDPwrHk+88dlDWgs88/FXs+ZZEnO/d9xMA\ngEkvsJGkob08+73v4bmnJeq/5/y75bXZ4/ANUgE1irJNudMOKNqkY16rKtFu77vy7+s9d6vbTRGR\nbkZ68FU+MyYHjW1sYxvb2Mb2fbRbIuKM8hwvbLbgux6qzI3VAvHxyvUmSqR/GwFnleaYmhHvNxlE\ntulzh2ouWZbZDvYh8x9BEGBigp3kT0tOMTrrwA/F2z5ISv6dh/ajl4j3scIi/lPLK+jSA29Tq7XX\nHyAzZJfAR4nF8Q5/I3C6UB0pFTFi3EmWYKIsdPtzJ6Xh8PL5C1hbFSJT2YgZKMd6VYrRDlzPFphP\nUehb+x4Kx8iRF1Y4wESejips/sokWbRy4PEzDstXnFwDVDQKyCsapgkOLEk+7FsPSx7o+MQkFial\nDOWxZ57ndwBgzjSJMpvbdHj9IgCKUbNpIbawuA9Dkr9c04pLa2SGpGISQnoUcY7St8qSjHbNWyhg\n94bmV3qUCiEHh0CEkJv4qiXMOC5qJM1E1ER1yxV0qJLTIDHlxBOP454H3iznNzmBac4rg25MAFAR\niWMnzwIAwgy4cFbasx37oTfJDydDbFPoI4llDDudHiJGj1XmIV1fISR5TW9tI4oEtVBluT7K9ZFR\nUMOIgZy7tIzjRFgyb6RCZa6Ly5y8QmaRDPPZ3AUqUxI9FyT8tFptTExT2N2tWMa/GfUgCOD7piSj\nsOOqMYo0AUD5HlwzJw1vwHHgUATEI4nLyxK4jLINec5zFSo8l4pyUGVeV1UlunzzbUfw5e+J6ufX\nP/8XAICDjRoeuEPG+70/fL+89rk/xSMPPwwAWLrrCADg7ve/A5tsWN4gWhIqIN5gSzlq/PrQ8Gzn\nb2VhjcLwExyKcMj/cKW9VgH5cY7z5u2NFoK4NTbOLMPTmxsIHBcVLqRThkRTqaFhmHKGgqAzTFOQ\nOqiXMDcnG6vmxpokse0ZOOTkTtIUOes9Qy7qtUYTIRfh3pkzAICV6GUoduyoc5P4ybe9Ay0uOJe4\nmV5st7HCWriNXhc9LnYxNxE/jKAokK0D+b6GAziEaM+/IspHve1t5IQyTS2bclzANxuQjIeGh4kp\nqfULCE3HrouCQuXYcdMpAwuxD6h8ftSfMDYdKMiwLHk+MirYOLkc33S1iirhT1N7unhgGnlPxjMi\nVOvl2nbNiIdDuITDHHZMSfMcKReVJcKEE1OTaHGjVm6JxwfLTTQkJ+lKcwURaAfTdqecoJXtvmzN\nkAW32BVY0QhAp8QsZq4DbbrSFIYdPGLQZqzTzPMMUVfGqzkhUOWlkyewn38fOXDI3ljhjsenH/4b\nAMDWw98BwH6VVAQy3UqGeQLX1B77oz6ZBp5e2CMO40ZrA2VuYP1CQxtFnbLpjKOQEBIt87tb3R5W\nuRE4rInWyse0ccToSPh+2TYDMI7ZUA9R4z1ZJbFGtTbgmRSG4yBJDbOcJ+0BAe81g6QnSQLHQJkB\nmcthyfYWBeezVo6F7ksG+s0zC+0P6biEfgllbmpFFKHGVEjGVM/HP/hhbJ4XNv3j3/lbAMCf/OEf\nYM+v/AoA4MG7hUn7sz/xUfzrP/g3AIBHv/YVAMD9b78PZYrhT3CsD++dt51smoahnBco8biyYsRu\nN5tl7gDaMXAs5RSxm1j87s9Z2/GShXdx/efyN3a/eMPt7wKqfT2kIGNjqHZsYxvb2MY2thuwWyLi\nhB9ALS4hSRMM6Sn2CcVs9LrwSdQA6w+LaIB3PSAQi6dd+KzBdAoj0O0gLxPSYWmJk+WY0+Idd6jo\n09rcgO9L1Bh4jJTSDFlXfqfVEg3Z5ze24LMH4QQh3bk9c0j3CR19K46wyZrHDnsI9vvLCEwd2roQ\nQJqBi5UzQlRYPitwXZaktt4uZ+2c5wXwWDrjM9pBDguL5aTnO45jW4gVOofSRmXH6HWOXFQTzRXa\nRRKzHVWFPRmVQk6tVLAF2HS9jPMnRRd1knB3GQ7OnZRI2cCX7VZbCv94/JZe44zKAiISRA4dERFx\neD50KsdjoiK37EHHcp09Wwg4IlNY6BpX6+pqNYJWd9MhcXZ9FnAdQpP8vsxVSEwLVZiyGtcSnVxT\nl1dkcBlWDak8tXz6DDSj9ipGHqnRdT2/vIUnHpeyiJB1u3vDANOcQ+VZubZOswqPCjxbhPp7gy5S\nws5VAw2vryFg6y8PGhNU11pj5CZ6uPK3YyNm4Az7iO5nqkM5LmZnpPwiY+mM74U2bDHeeZwDZV7z\n5oLAz/n2Bhw+54chNGsdc0arzg5xda1N6Yw38tYZDuW5HkWpJJcVhUaecHlic4CwVhm1guP1Dj0P\nvW25T89cuoTStKBP+45JS7XG7AR+4RM/AwDYPHsaALC9soqvfv7PAQDTRBjeet+dOPRVIQetnpI5\n/uhXvoZ7770XAFByZQ7ngz48kqB6Lbm28/lBq0okyACvgcdHVYzqN3eMyWstQ7nSbqSO8wfZw/NW\nBohfDQ6/0XEaR5xjG9vYxja2sd2A3RIRZ6EUoiBEorUJXuDxj6GrEGiTKWLneJXhO2dOAgBCR6PE\n3GCVDa8r5RC1ukRxJZI0At9HsiIlLPWaRI/lKEGXecg+c6IlN0RIYpHpPqEGEYaMJLtsYFyEPgLm\nWeuzU1iYlrxPaVE8+XYxjZDtjk596xH5vSzDUyQFrbFtmio51js0Cju+60Ax4rSF/UWBKglIuYnA\nmRkEJCCzTXktN2aUM7HNvqFsc2zTbDlXGiUTORQyDmXPwWPPig7rvnmSQqIuztMb37dHoo61M2dt\nCZHWIwUbk1PNtIMBC95nGalkeWFJQWlPxiio+tCa3UUwMnNKxqE2+Vs551Hkme2ieWm8wmLH9+w0\n42TmfDHzFGLeETGjnKqr4dpWNvK+SrOKhOO1yVZwnfUVnPze9wAAR287iqor82+jJ2jD5sYqglnJ\ngTYGcs5nn34GUSxIRdgRgpje3sALqzI35vYKOUsFHkKWacwyz50NYuTM7ekkg88kIrU2kKYpQiPK\nwfyb53lY25Tf2W/Ld7RtWj2k0IhX8lGY6NrwBnSBhJ8pT8j9s7q5hUWSkvxKCR7z2yEjLddVKFEx\nyHT70flIqIJpcDiZbyeouUxZ5iFnyYnNN4cuPGoIm3ZlSimsr8s5Pfbss8hYhvIxjlNYDrDEvPAn\nPvYxAMAffvK3sHpeEJ8//vSnAAD/5L/4x7jzoOTgn3xZruM3/uyzeOfdot8bsBTu/ImXUOZ4Xjgl\n9/LBt92PkOcH7ULxBjT3XOYABeeYs4sSwlgA4Qdnb1Rz8lti4xwmCU6dvQAUGpNM7jerQkQY5qmt\nFdtcFpipMTONZ068KH9XSphh78AqWYFuL0Zds91RQTHn1MN+bpimrZNbK6HRlE0haskG6gwzNEi+\nidiCKfR8ZKwl60Ws1+wPEGh5rrO1gmWSCJrsX9ib8HB4RkgX803Z8J5+7DH0Ce9MNYQh24q7qJRl\nA+5RGm1uqol+V27UiPVvBTwoLiAVQoeZo1AYQobOobXp7cgN39EjFSFlFFdgoSb6G8jjBAUhxzJf\n295cQaMsnzm2Tza8lz/7HeydE6g6IjSdxPEO1STX1q4lJEllUDh6+50AgMUDB2XsNJAbSNFs7EWB\nGmXlvLjLcx4RgMy0LnIgd0YbtXlfQSKU7/uWUa0JPSbxEAX/Dvia7/sY8ns2t4XYVa4HmDwg57p6\nWljDe5sziNusYyVZZ9CL4HBDMLJwc/v24//4jd8AANx+711Y5mfWOwIj1msz2HOb1N92tmTsziYD\nKId1v44c/4GJGqbLsoAnlOurVOu2hrRRlvvj9iPHcO5FuQeCOMYEFZ3cNudIuQynMHWnZoEALq0L\nI3R9QzabYz/0w5igsPo2YdAoBxKyx42cYq1cQY/3wOJxgdy/ePYMYo57rVbBHOfGkcMHAUitpZFe\nnJkRKHonic1ev1xIQwAw4AYVxCnKTbmvh0O5PoPBAAV3oxnWxw6SHNjk9XFcPPaIOKkvnBbH+j/5\n+f8Ub/2hBwAAd95+BwDgfe95L/7qs58FAJS54f3xv/lDfPhHPw4AOH3uZQDAyydP4JUnnwIA3PW+\nHwEATFUroH+O7oY44gvNBhKSEFtpZpWTylVZt6I4QZnXrdWRY224IwfC2G5L987njNzlZXYFpG6e\nM//fjRz0arCkqYm+0Y36ShF660S/DjH13cw4TzdiJgjaabu1g3ytNoZqxza2sY1tbGO7AbslIs5y\nWMIdB4+h29lGh9BpiwSdOOoj6UqUZyKt2tQsFg+yfVBrHdpobOZGPDrDNlt06S0qEGUZll2O9Pck\nAAAgAElEQVTxenv8jSP79uEASRkG0p0qlRBvioerGKUUeQqPQ1Vm1FHKC7g5vfJeB4p6s+lQCB3t\nyMc5Uv+xQo94GME14tQkOiXDGJkRfqeHnUPZesh+n4orM3MoGzUewspb/TbCKUY+jgPjxBrdWTga\nKWGjxDTGTjOUWB7jMipM4wFcQpN5LNDbxVMvolmR70mpZJPGESo1Oa6tTfG20zSFR8ytVK1gm952\nbUai6GhjA/v2UmTbEJmgpFYVIzH4XBdWp3g3Ks9OIpCxne+7zHs00DEfXahROypTeVIAvqmbZVmB\nqvjwJnjcVPNPlbZNAVxeE69aRsISHNNIXOcFOlToWVtdh27Idxo4fztwUeE4PbkiMOGff/1LSMC6\nym/9pfzG7/0GtgYy3x+4Rwhwi/U57N8jY1g3jQeixDaZ9qMIPlWqHCInblEgYA2wqfH0Sj4cjvfZ\nC1Ki8a6f+DhSlloVvqmPHbV1NqSeOEsRMBJxmTJYOnIIn/viF+Wz8QCj5gIGqtVWo3aaqNDBg/tt\nyqHZnORjEyHVi0zNb57nlixXDk1qwkGaGFF5aa+mnQANIjsf+vEfx4F7pT7zu6zd/OTvfQpf+dpX\nAQA/83GBaj/2sY9hgiVu/+4Pfg8AMNjYxIFDQigykC3iPr7wb/8IAPDCN0WfNukPscTIOqPi16ln\nn8XkHRLNbg46mCCKFbNWGY7GgI3B66HA2djR/P212rVUhMxru0G915eUv8bvXJEe2WnXe+7K+/Z6\nNamvx26mFdkbbeOIc2xjG9vYxja2G7BbIuJEXsDpDjATVFFvGK3TUWTTa1Hphz5Nv9XGPffcDQDY\nWF1DEDJKMJ51ENo8l0kLaK3R6jGpzwbOhyZn8fhZaYIbmoL8/gAHWZS+d1oe834XHn+7XGbUobTN\nIRVFDg+mlIQ5wjzG+jkqjKxJFJBGEVLq7kZ9OacM2oqzhsYbzQvkjCBMTm6m0cA9t0u3jKAq0UyR\nA6WSITJlljSUsEA7zTPoKzqJOMq1EYYZnNDJsZetrLAlr13strHEfF/fKKUUOVJ+99qadNxIkhhO\nhXlkP0TMaNh0gYnzAkfojRtRhAwKitGLb1pZZdoqyvi2QfXVXmyhiqs6TWg1KqVQSlliksfzCwIf\nHn8nYEQTeD62+JnQdNwoeShTbzZheU6uMwSMSEPqpCqt0N2W62f0d3Wu0GXu8ty5C9j3FiGVuNRO\n7Tg+9nOMIxLXNpXGHj7XdmTcVrtdW4Lz6GNSvuJ2M0v6qVNTeHZ2Bg++Re4B13GxtiUIgIm2FQqr\nc9zNzTwtTF9wnDolOcBKqYweX1cUO0j1SJ3J5LuGRWrb7VV4DD/2Uz+Jz3/xc3IM9ToKdrcJjNZw\nnsFhFGqQhae+++yo041rrrNrtZltLmpHPs9XjKYdIOfFz0zyzivhLe8Szdh//IH3o3H4kJwDORIv\nnj6FASfRb/3u7wIAPvqe9+IXfkKiz61zEnl/55vfxJc+L3nPBZLYpsMQLfIOLrwseU/fC62a0vpF\nWTse+eY38aElQQSaYWk0P20rMVgCnXfTxR43VlLxd0EQ2hn1Xotw81rKbV7NdstXvpZjeyPtltg4\nkzjG+RdewtLSElzeqGaBawRlOIEMVJ2wV5LE+OpfSa/Cp59+Ch/9sY8AGCnh1Otl5KwpM+SGLMsR\nk1jQJgHuxYsrqBHO0pTF8/0QJ9qyAJ4hHHlwbg4VxzBeZQGoBx5c1m7pah0NwqxmsUr1JlY2hRgS\nZQLpZnGEPjdMc/GDcgkxN9uYqkI+AukzCGB2Rm7iyUYF994mG2ef3eQXKyV895RsYEopKMP+5OKY\nBS5SQ9bR5tFBtSoknAHrBFWaIadsYfu8SMBV8hw1zu31C/JcqRKiRTH8aEg5N2hkJC1lGnDZu7NH\nuTe/XMbh43Lc2sKyo4XZOBrDtBjRXJVZUPVIvswuRi60qYVTowcDbbtQKOh0aNNvMy+QZSOyEgDE\nCig8WVwV6yazQiGoUqnJGc2fCudVg+MWOw7SjW0eEOHLwgFI5lm5sIbFt0j9n6kH7TkKLR5Pj+Pa\n0xpT3NBhRMuTDIpkq4Aw8ORUCcMtKjtxbLr9gT2XSq0Kn8Qqty9phsBRViTdyN6l2dB+pkXo8OUT\nL2HfXSIwbxyNLBqiIDxtHI4kiUEiKyJutBN79yAwvWHz3KoXzfBYttfWbXrFI4mqXCqPFK7Mo+uP\n2OO8fxzXs9egnMk90xtE0Nzc45yM21yjR+iuNDMLh+P4gUXZGFWjhi9//vNyDHSwv/q1b+C5bz8K\nAHj73UJcu//Nb8ULJx4DAKxxvleCEFNM4WScc9FwAMUmCYZI9/JTT+MY6z3vfOe7cZqpnoKt54DC\nSiX26Dg73tUL+auRg+zfu0lNXuP/P2jloOttjFdurNd636vZzUC17i5krNdjY6h2bGMb29jGNrYb\nsFsi4szzDO1OC3PpjI0ah/HAvm7IBJMTQobodNu47/4HAQCDOEGjKXVa24RVet0t281+kqUsszNN\ndNkmzDsqXutLp17Bm1mndYZ6rHccO4I2YTpTi/dip42KgZ/4HZOlMkC9zHQQYc7oyJpGvGmCMmvK\nNJVbukVhxalDeq15KcCALaNMVJRnsW2tZbz4RqmMuCtRTuHKePihwo++RaKFQdS34uBrbXncHvTQ\nY/SVwzSt9tGoSURglIVqlRBVQtUDRpIP3nYc/pCEJ9YqVkoBTpKC7zDCyzXQZylOohXKvEZrW3IM\nc/sPYG5B1HHWDFlCKxtNuIw8dZLayhlbc6rUDlLQqB5V24h05HmaSAyFhoZpmgyes2sjW6Orq4sC\nQxKvjNMbDYYoEfEwc264tY0pRjkTFNlvZwUKElccRj6+E1jyz9bqFjK+3uW1re6bQ8QSI8V6RygX\nPdZ0ZhV5f+BVbCnIsCfjirCMMueLJXvlBdZJSEvyED1et8CMq+chGso9ZOZhJx4g4fx0qZjz1S9/\nBf/wdiHUBGbSZaltLG2iVTd3kTBijgZyfOVmAw996IMAgC//6Z/ZSKjFUiXtKPRIoDHEtkqlYssq\nDHRfKFg944hphH7SA1hDOjUvaE6WAw7HwbQ9SwdDuJzPnSLHOtM6GU/lvR/9cSyweffnPi1En+1u\nhJiC/c8+IySjg/Pz2Lck6E5MPea8F2HIcqKC17kxMQldkbmxRTQriWM88W3RH953/E4EhO8HiVw/\nzy/bxuhvBFT7arYTtr2ZyMhGga8WAl/53I7Du1bj6DcCqr0VbBxxjm1sYxvb2MZ2A3ZLRJzKdRBO\nVFCECuGE5AJS03bKURjSA9+KJM+z2d7GjC9R5tT8AiZnxVMsUeCg3+nb5tCrG+KBrq134TrizRpt\n2D3TU1hZlxzh7Lx837mNNYTUA+0xksodoGQ6HjAc6kIhGojHOewO0avRoyRzfqq1jpAumNEXbXv+\nSJeW3mqvKJDQ+w3YgSEZxqjTq9UkXMw0Gjj1vFDsvQXJKw19hQsD8ZjLtSomSGw5MsluMTPTMHF7\nh7/RTXN0mT8NYlPmE6C3KhF3wtZsUzOHcf6EKKi0zknOR+1dQrvX5rGKV51rjYi52cxx0eS5bjPi\nvO+OO+Ey2tDpDuKHvrzI2lOOJTLpHepAVgDBCjnsKKbe4VU75rN5Bs0yG1Md4cKBZ77IaNpmBWqK\nXWZI8kqjCBX2VZtjwf7g/DIcRmwNlvEMdWobdrv8ES9X8Dz5vo3lTcQRFXd4rFE0RIs5b8e0O9MO\nCqPWU8hvNGslDJWMYZVRn9PNbYQ75HwIqxVsM4/sVQNEbARdYc4+cYFBZBqDy3NKaUsgK1N044nH\nHsHHKCAwVWOnFse1ZSiGHKRcF4aqNWQpxVY0xFvf8Q4AwJc//WmgJt85YKnV/r17sbksHYlc5i6H\nUWx5DEb8Aa5nCXI+51WjFFiS1+aakNPge/DYTafP30AG7KMgg9+cQERyWpMCCc+8cgZL+0V44p/9\ni18DAPzZb/8OTnxbhBIm+L4L51cwLGQcKowYa+UyMi6RmsdcqpUx4BRMKIbSbEzh7EtyH37nW3+D\n+z/0YTk/Nor3fB+9Hu+1EnOmeH3lKMZeTZP2ZuLbm40GX42c9EblOG+G6PNGR7i3xMbphQFmDu1F\nJ4mBTDa8IesBS5UKMt8IRMvj1NIiVtZE+STzAlxYl8XewH6u62OCm6kh6yilUE3lxrhIWDZNhvjK\n178GAPi5X/x5AEBnGGN+lmxawpGx50BzQSq4MZSqdXRIMupEGUokAhg27IzSaBLay2O5aKVSCSEZ\niR06AxEVR+S45fir1SrMmnKMLMH9exeQc3HpkqDT1TnmKwKDxmtrOHdOBOT7JIXoUogSIeTKrNS6\nlRuTmKbAd8TF0x3GeIU1iDUDNfcjKC4MpuZtefWSbd9lZNByNRKd98t1JCZxz2M9dsftVrjfQKyO\ncmB4cfbtrgsDgBSWUVlcpRyksYMoZN+1o16t0FYlyHxYuY7dWG2rzjzDLB2NdsHa2yK2UNrinAif\nPz94HBklH6usNXR1irIvC3jOzU3HjhW4X7u4hpROVWmKDpBfwWRTXo+m5FoEQRnVwDhpMg8GrQ7Y\nswB5j6o8uY9FShxuxxR+dzI8+7Is1keOHESdpKY6N3knKyzMmjC9EJYCq8zjE6rNt7s4e0bEz6cW\nZa5VSiH6jhkv4+wUCJlGyUjxHXQ72LNf2KTV40fRp4C8aYnXHwzsxptlRmGoZtuFmTZkaZIgN1fY\n9HP1AkugKfGeQeBbUXlQzhJOjql5uVaDogDIfO7SeZrau2hF+s+fkvvjgx/5MSyFcm/+yW/9NgDg\nHfe9BWliUiWEz4cFXBhykxxXEkfIuRbsIeu+5/hosdb8iUcexf5775NrsShjE2mNklH7Ghr4/cbB\nvlfbMHbbRH/A3KDL7PtVx+k4Nz52b/TGOYZqxza2sY1tbGO7Abs1Ik7fQ3N+GhcuXEBeIoxDuMSr\nltFjNBR3JBptNibhUiu07pfQN/AVCSC+69tylkEi3nEcx5iuyet3HJEO7/10iFfOiGj5xoZAtm65\njCee+S4AYJakFjgKOetKwQ70ebWOrMKoMYgQMQKJU4kc5ubmMFOiBm3MiMwfKbeY0pNBEsEnxGW8\n8un6JHorElG/+R6hue9d2IMqBeSNCLjrA5eek/oyuA4Knn9OSK3b3sKZc6JSs8nWXt1UQxNSXNgj\nnvrxpUWkFLE/yAh10Gphc1kgsuWzUuu2XhnpwMYkiCh4NgIsVyvokszkMzJfWFhAxIhHG01b52pI\nx9kBD9rX4KBQV1LPFXZjKHTYYNzXClUe4ywbSy9Nz2GOKYCK6VQF4NwJ+UyRmFKDHlzWDE42R7rG\nhSPzyynxCLRCiWOYcsyjLEbByLuz2UbKeVdjVH92eQVNT/42TZt1WqBWkedSQulxGqPG0oUJNlRv\nLS+jzcbhW6lEnJX5CeQkyOSuQmagRIOMFBlC/t1h2VGtNgmP0XhMVMKr1bDMSPFNnH/lSgMJyWIp\nIQGttSXcmfA+SIfI2R7ugR96K775bz8jn+cc2lxextLikowZo8tOa9tG/+ZeCAIfRvbKlE8UGDU/\nMI/JIIKjCDsT0tVpjrAqYzjMMkztkWj+3LJpWu+hMyDZj9e0mRV46H0fAADM877967/6MhozDZ6X\n0U+OgSHrUImC5FmGyCAobH+nAxc1plYurK7hxEtyTz50t9TZ9la3MDslakMnX5b1pj4nx/J6bbfa\nzluBePP9rOO8FaDaccQ5trGNbWxjG9sN2C0RcSIr4G3EwEoPjQob7DJHlm0PUKMHWGauzR1GmGyK\nl/niiy/i9uO3AQA0iQ++q7G1IV50jQo2k7UQJxzTbJZ5nprG4YckootYcrHHc/D2JdGqVLnkS84v\nt7FZCNklZa4i3s5x26Qcw21hgOHDDwMAfuSeNwMA6hUPDptCv9KSCPHZiy9guSWRrcnbhl4ZDssd\nyoyQVto97L9f8iTqzeK1rlUbtm2TsyARc9TawsLbxcP2tcLKaVEyqQ5lvOILq5jsslsGyx6CwEeS\nS6TlsPvLK0/8LSpVGZvSAzIeQeigy+MfUFmnmbuIGbn22ix/KDcQ+OJtX9rsYptRydF3vwsAsDHR\nQIsRihF68MMAysiPmlx2kaHGZuJt5rQ8x7HavpoiEjqK7bhW6XlWXQVFko2Oupipy3W5sy5jszQR\nImBWNaCv6ECjtcR87RrPc30Lk4wcXIciEUETm4E8t7hwAABQP3MGU4ZkU5LffcXdRJ8F8XF/A7or\necPahuS+lhBi3nTOOSCPaSXFqZzRIOd2kA5R4nm1h5LLTurACti9h03F+/0+JktCYNo+1cZ9D0lZ\n0qW2FPYHYYioTUUgIxbQSnFgSlCUZ188wXFNceprIiZy7Od+FgCw3LmIMpucb7A0oz5ZxyCSuWvU\no7p6j2kYg7c88CF881PSHLpgh5bbFw7jv/6lX5RjvCRz8//8zX+NuhFrqMk5t/MUrZwIDOdI5rgA\nSVuz7HoUxT04pkUaI9RUZ5ihvvCM7+DCi5L3vY3dYvbWylg+Ic/NMf9ZdjJkjhC13vK2gwCAp7+n\n0Fk2yAhznQGgyya6kevkFkBY8Bg4d5P2BmaqQjKaKTysf0m0cf03idbwVK2OtbYgSJWDgvJ0Msdo\nXsA3UVg2hGIJi8OuM4EL2zbRkJEKBUCbCN0s4cr+reHbxvU+E+a7dSjZ2cFk52sj5Gc3ss9uEaNB\nEK6IBK2gCa5pRqDmWse4m2mOzW52ZTRq/2+IA2+Q3RIbp6MclMtl+L5vVSHy3BBKRon5KhfUcrWC\nDbZFKgUh2twAplmz6UChRvhT75BnMjV8PidYPoxQYV3YwLAbqz4Sw1PgRDh4/CgcCsO7NXn/qRef\nwWQiv/GXf/Lv8E8/+qNyDPOyKFaDGKdPC0x66Yxs4tkwty3EjGTYICkQ87h6lHFrzu3B298vUFJ5\nUmCv7ShGxGMwpKXGwiKGLYFT4zTDxJw4HRVHxqlRm8D2ijgEG2tSf+l7DrKBLAJBWW6+iVChVjXN\nEeW4NjY2sLoq390i67I+OWX7NBrHJoljKC5s07UJRCSfvOmQMB1ng7JtyaZ4noFWcIwyjzLXBChT\nq22F0omO0hZuDHnOqhxa+MyQjeA5KDhf7rrjAezfIxuKaT6UYEQeWmbt48XzZ3HSwIOEknOvhCEX\nDc0aQ+24SHjTRSR2FHAQD+WG75LU47o+QqYP+kWK02eEibznkBBuam7JXoNpirPDUajVxLEreFye\n49p6yszKJhVWgc7UaWo9Ou4sy5ER+j92RMb91KnTFk4yNalRlGJ9XY7B1Df/2EPvQ4USk0+wJRca\nVTQXhYx08JBAra+sLKPgINZIQEqzBBNsA7h3cY/Fr3IubHff9yZstuQ+feQxqXP0PA8x2dym3jYP\nvFFtZ7FjsaUjlWPIMXbtQmsXXMdDSDZ6mmuUCX0bEfu//PM/R5ub9gIdqkN7Z/CB97wdADBR43ke\nvx1PviIyhIYFHpY8OP7Orq5AkaSW4MMeD6hVJ9E3TPX6BHoU6f/Ww98AALzjZ38GA0LkfTpccS+B\nz+uc85r6qoBnxNkNSU+NWvAZ5S0lPHI5fUuoc+3fGrIGcvD4PVdDpzfSm/JKiHW3z75eOPT1wM6v\n1iLsjZbcG0O1Yxvb2MY2trHdgN0SEWcUR3j++eextraGSVK8G2xD5PoeIpZuDOjJ9QZ924KrHJZw\n8aJAoUZT1FWOLfswHezr9Tr6bXqF9BeipECF3qptaeX4iOmcGDp/Px/AIaukwse7jx9GuSuR2IMP\n3I19BwUWTDw51lriYPmclL2sXxKv29EhfJYvZCSSaE8jM7WJLE0oT8+jPCeQ2qU+1UeqNWjS/Nus\nUe1nGWboWW53+9g7LRFnytAgmJtFmTV8FUbP5dBHzmbanmvgTSAkVDtg5LK2so6Yvx2wcWw/z2wH\ne9P+aRgnCDjWzaCChL/94H6JfMrDAgOSKTzW2HhuaKPFAclUOi0wZCPuKUbO8SBCRuUdo7WLLIXL\nc/YY/TcmJnDHgswbHwAJ/zCATgzgQk+i7Fcobn769Gn0Fvbz/KgWVGmgz7lWMNLNXR85ofTCEKOy\n1BKeun1qyIYBghKjx6iD7z4jjbDf8cEPyTj4IVZXJII/xHIgeB4SRuiajw4K9Bh9hiTAhK4Dh1Bu\naMhpaQ7NqGs4jJFFAr+vUuw96nbs/WBAlzzXcEmGKTGiqVVLOEUo88++KJquG/0ebntQYMYj94iW\n6/s+8mHbjNq0qBu6KdJM7qn5hSnUDsmc7bGJ9EZrFd9+VO7NTldSHWGtZGush3xUqMAlxO+wjMTV\nLnyec6kk17szHCJhLbDDFMzB+9+C47dLqmaj18dp6sx++g/+UK7Po48CrJ2emCb5R2f4fxkBH1gU\n6HRmegJH9ktbsZiKYNFwYFEGqy3t+KhTQD4k1JwmwEZP7qlSuWpVnp57QmDz+sElzJMoBJb3zE/M\nWjKgmePIc9v8wOWcUy5sS7wRbjKKd0zzBncUYwJQVmlLF1dHccZ2a0N25d9XvvdaUerN2vfz+15P\no+pXs9e0cSqlfh/AjwFY01rfzeemAPx7AAcBnAHwCa11S8kR/gaAHwUwAPAPtdZPXu/7y6Uy7rrr\nLjiOYyeogQnhKIRm4k8IDNqYaFoW5dTUlIVtTR1ks96wRfCGPdjv9+Fxc3Qpf1UuPATMV9RCgZyG\nSQGnPioiB4DCKVDwoqZcoKrFEGEhi/4n/sFPwduUTdLkKM6/eBFby5JHcVncXvJr6MeyKMZk2uog\nhDabGpl3R+97ENUFgchaLfmOfl4gNfVzzNX6bogpQlP9rS5y/r1KFnIJPiJ259gmDNrTOXzWL+Y8\n1iKPEVSMIDVF14dDhFzMmg1ZcM4lQxSEKEvcOD0XCDmN3EGM2+YE+prlBuoPMvh0CIbMlaaea+v2\nhjXCbGkKcEHeoGRgnqQWpi9V5H1O4NuFpjCdO5SCkVzPAbDqz07uC8vLeJndLUyN3uyRw2gVAmHm\nRgax7CNJ5ZsCMloRljEkvGa6o3T7PQtHGshQB4G9Of2ghBdelM0j4nilhQvfLIachwvH78CA7M/a\nhGz8VVeht81FmHBx2GjYuW0Wl7Qo4BkhgURJP0yMZAHTeIhNio2bmmhdAPFQNqseN+qv/OUXCIQC\n/+iXf0nGuFTC//67vwMAWDkvtY9f+tSn8OAH3w8A+OVf/RX5vpLCoNPmMIXYt0/m79lt2Sy3uuvo\n0hGZbsh4JnEVBWHPlI5wPkwBTWF71mKrAnY+tPgbpUoFC6xrbnEc7rzrTYhYO93uDwBfrv4//7Vf\nBwAMtrbx3OOygX3xs38CANjutJFfkPTJi2SdHzl0AEtd9iU1OTuUUKKjW5ikfJ4hj8lM5rxJohRL\ne8Vp6KQFVjdl7epFcs5nn/su3vOB9wAAHv2eOFS1qWlbC50wp1q47kiM3FxvAEY3xAjgA5fpgFhz\nLvvb9JO9sQ1jtw329bzv1exa33G9TfR6r10rx/l3BdV+CsCHr3juvwHwda31MQBf5/8B4CMAjvHf\nrwL4zdd/mGMb29jGNrax3Rr2miJOrfVfK6UOXvH0fwzgvfz7DwE8DOCf8fn/S4tb8LdKqQml1ILW\nevla35/nOTrbbWitMcWo0iUslmSphcMuXJAkf372LBapypEGKVx6E6v03huVGlJ6ukY0XucFXNPd\nkdBh1QuR0/OeqAoMtd5rozTHXpKEUuAWcBipNEmMaJ8+g3uPyjG4gy2kA4l6O4TKLr1wEr0t8ag9\nJZGKixgJGa+ZSeo7IWISWxpNOYbpfQdwkVHjgHDVQCl4jPwaJHukukDrFYmQtrMCPY5ZRPatDkJ4\nExJJh6xDTfsdS3YrBmTX6gg1jnuJcKnW2raZMko8QzWS13MDiW5r1Rr8TL67iBPcte8gAKB/Xjz6\n0jCGY1iUJfGiu3mKhC6zgVtr5QCKkfc8GYpJEFuymDaQbZIgSRgZJGQR6gIXl2VuTE9PW2JYTJHz\nVquFgmNn+pvGYYiikPGOSZaquCEcnzWbVbKe6zW0GJVsU7y81d4CeKweodNhkaFg9BmWytgiCWeD\nEobh9B7UKEZuxPx/6id/Gt/58lcAAGWDp8YRykZAn3OuVPatWoppS6dShRr7t6ostSzMmaaM3fql\nFQxZm3vfA9IQYXFpH06fPQMAGDAKbfcHeI5M1LffL4zq2+68Cw/eK80P/od/9a8AACtRhHOPPg4A\n+J+/9yIA4Jd+/V/g0D5BRpqhDyeTcRxsyr3wzOoG7jggx0MQB7WJCjxC0M62PLa6AzvHSoSSnUJZ\nMXmPUeQwL9CPBOVpE1GaX9qHPoXhg0oVdcKZHc6R+f378W6Sn975Xon6tlYv4utf+RIA4MTLL8i4\n+iVsdRhVmj6ajoZyZJ66/F4PyhLozHoyPT2BAX+vvbmJOfbznJmQ6929cBqr33sGAHCczOoLWysA\nkSODLCg/RMHnMqYmhnmBlERCkxLhAMlnmPJxUEDxeBw9Anff6Ejrenaz8nk3CtFeL4q8VsR5M2pD\n17PX8217dmyGKwD28O9FAOd3vO8Cn7vMlFK/qpR6XCn1+JBQzNjGNraxjW1st7q9IeQgrbVWajfU\n/bqf+SSATwLA/O136tnZWfQGfVSYa1PE+H0doMTc0vSs5FB838eLL4rX22w2R/qvpmTEdTGg9288\njn63B78k0ZcpUfE8F44Wb69GL/jiZsvqZaasI0MaY46RRdgWQtD9e+fwtn2S11h96SmoWPJJy2fE\ne19faSEZGvIG6966fWQsyXCNGDcUKDKDOktPMsfBuYvik4Q85zQI4FHou6A32h5EmGQkpTs9tOi1\nu3xu6PtwWI/XqLMdUxQjIPkh70jk2isSZMw5thjpbm21kDEqyflY+B4YLNmIpVFv2oi/WWliYY8c\nb4cRV7u7DbDmNnLlN1Y6LWwnEp2U2Jx8en4GTUa95SU5rrrnWd3ahHnGBBq5b/RMmVrlgRoAACAA\nSURBVA/KE5uL6nQ6WGdNrtHQrdZqmGQJSI9R2Pm1NeR1KcnImHMc5NqqDvmMfGYX5vHUs6Ikdfqs\n5C17/TZc5pvLzNtmeY6EOWO/FEoPLEjkBwBHlo4DjEo0EY+3v+MhnH1e6im3zgqpZXNrDQVlWOus\nRQxCB0YtyfNMfje3+d/QD1AlyrCH8+Xs6dMok/hmeiYP4z5WqNPcIYqzubWFu46LCPr/+N//twCk\nMfYHPvAjAIBf/6f/FQDgC1/4Al5gntggP//dz/9neBfbir3vnW/HbUtCtJl/6Ifld/MUR5eIyvBa\nnD5xGhSVgmOiq1yBwaVt4u0WDnLmAAPO4eX1VWy+LNcAzCnuO3DQKgdpx8EW64xN2VesFXoc9ybf\nN3vkOH76l+W4LrJs5TOf+SOUTQ6aS5nrOVC8zub4kyKFQyTK4TXOEGHIe312bhp72J7s5LrkOtNu\nC3/0G/8bAODjP/cJAMDE7XfDNWpknM+JVujzWFNTluOWLHEqtfWVBZQR4ecz0AVcU7OJAqZ8BiD5\n8XVEnq89n/n9FWzfVYv3WnWbr+N3Xou9no1z1UCwSqkFAGt8/iKAfTvet8Tnrml5UaDf76PX6VrS\nDwy7zPfgcmKZziLlahX3suN6v9vFFvtwvsQOBUWWW8j36GERC5ibmcW5ZVnMAwNBphnKhIEGhLqU\nciw8aKTRpssBGqzTqrFm9MGjh+BSiq7e3kavLQuSw56Z0XBo2bIDEje2Ox1Q7x2pEUuHg4BF7Xu5\nEVcqFRwiuzjizXyhvY2LazLEFUqHKd9HbZGygGtbWOkIjLf3EPuWJkO0TQcN/l655KHS4AZF1nC8\ntYFBTz67QYbyyqVl+BQaMHw9T3kISZoZdOR743IO5ckYHr7rdqBESbTcwNxATiF7TTk7RG1snhf4\nc51EmOZUE/sOCMt141Fxivbu3Ys5CniHZVkAGtUaytxsC5IlesMITmkE5wU8r4KM4jiOsELCkem4\nUa/WLMHEMKvzNEbC4n4VyjkfOXoQzz0sf29tyvjnWYyCY2PGMHOA2LAjs8T2u9zm4hmUG+hHMjeM\npF5rbQNsoIEuyWK9oYZPWTm/Kht7NOxDm6JBdgdRfoFoyIU7V6hyk13aKxvC8+WKFf948onH5PvK\nJSvSb4QEZqabUEY4hDzk7uoqPv3J3+apyGvvese78bbjdwAAnqCgeXV2EpeeegoA8NkXn0OTBK4j\n++QYDi7tRY3XJeS1unTmnJXVM07y1ISC25PfiVKzOLpoEtrebrMfbLVpxeffdN8DAID6xCQ26DA7\ntRpKJEcl3NTObazBobfX5D213Wmhy16ns4ePAwB+8pd+BbMnZO4vr8jjqZdfxnkK4Pc7rGX2PcwR\nbp2uiYP31COP4P77RPhkenoa57gZr5+Vz+6/7ShOnRWS1Tf+6NMAgNs+8QlMzAhIN7VHxissN8BM\nDpzMkJK0JZUZEpRWjoVlzfaodLEDts2gWMCpmCYCroZSX43ReqNMWl3c3Ma5G9v3tTx35ffs9vf3\ny14PVPs5AL/Av38BwF/seP7nldgPA2hfL785trGNbWxjG9vfJ3ut5SifgRCBZpRSFwD8GoD/CcAf\nK6V+CcBZAJ/g278EKUU5CSlH+cXXfDCeZ8k8Rkw8Kwrbfmh7KB57t9u1MJXneVZyb0Ax6+nJSesZ\nLS/Lnh1FEZpz4uEpwqTpIMFEVUozen2JdEPHg0fR+Co9cXerjZSR2EO3S13b0azAxinxKIPOKlrn\nBEJqbYq3GetpuBSqT7TxpgeIGM1GrHVR1QKTc+JxHjkggfqgvW17eBqo6J6DB7Ddl8itb3p5RgN8\nj0SN50+8ZIXv994hXrQKPUSk/PskOVT9EFuEMqfpmIVhCJdyXhHJF71eF1VGTQnHw/fKcNmTspOK\nl9/LhtCEuefvOII2YcjKpERASZIgYbRkatTKvo8+j+H5x6lWgwKHDwtkeNs97+Znhzh7Rjz17a5c\n27BawaHb5HrPLgkxxQ98OEOKm2sNo/GlCHGVAg8NRpUD1l/GnTaaMzLeNcKtcauHlIQppeS5A4vz\nmKKkm0dykEKOIpOIpcTazYrjoMtxSod9VI06FT+TFT4GFJOfnxRE4MmXn8B2n9J9TYFYF0s1eKYG\nj+PWa/eQsyahyqhOuwV6A0EJijSHX5FIa4HEFKUUphlhrawLXDxMY1tSs7EmEfjMzCTOnJR7pEJE\n5+ihozh98gwA4M5jMtbPP/Y4NFMFd90lxCG9vY6YvneQKlRiufann5a+scOVFWxtrvN3hCTka2V7\ni5pGDPV6HWkR87rIPHSVjwpJXl6Ngu5BgP6WRP0Hj0rNZWVyEj324BzkOQapScPIZ2YW96HflnVj\nvScwfbXWtGL427yO4dQMJu6TSHKPL3KXP+S6SEnGWj0rCMlLzzyNE08LdP8ElcEO3XMvNklGPP/C\nc/AYFd9+REpndJrgOFsVOpx/f/r7v4O77hWZxAffKaSlpaN3Y4JlcQVTOu1kiIiqZiAZDBq2TtMx\nqj3QVolJ6xwaV/e9fC11nNeq7Xwj+mjuZtdSNLrR6Hi3972W52/WXiur9ueu8dL7d3mvBvBPXs9B\njW1sYxvb2MZ2q9otoRzkuS6mJybR7XYtLT2hVxGUSla9o0atyaIobElClmU4c+YMAGCWxIi1lRXc\ndkyiLkNDbtbqWIkkaumsSb6it76FzXX5ey8T+n5eYIbeqEOWxlzgY5L5mPJ5IUaceOFFdE5LTrXd\nXcG5dSF3zFPb87wHnF0Wj3SLIgZFEFpauymDyYaAZu7sO9+Qptr9fCT4fug2iXCXDh/GHPNYOSOp\nPPABnnOcRNhk1Hj+vES9p5cvYvGgHE+NEXxZaVQM+Yld6acnJrHNY2htSSlBnueImN9iTTrUILPF\n65MkMk0vLuLCmuTx+lUPs0ckijtDD70x2YBmuYrOTBlQDW99QLztOYoxnDzxMlZJiHpuQ0THDx87\naoWiOwPmST0HvYtyDQ4TaWjMzqBC7VUV+phgpGUEHBzHtQ2xe5xXeeDjYl+ufdajAEIRY4JEprKW\nOXfx0gVsb0p0PMGC/GazDpf5zGgg79OOB5cIRXc7QmNe0I2XnnoCAHDsYz14FMP32G5utdXFxKyg\nDQWVjfJBDwnLY1KOtSrVbfH72dUVjqGDEhVqfDdETMGJU0RBHM9Fwbzp+973PvndwLUa0AOW6qyt\nreE975IIP2JEduzIMRxaOggAOH3qDABgYW4PXJZNmDZkU80GBjEjZjcEDGmGovKdS2uoMX9fUIWq\nHw8RGUknV47fK9et8HtC8fJulI3QAUZXYRDiAPOs7/+IaEO3e314JP1kaWpJd6aco9PvQXmjsiUA\n2B5GMEQWzTy4dgusMVI0i2I27CPkcwtvFk7F0be8BSefeRoA8OS3/1rG/NlncWCv5OILz0GJKFFo\nyGuJRoXnReAH+5o1nHpKynu21+See/eHMxy9V3K3IcfQTxXK9ar9bkCIeeY+NMLqOiuQcE6WQhf1\nuqwVrc6VbflGtlt+ERipJO0WVV5Pl/bVGlfv9pl8h5b49d638zmDNt6I3UrkoDfU8jxHJSzZnn9l\nylplRWEHymyqcJQlCjlQKNihwqOM2KDXsxtmyg2qU2jkpBfOLciitm9+L6K2QDHbLVlEX3z6CZQT\ngSEPNyt8bGCGdWPVVVk0hqur6HHC59tbUH3ZZE8+KXVhJxvT6HRlITIKIb6vUDDRb9L6cdRBxAn/\nN1+TjaOf5hgSzsq50SrPx/SMbJJ33PUmebzjLkxy87j32HG8dEk277175fwqE5WRQg9l3L79t3+L\ntx0TmKvGHbHkOvDNzkKoK0kSpCnFuLlhzEzvxTqdgBYhzYtb6wDHqV/yUKnJtVp64B4AwObaOrIB\nv5vMqMArY54w3Oy0QHiH9h3E6rKM7cqLrNfdbuMiWaB9bpyZ0pZFGRKybtx7LzbI4p2Z34PWhlxL\nxZpb1/fhk1w0u0fk7rIsg64bmIsLvtKo8FwDQ25KEoDXfsjfc4oCPiHrwnQeSRL4JJ01SiXLvNyi\nwHiWFajR8VnfkDFsNKex5YnTUZ2Q+bydFqhOlHjOHR5LAZWRZENY0lUaBTfqIk/Q5Qb+DJVpXD/E\noSMyD0ynk1OnTuDsuTN8nbB5uYzTJ4Qtm/Lanz51FgNudBNUNModjW32wy2Rwbu93obLTU15Gn1u\n/oZxHIQ+SmwAsL3FfqlhCT6hdKKRGA6HSHIq5Zj1zVf29dRsOsrDgYMCf5pOQdtphphzI3dd+FUZ\nuywi+xgOHCNvaasbHdsBxSzHhXKwyaYHRr1Iqxw5u8P0SAqcKoUo7Rfn8L6qyCku3nYMf/V/iyrR\nkflZlExqg9fHUQoOWT8TrMFupH3MLlGikO//1l9+Huur4qS97YMfBSCkxlPszatJZCwHATQ3gmHM\nNSaLYPZppVzL6B+1Orhxux4sey0x+Ot9fje49WbsVug3OhZ5H9vYxja2sY3tBuyWiDiLPMeg10eS\nJBgwctjrizeW5pmtRzPeqO/7NgrVWo+Eshn2Z0l6FdzgKsf2DjTalyrNUWeEO78ghI07D+7HUijf\nPUvIzN1cR4X1jZpworfdgiLUWVIBDi5K2cupNYHStgcD5CaBT6JPUCmjUhKPs0yR+maaYmiqNFjv\n6Xb6Fqar1tmmrFpDHMnrT37lywCAr//7P8bEnULUeOcHHkJlQaK3I8cOyhhONK3azTTLc+5630No\nnRDCTbMmEVBDa2wTlgW9X1dpq+6TsPQiurhslX7mSULpBg7mjpEE0Shjg30zb98nUe12lqBO6FSz\npKe/toVNU3ZkakX9EGFDrsEDb5VrH5RKWFmR8TTqUZkusM3rd/aUnMd3vvVt3PdWgbgu1Go4epvA\n9I1pgW/TrECfZSa9cxKV79u3DwEhZFM64rjKlNTBZcSp8gJlQqsOI580HqJMUpCrCQ3GLdsKql4p\noc+Ic+WcRJzJMEKV0XWPEbHvObblV0byE5RjyzUMxB8PB1AUyNeuqWFVUBk9+kKjz3TG/8feewZb\ndp1XYmufePN99+XU/V7nBtAIJAgQBBhFSQQlSlSghhpRI2scZHlKTmPXTE2NXQ7lKdeU/WNctkuy\nxqORKYnKEiWKmSIhAkQkMhpA5/Bevxxuvuee6B/f2vs+AA9AN0BpeqrurkL1ww3nnrPPPnvvb31r\nre/UIeoTV5ZxkVIK7aAUdDvGWLxLSclWvImJCYlMixwP/SRESseq1R2eQ5yiVBQ4NU9NrGcVsEvy\nT7/VR4FSJY+QYhC04bqUQRFWjpIMNq8h4bPZDwJ0CTVn1HbajoOECJNTlLHbT4EDR+TeZpRARXFi\nyr5lyt4nGkkHEc+eV/Vr6Z4XmyTX+ESrcoU8FM8n4DjdhcJISZ7dUZK8ihPj+GmmCr70hc/jxJTc\n55REOztJDNkvJXluzPNMyTxQ/7uzvoJXnngUwEAideJ99+PgqBzv6qYQuhyrbIiAHp2ZO4gR89kN\n+7Exd/9BtbeDYd/qMz9oI/d30n7QUeow4hy2YRu2YRu2YbuBdlNEnLZto1qtIkVm5CN7m5am7NRl\nx5WmKSraMWdPxKl3AVEUmbzUa7wKuSPTO2K/mEeFuVKbJgU1V2GO4vC7uAPvnT+D9dOSu/RZccJP\ns0FZINfHlXXZmT/+vBCGSh+8y1TO6JC0s7ndQGpJrlGX1YqTDH3urLd47Cga7BhD5pXichV5VhmZ\n5bXPlspG2P/V3/s9jDDa2NqSKO3We96DW26XckZNVpCpFquo0EBhyqOYfnsLvToJTIzM8nkflkdi\nAdOy/d3ERAkBI5x6lOCH3yfR3onbb8fjpOq/RJeZuYlpHJtfAABMM1/Wr7ewTV/h7XUhJV29ehUN\nCKGo3ZX+KBdLAElSOeY1R0ZGcJA3Wkej3pkz2CaBp9Pp4AxdpXQZrPn5eSPNmKXjzNWXT8Mblz5x\nKafxCkUkjAz0a2mkUK0J8SPx5ZrjdtfIBfqsdhOih4T+oZbyEDFC0ZHdhdPP4cgUz2FUxtU1K4ND\nU4hnSBTptZpo8J7m8ixnloZwPeYFGZ3YySAqTvo9bFByci4v9298dATTRGXOvfIyAGBzc9OUxLrj\nlJBdDh05jC6fnzrJQZ0wRWFE+u7CVck7N3shYkZfX/++FDu67fAJhHTtcrIEBxmBdSiTiZSNtEsT\nDeYZbdcaOD5p6+iwj4RViixKgxzbMpFkkUS0zVYdk/NikhHpCMJx4RI1ClSGLsel0u9ng3lBmZeS\nQbYzG+Q6HR4nptFABMtUBvJIr4g6PWxrJzCCNJVKFWNEOT71y/8BvvjbvyV9S4LOWD6npyNYthxo\nBBY67O8SpUvHpiaxzlJrT31LUKVus4V7f0iK2s8TpWrGAQJyKvQ5l3N59FPK7OIYUazdj3DDbb/c\n5PVEmG8XRL6dJOZ629/Vd96q3RQLZxTHWFtbQ7lcNgbd+t+1jXUE4WsdbCampoxbkGs7ZmHNcRAV\nCgUD5fYID/bQw9QsWbfUEPb7PXQd6dBRDujZ0QJGOTmVSGg4XCjgSl+gtBIJBPV2B5t05ek5NawT\nbi0tCES5HgLdLvWnjR6/00JMopAiQzGxgCTWTDU5RrlcNoxJzcJLwr6plamJT7ayMEkot9NqYPus\nXOvXr14AAJx7+QUc/Mf/lfQZYbbNs2dw72EhFBXZNyvrm9gmEzfma45rIeOkmNFFp+SPIaNNWF0T\nQNLYbGL6/QgxSy7NjAuUe/vJ2zFNqFPTokbGcyiNyL0oT8siEZYqaBC6qrAMW5LGpg6nZlFvpgkC\nkq5KZBR/4NAiVpcEgr22dNUQZH7pF38BgFjS/f4Xfg8A8KlPfQoAcPzIUTSvCpSZ0MknKVegCMG6\n7NdeN0WuJL/Tt8haLFhocpPTJIzdVyUoLpxRlGgEGjaZtEW7j7IjfdOkA9SVc6fxEhehq2dF++j5\nOSS6bJpDs34VQ7s/aj++MI6R9WVcRd0ulpdIlMppJrSFhJsgjdrNzs5jnmzfIjeM15au4ZVzokHu\n0Psxcn1MLoimNmapuunD07jn/g8BAD7zazwvO4f6lkC1D33ly7hIM/wtjqVTiwsokZTV5jNnIcNg\nKeNiCjUw4eaa6ihlIPSMmkx4OYyxbJ1exFMkyMh8TZMEmXb94mJkAQAXYL1wWllmHJS0oXsKoMI0\nSqdP7W0QIEkIK/N4UZgiortR6GpHqV1TNq129Dg++bl/AAD4yu/8f3ItozVTO3WE7PxCLzZaU13W\nLcyAiATGFsfV2pkX8Z2mbGof/NmfAwAULQeJNoFnIQCVL6JM2D+IE7SYRrLexYLxVhpQ/fp+n7+R\n9ne1CGo3uB9UG0K1wzZswzZswzZsN9BuiojTsiyUy2Wsr6/jsSceBzAg8MzOz2FySnbJ2tWm1+sZ\nnZKtLLMDcWkMb9u22cHuLUGzdll2wjYp65VaBSqTHdsOtYh+YxcFbpwWCdudfvxhXGLF+AKT8utB\nhMskZzTLbby4LhFI4ND5yFHoMCIN6Cnq2QX4/iDSBCQayGh6rU3JgyBAoy4wopbYjNVqqI0LbKmL\ndHdbbSydFmh0dHwSfe5WNwgNX3z0e/gmfUN/+e9/Tq65XEWVG7aUkVtnbQ3dbYngdSmrLMsQ610a\nd9Zra5twtaasKFHHxMQE2vTIffqxJ9Csy2/f+uMS1Y7nSmZ3RsUEtndb2KUjS4M+tpsZ0CfBIj8l\n0O5otYJRymjau4zwdnawuSaEm4CwVjcMUJoTveqHTt2GT/3MzwAAIvbD1to1/PRnPgMAqHLcpJZC\nhQQypcvHBSHaNFjv86Z0OgnsvECFKYlPtl9A1OKO36YUwgVSjqUo6iIiaSPHcnVJcwvPfk90ug9/\nQ3Sq5188g/XL4kg1S1crx3KQJBKJNNusGmQNdvwOpTO2SqCVTX7OBmI5jxcIU2e2wgIJXKNjEjFv\nr13DFT4DWsqyW2/CJhGlx9vdDns4MiXw9H/2T6XMbuD5WCUCo8luV7sB7vqoRKG3fOxD2LkkZK3f\n/7//TwDApdMvohvIZ6eY9oh73UHkx2sStzD5O9bRIwYpFW3cni9VUSIxSZfkSuK+KdSdIIVD9Emb\n7KsMsOmhaqKENIGl5SgmeMmQ1WWsuT05npNYcBgVZwz5sxCwqP202Q+O56EFIgEAZk8JYe/nfuU/\nBgB88V//vzjIVMPWlqANx30PRcpLHEqgsqCPKtNEec4T9dYuzq8JXP4dluU7+b77MHtc9N0NolVb\n/QAxZTSp4yFTGt+58XajUO2bkYD+tghAw4hz2IZt2IZt2Ibt37N2U0ScWZYhCAKMj4/j6NGjAGBo\n+hsbG4YwVGVEMs2KGfq7WoYScVex141CGyrkcjlMMNrY6cvOstWow3HlO5MV+b35hVnkzkuO8MpZ\nIVVsnz+L++8U04GFU+Jc8vzaOi48JoSO55avou5J4n76sOQ4w3YHKXfCWSzn4PgeUu50u4yWgiSC\nxUi5R6eUQqmIkXHJG5qI2bXRY85KV6xo93tYqAlVvZdEyOhpqc0F1oMOnviWRDlVVoh476ETOHI3\nfXBJTrDjFCUKykco0t/oBsaJRHmye51ZnMMuvxMyR/Th++/Hp39M8obNIMbFC5Lnmi1LZLB1dQc2\npQYhz6EVhWiQqFVnzrfr+3An5b5+7+JlAMAtJ47BJYEpoZymPD6G8RMyRmz2R3NjEwnNAtYvX4FP\nh6krNFTI2Q5O3S3+o+fPCGmpn8Y4SKIMWEIscD30QhpPMKeYwEdxhHk1R0LmqJ8h8eV8kKOjUaKQ\n0DAiSVOzJVW2XPM3/uIPkdFgYP20nINXqCLPaL5WkD5eX99AnUQtj8iIsgdSLJ33c63UuNrYjoeE\npJhd5qjPX7wMlxHIGFGCQr6EiGXVbJbT890c6jQQUAW5947v4wzLnK0zV5YUbaz25LsFVsBJF+bx\nDIloqtXELI1FPvATMh6+3WkjIdFpi9V3qq5nDEFshszFvG/MI1rsoyhJDIKkq4KMjY8hinUEKJ+z\nbAcOkZYw6iPls2/pKjCZFHkGAKUjzyw1zjs65LQVYDdlPLlMtPqWA59/pyw9l1kKIYkHusC0X66g\n3pYcbmxZcBlSjx0SidrP/8qv4I9/4zcAADUd3beahpthaYKP78Pj+bSY0/fTCDVfzuHZ7z0MAOjH\nCRJyOCqziwCkGHaDkXlspQD7Trsl3Uh7faHotzNA2Pv5vwsJypAcxOY4DsbHxxFFkTF51/Z54+Pj\nRrdXp/bv8uXL5nO+7xtSUJEkD9d1BybxGsZJEgQcWB51mpWiB2XR5SOSyaOU80BEBHk+nD/+059G\nSiLJ178sRWAeXdnBOh+CyuwMIlcWznNkei4UqohIlNH6Ksf1jC5MsyAsBXgkULToChOEMaJUJilN\nDor9nCEUaQeUOBNyDgAsN3ZQo+1Xn5B2Xik0qIv92he/KP366c+gT5gnz0mqnM9jckwWuhjy3d2o\njiTSTj+0QWt3EXBFUXSeWVhYwPGD3CzAgkXzeoffHfFLZjF9lRuSzU4baVUmc2tC+g3VAmLCU5lm\nD9o2cpwAfJaL6oQ9bO/KeKjR8Hzq8CJCEijuuOMOLJ0VZvPx24RR3Nhax6sXBUZcWBRWZrPeQInj\nJtXwnu3CIcFHEXL3fKBKwlDmyvi5tryOzKGOk8QnFYXGYUk5ecMwTFPZfLTqW+ixCEFxTK4vb3nQ\n/nOry5flu7AxVpNrTaCdsjLjbgROhEkUIcr0axk6XJhKFTn28somLI7fO8n49H0fimMxJjM0SRJU\nWWZui24zmbLxylmpE/rcy7J5PPmBD2DigEDoK2RobyQBPLKPp0bm0KP7Vsr7st6oY0qX8CN0WvGU\nYSspbgLynm9SK524Y67JIVSrmK6wHBcNuhN5HpnxlQI8MnG79T4CEuiKJLapDMCeBVP6ODWsW8UF\nNgVQYw3PlBvQLMpMyTWb8KxvOwM3LpKpri0tYYzjOEWKrZb0g03Y9eDhQ/iPfk3su//w3/62nGuj\nZZ77AgeL6+RMCUVtA5RGrrnnEZ+FF579Ppb4DNzzw5+U37jtPYiZ/9nu9WViwaAW67tt18uG/bsw\nhn8nbajjHLZhG7ZhG7Zh+3fYboqIs5/FOJ9sYbRQBKgdzHG33drZQJfU7JFFygJ2Lbh0cUl22ki2\nJBK1bYkCLj3xNMYelB1gNk1tWc5GfEkIQPO+vDdV72Kex55qCaS0EAfIGAWMEDp84tFH8ezTIhtY\nokF84BUwMyrEm6QTwk8kUluoybGfbF4DZAOLhHT4XlZHTKgp9eW1NE3RjVkku0boJktgSmMRIkqi\nPpo7/de8pgBcoRdobuoAGroqcqrdSVzw8uBZ8sdTX/smbp8Uv9b5OYEgw7yFBqPwltLOLRUUGZ1k\n27Jbc6I+UkYYq4wadksj+EMSUiqTczizKxHDLplA67sbCEbls433SbTXjfro0wUJHekPd60Dh36e\njzz5ZQDAqVOn8LGPfUy+Q4g4QwZ7RCDFFneRTq6IbZajWmtHaJcpO2pLH7/3h38GCeVLVwmRt0Za\n+H5TSEY+4csJRBgnZJ1jpFTITaDeoxk5x8Mtxyt46Bt/AgCob0gUnXO2UfIoY8hCNGh+7uUkesw1\nmhjJKOMwRtmRKQ9FAyJkWYw01WXcBu5YRpaYaJ9XF3Em73ezDBlJa1Zdrnm0MIY6hYbPnLsMAJid\nm0JBOxXxeIXaKLp1ieJGeRLdVoJbq6J3vfCojPv33H0/nLxGduQYRzdSU7SgHHgI2zLgF2dF19vO\nZpEx6srVBMbtIkKBHsFeKs8MojZ8h6X8CEB4/Q6afCZn7EX52Po2yozytMzC8Sws7cpzHUchFIlz\nHp2PnHRgOq9RnkRZA7iVkW5iDUz1tcVY5mR77pUWjQzun3aBnSuWgK5ODzmALc/XDj+3EwCYFJTn\n7n/yLwEAl/67/xEJyWQTExLxR1kTaSRjKOcx0m1v4ABRqhqjzNvcCpaeeAgAqVNquQAAIABJREFU\nsL4iaaxbf/EfYuq4kJJUHCEjerNmd3hJjnnmNBQ9Uqwi4HMVdbX+dwx9lkgzUp0sMxrljLK9GMke\n1yXKiqIiXtteF+7uWwZsn9jtbaLkGIPocT/TeS012vtass/PpO8iCh1GnMM2bMM2bMM2bDfQboqI\nM01TBN0eWv3EyC90rqJUrcBm9Klzd0op5ItaWJ5HuUpDAO764izFii5g3ZVII8x7uG1cdoIWgX/X\ndRFpkg6LTV/dXIHPfNm1a0KQ+KMvfR2LBySKOXBc8nld28cGU0wj5ZopY/bwU0+b69LYvk9fTVgw\nBgjadShMQkRvIDQoDOo26FAjAzRBYc+OSzv5IE2MnEV/J0lTQ8NOuLNO0xSvvCIuSC5zSJNjY4aM\nFXC32Ww2ETM35JEclCWJMZbw6GIURRGazN3Fdh2bzKle9CWnmFlARIJMbDPnYVvIsaCyx1xpoeDA\ni+RvHWWurq7iySef5PXJdw8tLBopUkJReRRFJqft2A5GSCTqaJnM008bQpnF8z9x4gRuK4lkpk26\nf29lDfGWXEuLIZlfqeDWo0IIqx0Q9GJpNcTf+4yI0b/zRfn8+WfW4DAGsV0LIyzkvd2Q93PvYIu6\n325672v7vs9/EzUgFMUcF2ESw9WWxHQdstIEPnNtPRp2pJmFHmVCFy5IRN1uN00Uo3P2lpdHwvuy\n02khx7ya9trNHMuMSb27V66DjJInHVo4lg1PE520NCOzUSCa0uPz3+60Ud+V8XXPvZK//u7Lz2Nk\nnvc2DEyRbP0kpLCgrNfm2FK1h9CiiUOZ9ZaRzrutFPL643zwwR/Ft771NQDANe3PPVWBpeS5iCkV\nOzS/gK72Nq7JIFrdaGCU/sK7rI7ym7/5G3jgZ34eAPCBn/gprDS0FzTdzVQCh/OHJl0hTc1zH9oy\ndndaDVPke0Arysw8Yi5TKQADEuY7be+IMHQd0pjref/d5F5vioXTtm3UyhW4cYaEhBtNJnCtgSZT\nl3Uq5HLGScZJgYKiZRrhqsWji5hdkNI/TToD1bMQFy4LaaRKUkJaLsDlglmkf0ejtY1iTwbdSy+I\nRvKBT3wQU4TpyhywbcvHFkkEj525YAaqW5NJ21pvmUVG/2tZlhmA/UyXPRq4ndhmHO4ZTKbOktqz\nYA5m4ZiDN41TsyhrEkSUxEj5msPjREmMF06LS02e/ZXL+YZMoGGaMI6gCLMlhL8cNXBpGqO9Wq02\nhoxErSzLzH3ZIoFkZKyG1JSestgftqntmOeiXMx5yNF03e3La4cOHcLxo7JR0Qvy1sYmLp4/z/OW\n3z16+AjGeT6tRhMRz0FPCjs7O1hYWHjNeQVhiO6GLGp5SyarqYXjKB8SuL+1Lf1w7uIunqG2eONr\nJE7t7uIzn/oRuSYyhvuhQp+T1PbGKmqTwnbWBvkakn19e/3i92aL5H6v7fu+qx14lNn4hFzogiAw\npC6Qwe2mgEtWcaq4cKYxAi6c184JDL+2torxCute0lkL+apG89BotjFOrWLK34gtIOI5+NwQ246N\nlCQ9/Sz4no8cN1UWUx525sB3ZfPRpi2hnQU4d1pqYdYW5Tmcm5pAoOG+VKHAcwhZVizLgISYonlq\nFKC3GANG6LubcG+UFHPg3vfgUJ11eB/6BgBg3pmETe33JKHtEd+BVWCBAuKNpVGFkA5eepcS1tt4\n6pFvy3V6Pm65S+rdln1t2wh4eZ0PYF3PbhsWYWDttJQgQ2gYx/riUsPONYtptt/6deMLkK0X8Rto\ncTIY9/veiz2Lu35dkyzTvQu1/s47WLyHUO2wDduwDduwDdsNtJsi4kSaAWEM3/awTUmG9gq1LMus\n7oMSYTbaNNdGrOAQ6iRvALlqGT53Vw4dPZwoxa23SNQRNQSKDXc2sUt6u0PI48jUOI4fWQQAJA2B\nSGaqIxgbFai2QReg73zrIXzkp34WAPDT77sPX/jLrwAASozs8s0tsxuyMdgVadcfykehlIeYEbU2\nl0Y2CDR1Aj5DCr3P0VpQQNxS5NoTQ63XAWuYxFDaxJqvJUmCzU3RnF2kRKNULBhCUcTz83MFA2M1\nKQOq+VX0SXrRUXQul0PMKDRTCqUCIXRGezk/j74rfUbbT6S2QV4NjBjFMRTvo4Zam/UG2rw/GnU4\nduyYGQ+r11bMdTy3KySWyfEJjNPQ3aWzy9zc3GvOF5BoZ3pK3IZCjrlmK0ArkPPZbjFy7vURUwoS\n0snno/e+D2VG40FDvus5ZZSqFXMtLrWOPiN+xG8dXe7X3iq6fP1r5m9GX5alkLKTI6YFekEAxajF\nMYiOg4RkJJ3CSJIYeqz1KXO5dO4sZk6KfjZjBNtRCdgNiH2FDvspz2cvzmKkjGgU5RXKspAkOpWg\nnw+XPkuA4jgEMvg0tl8LZAy4aQ/PPi5axsU7BIm47fCHcIEG/5bjwiXM2GetPtFfsm9Mz6aG+GIZ\nQCeD2ieO2M+P9e0iyutx3lm1gWMffgAAsNEQFGTt6mUcGZGIuUqJTdJpoMii6X1frml6fAzLu9In\nFV+es7sXF/DcGUktfeuPfxc5lpKb+qQgI0k60IlrBMLKBm5sKa89Xywg1nC30jA2MCArDjSxSr+m\n++odhGHvBKq1TFcqIw3a73gZMuzVmMq/+5wDbjxWHkacwzZswzZswzZsN9BuiogzSxL0dlvIFcto\nsmB04cAhAJJfSyjh0MQOTawBAK+Yh8ccZ2dL6OuJk6HTY6RC143RUglq/TIAoAotznexSElJiSXL\n7pyeRJ67MB2dJJnC2Ysi4l9iVYyLSyv4EPMCsDwE3ME3SO/O5YvmPHXOLQlCpDqq1HlD2HCZ/+nw\nvUzt2QFpGjisASV8z/Yo1YSMKIWldESuI9gE9ut2x2mampzqLuntS0vLRqytc5zacUm+TLcZz0eX\nTjAezROSOEOPEVsMmIoPPqu77Jf7SdIB2UDFg3+1W4/NXGiWZSbS1JVxer0e8hS3j49LHnF0dNTs\nQus7u3jkkUcADMqO/dBHPorlFfGEnaQUp9VoYumy7NBtFmAGcrA8FnMmm6c44WBuRmQ0x2fk2ntb\nG3jkOcl7Lp+XqL3fjRGx77pBjF7E8Wfre3b90eXrX9vv/TRN9/2OHg9QA+KY4thM+gFSSlh0f7mO\ni0Qbg2gJRxQhTyF+viB9ff6Vl/DhBz8hr3Gc1dPQ5M7z1TL6bXluyqwAAs9DFL+2AHecpQZGSfRj\nnChjhqALgzuWhRyfiywQ5McK+7hGb98TCyKXWV++AsWxVq7W0Nf5L3q1JrY1QGJMhm5PtKSfmTeJ\nOW60gPOb5UJff5xrSDBBPsQHf1yclr70G7+OOJFr3qbEbqLgG//dQlGO3bMs1CYlp79L04qtjWWM\n+5pICHz/K2LUcu8JIcBNz80a56pel/K38ghscgyadI+CYw+MNfbEVbY2rUi1B3gKZTgV8pn4XRDg\nbqTt7VeN5hlC2p7jWVBGmjJA/15bvNwc8wbP4aZYOH3Px7GFQ+g0mhhhiSo9YYZhaCz0PLq5JK5t\nXstsC33ewCYJDaVaCcUS7cqYRLdyHk4KQosSiSkLk5M4SHbnNsk9XqON3StihJ00ZUHwx0dw5ZKQ\nJPKjMvH+l//Ff4MynVT+j9/+HdTb8tkyq8OvdbdNEjvU7M+wj7T/2sHmKWUWTi02ygbmKgbSTKzU\n1PTbq0mybD1wEth6cPC1eM9i6ugaiEjh8H1dyanX6xmmpC5d5nr2AN6kNZ2CBYtQ2Cir0ldrI0i5\ngeiGlhmgGt6t2BWEunYlNbqhDSilNXVyDsq2DJ6sXaO2NjYR0eHG52KJNMUuDd/1e57nwePErElA\nALBGZvXC4UM4+4rcPw399no9TE/JvSxWZBIKVAF1aj9fXZIJunl1BUfI4s1IUNo4dwlXz1+SfuDv\ndvMVrO0ss18teOzuaoWwZaP3lnDrfu1GoFrdNBHL2gs8ajP7KDFkjBy1imXPM/Vg9YBoWwqKsO2o\nK/d+9cIFbF4Whu3YtCxaq2lsoOFi3kOT9nwun7mJmWlsX5Y+iU06JYWtxzH/7fUT5Dgeinw2Hcs1\ns5mfycZtJO9ioynP+NXzcj9n73wvHNoy9tMMic7XaMNzpWAWTJ2vyAZLgm2YJBnSPSkVYH+I9e3K\na70ZSej1xwlKZaxxsVog2//9P/IgnqfD1wI3LPl+ghFu4MOYdU6zGDkyoV1uWnv1DZSoTy8V8li6\nIv3+7T/7cwDAxz/xIA7SzjTzSVBMYjgcBwXaVHqlAnpaM72HWKP1lnoTYmcpbB048HPRO1gE342j\nj9qH/AOo1yyiesOd7bkveiZM9tzKGz2PIVQ7bMM2bMM2bMN2A+2miDgtpZC3Xbx66QqmJmT31ScE\n4RXyxvg4irSzh2vkDGGWIGQF+82mRCLF4gwSRp9he0B9H+UuzOMu5NZ7JoAWHW7orvLQ8y/i3PMv\nAAAaLLWVK5TQZsJ81pJk/LNPP4sr3/4uAOBrX/kaTt59LwCgq0t+xQFi7uQjOgclKZDoQtYGsc3Q\nV9oNRl7LMACV9K4oQYbY/M3PKSBHiNVGBpd/a30mkBnyg6flAFAocgdbJKSWxbEhyBho1LIQaa2f\noyUXKXz6tlZrQsBRyjLG256XR4HHrG8JYaNULb2Btq6UMqwMLXlBasHieW+uC02/1WqZHbyGZ3u9\nnpG86AO7rmvkMf1+36ARC4uLAICxsTGcuPUW8z4AZJbCqy/Ifa7NSlrAKs8g8wTxcOiQVCvnMFPh\nWNuWiOq+B+7E45RNXLwm59psNuEQfs4XXPQD+WxjU6KEgvt6V5U3b9cTXb5ZxKl9Ta1MpFoAYHNg\nuUmCAv8uMySuej4yPksdjoGipdDjvXf1eF5fx9knngIA/ORn/x4A4FKWwiIkYvcDFDnWXJ7PqZMn\n8J0z4nnbZdrCUgo5aNhMFzeIwIwKciy1lTkKIZ+VWoHabmSo0Uj6L7/weQDAL0xOoXrkJACg3WzB\nyQs6EGn5AQZjWsN2VqqgTPQ5UHzqCPdGNX9vBtW+2WcAIHZ9dDmGVjlX3f7Ah3HpORmTYUvSKKut\nHSSU6sTapamQR8zfqXGcHp+bwe6OfKe3s4rpqrz+vZekqPuLxQImaPY/NS+kuKX6LgK6deVGa/yN\nRAfrUHRnU4CZnHS0Zqe2SQPpRzjAIIV2vW1vQY7rbfp+7u3pvfdnr/TERKQm8txDMtUwL268BNow\n4hy2YRu2YRu2YbuBdlNEnJ12B0899ji+89ffxi/+4i8BANosQnxgehJJQN9FRpRpFEnpHAClUgH5\nEfqBMq/p51w4pNh73JfkfQ+3knyyuiREH4yMobUkUejVR8Sh5szzz8Nn3upHHxAHmxAWtpj7WyEB\n4rd+698gsCltcF0Ekbyv6fe9fmCkJ4YybSukli5TxJxPFBmyjkuHoQxAovR3paWD+hiUpsjnfO6a\noiyGSz64b9yGTA1q+MzleFmGal7yukXtEBLFiFlCrFhm1Q/PRasj+cCIOdo0cRAz99Uiger85StY\nZymu2YOHkaePacuSHKfv5wGHkTf/TWyYfJJuSRYjJvHAsQb/asLNJgkNSZKYKjgllk/zHdfkQDc3\nN9GhG1SNZeguXLyIaRZD1zvc+fl5HGZh8CYdi86v7aLZE5ShsSo5zmq3gVKBco62eKJ2O1soR7K7\nL9JneNSz4NDpphXsQIVtnpv2OH3riHO/SOXt8p/7RZwWIwPLAiyOK0/LtCIg78r7JY6Vim0jz/5c\nob9wEUCs/Uo7NCQoRLj6vJgPTLEoei3pI2Pk5rS6yDPnlWPu+fj8HL7D40Q0V0gcD6mWsHCcdtIY\nHrVKJU1Qci1ELJVWZcTZ2tpBni4hW1cvAwD+9Hd+G7/6z/8nACLxKpDUFlE2laiBZMHepzttI6lQ\n+/rgvBt3mbf6bhCmpswedJHrJMXHPvtZAMAX/7WUISu7HtokPd52REhqxbwHcDbokriXSzOovIzF\netRFQuONQ6OCplx8+lnM0z3rQ7PiUV2wLbS1mQWj+93tLXh8rnQsrjLLROg6mrMzwLJ0BK+v6sYj\nzndSYNqYJuwhXe3nO2tlb/Q2UhmMJmVv5Hmj9/emWDh9z8ORg4uofPrTaDRkQtJkguTKEjq8uR5r\nZlpQxlnIcRxcXREyz/y8DIi8Ukh3BCKb4CLRXN3AyiPfAwDcfquYISdnLuAKoYwtQkrvv/UOFMuS\nZA84mB5+9FFsEA7eIInG9X1EZLtttFuYieUcZ0hOWcUmdraFjaThWc9zjVYxJe6qfAdxoDVn8p6f\ny8HmoNSLpJ/30aPp9fikwKT9fh+dDWGOjo2MoLkjvxcRWi25HsZK2mlejjM/MQ6Hif4+CTy2Z6OU\n0+QbLui9CLaGeUn26CUKIaG5xSNCNJg9uIA++3p9YwtBS/rp6kUhkrx64Qzu+/gHeQ1cqB2gTwax\nLh2VBokxwPeogaxUKoZkVObkUiyVzYOjB3sYhuZze2FgDenkcjnskFCknY/CKEJ3R8g+kwdEE+gV\nxtBo0kHq9Ivy3c4Ozp6VTdVEV/o3Pz6Bmi2T1ESeZcG2N9BuCTydK2UADbyjFnVy5cGkcr0uQW8F\nYyml9oWXCjku0P0+WnShmShI3xVShVESaWaKstkccXPocFNSZr9WpyaxQYKIZqfV+xHOPvYEAODM\n9x4FAMzefw963EhGUYLZGWGod5j+uPPoUdx1m0DkZ05LebJyqYC4S10mnauSXoxNamR1HdrR8VE0\nWE+1wvMq5z0opgpUKGPlpccfxbf+XAgwH/3MZ9GgHtvl6mw5Dhp1ObYu+zZRq8Di+wn1niOVMsLg\nxid+4LUsf+CNsOx+98kKgfEaLUD5oO0EHUNWuuvHpFzYynPPYP1lgW+32tRh9gKEDCLKFRYlSIEy\nYdsGIpSpB83XaV06UsY3//SPAQCHjzI1MT6KsZL0506bz1k+b+qlaitQZbnGYpNe/Aj7PeQYJGjN\ndrsfX/cG8K1qdL6pK9bbMM91228RNXr4vd/d57XrbUOodtiGbdiGbdiG7QbaTRFxxnGMjY0NlKoj\nyJVk92JTD9gO+vAZObSaspvsJzEKNdlR7S1+vbIisOv04mH4jFpGuGnvbjVw92HZaW0S5lleXsZo\nTWQVD9z3ATmXDHjmJdkdP/2K/LuTxIg1/ZuuNmG7jkbM3TaAq5uiCUzJkEijEAmdOqJI0/2TQQV7\nLRtwXRiza8JMynEQEfrtMdpWnjJJ+JAw9u7uFmb0hq3dxjjhyslRIcpYcYoad4MpC3oH27uosiyX\nrWE2yx04ajAatRUGBB7ur3KVEpqMuEuEOW0/h2JVPleo+rAn+Dd3qDs7G2gw2lu9Jv/mRqsosuBy\nojWbUQQHEg32OnJ9UT+ES9hcG7u7rmvcTrotiVySJDFQrWVZg4hUw9T53ED/GA+iuOl52fGvbQhi\nUSlNIVoTiLbUETeXibiL9912GAAwwyjSDUMsTMr1d54S398TC6PoXWKB561ljI9rGF++s4v927uh\n4+/XNMnLSVPkeN8cwrcF24aibCqERGE79TpSAlqK/RYlCcDjzLGo+EKpjItXpW8eZoR3zMqM3tf1\ni9ihqX6Nkq0DszP4yN3imXruWXF2CtoNdDvyuZD3Pu9asOmp2uK4L0QBctQ5pnV5rkdrI9hZEoSl\nVpL+nylb+O5ffQkAcOjYSRy4824AQEz2XS/LMFIkfEsdV5xEyBFWdujT22v3AMLEN9o0sqHbflHU\n61+rWD5cRmxacx4FPYxSjjfGSL0fBdjeFALaBeqSDxZyGKObUI8l4SIVIehLv+bzvknslImjdloN\nHGQB9T/7nX8LAPiH//gfY6Mp46A0Iv0Z2goRyWJINQkvhc1rdClfUV6CmATONsvyKUddN7FKv7a3\n7/aT7+z913zHkH/e5Nj6eBi0/QhD+3naXm+7KRbONE0RBAHKNctoH1WeUEovRY2MSacrk2MYh9gm\n6yxCiDCSG/fiUwIlHS2VMBdTF0YT7nKni+eeEVbgGC3ZPM/Fblvgt4svC2R7aWUNu5w0Ngh1JXkP\n9T4rs0SsLF90jSl71c/Q7RE6qQrs126ncKnoT5kjzKwMicb0dd1L1zYaS82qjZO+0VBWyRLMkggh\nJyZdq3S6PIJJMvL63R5GK/IwzerqId0AI1zwbZrn72xtwmMOStugWSqDMskLWqTZlslh6CryPdsC\nkS14hE6b3Q4iiuo91zG1GsfGaIoQB5iZktyK3Zfz6yBGfVsWmc0OLRF7wHhBJsrFIwL5RUHfPBjV\nklyTUgqZhumL2jTeQZ6QfBAE2GHtzVZL+mtyctI8GFrH2e52TP57hDnyqL6NxZJcS2VONlRHnQzz\nlty/5uWzAIBXz7yMx58VKLfNCezc5jY6zOcdnBnD+auyGM+NSb/Devuc5X5/32gLIunPku2gSIZq\nkfD0SD6PMjdDReba+0EXCcepx01rHAYA84t6o5d3PIxxkVw/Jyb7/pOPo1iR+zJSm8AWh/ZlS36v\nVB3FKebl/ut/9J8CEHvEF1+Uvrt0QdIjnTRChbrFZodphm4eE+Py3Ocj5gB3Gphnfm5tW+7tmO/j\n3Los6F/9oy/gs2OyAIwdllTCVhgaKziLm8I0SqC4ADg81yDo/0AWzutZNAFAtUN4Vc4lfGYixOhy\nRi6wLmzt2DHcSrj8xa9+Xa6p3TQwKcvswsnZ0FNLpVREm/OCG8omNOt1UPCkb9auSa7+3HPP4PC9\n9wAA6rToyyxlLBFVpCvbpMbONCGvNotTw9jXNVctK9sXgn0rWHavyft1w7Pxa7XwwMC8/TVmE1n2\nBlsLK3vtZwEuoDf4yA2h2mEbtmEbtmEbthtoN0XE6fs+Dh8+ithWaBLe7BKuSzFI7PrcEWZZhknq\nCOEDfdpU9UlyCJtNhKzNub4ikWD7wlU89KjoLqemZNe6sbNrXG9C7iEaQR8Bo64GmaaFasmUUuq2\nJEIdqRaN6Xerm8BX8nsaDok3d5ESrmxGWoelTOJa74Jt2zY7IO2IUy4UkWeiX9cijfoJxghJj5IA\nUq2UMN6WA0WWixzh7RyhzCSK4DO6LJIUUhgZQZeRNIx9lgul7fw0Rc52YGv3FV1yDIDFyDVHSKkd\n9hHw/sRZBCfT8DRJVK4Pj5EPunQs6ffgM3qZrQqsl7b6QEe+c+aMlH/b3t42UOA8tWeO45hja02m\n6w5YtemeGoM68pyamkKfELN2SInjGJGlXVfkPt4yNon6skCv87wOd2Mbf/6lP5Pfpu7u8rVLyIoS\nEWjCU7XmIGxLOH5tecmYdFeqwubdpOMNsP8u+vXvvdOmnxU75wFkVupo3Hc9TJA0ovV/SVzEDkln\nEZncadyHY+sIXUgj3VYb1Yo8cwXa8bmdOmzas23v7sAjCSkl23z10gXMzC/Kb9P8/9bDizixIPey\n2/0IAGBrcxUXz0s0v3T1khxvI8PESJXflX/ddoTRMXGV2t2RZ93zXByjA9SlF5/Hw38lMPKDn/sH\ncu3FomFWRiQUWZZjSE8RCUOu7b8DTih4vLeGavclB6UJQIKcX6K9pV1FJ5D+3qAL03hlFLfcJ2bw\n6MiYvPLEY0azPlmUiL9QsE2920zFCFOy5PnaTqeFiLP9oSlBU773za9jkvfCYlEN3/WwTVtNPX9Z\nXn5QlEEbwKeD+Ti1B/ac16uHNPrKfaDavX/v746VvuFz+0KxSr0Btn29zlO/9gPXcSqlfksptaGU\nemnPa/+bUupVpdQLSqk/V0qN8PVFpVRPKfUc//uNGzqbYRu2YRu2YRu2m7xdT8T52wD+LwCf3/Pa\nNwH8syzLYqXUvwTwzwD8U753Icuyu27kJJRlwcn56PQ6sDxdooo6s5ESQu60HOLrOdtFQsNLJ+9h\nhCbdt98iDiIztTGMhYwG1ySX5u12cHmT5aMi0XEmKVAckTxKsSr/tusNONxPjLNo9Wp9F+NTstNd\n3ZXjWZ0u1LZEEdMOMMtd3DijuahQgZWT38vR/idIM9iM8nT8oVRmtkMmd2dbpnRTj7ncgqVweFY8\nQrVDTXengSLtYaq1qnFx6VPHWHBcZJqKX5DjzUyMYYVyAK0VzeIMqd6O6pSDk0Fb6OrcUGRZGJ9h\nQe8x6a/Ey6PgSkSTJo7RSDkkGKwsX8PsYclZaqeidhIajWhsSyRycHoG8+OCBGx3JFI8e/YsLl2S\nCOTqVSFfhWFodpQ6V12tVk0+UymFSZ7j5o7IQ3ph38icRkmcSpIEHUboJV/Ov765ilJf+i4kSehL\nn/88FkiEWl0X+crhI8ewmcjn1ih/WFrZRGlcri9f9FEqyXjo9AeP2FtFmD+oHGdCR6DEVoiJ3uhc\ndhj3YVkVflLLnDzkU4kQO4wue3EAl31SYd680xlEoX2SezYvncW9HxBSXasbIiRZzmZ+PvUsbC2J\nCX6gNYuOayRBpih6sYi5u4XUE/AZ7nXbsHiOVijnfPBwDevL4j88x8Ly3aAPVxdHqFXwzEPfBABU\nJ+Seve/BBzE+KeOquynjSkGZkEF721q2hzeq/v72WqlUNLKPoCVjKLZTuJySLV1w3HHQ599H3i/u\nZGG/h/XTIlGJWXqt2Wsin5OIv99uwu1J3+WonXYRwiIC0Sdq1goCI+W584d+CAAwlTtpHKBSTbKz\nLGREnVJPS8EGudBmT5OS8u9IjvJWZdreLhJ8/Xf2y2Hu93n5LKPnvw1yUJZl31VKLb7utW/s+d/H\nAXzmhn71dS1JEjTaLXTjEPmSTGzalFe5DsJQbkyREGUuV8TKlmi8YhUhZhJbw7clx8EIoUnPIuTp\n5zBx9xEAwC23ngIAWF4OTz4jou4rZOut7TaQo8ZtjLq0fi/EVF5eayzL7wb1Ho6Wpfs++MH7cPSY\nHHuDuspAhejpBD6hyk4KJDGF5Vz8oiw1dQmrJFqE3Y4RZo9SnJ7PMng9VlmhOfRkPo8i+2YylzdV\nUZpkuxU9H61ug50sv2dXKshz1og4McVpYiCYJNaYTIbULJza8izG4UULY2McAAAgAElEQVTRqYLa\nzsRWsDytx0u1DNRArNPT0+iQ1LTcEFKCVyti8YCQRqo+2dGtECs0o4hZrDTv51CrCoQ0Pyv3Yqe+\ni3pdHvz1dTne2tqaMYbvx5GpfqPF1b1ez7ByNelqe3sbnVGBACfHZJEL19YwzknqkcdFq3ioMoK7\njt8KAPjaliycazt1jJ88AAD42EdkMjvy0ouoE2o+e3ELZ87KZzV7OMtkUZK///ag2pjn381C5MlU\nzdFqrZhlxqgDZHq7DgbVMHSxH99Gl5/TrNNcwYdDN40u7QS3r27Aulf2yItzU6jTQKGta2G6ylCb\ndY3UpeUVWJmMaYs6wcbONta4GHuWNo33YXOyLvD+BJ0uStRYa3LMxto6coTmgzBAiymTb3/pTwAA\n00cO4nZCuWXf4fntMf/mccIwBvwbg+t02yviv15j+FSlsF1dyIJFILqBea1IolaKFGvUKI9zfph9\n712IaSjRXZYgoLu5hgUWY3BChVxfjrPRls3j/NQEVvjcpCSDjRUrOPPsswCAgNdwd2bh2HuFMNTK\n9HwSokWyGPj8+LmCcUiIqH/dqzt+N2P77XSc1h7zlNdXP9kPiuUb8s+e3xncl383lnv/IYCv7vn/\nQ0qpZ5VSf6OU+tCbfUkp9StKqe8rpb7fY2HpYRu2YRu2YRu2m729K3KQUuqfQ3yWfo8vrQI4mGXZ\ntlLqbgBfVErdlu3dbrNlWfabAH4TAKZP3pr5+Rxcp4CExANt0tzu9IweL6DtXRKHGCkLFBOoHsJA\ndqvaGSTtR7Do9FMi3tjabuBjHxMLvTxJDOsb21im8XsQyG5pdnQKu4ROtq9KdHny0BE0CPvN06x7\ncqaGE8dF3/fR++5Hji7VL24IHPRyN4DHOoc5rd20bPR4PhEvKoMykE2ZJc4anS48wmtT1FcVkgQl\nbQZPaGpxahZWXc7RSzNUNWGFsKyVZoi5O8uT8NSv7yKviUlKk34ypDwHHTGmMQxsm3Jr6RTzOHRU\nImsdrYZxhJi70XYrQD91eL5yA9fW1lCdlChBR4WF0TIy9oM26EcQocDos88dse/7JkLU5J9ysYQK\niUka6kuSBCsr0g/dfoAuSWLa0eXChQu45x7ZRXt0SCpXK4jGJBJZWboMAPixY0fxzL/6VwCAjXNC\nUPrPf+5z+Po3vwMAOHlCkIrabYs4fJ+4Tz38okSmo9OjaF2TMbK6uYXRKYlIN7epF3D/diLMNxyP\n2qEoTXH0sKADB+lmdev4JLbOSjkuh7BdGLRNf8eE7i3fRotRDsU0sOAijuU7BY5TO5/i6mWRlExM\njWNqQtCicepxt5td7FB73W7K5nhhZga729JPMdMafqaMjKnKSCuLIqxeE0mPPSJoQ7cXYoJwfkRY\neXK0hj4lOMthF3NjglBoW83v/fXXYVdlvMwcvR0AkKSDqDDny+9JhP3OoNrX28ZdjySllwSGXKN1\n6rbtIdP1RBnFhVaGmPHNZiivVWcmMdYV2dvVpvSlXS4j4XivWD5KLFaw7smzOTk+gjpTNNoWs+vY\nKDEKv/DKK3Ke+RJGCINbVUEJXN831p0dFlhILRuuRvU47yTdyFzf9Y71NzPIf6uIcyBgeSNUu1/E\n/1a/I8cb2DJeb3vHEadS6pcBfArA5zKeSZZl/SzLtvn30wAuADj+Tn9j2IZt2IZt2IbtZmvvKOJU\nSj0I4J8A+EiWZd09r08A2MmyLFFKHQZwDMDFtztemiZot9twK0V06ELhcFeUWQrTU0KK6e+SvNBu\nocSdosoGlOYiRcPjtRGMBrIv8Zlbafdfwde+9m0AwNioRD6zcwdRobA+S2X32663kDHcvZuuJ1mS\n4sqauAjddVLICx/78AOYGZfdLTo9LJ8WEku2Rb/YVhtZV6Ipi6WLHN+Go0sqaRcMZAaxT5kjGKmW\nkdNEH9LSJyoVfOCU7JjbGzQbbzUxwevrtNrwtbUQpQa9Vhse80QV5j+a7RY8+lPqSDJCanKu2pg+\nTVMoRvCGjDM5gSPHZacbkJCV9WOELEHVDXrIaDzh0kDe8zxDyOmTqNBNIqTMseVZKNnyFELKS/pK\n/o3j2LgEaS/aRqNhokYdhYZhiCmauNuea4hAOhL4xje+gQqlDVU64ZRKJXSJBEyxkPC1y+fw/UfF\nz/gXPiroxPmXX8EH7n0/AOD2HxYCxXevnEaBx5s9KHT+Thzg1YtCKHL9PJYoMh+fkn3jbkfcX96s\n/aDIQdpeKkWGhSOCiBw+JI5Z9992O75PlxqXEefW9gpamyyBRsJW6tgG8akxmojD1HjaFvP0P0aK\nJUZ27733/Wg1BW2JGHG6Th7Hjso5LLM/8rkSbI5z/Swk/RAbKywcbn4jZwwcllek744eOID2lpDz\nxpnXPDg5iUefeAwAMDcxiaWOjJODsxI1Pf34Y8ix8PbPHBXEIJfLo82C5QVKQRI/Qwwzld1Qe7uI\nc78oyMl5aLfk93Rh72q+bIradzTJMItg+VoyR3KPreDWKNFhNF2dm4dFjoBv+6jyuo5Pyb1qBQFm\nZ+QZWaaHtu04KJCMqWjkceHMGVh/LfPkyfcxf3/nXfB1QYjdAbEoyrS3tIyRbE8/XO943k+OsjfH\nuf8xBv2r3X/2y11aWWbkWdjn/XfznL3twqmU+n0AHwUwrpRaBvA/QFi0PoBv8iQez7LsVwF8GMD/\nrJSKIKnjX82ybOftfsNybBQmqlhtrGGEOrNySDeaegGFrkACkV4YRhNkviywxwsjOP0SjbldWVie\nK9+CHUsG0cm6sPBmDjawHgnME5A8c+a507jnmCyESyT1PHPpDOIR+Z3lkrx26eI5lKZlUBy+hXDi\n1iu4eEke0ubOFmYOysMZtGUiaW0mqBS1Zo66wlYPE5x0VusCsbTiHrqpXEuRC0Kjsw0+I8iV6Xzk\nKdhEvKfJGHx1fQ0PVOXvpbiHHi3oGn1q74rABm3idjIZ8E4eKJD9mNcTXDtAhYtbN9GkghC5Edlg\nrDTkXEceeBDnAzlHl4tlEgQo+xzwUd8sopU5If84mx46NMB3WT0knwwcWgLqdaGAHjcvtYr8bnd3\nFzYXaF2LsDo2aRbTlMM3yRL0OdPbaYIidX8Tt8j9bjV7ODC7KH3DRbXb6qO5+X05NnVo4ZVrmCQJ\nbOGEQNJXc6/gjv/25wAALz37NABg8tRB/O6v/z4AoNCR7z7/8BM4MCvw7PvtKuYmpL+XOuJm5ftj\n5prbu3IOruMg72g9JU3vrUHVlx3m/m3Phc/KP5vU2CnXQYtuL04+h5hw5aktOXbOd3CgLYtM+6r0\n15WKhfk75bpKZJMXNho4WpQN4F/8lTBSX3jhNEZHBN5d25ExNVosQCn5vW5Ha4PHsEPi2O6BO1G8\nVZ6/NcKMa9sN9AmpxrznxaCOfEUmrsNclINrdbg1jv2ePJs7dopGRa55wZNFd/PSEziwIJuAbl9r\nqDtwZuRadrYayOfkWrxN6afDSQmrf/GQ/M60POsf/fiPopmQhU2T+tX1dZyrCSRsasS6trHNSkja\niVSCiBNuzFm7E/ShTB1bx8B4DjXiFhSsTNtXSsucCJ6mr/ZYWKHfgKKTUZEpq75lI6B9YJ9Qcjfs\noThOwtddsjFbevYZlFx5bmzbRYPppkOxfG6zvoWUz/EkKyDt9BuYsOT6M1v+PVQuo/Wi9NfEjDxH\nU+Nj6DjUP4ecj4pjWF6XsVGdI/lqdwsBV5S2m6Lhk8Dky3nHSGCzalWRhM5qX5m/fa5ymbLQJx7b\n8aU3Ox7Q532ZC7i5hzJVlnRKKoGNUKe0lELKfk/0Ip/34LJvtTa/3dpF2B/orK+nXQ+r9u/v8/K/\neZPP/imAP72hMxi2YRu2YRu2Yfv3qN0UzkFhGGLpylU0oyY87ioKrE1p2XuNg1lqLElM1NG38wBJ\nDfpiNq8tYxyyW9dQxOTcATS2ZPf7UTpxfOPPv4ylNdnNlmgo/f577sNLS+LF2SC8lGymuPceIYN8\n6M73AQDqFy7jEjVlqeOgPCfQkBfLLkxdXIVi9BXRlN2xLLToNqTPGWkMj9e3uSw7woMHR/Dh++8D\nAFw9L+dy33vvxU9+4icAAGuX5XevLC3jhQtCYqmMjyKhHGVrS4L8tJyDRwKN0t6kvS7KLOdkJdpo\neY+Tik7+26nRWlboFayUMhGbhljSPa4b+VIRVcpQNCRq27aBRBI6/kRJYjwqNcEnn88bx59+lySv\nNDX3Wbe9LkGa/JPsOZ5SyryunYXSNDWv6d/zfR/zBdmhq22JTpZWruHeD94v/X5NEIuPf/azAGUW\nD9Er9NM//0tobEsf1xtyH4+eOIlNmnGnFQe+Ymk0Si+utTpQ7OOpyUleZ8/UFm1Tr1sqlYyDVI6O\nP3Eamf4eJVnMyfvISFiL08h4IEd9+Y2ZyRE8+7QYq586KfD6n778Cj7xyQcBiO8rAMwePIIXX5Vs\nyoc+KOXfTp26E1/+0l/J7xGJqK+vYX5KomaLDLJ6t44uITwkMXKUJRWJLBwsVpHRfStpyHGCq+cQ\n0KlIk7iQpshT46ulSHGm0KMO1ac+sZAoBCTcBXTEKpVrGOf4tB0fm0znjI3K85ztNoyG9PHvPSK/\n2wswMyfowOw8/52eRo9wZaRTD2HfoFO6KIPn2vAp88koybItZw8kqGCoI1oWkaRINAzJD/aj0EDV\nrh67tm0ipB7TJFGcoE/4KVfS4z5Cxr4bo3xv+rY7EdGEvxrFOHhMJDwZ55Ti5CjyOzI+k2VJKwWN\nCA6dwBJNwIxTTI/Kd//mW4JAjB84jn6ekeKkIEkNS6E4Kvelw2ydZ8O4FyVWamQjjq5xoWAiby0Z\nyRQQW9rBbICrxlwHNJiqMguOnjJ53BQDOUqmXc4waCrNjK5clyUMowBNjr84IvLmuRil5Ol629Cr\ndtiGbdiGbdiG7QbaTRFxuo6LmckZFIK8WckbTEJ3WyGKJVLsS4ye8hZmSBhKml0kjJKmxiRicX0X\n047s1nvnZHdx5vRpLB4/AQCwubudOXQQzz4ueauAO5eDJ47iPSyYvbkukV1wvo55iwL6XUZDOz3k\nuLPOjY+gwZ58ckkKOGe9zOT7QsWq9uURBHTZ8HgOFTsHj3m8siPn8LOf+CQ+9AEhpPw/538dALC+\nvILLVyR/eviI5DVuvfduk2tc29pEuSy7z4XFRbnmlWWEzP1Nzsp7G+2ucWVS3KU5KoGjNT+MXHLF\nHHZJFDrFEkfj99yDDl2JtkjSaLVapuJIqVrBJKMpHeHlcjljhqBJFFEUIeQ90z8bhqERUGuCUaVS\nQa0mEZaOYBuNhoku9ecLhYL5O01T87eOOG3bfkPEmc/n4TCimR2X3eaKo+CwBNX776A/qGsBdC36\ntV/6ZQDAEy+dx/vf8x4AwNmXLgMAzr18Hqt12fFXkhG0M4lSbUZQXmajwUo8be6wK5UKHBYx1qXx\nisW8iWgaLUpCvJwprxbRqajXCADKs3KuiwKjpflJOfZ0bQw2UZSdDTFj6HVb+OMv/AEA4DhNQIql\nUTzyN+Lh/N57JNouV0cxNy354cU5+fda3sMojRQunRNf2VKliCs0odjZ2MS0LkrBcZPYGTwS1Wbo\nNfzdx/8GV597Ts6b+dpiGGFuSvKL+RGJaouVGlze84CRtZ8ro92Ra9bStDQbVAXxLUAxwq3mpQ+7\nbQWLBLmLZ4TgF/b7uOM9ghxpRGN6dg6pkojMpQRqLOcZc4+Iuc5+EqPD0mzaNKDqeYhoFhAiMfl4\nWLpqkAdHF4LmsXdaW6aEX8bxECWZKRSvm+XayNlyb9c4DhfmppBndZdcRKOUkVnUN2RsnH76e3h4\nWQg+ZUa4Y+OjKDK36ZJ4WclihPEA3QGAQgrEnDPKzL//5Z/8EX7qP/lHAIBmzALnFRcW87HbHbmP\ned9Hotk6VgabecVcqiNEBUXnNEdH4xZAOoupDgUAtB83c5UDZYhAEReJNMvM+zqiT7O9RCFl0JGQ\npNMo7KPIe1kpy1jL0ghdlle73nZTLJy2ZaGSK6BQ8aFJVqlLGM5WYP+jG2lNWAOdhiwi+X6ClL08\nMyqLW3e3DpeOOiA5Iev3EdCh49ylywCA93/ww1hZk0llkwvBdx99FOWqHOfovBAkfuKBD+BoRaDY\n1lnRlm1eXEJcIOzgVLFDi7w6b8qhqUn0OIGTwIfASo1zUNAiYca14dLd6Ah1jg+cvB3ZDlmk12Tx\nfvzJM/j6Xz8EAPjv/5f/FQAweWwRyy8KHIekhAusR6rL/EzURrFGM+j6jkzas7OzCHc7r+l/33Lg\ncxH1uMhnxTJ2bbmmY3fdAQB47NVXDXx44IBAXHeMjppJrNXtGOs7XTrq29/+Nu5673vMbwPAyOio\nIcDoBzaOY7R5f7UNWghge1PuT4sQcRJFKHHToR2E4jA0izMAKFMuiBNAsYhMMzm5cNpKISKBQjvP\neJ6D8TG5z8jz0ei2sHxWtIprZCN+47uP4/I6zbgbMvHm8iV8+OM/AgBYWVlC67LoJcOW3O+5A4dR\nIMTUo+615I8b0//FRVlY2u02KqyXmtDRx/f9gQtSixuEIECBk7WTKkSELhfIoJ2bnoJP8V0xJ4Sg\nemMHTz4lpfWWLsgG78TJU/jRjwtb2GVZt0cfexKf+4WfBwA89K1vAQB+7MEH8fxTj0t/lrWrTWwc\nqXqNhmGHppyMbc9HRvAs4Cam2w+xuS4LVLwq49ULAnTIMHXLXLyqNSiyNd1ENmYT4+MI6GzlkXDn\nua7ZhI1WisiR+KGh6KDgY5fM9C6Z3L1WE2vLy6a/AWBjbQ1HpgnXcaFNbAcJoWiLxL1CIY9Cjoxy\nLoawPfQ5gQeZQsCZm9JwhP0IERn2gXYsQh8pJ7uYC2yawsx1ll504SLHZ/PwrMxHjZVr2N2W56JA\nh6cXXz2DR74s8Pr25cs4clA2ItfoLJTLeZielOtb4Htj1RJcMH3C8eMBCHhP50dlYXl1YwuPfVfG\nwd2f/jQAYL2zhoyQbi+TOabjTwwgWGRwtcsijaksKGR6p6zTb0oZItBb6V/tdKDf1OSfzJgywmgT\nMuxlMGcgcoxeXc7RsRWcWKet5NmNgw4S7Yx0nW0I1Q7bsA3bsA3bsN1AuykizjRJ0Wu2URorG9JM\nRkgDRRepjoJysvtz7BR9yhiuXjiH3hrhljGJaCrIMJanNyvdMtq7O2hfFihtkYSAnWYLh6jLvJ96\nvO88/F28+LwYKCck5pyoTaGeUELAfY+duSgXJDJIC2U0uROusGhzpWubgti6aG6n20GRkUydO91K\npYYp7UHJSLeWAq2GvH+SZZlWVl7AMnkypy/Jed3zoQ/j5EeE0PH8U0/DofZL77KWV5bhEXaempbz\nunJ5CRP04nUYsdhKIeP5x4xswiRFQDwlR6LFeG3iDYbMvV4PdUKKlmUZPeXIqECsy8vLBm7VWsyt\nrS34jFxHRuTYU1NTmJoQmLe5K1FruVw20Y1GIpIkMg42ugCzlBobwLIamrMJg1YqJfPZLJOxFMch\naoSaGhsS5UxMTKBSZCFlSiG+84XfhRvIdx9+RPSC+doUXPbDMXoUN6IIj3xfXIQ2GzuYKchYdT05\n8ZXdXZQ0DZ6w0fq1JcwflLE4R2P6q9eWEWpzdl2uLQpNZDdK3XGay0MR24qCvtmFK+172uwgYhk0\nFOVapkZHUGBHri3JDvyrf/El3HmvjKGthkCwG9dWcIlj37U14WzDRPWjLPy9urGMUcJ//VYLSkea\nPO9ybcREgzsrOvLJoUr/YUUJDVoNRMThdIHz3tYOwkwXDJBrmtrtIiWhY3Ge6EWlarTK1UIO0xyr\nDqP1pN9DY1eg3hznkajdwLXLEnEfOCxpj7yXR3xNSDOm420boFevjn6tQhGKxeV12S0USkbL6ORy\nyJNwEzJS7MUp2rzWkIUc4MaGsJfZg9/LDFGGJJs0RNKjZy8/1rh0Da8+LjKnKy/KXNVau4YaS9nN\nzS5gc0vu7+iiIBBb62t4lcXV25wnji8cxATHk54L0jBCiY5GXaJHJw/O46lnn5QfHxOk6MQPfxRX\n63K8Mc4xcTc2cKobZ7ChJWLagF2ZQtgJ71lsKwO96mA0A4xXt0YxHCgTzXZMYLpHK6o9a7PUFLtQ\nGBTEmKjIeTtpim5diH1dpgpmJ8Zwx+0C3f8Brq8NI85hG7ZhG7ZhG7YbaDdPxNnooFQuIOzJbjuk\nyNpBDlZOdikFvTvKVdCjcPfQoUMoH5Qd3hF6om6/8gqWNySRPk5ZwWR1FK+uSl5gcUqiy6ee+D6O\nnhTii85H3POxj6FCIsO3/+rLAICJNMYyqzfkSxI9+ZUqDh6WaMM+PI6zL0k0snZRcpLFdsXIURLu\nIvvdNoqGFi2vTZZLOHVQKN5ggrp54Sp8kiqKOqeTATXZ3OPhpyVPNXn7LfjoveJulBsfxZc+L/ul\nzhZ9dWfmsU2Zw4VzIjnwfB/K1gXBmTWwgYj5n5BJlmbQQ8xcYpPRzuTkpCE85fhelmWGeAMM8nea\noDM7O4vD3PXajLiCIDDEHZ0TvXj+PBr8+9YTt5lj66LVOp/puq6JdnUE5DiOiWwsy3pDYeFCoWCi\nXU3CSZIEefbDOKPkC68+j1M/JQWQH/3f/wUAoLG9jWBT+vP2k0Iue/bsFSPpiRKabzTr6JG4c+eJ\nIyg5JC3QpKDk1rC8Kn6682Myhq5srGOCFVoCypSq5Ty6gY606GqVJEhoKqAp+Zvbu+ix6kyGBCM5\niQLLzI0tTExil/KDnVUZkyXHwjx9SHO+IBqrOzv45ldknPv0f56cPYCvfkXyZT/0YanTsL21iREi\nIhUSqHI+0F4SFOflZ57FvZ9msQaST5auLZsqR3neiyiK4DGi8UxVk77Jy4MezU5mGxRkt6WjtU1E\ndD7SxyjmfBRYWqu+vYFqWfohR9gl72TIM1RhagtBt41tVhrSRe0LM7MIdiUqdulY5OfyJmIBEYuk\n3UUPMo/0WT6oMj2NkP0eex4Sergqoir5QgFFomVWQY5tV6oIGIW2+Uz1VIaUHIlUe9b2E4DI1flX\nJEr+yu/+AbZfOg0AmKBcaK42DlvL9eIIMaPZNp9ru1g10eDKZp2XlCLhXDdPhKhYzJsC8B7PP2js\nYIrR7FPfkHExc2gG0/PSd3Eq57djRbBI/rFUBkdHnNDmD4O6JqnS7J9B3KglMVADIpDSxbnTgdRE\nmx3AyozEy/Aa0gyKn3TjBE6m/5Y+jjstjHMeOv5emTtvP3oEczSUuN52UyycURhi9doKxsaqKNBN\npDRCaMTx0eMDFIR0xuk0MMNE9069hYIewHTYmJ6qIk9HFw3bQSmsrIgT0FhNIAbXdbFL0smXvyR1\n6X70M5/G2FFJws+9704AwI998ifRelVgnEJDJsL1M+dQ5IAuNXu49splAEBC+7JybQw5R25Gk9BA\nmoRIwv+fvTeN1fU6r8PWO3/zdObh3nPuzOmSokiJlCjJqmJJtSxZHmAoTtK4tRGnbVy0QP+0v1og\nCNCiQ/KjQAAnNdIksBI7jhJZlh1roiRKpDVwuLy883Dumcdvnt5x98ez9j7nikZEumnBAt8GiHN5\nzje8w373fp71rGct+bteUAfNfeTpwv7EJYGNT5WrhrSQEbL1LWGCAsDGgZzHra0NPMbeus1uBy2q\nXxTIhuv3hsgIDdXoFB9lymxqaabFpT2knIz6YbFyeTT4YEDLEtqW0cHWPXhKqeMeSsc2JBb9M4oi\ns7Ge7N3U7MKTjFsN2/a5IRzuH+CtN8U/vcW+ycuXL5t+QX1u3W7XCL9blmXOL+Gm61g2Qt4rfS6O\nZcPnYtY8kg3m1MIiQNmytesCWy4VCyjxPX/4b2XROP++D2JMaUWPx+8DmCKs3O+24bLn7iMfkX7c\n3baFEjf05TMyv7736g9R5IZRLchiW5+bxS3CpPWyBFmB46LNzbvHHl17PMIsVaiyKIZLQtXBhszt\nj33gGdy9KpZ5tarc0x+//Of4MHs1bz2Q17l+Hr2Em1tNnqmdvV3TK/tHX/rXAID3P3UZt7ckGH36\nfaIQVK0UjRPXm29cwZjerz6Dw4OjIzgMMDwtPh+lD80NAOgN+nB1b7Er18FVNlJtj1eR4/I9CxYZ\nmp2uzL+DwyaWpuX+dFtHcDlBdW+kisZoEErsh2R1pxkcblab9ySg9CwPC6sSDGprvWE4QsYebIsE\nPt/LI9D2hpzD5SwzPae9fg+hZo9r2DXwzPlpYfTZ1dOGdUpeEQr5ACHkuI4YRG/eW0P7gQRcL39F\n3ByLYYpFljViBsadboRcmWtm4Biloz2+N1cpIefL32M+j/utLnxbgirdUzpfrZlyjEdGqup0EVDx\nZ4W9q9/83X+MX/+vfxsAkAwJSReqZiOzYcPVkLdmDyPDcY8rN1N1DBPrLVTaL7UNGMsR9nHvZ2Y2\nSQsWr7X+Xkdl8LSvcZog4H3OWNpr+D4us+vgw09LgD7lA++SGzSBaidjMiZjMiZjMt7NeE9knBYs\nOLDgWS4sQgsJozHHsmAxWtXmrlZaRZ9tAMNBhIbGr3oSlZfCPkBdRlBpxPULiBgtvck+tPOrZ9C6\nKdH9IvtCP/TCR/HyDSm4P/JhETkeThcxnKO59ay0jAz2t3F1U6J2tfsAd6/Jv1fOy+cgThAQzgxH\nAuFZKkZCnUVP9yQNeigRtjhNenepUMD9t9hz1pbsq5bzsE8D62FOzuNHr7+GJ+fkeJZWT6HGHsrd\nN6UVoubnsDQrxzNgxNgZ9sW0F4CriU6ei0xnTtMCHeYbRZTPCzRZnpXMM/RcY+Gk+zmzLDNZo2fb\nJrvUPwuFgumd1JFsEh3bD2lIJh/k4GqrMWYap08vGyKQhnZbrSO0mcFr0tH09LTJYEUlSL9HrpdA\nuSRq8Qsdx0KHWeiyVse5fQ2vfuPbAIBzhPCS/W1cuSnzYYVEoMTOsMUSwKd+nnZllouYkG/iJBhQ\nQeof/Z5kbDWrgNqUfM/i09Lek1cZtu/J/PvoRz8kx7J6Bm9dkb0wuJUAACAASURBVD7Hg23Jaqer\nU+geCGkGhBiffewJ/OxHfgYA0Dtq43WqBE3xe0uehyW2N3XaAi0uNhpQtHFrMJvd3j9EsSqvu3rt\nTV73s6ZvdkQ7sPV7d+FZ+v7JZ9y9eQM1tmbksg5c3vOpiiAH56enQGlTHN2WOXlwdIgBUZSAz2aM\nDAEzshwJdwgVYkK0HVqT1aol07e3z3IE4iFyjiA2w04H9aqsERq9yLIEJWbzvZHA9a6y4LIUsnFf\nMs5oNMapOUGY9Dz0gxwCkoN8Kpk58GDrxgiuUc3dbdiEjnOuixxh+pjqP+NhhNE+23GIgoy2NuBq\ng/FFuf7VpXmMuJRtbMhxvfaNr+Hu94SYU6HtXk55SNhml+M9aSzMYEAN6u3WARQJiQ2ua9F4aNSW\nPGb1yk2w15V7kSRrAIBWuYpz7N3NEblqHh5ggaLyB1yPxv023vo9MQv/VbYu9cIRFHOxFBYSZpIp\nSXgpnBPGbST/wDIiag6z0MxSyEwfp/xM7Oy4NSUyqafJ2h1mx16aIuC//TRGjtnnE5fOAwAunzmL\ns/Nl/p3fO8xQcd9dDjnJOCdjMiZjMiZjMt7FeE9knJ7vYWl5Ad12B+dpQ3TYkaxiFPXRZZOvHUq0\n05idR0Jiy9jPo8rmZJ/1Q6u5C49kHk1W+eKX/h06pyWjy7EKPbp7x+gyfvBDoppy/Y238NpVifg/\n+9fEFePVN17FH//+vwQAPDYtEdx/+UtfwJ9+Ucg4d9+6gbkFyfaa+xKhLy0vQvm69UEiz0cuXsIb\nWnWFxfbFah1FZsIPaJ48zBewyUxklkX7HTvFlKaoU1nm3q3buHVmFQDQK9bw4Y9K/epfXZXoPp/P\no6NFAnSIlKYIqI/qebqRu4gWM5kNtmb8yn/630CdkXM9YBN/K22aqE//LJVKD9n06H/vkJBy9uxZ\nU8vSogdxHBvSj67bdrtd87s6nTuiKDK6rY8/LvUI3/dNtqs/d29vzxAaqtUq5tl6s0ziw/7+vslY\nC0QB0jTFkAIBPdLzl+cW4TAz6u/L97a2drBHDdrLJMp8+0dXUGf2WKXqU9Vy4fGztweHuHlP7nNh\nRr5jdlxAxgw45DlF7TZqs1Kj/voffRkAcOPuPZRIwimVBOUYHB0g6ct8vnSa7iZugFWe55tbOxjT\nSaXPjDNnO6jpcx2wvaAb4dYNqRmvXJR6+tzUFDqsj55ZlMb4o6MjdPl5C1RVQhpixCznjR+Lq0yl\nZMPl3J0rl/HS174BAPjYI48BAMZWjJDZ2Sw/e2npFNqcG9vX5adfyCNhS0arJ99rDRXyWsGHpCWV\nxUgZ6+ua436zhWW6cwT5Atp9mRt5olOFUhEDGixrTdvDzgAdiiJMs7UmHHTx+99+EQDw+c/+gpyy\nn0fEbMhjDT0OUxRZKyyy7SQ5bCIkMWxhdgaHB6KmpDvq0O+iSxUyPXdr0ytwaO83PJI6ZHNzDetc\n9178rujqbm1sY4q1y5SiDrblY5rtUhrNiREholqVnbcxiKmP3acTkW3BIRkuY96nbCBmZtfkszTa\n3zUtSBVm0RUvQLQjGf4Ks+T5oIrcfTmn7/4DUTeb+6/+O0wtSLZ6c2sLPnWVu0S7yo061mkR59ms\nZWcW8rqu7Wr96wwDtpdpZ5jIS41lnh/L74p+Dh4RCE+3q8UhQhqlLzQaeOEZEV85y3k85fuoksto\n0YlncHiELQrgvNPxntg4HcdGqVKBbzsYkFmp++5K1ZyBScYhoY/uECM+DBvru3j/++VBdXflgnm9\nFsaHMnk7Hfm8LoArPbk4F1hYr+fyRtbs6o9ek4O5fg3+FB8mEoGuvPkWHnlWGFh1WlC9ubeJewN6\nb1byqNMXMzyilVAhZ3q3pubk+z7xiU+Yjenepjwgn/zARTxBtuYP/1SK/9XVczizIkzbMSXN0r1t\ndLgoDEOyGmemcfuqQLru6VUjOu9xY43SyLBWpwnbuWmGfEE2sKMuPf8SIOIi/dFPyaIx+8hj+CYl\nyh5/QeT/Rm7eBAFaCDtVGTw+YK5lH8MpJGf0ej3zHk04yfmBgcO0PJulgFJBHsoBiVFpkhi7LZuf\n67kuitwQ8mTIZlmGKcKtvV4Pd27ffuj79vb2DCFlTLUQ3/cx5JqikeNyqQSb7NWcosTdcIxHnxR5\nuojshNdv7uKjH5QHEtyQ0R9j84GQZ+50NzHQJJUKFY1aA3gMpAr820yxgA7l5OZKsskv1apY35UF\n8gzh4m6rDZ+Q0zQ3hIur5/HKS98FALz0zRdRZ2/kc888AwC4+vprWFqUeTfsyTEsz8/hkL1rR3tC\nMFtZWsHrNwUW1DZYef+YuawZiq5tQ5HxytZUOLZCxvMv2g5CMpczQuWZ7yHi+zOS9DzPw4hWXprh\nHFmh6WW0uRHbYQKHUJrSBA+VGUUdm9cyVgFaA/m8uakauoTkXT67owQGks8YbJfLZSh6vvYHPH6/\ngG0y9b/4NVHJ+dt/67fQ4Kbdpk1ZUPDQY6lDB1y12Sl47M3tjfuIaaPnclEv2AozmvzFi3fn5nW4\n7IFNSFJz6lW0Iqp6HQq8XopGKLGuE9Ii0EKGhM+N4j0b2wki/j2xYiiyUV0SohQsEzzrIAW2a6BT\nzWi1YWGDEo0XZ6T0MD+7gCmWfGYZQPSOjpARsgd/3PrWd6C4ll145AI2uP4FDDD2mvuoTcv1TEZy\nfEV4YJsuYhJ4xuEImc+SVpm2e46NcSaft8CNtn24Dy/QREH5kKTTxocek06JTz33LOoMDLSDrJsA\noGJYZ0eegdbWNobtdye5N4FqJ2MyJmMyJmMy3sV4T2Sc4zDEnXu3cfnS4yYDKTAKC7PQWF7lCDV4\ndoBiSYrVNwcJytqRfijZVRAOEbA4rpgJVmYbaHqS5d3pSNY3m6vixh3JTj79iHzGYr2BrQOJPvbv\nSF/X6vwSulQg+sSnPg0AGOzsoso2ktpjFzFg5nrQlCjm+cUl3LoipJLTF8TWaWZ2HqunpadR85la\nzaZpn9ihmfZj585idVUguXuEbnK+iwYJFEpDLpHC0Z01AMD2KMY+WylmSNgYjyIDf8SMuiuVGvok\n32S8xvfbbVx+XrLKpQ9IZv3KnbuIKRxeqEjk6cSRyeI0xOqd0AodDAamlWSPmfK5c+dMD+WIEaVl\nWW/TpXQcB2VmnIehnHOaJnB1X5+rbcNgjGj1UEqZ9p25uVnUatWHjvHgYB8hiRH7+3u8DhW482yM\n9bVKC+CTEGFnOnP2UKvLHHqF8LllH2v1dpo0lh7HCEm0cBRQrcnnDBjx5m0LPo+7yHN56sJ5/PAN\nQTpyJMWdaUyhy4yzzQw2y4DnnhGi2iIJSMNWCzfeEtg1S2KjXfrqj4RI4jk2Pvdzn+R1ZzuUSuCR\nFDPk/Ds63Ec45n2hIk4x8A2RS4tkO5ZCnsdvk80ROBl6RHQqQQ09ZioJe7GzvIsYWgmM2Ve+aKzp\n6rpFKsoMmcXc77EFN9QpJw82iY2ClO2Q4IIY+2257qfPnUOPbRwDZpdetQGbVmtdGogHgQPTPaio\nPmW5SEkE6rHV6odXb+A//63/AgCwtiZrQTIO4ZPM16Md3e2dXUyxjS7LUsyxRFAJ5Hr1DvZw1JRr\n0yLCUCmVAGbXu2y1SgdddFla8kkErNoW8kbXlRArjvVk2bqJ0FYIqZakVGb6JfU6k1qZaefQQ7JM\nfUEpUq8sgGSeAntiG9UG8lwz0jb1pA/bqPD5mq5KFvnGtetoMwv1bWDpsmR+ugQzVa2gQ4TCpopT\nr9tD1ZbP0W10vm0jckkcY3acZTFCZpUNyOsK+Tz2NuS+LE8L4vS5z38OqzOCvjiDMapUzbI4l8bb\n2zhiy9aQJRM3zlDBT1ycnzImGedkTMZkTMZkTMa7GO+JjLPdaeNLX/0ySrk8zi5LbW+OdcFO2sI4\nkwjQZhQcKBdxJlFHrTQNpSv4rDl0trdRYj0wJjmhBQ9H9M2lEBFSO8NTZySzC2jb9L2vfwtPfFSI\nQveuSI1v7rEz+PlPiwGw0pqTfoCl85I9fvYz/7FRAfmf/5f/CQDw1sYmLCqjBIzIeoMQly5JFDZV\nlqzIj8ZYpNBAl20rR4M26glbS1irDTwP55j55KmdutVuo1GUDLCzuYMS20IUQ8swizDHjPtgUwgI\nU/VpxIzubTZjP/+xj+Ej/8nfkGNg1vfGH/8ZynQKefnPhSwVVQPTpqBJNvl8HmNG6HEcI1eQ6FHb\ni/X7/RN6ITIcx0GFTfI68xwOh6YWqsUMAKlHAcdCCWl63EBvbMiUMn+P4/htgguLi4vm77qFRSmF\n1+4KgYclOYT31/EoG94TthLU6g0cHUhGsMUMcH7aw4gkj/0HJPr0B+iRwFOeKSL25f0HzMBXl5bR\n53XqElk4PT2DTZ5r1JGs3AkCNDg/H11ZBQAEfh5n+DxceV1EDTY2tgwSM7cwZ2zeSiSc5PI+FCtY\nCyRsDIZdrLGF6rH3izZnqdPH9XtyXh4zLtcLkPGzM6IJcGCUYLT/k2uJSwsAVKo+HpCUEfM5zKyi\nqaulzODL1QpGtAZbWmT9MO0hY0aqraocJzOZbc5mtpDFZm7bzH6VyqHN75s+dRY5kgI1OS1vuXCI\nTukMNhyFUNo+jwyeOBphqkBVJdZRX3/tNbz2hlzvJ94nNe2Dw6ax49NIxPwjl2CxzefVl79/7NbC\nLK7QmMEKn/cLJLgMWwMM+Z4jkq2Gwz5GnAeKZD3XAmKSI41ri0oRkgNCBzAkyJDw/tg24Os+Dgoq\nWLDwE48hAAuZFidgTV8hRZ9tQms0xraaAzT42SskWIX9AVqarxEJEhNWq7hPh6b1zQd4Ok9Te+ox\nF3I57HLuV7WoRalgVOLSSD+3FjytncDafslTyFMPuHtdavKB4+LTzwhC9jwdnKbzHjyiN3nHAmhP\necRnd7C/hz7FRDzOgVKhhDLXwnc63hMbZ6VawUd+7pNYPLWMI/Zn7Xdk4neyJqr02Vysyg0IbBfd\ntjwsK0ur6BMimybMM2odwSdTcLslN+XuUQsrqzJJWnflgn3sl5/H7JDF+h8IrHqYdnGFiiuYkUXt\nA3M1vPbnInP3sQ9Lv92fvPQ9/OZvi3JGf28bd9flZl6kqoq93sHcgjAJb5Ksomwb85Q8u/m69Myd\nXZjB1771ohw3F+vra3dxSN/O9T3Z8Kx8FUU+sAVak1UjCxWHfZOOZXrhxpSBs30bDulmxYBQ0jhC\nSKBhsyfX7a988hPAokCAIWHgD33m53FI66xT83Ldt9N9A7tuEO4oFoumZ65WqRi5O70hRlGERXo7\n6g2t3+ka5SHNCrRtG9CBURCY15+EhAHp5zT9oCek/vT3hmFovlvDt7Ztmz5PTUiJ4xiLc3JedZJL\nZuIMAaHF2iqd7jcTbG3InJwqyOIX5BzsrMkCkQcJHp6NAWSuFewiXB5jlYvdoNMyxKT1O/JzcXYG\nzz0hD7wmx+QKJaTPyrkccCNSsHGTsP/tm7LZl8sVuIQCj9ot0yPa6sp7aijj3gOZk11ay2VZirwm\nqZBNmng+Ai0+z8XYsh1Yuh/vRF+uFs3X8C1SwOF5Fh0X6ZByi4TmLMc2i31CGLFWq8GxtGIVAzjX\nQWywRf7OsQwkqh3eIitBxg0h1Sozrmc8JRunzmCBc6eTyPO69WADiizMEhf9zB8h5b2wGOCMhkPM\n8LgGhGBnVs7gD/7pPwcAVBj8lmbn0CNsmWcQtnnYNP3Iw/qUMTpwSWCKwhAhWcqaUDO9Oo0+oe0d\nljB6rQ6ahP61VR8c25yrw9JKjMyI+ifq2IcW2rQhs4xqj2LQobTE3YlhKcv0Tlp8r6WO1XgSMoYG\ncQKbcHmVcyRxLXhVmfsOv2s+s7HFHmu3WcZb3xRP0Bf+5n8m1+moiWKmIWaqegUldLl+g1DsVKGI\nHGHs3kjgddUfgRxEXJqSTffShXN49rKww1l0QTYK4ZDhnA4GOGCgOKSVXQBgluukk5C4Nh5h2H/Y\navGnjQlUOxmTMRmTMRmT8S7GeyLj9HMBzlw8i3ypiDp1IDMWh/ORi5QiwgdbAh3c2dnD8sr7AAA5\nt4Qf/+B78jmJZKn1cIRGXaK+ow3RmO1kNvK7EmH82mdfAACUYpho9NKTAqGudw4REf68xiyy+xJw\nelmyx9e+J9ZRf+c3fhPxlsAOX/+zP0WTqiSPPS2tC9+58m08YOQ6pEnv3kELQ0aeOmOL+20MSRwo\nlCS72uk2Tcap6fle3seQEFeR2qKPzC4CDySbrc5PY4+9jKBOqu/76JG0tEwT6W5riArbHH72BVG9\nKSzP462mQMJRnRCr7SFmEd5zSL5K93GKbTKrut2k08X9+3KN7925gxm2vej2kQcPHmB+Vu6FziQH\nlmX6KnVGk8/nTVY5YrQdhqEhNBidyjg5zlIJr9u2jREziGKxaOBY0+e5vYMRI8oejYmVUpifY1+v\nkus2ffoU9u9JL205lff+8I1XjQ2Yho2mKhVsbMv1WlwUqL+Xxig15Ny9nIuQ5ssV9hsmw5HpydWj\nd9TEIRGWPr/DzxVQIqx3SNJIs9s1+qfaNssJcgamG0ZjjNkCUWLmVqnXcO6C9ER/7yWZa4eH+2jR\nYuvLX/43cj1zZTT4mUdd+YwkTkxmroiCqCQ1Nlhajz1LIkMYcqCMGpYm+DmOA4vtFwmNnOv1KQPF\nJ4mWjLGNUlimM8ksg0/41oVWukoRG6IMNY4tB5knz41TbmD5rJyzW5N78eLXv4a1G1Jy0apRRd83\nWbNHveZKIY9DIjDv57MSZYDOQ776JdGy/vjnfxlVQuhtrYk6v2Da3nJnH4HNnsFMt1yNh/AabNFh\n71Ozt4MtXqdbRBbsUYxIl50InfpOIHgtgJjXJnQUYluXKwhxw4KjIfQUcDKt2kMioK0MLKuzS1sd\no7cus0svtbWePUJ+R28co88e+YRZn0ojFLnOFEmMWokcALJ+Nztd7Fy5DgDY+NGPAQDTzz6PLhGt\nwwFbzoouspLcy4DrTeJY6FCDNyZaUs0HWGDP/S89JQpPs/UieDgYNGVdLeV8DHk912/egMcSWk5D\n8wrwjBwRYew4NojBOx2TjHMyJmMyJmMyJuNdjPdExgkINXp7bwcXWE9zaKJccAIT6RYDiWaqyAGp\n/K476uDOLbHbmUulHvjEYIi4IBHu1RuSQSS+jxoztufmJCqdzpdx645Eow5JLaWlWbxyV343dV6y\nq3u7Wzg8FIz8Weq33rlyFfduyWdXGnV87hOfAgDMrEg219odoXskUdM0FTTcDMjYYN+gOs7e3jbO\nLEl0PBrK6y3LNkbXVTpW2JaHiO+tOYLo14o1JFp3MgMskmV0XTOxjtU2dM+zbzl487pEgn/9b/06\nAKAZx4ioL2ozK9rf3XioXQAQwo+uvWibr8Dzcf686EBaSpm/370thIG7d+8ag2pdC/Vsx/xbO5gA\nxzVLnSmOx2NTz9Q/0zQ1GaeuZbqua7LM8XiM9XVNdmGTfBzjzJkz5rX6dWMiAUq7xfguPDZod3ck\ni+6Ox7i0KO0FmiTU7o2QjI61fwFgbX8Hjz0laEOruw90SHTQAgmZhxxrXjorLxeLGDFTcQISFUpl\n+MzM+8zqm3GMKW0Gzuu7sbMLn7WacqOGSBMi8jIfhuOByer1vQKAPslPA+p9fvYzn8Pr1+Re9UKi\nIOPE2HbpkWWRmUM5TxOxesjnZI5YWYpAZ344JvC4PvWHKWJQLpfRoFhF2JGsHY5ldF115ullGTxH\nN7fLNfJshYz3PLO1ygygON87oxBFZv3LNGt/QVmIeB3WqMUbVEqoUcXKITOsViqhSrutxrygS2+t\nb5i2oxffFBsvtz6DD35GPtuuy3cNM4V7bHWpVetos42rr5NHKCMCkNokwBViDChy0CJxqp4vwtYw\nAuuocD3YJPNF5DYkFsCE8thz21LwOI+9BCb7HHBewbKM7uuxK5dtjKJ9nblmFqZ5Xi7Ve1LHRpWa\n2KuXxfg7tWI0e/I8bLSEmPaYV0ZDydywvAB9IgpXviFCHR9fuYQq68w9jUoUfCOOMSbXoNs8QMCW\npvMUYfjA+XM4T9RvmTyezmEbPu+jdh668crLiNmStFAtwdLiv3xurCgyJCSNYuVsHwFFdt7peE9s\nnLZto1Aq4nB7C8k0VUIIz8KF6cks2NryKofEkn/7OQ8XuJnNHLCHqLeHgwOZlFcI77r1RXxkhpJo\nb8rGsZvZOL0iC+p3Xxc44aW7dxBVufHQ+2+/00eRC6pmL77y0vdQ5gISDQeYOf0FOV4qfyyvnsFh\nXl77b/7FH8h5hgn+6i/9EgDg/HmZgPfS0PQnDckObEyVEHYIyxBqyOIMtkXWI5+WcaeHs5xYG+MO\nZgi59UhJG41GqBN6be9Skq4wjVXa6niUKizUqxhzFo24EeSrVUR78t0O4cad/TUDs00TjrJhGcJQ\nppRh05bJml1YWDCv3Waf6WAwMIunhnTz+bwhAp300/xJb80kSR5i0wKygepjOCkqXySrud1uGyhX\nM3J930dE+FD3sB31Oji9JOStGz9kb6PnokJm74Oba/I7J49Fws9WlbDjDrB6UQKI8MYACSXPylRx\nmvZ8cwx6/WrUaijzGLVwuOcHOCTsdO0tkf8rBXnjaj8iqWp1ZRkDBh1RlqI2xaAklPl3+fJlBAwG\n33pLCEWNqWM4vExi0dbWlrkXHksPdngiOOG8iBMHHoOOgPO+P06RI2ElSpX5tw5obNs2BKCE9ywI\nCqiS5bp1KPNBeRZSDdWesKXT9z5jD66lAIfHYPFzkaTIeO06/RFSkmDu0jbt8ScuY4+B1D32vfq5\nHBbnZZ6O2gLrFXIBLp2SQPn1W1L+OLu0jNdvSnBc5Dm//L2XkPB6ffxXvsDzddCN5bgb1TrG3PD1\n5me5Fmxf9wczISg58LaktJQyULLcPCwqoo3INLXSECkjljRH+NWxDdlHPx4OLNiUp7ORwtbBIOFW\nuScPP0u2UnDY70qhITgKiEjy0v3Qs9M1wCLEzDVKBcAMSwEXZ4Wh/cmBhwd7suatPP0B/OH3/xwA\n8COqLl39wQ9x6ed/Xs6fa9Rmu4mUvcXav7hcq+CZJ+RefOSi/FyyAKLFANnR1VoNzXUJcO9claBI\njYeocr/oHBzCI+6se2Hztg2fBDleLmRhjPFwQg6ajMmYjMmYjMn4f228JzJOeA6c+SqcN27jsbJE\n8n++tQYAaJ86bWjwa+vyu+WVaRzkJGssWBGeHkrE0vuHEsEpawnfaIqixC1az/cbHTzapSbkvkC6\nTq2IzW2KYjckMjlrF3CTZtT3bwuUNLsAeBWJcq5sC6y1cbiGZy6I8Pgj0ytY/44QlE5fFN3c2djG\nsC1Z0FPswfMUkB7IMV4iPLtxSyEkbOGT0NBVGQpzAkskmhzjWbAJv1ipHJ+TDXGUUsi7XEfoUd2D\naigly8OQovO+JVHtOlLcYHh5viERZZQpzPgUFKcKy/72Hk7RXkg5krXP5WYN/Demsklywqi6UCiY\nv2sx6/F4bLLU3AXJyJRS5nXx+BhObFNRZpq9p71u14i8P/qI0M7r9bp5r/6ZWYBPiDLOUowZZfao\nprNwetlQ+cc8LtsBTkWSOYyqcm/vexlKRW0jJVnyzKCA8bYcV9OlrVtdoZxj/+matIl8+uxZdF6T\nftdzU9O4uyP33hpLbDrjdlHR7RBUVQqVwoXHZA6dprlBdxzi978sgu9BmRCdA9xltn72kphg9+MY\nDkkzcX+IwJeMU4upe9NVfONVUSXa0O2X+TpsmoAvMLsa5AuoT8v1DnbkO+wsRGTTNo7wIAIgCeRc\nmmx3mg0WoVJmnEmGEtHd4ZpkuFkpwagiyEOVyMdaaGPuP/pZAMD6H1LwfNRFJZHrpds2kriLvlwu\nuDG/YxAZ4fTuQOZFsTqDHmWQanOnsT1mS9rUKgDgblrAeEGubScv890plpAQZjxFEmINIX7sCbLQ\nPC3o0s3BHsbkxTUIs4/ubWPzn4m5Q+LKH5cefwS5Ofn3G7vXUTot9yAmDppLMzQyORmnRf3rio2Y\n+q8rT4kqVLS1j/s0nvbnZf5F7Q4ahNXnmsxW4xh9T+7BHo+vU0gB3f6cQWSwADSGRf7OMvBupu2+\nLCBmKUeLvY9VBps92uOK/GylCj4zanVHMvQgyWDfoE1bXa7l74RbBnFKdtex3JCDq1CQ/vq1H8Au\nyfX+AFWFVlWCLvt1p7nmve+Jyzg3JRC51pjNRwCTfuCBrKE4PERGvdkFZuqBk0eRJCMnsI3OcUR1\nLFg2Up2mM+vNXO+h1rZ3Mt4TG2eapGg3W7AtF1ffklpCbZWTz8+ZRu7atNwURBECLdDdbmKmIDOm\nNCOTzWqPsM5N1td1hs0Bzn9YmmW1pNZOv40uodUcGWLnFs+i1JDf7bbl4XztZhtFJe/Rsn9QLu6t\nySTf2zjC7p4srufuCCy02+0Z5f4Sa5xRv4+DI4EyuvxspYACYU0tdgDbMv1vuufNgwtfO0MQmrKt\nY4grTTMDYaYnersy1k9i/i5KYnhkbe6zxuLNT4M2oShQdq3VamFuZoqfLe+N48xAabpW6Pu+geNc\n1zV/1xNR/DEfrl3KeVNGkezNWq1moLkuN9D19XXDPtZwb7lSMSIMWhzBywXms6MoMsd2RHad67oG\nJj1ZHy0wcGiFch0yW2HEc51m0/ama2PIWo8ii9JOjj1IFTeG2mwD9zbl/hVthZis3ITHdeqpy+Ze\naQg1Xyhik0zog+vyHYftDt4kPFhhLbTb7+H8Rdkw9eqRhTFOLcnmt7W9Y2rm3b5cuxe//V0MKd/m\ncYEol6t4/Clho+/R3/PunTv4AOun507JdxQsF0NC30p7KSYxFKHtEiF1x3JMjdr3y1A8vzked9+2\nTeCzuU3h8OI08kX2/3He5ItFIyihuEnki8eQe5ffG0URFIPHmLXANIqQkhGapqmZB9pvcxiOcZFu\nLY+TjTnauoPitKwZ46Yswk6hgBLVGmyaIGRZhiN6gZbIG7i95gAAIABJREFU4F6ZncPulsyrF7/6\nJwCA5wMPEfugv//9b+Hzv/kb8h7WOqv1APGhzL8S3XTU6AiLc1IW+NBzzwMAmnfu4v5t4VdkZEkH\nHuAQ3tUM2cjNkGohCGhNvRO00Axge/cxG91Sx8xRblS2fvGJYUOgXgDIKLwQhWMo9p/auo82SpAR\n3bSJoQ5H29hel+Bra30bPssQswzS6sUiYnqx3qeD08UXPoinzklgM0upwmqugiILGlqWIIsitFsy\nJ9Ob8l6VHq9HxvM3zcwc8D0Prq0FHrhJqsxcq2PZT/W2ktBPGxOodjImYzImYzIm412M90TG6dg2\nykER/vwcpgjVjkhc6bXaGLEX8TR98NLREElXIvXVUhmrZBfuEGIYtLom46wzZKnVi+ixh8rh66Zy\nOSj2E7VZHLajBLOBZDINEi6chftoUt1ju8uIFjEiQmm1WoDruxLB659B4MNlNFRn5NXc3DIRVELo\nIOd7Rq6rQiZgZmVvI0sgObbyShJNlrDgp2SOpqkRU04YbrqpQsxoNWG/6gARHlAW62fJpHXyRVSm\nJUu4S9H4xfl54585YrRpub7JPnW2gOw4Ys2y46z3pOydjuz0uSilzL8dQmC5XM70eWqotlgsGk9N\n/XN7Zwe7u7sPfUexUjasWtd1USFhR1uqBUFgPlsfS6/fx6HVM9cEABqNGhJCgAWyow+QIkfG4dKc\nHMNu3IXDCHX5wioA8WsMN+W6BqU8Tp9l9sYMY9zIGcJaTBmwrN3FkJmw4ufFmcK5p0Tebcz5ejiK\nMaI9VJOSZaNxBI+M6jRMMSAE6GZUQZqfwwJh2zv31gAA99bX8fQz0rtrEcpr7R1g0KRQO/1Ze7aH\nIbO8MjNry7YRkZFbYG9mmIaIxyT9uAWTNVZofbYwO4cxWbX9EVOg/R4KzOiazEa7ow5sIjqKCkOO\na6PV0RaDxxKLSqMuJMdkWYaA19gLfChbE+No7eV7mKZN4HNU/brxrQ5UjshJWY6lG40x5dDDk5+R\neQEyh5kf5025WEQf8ozfeV1g+mc+9AKe/qCYJHzHr2C8Lgz8JrNVe3oJ1VTm3yiT6+p4EYKC/O6S\nJpWVi3j5xa/JfTmkV6l1DFFqomDqZIh/ovHQSxUyYrF+asPXfmEs21iAuXY6WxLQR//fsb1fyB7K\nYcy5mQIFrkdlKpDlXAWf98UmdJ+zXfgF9p2nKWwyY3duSz98XymkNFlQRHt+8Vd+GQUtiUhmeM6L\nkSPBakglpZ0764hoB+ax1OHaDvJEFor0GC74gYFnx/2B6Y8uUK5PqRSp7h8+cQ3fZcI5yTgnYzIm\nYzImYzLezXhPZJxZkmHU6mNrbR1nnpao/g5tfOzZChoFyQCrrLdEvT4WpiRDemFlBeo70koSM+Lt\nRwNEjJCK5DZ84rFnjHBwn/1CYRiizH61Ulk+bxCOcdSkdiTJJ0/NnkWHwsfLZYmCD/p9HLAOdDg6\nQEmLMjM8nK4WTcapRRazXB4x+4kcV4uWZ9hZkzpeQFHk1DoWajeGwpYDl7i/UdOBZWqXcZogjnWb\nhs5WFRKTcdJaKVOosR7jU/GjOxqiQOp8RAH56UbDZJW6N9OrFI6NrJndqjQ19cqTLSU6mBuNRm/T\nr1VKvU1v9mRxXhtZHx0dvc0E+8yZMyZb1S0oKRTu3pVe3mq1ioSqMCfrnjoj1ecUpwli1qvjiLXV\ncQyP53X6lGRrtUcuYnx/Ta432yKqfgFbuyQePbsKANjsHGGnK5nIQjxCm2LjKVVfvvLaNZPBjzmX\ner2e6ek8vyp1Hsey8ORlqUPeZK2zNLOIO3eElFZjj935xoy5DlOVaXOuqyRgtTtd87unn5YMtlxt\nIOF9LjIC/8hzL6BJFSSjarO9g6wvz4BPI+6ynzOqMQ7rkC0nM7WlLMswYPa8wWc3W5yCcuR7dD26\n4VRRtCSLWKICz4Orr6JA0oJLuzDbyRCzttyoS33bc/u6E8Gom4/UsQ6xUplp6dLGWk7g4y6RgKkF\nqSkuXjiH5i1pTZlmO1d4sIspqhEdDWReldIMGdEinf1HozHqrFG7bOX4yu99EQvnREHqF1/4OKpn\nxUZwn33C434Mi0vt9dsyT2ceb+CwJehBTYv1z81gfkqyr/YGLexcBQScsySnxQASS68PFJJPHNi6\n3pfaZo1I7GNESNdDNTlILhGRH3X804PWvAV/KuR5jatsiSlaFmw+mzl6l5XKDWM8MB6FyDmsx0c0\n/M4V0KSamm6ruvaNbyPPHlGb17VYrmKWKkEYUku40zPZ7iqv9XA4xIiIob7vcRiZdV4pZdqWtG6w\nSq0Taw4nk6Wg1LvLId8TG6cNCzl4KDXqCNmDU+fFDD0bCRfIPNlZs40p/JUnhJUVHGzj5Vdk4yxQ\nouuN1rZJvSu8+ZfsAkolmfzjkV5wQ1TZtK2LyP2RhRL7FhVhnL1W3xAaFlZkgdsLR7i+I+Sg9U4T\nOz2B3zSEMlB11AgJuyRp1IIc9vdkwa1QzDoHpWv1KNBHM7WV6WzW0NNJD0uzcVoWkj43oCwzvXKZ\neVhswxnQpJd+mqHFBe6tG1JkX3juOWxycclzg/rOi9/Gp39ORB2W2QTeHEYP9dkB0rt5sq/yJ/8+\nGo2O5fX4upPncnID1f8uc4MJgsBsuloUXuG4t1N/h+06eOIJER+IogjrFHbWxKL19XX8zM/8jJwr\nnUIq1Qr2O/Q+pKNIooYYkASySyKGf3YFwwdybRpKHr7FqTl0duW91Xkh5ZQXZ3DQkvLB8x9+Dl/7\n+ovye8L9F898xLCLXQp6bKw9QIeEhwJlEG/dvIk/+vv/AADw1JNP8r0XsLjMgIUQ5KMXLxlm89ra\nGrrdNs9L5qfn59HVIhqEpmZmZrDOTc2x5DzzfoABHTlanJuIEpS1sAYhW5UBFTpIaEEB5cDAjXEK\nNAiRH7HXeTnIIWSJIyPUXFR5FLgwP/1B6f9rbT9AFpOMBE1iG8HnQjlmKWM4jpCazv/jDds49ZSK\ncLmRV+klqVwbo6YuU8iYOnUaR/eEld/hHGrML6LaSfk9GvJUKLHfVYvUh4hQrVEshfPUH8Z46at/\nCgA488KHUWRQ73Pj6CcJGmSbXiKxbTzYQpdGFBnhbHgWclwXPJKDclD0zQRiV5diAJXp18nfcokF\nn5GNndmwuRF0fd4rHA/t6wkFI96uh5WlKDFYKHGzzKepga8DW2+wKRQDmyylRGbiIkfWth3F8FzC\n7uwLzXsBklh7ucoxfOv3/iUe/7DA3A2WYzZHY9ymQ81URZ6vRrkKRYh/vyjXNe8HKLN3HUwaouEI\nY26iNgCfwhM2N840tmDpc850CUlBZf+B/Tgty/pdy7L2Lcu6euJ3/6NlWVuWZb3O/z5z4m//vWVZ\ndyzLumlZ1qff1dFMxmRMxmRMxmS8x8c7yTj/CYD/A8A//Ynf/32l1P968heWZT0G4K8CeBzAIoCv\nW5Z1USntU/4XjziOcbCzC8ex8MWv/lsAwKc/+wsAAJUmKHoSxTxCabdzRYAtXvjBV76B3j3JLM6f\nFijm2oNb6DKoeI5u4KcTB+1DgUm0AWPV91F22CIRSVSk4hA1wlglWjXV8jlsU1HniPJSyrVwhi0z\npWwaV9bks3eaUljf7HbQI6nm6FDgidVK1fQR5uh7WQx8VMsk6UATblIkTENjTYxQ2duyOWQKRWbM\nGdQJebrjLBWEciJCMr00QWVWYJDzj0sPYf30KnaZ+eztCLFhf3cPP35N7NWmFySCrkzNP6S8Awix\n6xhOPoZBNLw7HA7NvzW8q6G1k//OsuwhOTxAYFUd1esxGAzM9xmPzakpQxgqlUo4S6Fv/fNHP/qR\naWHZopJUuHYfaEiEW1FyDZOwjdiRYzxi7/DU5Seg3pJ72yCJZrzXNJZEe2wvOvfEo+iPZY4EgWcI\nXA2NnPgBXqLY9ellyeAvPfEk3nxDCCYBJQgvPf4E3rwiLVm7zABXlldw/oycy/U3JX7d29nFAqUM\ntx6sY8TM7tpVyaQuP/k+xMxobtyQvspwHOH+/Qe8TpKR9VsdzJMYpsW/q5UqirwXPYrQj5IExTrh\nVM6pWMWI2LIwHFkozQsc3uE1+eDMHDZ7tMni3M56KfqhZAR53hOvWESTHokVtoXZaWYUw4Ydef14\nHEGja7TjxThNDXpj27aR9tOIU388xuKqELWipsyRiruERbao3H9V1G3yZ5bhFWgLZ0kGa3fGSJlp\nWjla3iEwLTOjQ3mWXdvGjStyb7NKCZeeEwLWiJmNWwqwE8rc8TWJZZzDFFGGKgk1aesIOjessCxV\ncYA21aBStmSGDgBmjV56TAgKtPmpcpBpW7h3iEBqr2NbASOjwsWyi23B0bZkGdfLNIVLdMDnXHGy\nDAVmdnlYWpseIZ97LwxR4vqRZ4bYjfoY3JM5WWWWWcjljCfo3pEgKd18Hh73gRskLdWrNcwzk69X\n5fkp+AE8lqBcWGaujkiOVEjN5FC6hSVL8O7yzXeQcSqlvgOg+Q4/7/MA/oVSKlRK3QdwB8AH3+Ux\nTcZkTMZkTMZkvGfH/5Ma529blvU3AfwIwH+rlGoBWALwyonXbPJ3/96R832cP72K9mCEV7/yFQDA\nyoYYQk/nywanvnZNIvH73SO8j60pd7/7A5zNs92DJr7rrSaodIv3XZRC/bzto5mxjkLSxCBMAU8y\nxJmKRN21+SoGA8kUD3YlEqovLgNVNs6TEt7pdzACi/9RH+NQPqdQljDroBchGzOKo4BwrlzBCusf\neUZUfhShc8TmYkbllqVgMYpzGbZZjg2LkdLJZl3V0W3Mx/butiZG2B7IX0BIcelRquAyXsox0723\n9gC5ovx7fkrIEl/4whfQZxbep+6qFhQAjoULAs8zhBvP8040FcsoFAomM9TZqK51AoCimL/jOIZo\n4vPnSXKQzqanpqbM67RRdbvdNt8RxzEcbXXF4yqVSqYOpjNYx3OxTaOAflMypOb+Duo1Oa8lohfz\nFy+iVabC0H15XTXIYb4sLTPapku5QLEi83Bna9vcA32MScnG9qZkuwlrdo9euIgx7c7u37rD313A\nL3zucwCAAZWnyvk8PNbvC2y92l5/gCKvQ6UQoJSTf+9QhOFw75sYkcxUZu2xUmvAcbSggVzPUqWK\nAV9Xojap5zoY65oys77MddBPdL2TJJTARcJ2lDTJEJIQtX5VmvifOdg39bmEalWVWgOFiHXkDeEI\nLKycxs6+PGsu0Z6cHcAlSlL3iDrYHga8djGzk2g0MCSobq+HIREaRf3nMQAnN8W3k6zilHDuSSFg\nbd0VAtbeKMKix/ey/jtsR+ix1phpZMTLDCHHClgT7XWM7unGnWtobst9VkuCaHjlMnqamMg6pef4\nyLFWZxWZcQ57qFTkHkxR1KWsYqRsMYq12IkNGMVjpc3FLVi0IkssFxHr6KleAE4M64TogaUe5hpA\nKXRpYFDRLWf5Y66BZXKzDC7F9YuGLGUjHMl8HnZ6yLFOPl3nOTVmDGlul8IfjVIZBzRnz7OOev7y\nkyiV5FxanIdpOELI1pKYc6m51cVtatVq44F6uYoFCuHMT8+gRqOKId/rWrbhGDhcWx0n97Z166eN\nv+zG+Q8B/F0IrvB3AfxvAH7j3XyAZVm/BeC3AKAyN49xb4D5lSV85gu/AkAeMABIemOMeDNubwqM\nOBsOsKMf/ARYXJbN6EuvSIF+7ABF3vNFCjKr/S4iTtraLH0RM8tIzO0N6ftWcZEV5M0hC/CvP7gF\ne0rek5J04Ng5BBQLzg776JB5oBcIv1Awi5Oe8K1+H3NT7DUlZFssFFClkk+mtHeeK84mAGLezzRT\nSLOHNxFlAR4XQiGSavYqoQjbMezcREMWsHB6SaS+StNybeqJQqctD2eZBKXtzW1U52XBWV0RFlsU\nwijwaDh1NBgY4k6z2TTH1mGv4tLSkoFJ9YYZhuExO9c+dkfRQ282lmUZNqZ+cPXfTn5erlgwMHAY\nhigF/kN/t20bHaoRmX5Ox0ZGsssM59rpmRn0GACtEV6/e+0GYopUf4iSbVUnxk4sx9EhxJjFCT72\nsY/J31HEeTL/NumpOTu9gF/9ORG41qSeQgokVFK5uSWbiDUc4tS8bNoWiSm7mxvYXiecRYLR+sY9\njIZyjcvFoplPek10bRezJCZ1COOur28i4P3VLMM4jg3MW6zK97b7PXQ7cl4Nfp9TLKDTl0UvoaSh\n5Tjw6BfbyBXR9eR6rrflGobdPvKcYw59dvf3DnGxQIF/BsTLZ8/i6y+KCk+mSKQruAi0h6LNHsgw\nMsxxhxKLfi4wTjszs1MY5GSTvXUo1z3L5fDqVYG3l0kkiZ0Ej84LTHr6CVET2rp9Ez32P/d5EbvR\nAGNCtVpAfTgaocw+73muI7VSGRs7ci/ur93H4X0Jgi5dFAOJ1qiDjAS0oZJNfmh56JLEMuJzW3MD\nTE3LsznKy7EGoy6qHs0KMrn+lrJhcW0C3UigfCQkTIW2hyGDRy16L+/T/zj248x+glULBeS4Yep+\n21Ixh0Bv1Jbu084MXJmSWNNrt0w/ZbFSRjzUTkpyL8LR0DzHPpnv2bCPIo+1qjfn8QgjEiodBofw\nXOy3pHTh1kiy8x3oyKxFdu32/h5u3ZONuF6posG19TFKdvquZ9YAvbGfVD97p+Mv1ceplNpTSqVK\n+h7+EY7h2C0Ap068dJm/+4s+43eUUs8qpZ4tcOJPxmRMxmRMxmS818dfKuO0LGtBKUWlXfwSAM24\n/TKA37Ms63+HkIMuAPjBT/s8x7JQDQKMxyMkbB4q1CXaKfg5lAm/WKQ3z4xyyNakRaCcz6FQlYhs\nqy0Z6XYXePasRD51ZjvR5jZG1GHt9ane4XhwS7Jphywer3VbUIxE8tzQrakpdHUmxSxmL4mxsyWR\n1GanhaBENRX6v3mOA5uR+RSz3qlqDT22DQTMuAaDAVxyp3SGlKnM9F9pUEVZgGk10mQcACOSUPKV\nIiJqRuYpVB72RvCYBaQU7e0M+3j+E58AAMSMPDNLoV6X7DLHL3Ftx6huVKxpc3w6YtSWXbPT0w/B\nHDfY4vIVQu6/+qu/iisDIcBoeLfRaBzDt4QJ8/m8yWZnqEt77do10385MOLsjrHB0spAzWbTHI/r\num8jIdm2beA8DdXGaYKSr1XJCZVbOejAW/s6LjzzHBZGMpc6//xfy8vbe8gXSCyg0tC/+6Ov4PzC\nKgBgJ87haF9g1piwUF1ZCAm99vdlnr585SpCwt8+04G9+/ew9qaQsvo8v5mZGQz4705Tou6Z2Yax\n8RpFQ3T6Mq+q7POMoxQpe5F6VFxpzM7o9kfNxMfc6QW8+uqrAIDokILZczO4syZz6RHCz5adIg00\nXCnvzdkp0ozGAtEYHVphldi+lPN8pLy/+pkqlyvoUlEn5DP10U9+EnOLcs/3tiRbW6xVUCI8nfbl\nOzY3N1Hg/UsI693fO0R9VTK7NE1N+9bSKYFJe1CmtS1my9hRp4dvrwnEp30o1486OF3mc0g4slSq\nIOD57W0LIlArFI1tVdnYqyVIdbtD3seP/+Srcm2pHhXMTqOQox0aUaqdbgslrnElZmmdVgsz9H5d\nY0Y5W2wg58jrtvaFpOZalmlHYUKMODtWnxoHPkL2fmbjY+Kew2ujywi2lYH8nuNWsTTDhVOrcu32\n5Jzny1VcOCfXeEh96+bOlhGN77Lnt1jII9Va1VkKW7ODeD0TFZne1wLnkpvPI2W2t3Vb7Nwee/Iy\npuelZHRIhbXItZERzTsgfN4bD0yGi1gOZmpxBhaz0CxJsXEgz9p9kgJtHKNYWo1s9ewZs6a80/FT\nN07Lsr4I4OMApi3L2gTwPwD4uGVZ7+MVWQPwtwFAKfWWZVm/D+AagATA3/lpjNrJmIzJmIzJmIz/\nP42funEqpX7tL/j1//nvef3fA/D33s1B2ADyKkOsYqTaVYKUY0sdK9/nqhJ5NfI+ak2J3msrS3j5\niiS1t7fXAAAFBzjNOlGL1lKFZIxOSX6noX7b8+GS4qwFAprdPg4ZQQ2OpFaz2+qgQ+WQFmtszWGI\nkY7WHMBlBuWTvDHu9UxEWqB1j29b8DTGTwq9Y1smatQO7RkApeuUOP7dX8SZHjKrLagAHmt7OsNw\nEiDi9aSAEqZOnUKDTup9OqHHykWeUbRHgtLy4iKuUr2kyNqWmwVva4kJbfshXVptkv1rvybT5tSp\nU4hI6NjZEZCi2Wwask6BdS6l1NtUiSzLMhmurkuEUWQyU/23RqNhMs7RaIQOtY31MfZ6PfN3/Z6c\nl0OoyS7M2m3XMy1B6kS9aKTVkOhyE3aP4PLRqVBTc/2og81Yolqrq4CUmp151gi7PfTWpW3qiGIT\nlmWhojVqeQxqMDA1pplT2louA2ViYTuaABKjTQUsx3Hg6AyYmUh/2Eeen1MnIc12PbSpD9vuyzVq\nR2MoRv8t7aYy7EH72OwN5RlA0YcbaOEJrSwTwuGk9ZDBJ2En0GpcboAS729E0s9o2AdtnhETqXAL\nBZxiTbheY43MSmCTQKcCEn2iGF3OxVFIsttohEXen0qlgrEmxvHcbSg4PAYNJ3iODZvPZC6Sezq1\nfIBxRzK6Ip+jSpDiYENqy7M0kT9daWB5SlogTs9LxtLe7eD7R5K1l0sl3NuQeXD3698EALzw638D\nP94Q1yQwgz915gl0eW21ru723ft4dFGy9ca81DqHOzuoVdkWx1qhUjFiogkB21b8Qh4R5+zQVgi5\nftb43CiloDRyx5qklR0TBT0qmQWOh51NyTRX6I60OLeIIevyR1T+gbIQkCOQ6bmL4zUMOGGirTNc\nZLCMoAtVhzwbY669EZ/rrbV7WH3yMo+L9djAR6ksc8Py6WrUbBq+gK6Jtttt1Kh9aynAZv20TuLb\naDRCeyRr+OENIbFdu3fHOBa90/GeUA5CmsHq9aG8BDaZnBY3KqQ2wlTjEXKRBsOhgRaqcw382T/5\nPgDg7p68bnEaeHJFej7TI6rDzNZxmwv4gEX5ZmcfLUJgQ91/mCl0SXzpkvTSGadwudH5XPD9ahVF\nTczJYPrHIn6OGwFVejbWCOMEKoNHbERPCMe2kGW6/1Kz+h6GaI/HwyVpSwE5wrLKteFxMdAbVX26\njhZh6X2KRlvzM7Apwq3JCeX6AgLQb5D9nL7nGQKQ9muMOrFRAdLQp53PGwh2PB4bCHZlRWCqq1ev\n4vFHpWfuPPtwB4OB+Zw+VWvG47EJkNbXZZGxbfshBSIASNLUWIzpjfao3TL2VScZtCetz/RxGUJR\n4CMey8KlraqgUsNstrkIRZaHMa+Xf0oWs87WXTiEg2okvRyFA4SUsxsPI+QtQoqcs9v31tDdF1Zu\n2OvzuFwUKwIbRSRxDUcjeITzeoTKkxMQpK399DwPWqTQLeSN3GSZm4SXj5FwwQp5H+/dvW16C7W4\nfsVxYfHadBhkujkX5NjgqEdmbiMykmeZZq6qDMr08CpYxi+WlnJxhDgkfOhyU3YDpJbce/2ctYcD\nYwPm8t6F/S5cQrm63OAHRSgSmQLC1JZlGRg/jRMo+1gQHhCCHAiXe1S1yTk2Aj4rZT6PU0v78FKZ\nQ8Ou3J+ZfA2lihxjkef01KkzmKYNILh5d7a2cZr3Ig5yCCOZV1vf+g4AYHtlFZ/6xc8CAF65Iyze\nTr4Jn2Q/xzqGSVcuXgQA7D4lqlE/fLABi16TMzWSxvots/hnOvgNUiRa5QgRwNAnGyfmOml1NI9B\nhe8GptdSm094SuFgIBt0hUSyguti1JFrkzCYKbguHKP+pcXjHShG95mtzHqWsgxhW4BjaWKjthX0\nYXP9K5Mw1N7fx+KsBHuK63M7SeDooIjzzFWWITM2yJ7ttNqmL77X7pjj2WGft+t6Zp3RdnupstDj\nBvxOx0TkfTImYzImYzIm412M90TGaakMwWgMb6CQ00a0TL0LXgF5RoclRvd138P4vsBdQ8/GrQOB\nRnTv5qlaDfOkcEe2RDHjgo9v/VCKzzor7PS6OBpqjUySXioVeAy3E2Zz9caJNF6zKtIMCfU30yRB\npu22mCrO2MAS4cGqVtYIh8i0E7mOWRzHiM8qrZ3o4CfbtGDBhvUTcY6NY3JQ0h+ZKE5nUONxhJAR\nacaM+dmPfAQzJG+02AoxGI/g8vi1wHOUZga+0LZiKsn+QsNXndnFcWyi/yQ6hltPCoEDkknqrLHG\n9p7RaHTcs8nXXb161WSSH/qQWEIVSyXTT6qz3tmF+YfUibR910nTav19OtMNwxBWrGfMMYlB24U5\nOgNXwJAZZ+68XLfh9QJ8QvY28fpqUMKA0HxppoKclnlhIHtv7S4s3oMSSw7jMEamWwOYtUfj8YlS\nAksU5Qro5GWy0FGaGid723Wxx8h8f29kro3OOHNlHovv4wxVizSxozfqwyK0OtYiWlGE2WkhZ+xs\n7PF6WKb/LWMvs+U6sJnhqTRFxrJBQjupUa+PLpGCPn+3OHsKGOq2K2Ysno8cbQRB4odlAYuE1zZu\nClw6CCNYhIM11GpbLjaIUJwd9OATlu4Q7o/tTJgzwDFpxHKRkaykoUMnV8EKW1Oufle3oru4OCvI\nSa4txKInqgsY09Lw2htC4hrtHaJB1Z6dg0M8v7QKAFhnxnz9j7+CC+fkc55blKzxpX4XU9MCE/c4\nx4NojD5b7xYfl/7zswfPwOOczZGYYyVA2pbfdSKZh6M0QmrJ8+rlXFicMAUSqxzHge/qkhHPzlIm\ne7NIjrTTBLOEfy0eS3tvBznOymlNFksi0w/vkMbiwkdKHERZFpS2ftMtLLZ8p/ydxLVhz1jE2am2\nztvDPEXete5vO0nQZJZ9RDIfhqFBkjRkm7kBfC6aOmMGgKJ/vIazS9DYtI2jCGn27qg4k4xzMiZj\nMiZjMibjXYz3RMZZCnJ44eJjeOBFOBxK5Jxj+GtFCjoGL+S1ek9iXBnWdtdxxFqBxutPFWrAHnVF\nWXi/frSD6zsSsWk6clCqoxJI9J/xM3zfN+4j0Dr/6vsaAAAgAElEQVSxnR60SGbKyAzZsf1O0XeR\n17UlKricKpcxV9bqH3zvcABbO0swW0jgAI7WlSTxxgJSTQ6ydGxjmwZmW2vRKmDECL3eaGBpScgk\nDeo2rt3fxHZLMnOH5IzHn3k/+jobJHEgCHJwaa1lMYu+f/8uClWJ2LQARdSNTTvHSdcSne2laXqs\nYWsdt61oYo9+ndHaxbHerOd5x8Qdvv65554zwgW3bklTs3UiW9XH0ul0TPYZBMEJ+67j79OZpv6d\n63vwKDiRslYNN4NNBxSbUXAvU+hRP7VxnmSdhWmkd4TmPu4KgmBXHBz0JXPwilNoMIursma3n+zB\n0vOAE6yXRQhpAmwxwz2KQwTMDLRjgw8LY9ZPtw8kA7Rd36AR05mDPlWQtNvFwpkVoxgUUjRg443X\n0L53x1wnPeZIAsmz5pN3PMyTkBIxu6/YPvLM2KyIz4WTGOJHAMvcc23r5MIyNlOaW//KK69gLkfj\nYq0+VSxii8S+69SOTVtNvP+iNK3PFCUzy5QFi+SoferhJkmCjMS2fD6PVD+HPEbnBEKS8ljjFHCZ\ncif6OVQeqhfk+6Z35LMPX7+OWTqcaHKQ3R5i77rMRZckwrTdwmVawZ1dSHGdWfp5EnwGrRZe/ld/\nAAB43yc+Lt+xfAEF3crDNplyFqPWkIxu5nmxgptenMEf/1//DMCx08d0oQy/JvP4kFO3qyLEbDmr\n5BQcrkNTtjZwVscCCFrAIlXG0NzhffKy1Ai72CFbQToxKhRwqBAZUEgRkY9CWWf4mYNEabszINZI\nmgZ0bMugDFqxqFDIQRERiFgz3t/dR3dP7kGFLSN2roA8W0+qBXJVdvZwimSqfbZ4xfmycRxylY2+\nrolTMCNOMqMqpfV5814Ogf3/jXLQf9CRD3w8fmYZyz4QU8YpU7pPSeGQvWs+J9p4MESdC+5L165g\nn+hnmZ93qtCA16JoO9VArmyuIaDElV4nHSuGoiN7oiXGehlcLpo60c+5jhEvLlflW0rFPAqa0HBC\ntFx7hOVDG0W+JxtrwlMIl3/XC1wcp/DIzNT5v7KtY1sxYyVmGQajtgyyFVClEH21Xsfp00JRqFO2\na3NjFyMGIPVleYiDchnr7M8aUAnHVjnkkee/SVLp9TFHpmOojoXd7Z+Q/VNZZvo4dUACiOwc8LCF\nmJG7cxyz0Y05sT3vWNFjQMi2WCwaVZhLly4BAFrtNtbW1gAA9+6Js3yKY2uz6elpTFFyS/d5ntwk\njHKJ7xuISUuswbNga0UW3oxhksGlT2pGGb5+I2+YuHloVqmNFmHqw+YQp0pyHRcsWfTtpSncvy+9\ng8bL1LJRTANzHQFgZzhGSUOnXJidUYCYovJdBjb1UhlHtDGzhgm8kswDryh/32weYbgtQdMshbDP\nPvKoUXbqMSDZ290xgeIsSRUVN48in79FSjFWlAuH3ogOpSTb7hhWykDDtpAjgzHTC1y5ggY3Na0c\ntLx0Bm++JJvjj1/6HgAgCYdYnJG5eOGS2AV6owGWCRf3aZyQWRY8ylfqkoDv+zhLVZipeh33+fs8\n7agiZUOROR9ToNyCbezLFGXqYLl4QAb6/FMC2b711l3s7sk1fopC8bsPNvDgDvsNCaeurswjIBT4\nze98H+cvCCP0Tfqc/trnP4cXb8tm+6Xf/R35ugtP4hyfrw99VBSn7GoZ+00h8W1RuencqRWMSuwR\npRrXlOehOiXBTqPBHlA1Qp91gRQpHK0IBN2dcIJVy/UjcF0j4aiNNPKOgz0ygLWBRC0IUNQEH26m\nLhSK2j+Yz4Kb2rA0K10pU0rItHqRpcx6pjfTQi5nCF3gvWh3hnhwS67xeSr/DAEMCK02anLuVXh4\nhLD4XEHLRbrY2hYi0Gg0wlFTgtld9nNamTI+yTZLD7Ad2AyQ3umYQLWTMRmTMRmTMRnvYrwnMk4k\nGXDQg9UoYJlKPrW6/MwBaJ2VTMqhcWpp/wC9N94EADzY28GI2/8sM8nlcgPFA8ny9uhO3k5jBDqb\nJV08UQoVRrC1usBaDd/DDOnm04TZlmZmYDFLyNj7F8fhsWpKGhu1Ed1sGSaOEYQfswkvpxRKJNxo\nIswoHCPjbdC8o8xS5t8PDXUM2wIC1VqEeY9aTQNXrN2VTOzOnTtG/ednXvgoAOD06hmEhHGahBkf\nPHiA2JPzr7Gfq1QqmTaT3a587qnSkoFZdZ9cLp83WYzjOAYS3duTaPu5554z2aA+PuBYRUj/dBzH\nZBE6+6rX64YcdOeOQIzjMDQZlG55OWq3DOS7v79vMlL9nuXlZeTZ62fIBFGInHZK4ryAZwmD4cQY\npSksX25GQu3X3OoiDr8nxzjFTCqyUlQakl1eu32IWiD31+vLXLOX8tjl/NXH4gU5DDWBifd04FgY\nj3Q7kRAj6rUGxoTXY1cykfrSKXR1l5adQ5CXObu+IcpNU1NTqFLT02OmXwhyBgkYafFsAB7n3xQ1\ne+0oQUwN5yrRkFyYmWcg4Dw8VJm595ZtweWcCLRYv+MayylN1ErTFOdovLBUl+979OwKDrYlG48o\nmh8ORtiDIE1JVxtZj0wrhf68cRThzBlRtcmy7P9m782CLb3O67C1//nM59x57rkbQ2MGQYAAKZIi\nRVmSZSmpsoaonKnicuU5FT8kKectD4nLVSnLSfQQq1wuy4olMRYliqAGDgBJEARADAS70QP69u3b\ndzz3nnn45zx8a+9zG4RMtBVXwVVnv/Ttc+495x/2v/f3rW99ayFjKUW3XqhsIks+0TGfyHBpYoqC\ni9t8tiu8j/XTG8gpQm2xlWVzaxue7o3k/GksNPBnX/s6AOCFz30Wxz35nHMlgRm//rWv4LlfEZvE\nwpygMqceehav0WbunRdFY7tTdKCUlAMWLss1Ki8v4syTYv9389aL8r1xioAZoMesLyjYqHLRGA96\nyHh/Q5KHXNdFoUSjA5Ztim7B9N66GmbPc/T1ZzOTrDoWqjTbjviM+o6NIp/dmGWEPLKglG5HUbrS\nJX0oEBDNWBASqWm1WnCJ8ngekYpSGftbgpY8+vSz8hm2be5fjb3R5dyBy+8uZvr4bZxdXOXneaat\nT5vMdwZD7NEqb3tfsvtmq40w7eF+xjTjnI7pmI7pmI7puI/xscg4R/0+3nrlFYyWGjjwSQ8/JxFX\nqVE1tUaNw1frMygsSh2rUCmB5QzUGT3W/SIsbW9D66/UVgCjMF1fnK3U8cCaZLNnZuXzarBRZDao\nv9ca9U32qBvao3iMEfH+OBojZrSakNbslhYmOp2scbpegIpRuGFbQTghyuRKCyBYk4K6CZeVaZow\n5CXAkGcqlYpR7bmzKQo19foMmiy4P/TIZbmGlTJ8VvPXa1IrwLyF6I5E96+8IlT8TtjDgzMS1ddP\ny7UZdCYm0lqJJ/B90/6RpqnJILUIwXA4NKQRXeMMgmDSFkIaueM4JovwdUN+p2My14tsDA8KBVMj\nPGlPpjPgubk5LLP2rE2ru92uIRcZO7RCgFpNW7bJZ2T2hIClQ9UwTWDzeqUkCa0/fBGHbDa3SbwJ\nxwPMrElNzrrTNNmiz7ra9eYBQtb7VjfW+CUKI1LrtYKVKnTRYQN+3KJVXX0OvbGc823qyQaVBqBV\nYwpleMw4tSXUWqVqrsnmtsyHwPUQ9uV6r8zL8c3XGkLiAVClPV847mDIeTXPLAVRbDLOgqfrmtY9\nOsUajdBoShRFGJGIMjITOkGX6jNhW/4dhYuoz8hcXD0jz2O4v48BEYrmMVsuRiOMTYYr1//oSEtm\ni3OO1lw+YA09zi3kTA31vLEzGB1frX+aQiGYl4WkxYyxtrIM65bMoWPWyw+PmnjqEalNdigUUI7K\nmF+X+vcoGWJrV7KlzZYc9z/8R/8z/tVf/QUA4MknhfRzsNvEzo9FuWb7mHZ9p5bwza9JffHZ3/xV\nAMDGmbM4Q5eVK6zJR+MRBkQvbGZrlm8j0JkdEsRsIQuK8ixUSmXMsjZYIaJm5wpjqox1WT/t9wao\nsw1PE98QjVBkG4pNSzgrS+DZmq3INp9caelbWFD4KFZdlVIZ4BrosLYf2C52aDmnSZnFQhG2FjHh\ncxH1Boh4/AUSV+JxBJ9CHfE4NOIXDSKZc3MLOHVKruf5jpzzzsEhWj0qZP3BTz1kOdaP9mv/Ycex\nleNfexF+97f/d1w4JeSALz0rF+zcxUsoPCCF31t8SGo7W1h89TUAwAs9F8+uPQ1ARIQBoNltQq3L\njf7xdZmIO7sRunVZLGwu2hdnN/CZp6U/8DKh2tGNa4i2pW+szo1s3D42vZ8h58LQcZHzRg4dByHk\n7xNHO9339T2Dx769NAcO+QDqzc/3S0AiH1ojTBqNIqNUZPHfYThGTPUSPYHcQgG7HmEs38VtSnjd\n6smEf2ccI3pQYJ72g0Kg6Pg+dkfa405+f65Sw8x52Rw/sSpEhWu3ryMq8noSRvP2HAMzWnNk4VUt\nzJD1mOc52nSP17ZHVu4gTfWCyp7a0QQWsVmUT3MLri+LdKUs37G5uWlIQZqAlSSJgQQNTJhm8Mm2\n7Lc7yAnXPcZzLxaL5nf9ExJkP7r6JgCgviTQzt39TVw8L+zIIr9vqZNhnTZY7jFZghtnsfWEbOR3\nfywb8nqngMeOCFWihl6LMFCR1+lWCxeWZWN971VZMGdPLyOrkAValDkwKAMF9i+eo+B3dHSEM2Q4\n+wXaeB1t4UkKU3tJBwWyx7VJm7p6zTzd65SFKdgBCrNybcuObKAF34Wv+4d7EgAVEMOi/2xmyyf2\nkSFmT3RGMscqVnBIEkun4uBQr5NV+cJ2MOnX8xhAzFUbeP+OPLsPXJR7u9ftoF6R4zruyHksuTOY\nrcprBULptg9cvyXPZo9w9mYnxFZH7vfiQhHdDpmgtDsrFhwo9hZWXT4/SQSfrykq65RUGztKNsR6\nWU5keW4IVROln4ABeD8/RjeS+7PIwDNqA6unngIAvJcleHtVrt2n/ltRC/puf4jzK7Ku3fojIUTd\nfOkrWNBses30Tlr4Ip9x7w8Flq0/9CA8liQ+9zMyN//Pf/x/4WcekDm7xk3r6dIyktsSaFTTDC7t\nxjQT1/MKSDWpqyuM1V6aYsSosUTYv5UBKZ9JEnIxGCkMxtyAasJiVXFqVIuKXKOO3JvwSAwbDYaw\nWfYoEO6fqc5ij0GFRRH6KOkiJ7u93SX5Z3EVzb48P+OBrCdBoQyfa8qIql7luWUkLLVBW4eWykjI\nVM+jMcah1qrk828XERHeLWkp1KSNiytMIj7imEK10zEd0zEd0zEd9zE+Fhmn67pYXV3FL//qr2B5\nXqAaP5FI4rs/+D56V6lNSP/pJx0H86TOj2pVtI/p2E7h6jhNoDzKoBA+qjnALcJGDqPNu4f7+O5b\nknWo85K+n5utY4bwhk1iR2N9FSEj+r6Ge8eRKYpHcQaNWuRMM3uYGC7/u0aOiW6N1mPNsgyZ1mXM\nJ2QcnX3aJCoopYxI+vrSGnxqelqESHrdAZ79RYmEZwlF70WxgVF1b6BcOxJzdI9XDlRLpHgrwn+z\nGwY63aJQeZqmBrbV/ZXAhLzheZ7J9nTWmGUTUsk914Kvaei31+uZ13Sme/L3NCSoPxOQjPKkRi0g\nkKFuaznZ7/nQQ6Khq1s5EuyjTYWYW3c3AQB3fnwTgwsS8T98UaL8+XIZjz8t13WTLQelxEZMOLVa\nLiFkM2PnSKDVldoMihTFrvH+pMcdJJxXYZsmxZ2eub8HA8mu7HGMgPCaJnHEcQowy+4O+trPF4un\nBFVRtgWL10GdsFczgKlWl0oy01OnuBxIEnOvfrIFZdoY7GwipK7be0ajESJNtNMC/sUiFPWQ02Ri\nKq7vi76ntmtD+1tpeHlpfglRLvNgtzfRWy0X2ec4J8c6Pz9vUIR+v48dQm4JtWzdSgklIhi1kvwb\nOC4KxOLbXcls/EIJdaqNNe8ItP3Q3Cy6VI26sy2QbaXRQBLKsVbLgjJdu7WNB56XjPLPv/MynvvS\nFwEAazVZsEZpH//ofxHfi4cWJWMrFgqYo2lAFlJdyXIQEYZsjTcBAIeHR7AKPwAA/A//8L+X4/vi\np3DzB9LS89wv/225lp02zj37Sfmb69dR0QbQHGGaoc3WryERt1GcItblEV7DuUIBfZYPdA9sPI5x\nfCxZqs+5O1urA2w/6ndl7ron9K1t20ZAI+wBn7nuaIQq2+eiIY3gBwPU+Hs2n5nBeAS2WuK9a0J2\n20gUFNtjOuxZLpZKZg0Y6HbCboqgoM/Jhc/+2wmZLESV5uwDohZra2todz/aeq3HNOOcjumYjumY\njum4j/GxyDjjOMbO3i6K5RIyqqY4xMrXz51BP6BzSS7ZQO/2Jt57QzLFmYMmAmLV9YZQveM0RUdb\ng7UkUhokQqEGgJTU5a3DfRweSMbw5ptiTXZhto4lRqvaEWEmKMDSOqpUuUjDHOSFIMttozma6Xr5\nRAvghOKPhQ/1BuPQEbhSCgk/SNdWTzqmjEkJj+IYjzwmZIMLq2dRZkvJ0YxEfasbXXzhiz8HAPAZ\nHUdhz6gIaacCpDCGtjmdjguOjxqL7AVd7IiBlRURUtBiC8Ph0NiFbW1t4fhYCBP6taWlJZMBFhjV\nOp5nMkQjhDAem5/nqeF5MoLVZKI0TU10rDPdYrFo3vd9/55ME5Bs6KTtmP7sQZckIyWvLS4so1YV\nkke0KJ/nJhb61DN+h9Hv5bPzOHVOnF66dHGYyX1kd6TGVCkEyEsS4Z4LlgEA9bGPgOSbZEZqnUOV\nwqaepiZ7zJXmzPkNOxRwcIqoOHIP5pbY/jIOETCL7sUxRjRKzrxJvVmbVifMGrM0g5XqmqO85yfi\nDgEAAUk0rrKMyhEovKBUBpe/p+dhv983x2orHw4JOzprjOPY3OcyrZ70/Dg5lFLoU/v3iN+R1OfN\n73bozHF8dIhjtqskrHMViwHmF6h8tLgE9OX6DLQWahxjh3NxR9cPsxQrzPaO7woicHZ9DUjZXqFY\n45spY+4R4Qb02xT0KFURs1aos6Ljbh9Xqcj00EMP4OkHJfv8P35H3Bc//8Jn8NwTIqowOuLzcbuN\nswuC0DSKzDzHIcq63YuLS8MLjNtHti3n8fOPP4Edktwuk+jSvHEdt9nCsba0goUZud43r7ONK42N\nIEGBiECaZhMltFSrr/kI9PPKNaObdTGgVV9bW9XVq/ACzeegRVjgYcTsM7NdownbJ2FtmOQ4c0bQ\nm0Mt5lCrwGHGGfM57PT7sD357n22jDz8yJMYRnJN/s0fiaH8Cy98CmXWxhus9ysrNc45UTTGiAQn\nTdr0fR99cjyqvK53rl5FuSTf91HHx2LjzHORW6qtrSLmIUXcQF3fhUc24mJFFpxTKdBsitedF6fI\ntYdnTrWgXIHcAJxephXPqIfWiH1OfPTdUgEVwrIRC9RvHbVwRfcLEe04PTeLGkWh61zoCp5jFpoA\nLnJKfMVk0rbROXGGP5nY6z5NlSvDoB2O9aLumw1T33CvEMAjeUhZhFNdB2cXTgMA0lGKH10R0sm7\n1wVqKs0voEgVIQ3TlOpV7GgfR7LYolGECpVPugNZwKpBGTZJSx5ZpUet5sSWiw9uoVDAyppsDksr\ni2gSZnVI6Ni6s2ngZM2qLZVK8CmIrpuzHEtBEfrRij9JkpiFWX+fZkYCE1ZtFEXm55PsXL3pnoSF\n9c95nmN9RR7izT055k7Uxngo93SmJIvxmXNnoQhVFwvyHb3WHZTJLK2RDWofD1GkX2CQeMgd+d1L\nSwLNxZstBPybwoLM40EcwidsdEiFE9v3zdxIbEZfloJXkuugJcsQjdDjM9LxFCzO6THn6TgMMaRR\nQsgeUEspFMnebTAoCgoeOk35bovzy7WU2RW0PJltK9h8NhNuquN4gFKRC07uGMWtkxunIWUxmNm/\ns2OCGCPC71jmNTWY2Dvp9+eoktNqdSYymPkJQwAGmbaawMBjSmjWSyVUSbbS60jYaaPPDewb334J\nALC5toGNZ+SalDz5vDdubeLyHGH8JekdHl71jfnBTEPuY4L3sE8o8/lPP48Sn6ufe/xJOe6bt9Dd\nlWdye1vIik89+ah5HvaaDO6PjpC2RzwGubenVhws0zLrAqHww8zCmNj8m996GQDwwJkNtLj5dcMx\nXvkLIWDVyIpOksT0omoGdgHAMJbnPWWQqRJlbOGK3DjtSgU5rQrDSNaRXq89uWd8lOM4hsXnXsE2\n3zezxH7iQhGPPvsCAGBxXQLvH735BnpMRlz2cSo3NcH2cVOCUWe2hjJh7MuPCunv0kOXjOFDq8eA\nKonQoAZAtVZGndCwDpiDYhEhA1LdNx6OxlgmQfCjjilUOx3TMR3TMR3TcR/jY5FxOo6DuYV5FBbm\n0ByQVk84dRxFaDOqKCuJSOqwMWBmVwHQYuo9AjMVC7BJx16n2stcYRF3tiRi2domLBSOMYyYfbH3\nbwRA66rHFAbe2z/CPKHjWUZ9tczBrCXvL/hlFEicyIwp8oSI8eHjg42agIljLAsZX9cwm285EzUh\nRs7loIRGIDBP+6iNPk2H2+zV++wvPQePGWeL5J+w6GNMWLPCiHAw6qFaocURFWPqjSpAaMRlprRy\nah0DQjEaGh2FY5NVeI4LlxF/rSbf++jDl9Fli8oxFTsO9vbN39Sobzs7O4sqf7YJF5RKJUM+OQnZ\n6kxEk5w8z7tHlUhnnxr+q1arJuLUIwxD7JPqPujLZ1fqCwZO1YpMvfEQOjlW/Nz51RVkJA/NrEq2\nvf/aO7hICNyzgDZbp0bHNP51bTi5psET8hyn8HmNdaZlZxbGOqvmdejFsdEebY1p2+YC3bZkysNk\njFTbhB3K/YmSGENmCbqNybIsY0Y9ow2A7QBlEncKLGUEtgtFqJDTD45yYDR4tAWd65oyxGg0QhZM\n7gcgykG6/1nfiyiKzH3TxxWFEWaYrTvhxI5ugWjRaF/ubakYoEyxcV9DtcctROxZbLePcUTERNEg\nPA1D9Em+KfH+BG6ApWVp9XniE6JM8/wzz2LzNol/rpz0ewcHsGY5n1lGSd0AW4cyb54pyNriF6qY\n2RD0ouA6+PN/9Xtyj/gsbd16H9GxnEOjKPf06Wefxdtvv833NwEA3V6EObZVrLME8Pj6BuokKEU3\npS1s3rUxJhJz865Ani99432MaVloWRYyZuSKz08YhsgUBc9JioHlIdFkOaXVezyMRmyh4n1WloVa\n5YS1IoAoHiIfTJTTAEClEWyiRlFuwdbkLyr99MYJ8kDuyyOfZNvbrS0020e8xiTPNeYxJNnn9i1R\nQUPrCHpFnVuUa1NtVBFTvc11yRzNEgyplnZnexuKbShLSzKX7t7dNfPvzbfeAAA89NDDqFX/Y4Rq\nkSPJMxy0j9EkrLRIt/NaqYYEhAnasvE1t+4iPBSoxYkieCzQeT5ZfwqIuRjqjSyLQ/zSBekbu8v6\nxrW7t/E+oYBDbjqxA7hl9meSBXkYjzG05Bi0F1xhlGKJsFcyq7BE+MNhn93JTdO6p6z512+nvmEZ\nOggJNenJkiJHONYQq3xHdaaB3VtSo4myHDH7nEpsbl88dxY54ZQ8ohRgnsPhwqab7vtZF2MuPn0K\nElSrVSPF5lry+7du3zaLooaZPKWMUHuSpQam0zBOt9s1sMs6fUBtpUz9UTPymgeHuHNbYKwBg5mD\ngwMjrzdLuC4IAvO3GtKN49h8h1LqHqgXkA1WQ7x6I47jGAXCmqXAMtcjJ27e40K/1zzE2rpAchl7\nz0KVwiO7c+Oc9HPeHH8FIZ+mIPBRsrUnKvtanSrCmJteomUZI+SxFprmvHAthHx/90g2xqNwBAzk\nXrUpwGFXijgig9QqOGIMAMDJ5Jwyy4PDeTyBlSxkPL+urtWPB0i5CTWKPBbHmdTsdUHTPjEXswmr\nmToQ8F3PwOoRN+x+v4+Um7GpX8/PY9S5l8E4HA7h8iEpMiDrj4aYZ1O7DnrCMJxIPlIC7iRT2LGs\nSQmBAWMW+FAD1l75m3kO9Aa6v0++YxhFuLR8Wq57Igv54tnz6EeyztRXBVpcePwpvPevvwwAOOjK\nce0edXGqKBtCsLCMjYasL9/8zvcAAE9efhiffVZ6MH/EOnmr3TXSkAOuPSUAC9ygLnBz+OSFs3DJ\nZH3/pgif93o99Eaa3S/rnG9bCCiZ2Dw+gscgIWSpJ0aOjPMq5xpmWamB1z0Gxx5s+CytaIhfpQnK\nGlbXZp4WMA4ZjPPeVoNJ/Vs5DsD1pTOU9w97Q1zfFk5JQPed5z7/Jbz16ncBAHu3b8q5+AVzH/vk\nquxsXsf8ouwJFfb3DgY9pOzZ1P3g5UoJusUhyRPzOQMmE+MwNC4sWiClVq4a44yPOqZQ7XRMx3RM\nx3RMx32Mj0XGaVkWisUiRrYFn271Wqpr2OkhpiJOgdF2MRP5OgCYQYbBWPehsVfMtuAw9ik4E4/H\nzg2JaC7Qp3Dt9Fmco8P4NSqg7IyHOKDPXLspMEitXkZAWDNjNN0b9+Ew2qllQ9iUrnAIkXx44q/w\nQVZtpmAEp0OSOVTqmh5Li9CH5TrICJ1UyaY8e/ESXvymiN3HSmGnL5lWhYzP127ewOgircHmaW8V\nBIDxBKUnXrWCMXvTCoRL0zyDy4gxJZw4Oz9nYNcW5ao8xzXkH9/30SLpQouzLy8smsxPE6dUnv+E\nDN/MzAwc9sB++/uirtLv9w0Ee7LHVWc2DUb2tVrNvO84DrbZY3qSwKQzlZP/2lQ0cbXaUwoE9HnV\ngbWygTLF0sepZEoHvZ455wIFwcv1BpK2XJteq4eZmsxjn0zT5iBCyvmpyWl2yUNGNqxipth3gANG\n6HeYoXYQI6JKi13QfogZxiRiWFCG0ZoT8s1sZfo8NaEoUxkSkmtC7YEYJQhYhoh4XImtjD1exmNO\nVQ5tbZmzDzqNEyg/N9dae9JqWLbVaiHl9dGQWrlUw633hOmp+34r9RpysoqNJKLvIyEbMyAELAiJ\nxeOeoA49Zt61WhVlnkurK/PTzqsIxxP4FzOtrKkAACAASURBVAACy8GQ/bNletemmWWeP+2XWqrO\nQWUsG7D0sBI0cPCGZI03eb8LtRkERC/2vv8qDu9I/+3pFUFLApUgagp6cKYhn/N+uwNFxvLGIsX1\n4xCDttzzg7vyGUd7p9El8WiHvaStThsVzv2UUPj87JxhUdu+jyHhWJXxPL0CLC2vQ8K0yhUcZtw6\n40qGIQJCppp1H6sMMde1TPsSWzHSVBO05BiiJDcWhFZQRQJNxpTPvvzUJ9EgCefabWEpXzy1YoTc\n+1xT+sMBZnUJh6prN65fgcd5XD8vtm1pFqHE/UITfZLMM2UW23XgsgSn59Xs7LwhFC2QpLezs4Mq\nWd8fdUwzzumYjumYjumYjvsYH4uM07Zt1CtVHEcDkwXFWizds9HwJbrymhI99VrHGDMTGasUEYvB\nOds0LMdDnGqDavmOMBxjNSPLgwLrcR6gwFpcna7n21GIWxS43hlIBnf3sIW0ql3D9UEDNmuqTtWD\nKpOqz0jeGvxkLVPlH9LFmU8E3XUfZ6oshJrQwYwzUQoDRsQFvlcoFUXsGyJafvq8ZJqf/81fBwC8\nur+NPlOnQ0bl4/EQBdZ4I9aq6o06xnRNr7O3LB4MoVhjGrJm2E9jWLw/mtRjWRYyZpTjcATL1qbW\nEikmSWzqiq6na6Y2PkidSpIYMbWGP/lJUUBpNBrGOkyTkY6Ojgxx4GTv5jzrukEQmIxH10VPGo2f\nFIa3yKN3mbkN0xwJs+JoPMlobNZ3HK3Y5JaRU9S/PSDRanYeHjPzcO8YjRlm68xybCczc9twvMpF\nDDkhOpZ833a7hSu7kmHEJdZUbQ9DWjzNMQKPhiPYvD/5KILDml+F35dkymQJESPw3FKmBcmlVVqh\nIOQcAEipQZvaudGjzfhMeZZlMpCU+rUltzBBE+IRMv9eAsnJ667NCHZvH+Db3/qWnAszztmleVNj\nd2lc7BcCjFsy77Q9VZrB2Pdp5CCOY1O/VkrB4xwbHkn2UiwVYDu8B8yuAj/AqKdJcNQotWx0meG7\nFZkXzc4B/IJcu2PdeuZ6UBfEgOKVK6JTfKpUx/o54U+g7OK1l74pv+tQG/b4EGdXJdM62hckRlkO\nCswA6zNsO0pCgHXDQok8hIKFwy7bpcZyDYNagH7IOjGRhp2dHSyuCuEpsH30aSdWYytO4PlQZBeG\nJGCqBPBJdtRo1iiNoZihl5h5pr6LLnuZO9r6z85N+5juz86tRPPGoCwbhx3+TSLn+fOPPYGcSNOX\n/+1XAAB3zp7Cf/oLorR04aL0zN58501DdPJ4v2++dxUNrtVnHxVt8jRNjRF381Bqp5Y9aYdyXdeg\nUynru6MoNGuFJgytzC8aYuJHHR+LjTMch7hx4waOCg5S9uDMVuWhGnZbKJJwo5mmQRAg5WI27PZQ\nJ5QW+zIhjvod4/gQGEqkgpfKTU812zBx4bGoXOMilCmFQlU2llMsYI+W19Enm7FHGb7YseBwoQ+H\nLQy5mJTZfJtl2cRpgyPL8xOemjLyPDOTScv19YcDDHiMVW6m7W4Xxaosms98SoTpS7UqHiYr8Ntv\nvIYv/q0vAQC8dWF6VssW6qflYTokVFSpVHGHDumeS5YrbNTIJl1iI/HVrdsY8ZxXlgTSaPZ7ZjHs\ns/8rCALDIMmNAd+k3zI84Z8ZaUeUcWhYtaZBvlgyxKOtXYGkTm5yerIrpYwIgxZZiKIIL70k/Xhr\na2sGTtYb6NzcHCp8MPR7SZJgwAc65sJaPsGsc7ho1Mtlcx1AEtFoHCEPCBcvy7HcKZQwQ0eUo84+\nYhKcEnvMCxLBJnRaJ+OzE0VIOT8jomi3202gLp8dcxMYpBkCNmu3CA/O+iXk3NznCw2zCCtFz9qZ\nGWRk7hwQwj/q90xAqpnZaQYM2Ju3eyzzohYsIc+5cLlkKMcDzNAhI2HQ0CjPY0xYOVcOUpJJ9nbk\nvlQrFQwIkZ2blzlZdCoYk/DRIwM23kthEcptskRx4JdR1D2kFP/vDUdQ3Pz29+VYLdcxBJLThSLa\nnDMzhDKP+wM4ZFFqqNayLAPnP0+Y8GBnFwFZsmDQsFCdxTAk81obFDTmUaXDyd19CXB2Dw8wIoO2\nYJcm8KCeQ7YNm8Fu2mR/d9HDqoaxCVMnKodFd6hjblSHwzYGNvszGVzZUQpLkfDEoLRUKWJE5rxS\nDmYZgHhcWzrNtpEItHkdsiw18pyasOa7E+eiWp2wd79tIN0FlraOe22khPb1pmQXPZTLMrfvtvs4\n/4Rc29evbAIQz+AzZ4VM98yzsoa56djIeHZJ/szSxAR4YM9wOBjCZVBeWpA16s6772JAmdXTdBxq\nHh9D8doMh0MEnDsays3SFEUGeLpDAPOLRmrzo44pVDsd0zEd0zEd03Ef42ORcTqOjblGHb1ogPdu\nCHFgD5J1LNVnkAcSPW2cOQ0ACJpto5qSWQrI74XA7Ez64QAYAes8V0ickH9DEpHK4DDzCZgtVXMF\ni6ocRa2EUiggpLJOWCGUXAgE6wDgOgoBIVGPMIGRLDs5PoTynKuJilCXkGixWhMSD4DjrkRhs4vz\n6JN6/s6VKwCA+WYT7zbl93aGfSiqnOwlku1UTq0ChPZ8wry5bWOBka6nYZokwjFJPXe2pFds+/33\nsTYvmebpDWkjWV9dNTCpht7SOIbLTMr2PCPhpTPKVrdjWlOMao+a9JdlJBMkWQoiiwba9TzPZKFN\nqqvYtm2IR8UTmcRzz0kE2+v1TKapvUXr9br5zDNnRKLMcRzjZRhp79Zh30DIgfYG9G0EGrLWPWNe\ngLv7ksHHmzJPd5rHUFRNmiuW4NDuLeO8KuXWpDWKdHg7zWBTrUfDS7ZrIyKyEmkxeORaYAklEpqW\n/Apq7H1c9ksIOGdDT87dKQYY62ckluMPQwddZsKx8ce04HAeJ1RIivIIljOh9AOAZadICNtqq7Es\nTU3pQin8hP+iUsrcc40e7B7uGkLYuXNCXAvKRbToM1ohIa3X6+H6u2LpddCXjOTKjU0DDXdIgnJc\n3xA/siwz/b7HtJPyaxXUSAYcM0Mf9Pom24gJgVcqZfRsCs0zO3RHOaxQw9cyx0e1CornzgIAFp+T\njGrvq1/FlZtC5rkQNmCxteO9TWkf+duf/gxikmFclnIwHMAmPK3ZOpbjmD7oHt87HPSREo7Ufq4W\nlKb5QEu5uwqwtAoXMli8vym/bzQcImdvrm/asEqmJW08mkh7Lq/J865bXrxiCeFYt2cJSuWVCmjU\nJbvc3pFzm12cwf6xZICf/cLPYW5D4OvFM2Km8NoPf4gys97nn3lGvuNoFzff+aFcrytCdFyoFFFk\n1q7JUuPhyCAZhddFFenUJ59Ff1PWqyHXyUalavxsPWcC1cZcl6JxaOaIXhOKxSKyaKJI9lHGNOOc\njumYjumYjum4j/GxyDizNEW/20GhWMACazmVQCKT9cVltDsSyb93LBHHt7/2J/gUrWPivg1bR89M\n8qzMgsWYIOe/KYABla1zpSvYCikzDJeZQSGxoYjZB+ZzE0Pg0bJCqe0ih64PxMiiSbuEfEnxJ6KS\nHDkmVUDLvGqug246Rz4RJWad5PEnn0KHNaEa68Abp09BdeTnVTvB2mWJ7L5+XRRJrIoLHNAQljUa\nN3FwmnU5LVyQ5wFmKzTypt1PvVjEFVqu6cytMDtjLHl0tlc+IS6QZykKjI4XSDIaDAbGZDZj1Jek\niclOdMaZO4DSJB1mtZVK5ScyFtu2TQ1GZ7K2bZvPK5fLhlykFYYuXrxoms11PWVnZwf1mtRrtLv9\n3MKsyTQH1MUcdTpItPCEtptzC7h1m3XYI/m9Yn0OfTZUl9wYMWsviUersdxDyPaDiDVCP7cBXV9V\nct0qTgHHVLrxWaNMkMNm5lDO5bU5K8AaW2eWlQ+PmVO3xO9QgMUHosIMqOjZ6GlNZc4Hx/VM+0XC\n2TlKYwQs0Ft8TyFHxvdzviY1TY3sTOptSmvH2rZh9uhMcWFhAb2WJqrRwDnwTMa9RnTDb3ZN3ent\nG5K53b59x7SWtJkxWn6A01QWWr44xqw2CMgkGxrkOdoUhh+xRcN3A1SJxOhjRZah7ci8KzJ7D+Ab\njeqYiFJo+0BVnrniOUEvgvNn8fJ1yY5X15/DWF87Zk2dYR+OFlPnMx4NOrD0s69JYxYQUFu2dSzH\nut/pwCVvIrZ164gy112jWDZy5LzfeQrk+nlgbT8qVyekOrb1ecWKEXzX5u/jKERKXkWzLSiPF/io\nUHwg5ntxGuGQVngpj+vH12/h1/6zvwcASNwijkkOunxZasIHx238m9/7lwCAzz3/Kfm93jF2btIs\nnGtsyXUxYl3e08hPxcXdLdH7vf4VIRb9NysrKBEJ6Ol2NduBo5W5MhcJ1ybdKmVBGQEEnXGeREY+\n6vhYbJyWslB0fQTVCuoLVAwKZHKWC0Ugk0k0GAucWFtfRXwoD1/kOQauyClKbqUW7FwTiuTfGBli\nLUCs9GSzzGabsW/NRgafm59LHbM0jASLwuRip0iN0HSYhEY+LKPgvEVpsA852594Rd8yTbwJk9io\nCD31mLgq1GZnsEunl4YvZ9wfj/CX3xNh92d+8Yu4wwViSIiuWimYxb4IkqQGMcaH8nvjnsAgtufC\n5QYd8PweefhBgMy2xx+6DADYPm6hQ5eEfRJzSqUSZkgoqtfrhnigH1LLssx5mX/ziR+n3gTjPEPC\nnjQNAy8sLJj3tZ9mr9cz8Ivu3czz/B6vT/26lv3b3d01DFv9t7VaDU0yifcPBSa8s3MbFf0+F8xG\nqYBlepl2GXBFWYpCUY7n/CUhJcR7xzi4cY3nEsEmeSgje9Uf20aMXPfC+cqClfBecQGccYvY68mG\n4pHJmascRFFhc246UYqi/uwwBnpyzlagZdASJBo6ZeDieg4sbtQgTK0CDylVqkbc5IZRDJ/PSm7m\nvWOCQg0UJkkC1/LNPdBDb5KOsoyfpyF62ZbpwTwi5F6olKC4cerPuXLlCr729RcBAHcYzA0GA3Of\ne1oJptPFK98Xv8qBynGeLiTQ0ny1GkoUZa/Q0zQcjDEmE393R0hCs9U6Rra85mv4PHVRVPK3Q9ZT\nOt0x0pxzkkHiI7/yi3j5n/1TAMBbO3cQM6B+4JIEsoFfRnMocOYhCTCpnRkSUcw1IYlSFElmCXw5\nllE/QmRsZ+X3cwWjAKXVkLJcmY0zRWoUsEYMTorlEmLOvy4D5m4aIqcMZId/ezweIelLwFJZl7nd\n6rTR037EfEaDYhFtwqPnL4objDrcxaXLopD0tb/8FipzwiR+950fAQAevHABJTJxf/DyN+X4wz5m\n2cu8wqDHSWJ0tVwmBe6DoIguIdijsSiM/fHv/z5++dekg6DKftxW8xgldg0M+l20I84xrqeeGyBM\nyCpmKS4MQwNzf9QxhWqnYzqmYzqmYzruY3wsMk7XcbC8MI9WnppidYER0/ioY7KEDqPgpz//AlrX\nRPw38l3A1Ni1Q70Di3loyug4AuCAfXgTGpGRCD05VK4ja8JjQWAiYaJtUJmC0gQk5cNlJJyTvDH4\nsBPNLROpZPd8r9ZKlc8YpzEUv2+BIuLf+f4ruMKM5nnCDu++dw1bexIp/tqlS9jsSnQ1S5uv1HMn\nvpeM2qO9NlYq9K7TJBXLhsUsSIveq0IRXRJyDglBFqp1VJcE5l0iLT2KIhweSwa7v7tnomjtpbi4\nvGyycZ09Rid6O3VvY+BPCvn2iezjZEvKB1/T98S2bfN9juOYv9efd3x8bNpZ9N/6vo8zF4ScspYJ\nPJiGY/SpXXzjTYmSD3cOTD9rWpbrvnz6NEIqLeVFwmdeCRl/7/bdQ8wtEx6tMfNsJ0bRRJM0bAA5\nPydgW1TDLSHIJJIPCas6tm2ywpww4DgNkdsCMYdWZohqObPQJMqRQPddUhnJdwASaXTNIHd9JIpt\nVQy6h1GCOslwis+MbdkAyU22gQQzKA2LpRlyzqGI91sphTyb2LgBQvLSsLqG0nNLGRKYfq/b7xkS\n2CEh1jgcm3urFZDguGizJ7PZPMZD/BxNqrt7uI/DlsyNtTXRm11dWMYaW6yKzHbqtRJsr8ljkPNI\nRgkS41fJ781TRMzaxzXJhq7sb2H5M1IeCPttnKuK7dXOm1LqsI76OCTKs3JeiEX7t69AaZtAZujh\naIwCkZX5Ep/R2MaIutua1KNywNJwsIbMkBsiV4bckNy6bTl31/ORaD1jliaGFtAbSHaZ8F5ks1Vs\nPC1Z4yOPPQoAeO/aNbzJc9nl8/HLX/wCXiCiM9uQY/2rv/oL/PN/IQL3v/5b/zm++R0p8cTHci/m\n6jW8+4b4HpdJ0KxUAngpFZvYa25bCg32gfeIig37IQr07XRZ6nj12y/h8gOS1Z99XI655HvwmEnW\nyxWA63LzSObSzMxkLS8aX9LU2N591DHNOKdjOqZjOqZjOu5j/NSMUyn1fwP4JQAHeZ5f5mu/D4BS\nGagDaOd5/rhS6jSAKwDe43uv5Hn+D37ad1iWQsn30On34VFw0WGEHfeHGBfl52028T8w00DM2l3s\n2rBCZiiMiK3UguKppWyGDXOFIPX1OcnvYVIU1mIFGRJkJD9owYXMzRCn99p8xXkGU3qwHShmDKbg\nnJh3DUHpQ3SDkJ2IXRySOKwoF7EETLKmoFjAw5clAlxclazv6o3rKFREWaextIAfkBQULFMQIolR\nos5ng8pIpaUS/DFVQtheMB7HE/sy1nqLlmWaqLVix9C2kJImr9WCGvUq5uYl4hwMBoaafveuFPKb\nrSYiqjjV2ZRerlXMuerG5Ha/g/BIfk8rynS7XVM/1Rml53mmfqprmI7jmBaH0WhkshJNBMrz3BBR\ndJZjWRZabDKPNPknT9CgmMaDzEbPLKxgblGyk+tsN7l+5RoW2NDvEWG4fncPQ2bws0uLoH4Hrm5L\nDfqSswSLtemcyIiVu0gIYVi8/hW3iIBztkunGlSKSGwiBxTJaKsQPQr1WLbMeQDgnyKBi4ifOdIm\n1xaQ+toQnFlVlhlRgZBZ3CjMAKrngCQ1x7aNubWd6+foBDoQJoYkpnWm5XfUPf8GQWDuVco5fnx8\njDm2NmjyXBAEWOI8374r1z23PQxYY9ftBTOVWdPa1Op0jDOOS+LU2ZVFNOZm7zmG929ew5W33gUA\nNFhD+/SnnseoTrUhKk1HuY0CM+6iU+IxO+gSWUgKcp47nsLaGZkPd97YQ3JXaubzuk7ulzCeExGQ\nTZ1VBTZyogQgEoE0gadr3h6vR2oj7MtzUSzJDc8VAGbFmrSYqxipOtFCxOe4XJeJ2O71EGuxBD5T\nnTBGyL8/+6AIE8xvrOHxZ5g9E0Eon9nAKR7iLp+V0A9QWZYa5je/K+4mW7uHKNGVpj8IcfmyaMrq\nZ/ybf/4iop5kfnWSrfKwD1d715l+NBu1GXnmQuoVj8PcaGf75JEUbQffePFr/A45rgceeQzNnjz3\nyi+iwgxe24bZlmVQOM17sCzrPwg56HcB/FMA/0K/kOf5r+mflVL/GEDnxO/fzPP88fs5CAUpcpdd\nHwnhvB4VUjIAEZU85glbzizMokumWeo6E7CC+KfKLdhM13NNZFAZiuN7N87cys3mGE+2QZBUh4Qb\n6DgagURbI6ScWfYJCTXbSF9Netkmn/dhzpsnh4Zt9cJj2zaKmg3HDeqJpz6BiL2hm7elZ+ygeYj5\nR57hdcrhkxDR58ZSblQxINEGA5KfEgdLXNUffUhYgXMLHqhMiM2O/NRqteBr5utIJmqSndjcCYHE\nYWQeDFgKGxsChxXIDjzutFHlBtchU263eQCtGK43spm5WcxwgbM6ch22trbM5qgDEn19gAkJxXVd\nQyhKksQQiTSRZGZmwgbWcHGWZUgJF/lcZAu2D5cbSr9NabQImGUfoCLz2C5Xsfm2QLlXeS+effY5\nxLTl+os//B1sU0nmseck2Dm6uosCH/yMpJ8sshCNyTQmmc13Pfi8JhFJTpZVQqR7fTmvktEYtUgW\n81aSws7JUG1xobEUepx5hwxC27mFEedsRDZiMgoRcO7G3BjH0QSiBeQ1Bwoq1QQ6bvxWCpf3Ik1D\nM3/H4YS0pZ8HY/uWTyzlNCFI308A+Bbl+F77yldx68cSdIQlma+Li0tINFGroyX1Smj15OfN730P\nhwyGnvuc+D2eLnhGmWeOkGLjzFmUGeg2qaLVPj5CFNBr1qhj5VCc2rOErgu2gz6vyYAP9PVhC+W6\nfN7lhy8i3pLgMezIPWkmfRQXJGg8dHRicIixYfnKfSz6AWxNVtReuJaLhpK1wEm0ullmhPsTbpCJ\nlSNlcJWp1PSqN7gmqDicWOoRXu/EYxTp+7l6WTbO+tIy/qd/8r8CAHrcjB599HGcod/o+sMCjV7f\n3cPaRcmdWpRsbHeH2N4TSNrx/gKrlBl844evAwCifhfnN4T82aKI/bB1ZGzCKoROR/2RkVENXC36\nHyBiWUN7oxZcD81d2SS//VffAACUqnUEVH4bdAbokwjVoHrZ9p0dNI8Ebn6Qx28rID2R6HyU8VM3\nzjzPv81M8ieGkqfi7wL4/H1963RMx3RMx3RMx3+k429KDvo0gP08z6+feO2MUuqHALoA/sc8z1/6\naR+SJAnarSNYxSoyalV2mgLN5YGPA4qt189JJqF8FxlVNBJLVDMAmNTNyi3TL6Wh0AQKfqLJCPz9\nPEdMyEP/XgxlMkB2tyBMU6Mjm2vhassz2SyUqzsNoMvGdjzG/ZaQTcSeZxg2JYp78UWh5J++eBFd\nKty89kNxLi+Xy1ikCHocx8Zma5ei0IsXz2HIvrcas6FTwSyePi80c33d+jEQ81AXa0Xzrx1/AoCo\ncQDAjXZrYkDdn5gRa4swy7YNDKJbQqIoMsSPBTrZ5woIea7anmz/8ADRXfnshxaFQBGGE5WP5WVB\nG5rNpslCTxKCdDRtWZbRozVWQ0li4EH9N8ViEaoq0WxCW6QwSVBk35g+Zs+xje7xkOecpzkeflgI\nIHd3JcK+efMG2j8S+C9VFlwez86BRMQJUiM2bnlaJ9ZBzFarBLpPNTBi5FrQXDkWmAhjzH7NziBE\nuSuRc2GcwKK2sTNir6UPDDg9j4iEjfwAOaHJVPcTZjDQcJppy6gcYFasMm0YbZu2MId/q6zcXPcs\ny04Ivv8kVGvauKLU3Bdtj1culzEmKU3P9ysvv4z1khZ8lzm5cfqsIc1tbgo50HFshIQ8e0l4D8oA\nAMvLizg41H2c8h2uZaMxI59tswSzsrSE/UKH5yzH3up10N0n8kVOVaFYR1rW5Rp5LSp4yEi4yfsj\nrG+cBgBsvSJKOOdXVtGhCo9DneK876DP61BkBlgMCsj5oclArqEfBKh5cv5aZzhTypRWeJuQYELA\nSqzUtKbs7EnbmHIdOLz3Y0KirfEApYIgRBmRpGt3NrHDZ+SRxwQ4/OyXfs70Q3rMCv/qa1/Hs8nz\nco1PyWfcevNdnD4jz+7BwQF+TMRgg20tgUrRJVHLJYq4trGCkG10ul86CkfmGU6JfBTKBYx4DRNe\nt+N2Fw2WUW6/L5aRzYNDPPPcpwEAg4NDpJx3B7uCLLz55tuGdKaz6FqlfA+i9VHG33Tj/A0Av3fi\n/7sANvI8P1JKPQXg/1VKPZznefeDf6iU+vsA/j4AzFKlfjqmYzqmYzqm4+M+/r03TiUS9P8JgKf0\na3meh2BzSJ7nryulbgK4COC1D/59nue/A+B3AOChBx/KH05sOL0xWqSRL5Ro4zUf4BIjLr8v0cql\nThs9mruWkwQ59SR1dhUqy9QAHEZwZ1IfqtjX3w1AouRcR3Gk0CMDfNabbEb8rvJMfVK7CGRIkLJ5\nOFdjUyvVo1dMjTmsxajdzhyjg+uwqu9kGXItpMCIvjFTxz6bkKs1CSpOn78A0L1B1SVS+qN/+yeo\nf15UOV483MTsvNR/Xv7TvwQALJdnsDhPZxLWwN7t7+DVb0kk+CBtyOrFMuokAFVZy3EUsFBglrok\n0fm5pZppWThuS+azc7APi7T6ze0tZKzPPbhyiq/dhZ/I9azVJCOG42DI6NJVpIQjN7Wu0R1pSr/2\n+uu4e1VMgx99/EkAojXbo2VUmcScfJxgQGeIHBYKdHpJaDlSq9TR79M1Y0bqLnmmcHwoOperc2u8\nJy56jPS3qeRTnHXg2ZLBL83La9HOLugyh4XPfEGuuXLxzvYmAKB95wouUcTgwbvyvaVgHd0DQU4c\ntoRYgY8RiVr9kcSWljXG40uS4ftb8tqw2UOP82vI7De2Cuj15OeBW0LO7GxQkcg6sD1UbMmyCzz3\nuD2ERTcTbeA8CHx02dCvlUQ6KkPOhqrLi7St6w7gd6lGw+dnWBniuCvnWQ1q6LKOvurys9/bxdol\nmWO3t6nus7yMEb+nQNcPd9zF9lXJIF/7Y5m7L5x+HKopz+tiXa7XE+dW8dbbQoDbvi5zuFCpQpFA\nd3pxBde+I2jMf/mb/xUAwOtYqEGuTchnPU5zZBQJGXtsk8k8lPpiF6ZrocFFF/FpuTbHRA4OelvI\n23STeVN0tQ/fu4LyF6RaVV46g+f+u1+RY7sowiFf/u1/hqeJosTUek2OPZQsyZbKntzvzqiFAd1Y\nHNoUdtI949bUZS1xt92HxfuHkrzXHEdYOiPHP0hT9Gh398IFOYZyvYxT1NgNGjIvXnrtu9jvyjp6\n9tIL8h1X3kShLFyD138o1zoD8NADUgNdX5P1KKjbeOeGaMxeOEsinYpQHUk2Nxh0seBwfdwSrujc\nTANxRM1srqNxNIYFtlVpjYxiAbEmPXHeD8bHoNYGPEKBRV/B5xq8Smu2b/7Jl+HTXP2xL/08mocy\n72Y25J5uZOfwBEV2uvyc25t3UDAyOh9t/E0yzi8AuJrn+bZ+QSk1D+A4z/NUKXUWwAUA7/+0D7Ic\nF+WlRfiWg4zMsWFXNslWf4BhKgtOlRtMYntwdE9ZDqNOojejyMq10M9E5O4+U/G/6bBy/ISt2E8b\nGtaybRuNutzoZ5+lbdir38eZh2STG+DZvwAAIABJREFUvH5TYIm/86u/gnlChlmWYTCShebyZXlY\nRsMxXiesu0qZvdWVJdTZI6WVOLY3byMmEeD0imwsvu1gltJifRJYgsAxMPZCg3ZsjXWMdW9r4KJJ\nZZTb28KqLVbKBj7TsGsC6eUEAGg2r+vDYQ/o4nl5ED9nKZR4rGMSlN67fs307enezGqtjjLh5FKp\nhD5VTsoUQd/a3sLa2hqPQc5zZmbW+PF12WcW9lI4hGh1cLW2tobRQBaXJnvKFqsNRCRv5ISwdppN\nuCRErZ87B/8WbYx0z18awqaEXmZz4xkPDbPSK9COLgcyMpeXFmQB68QxFO9PTLgxiVNA+1B6yYS0\nxcUnVxHg0l+SOHwJgO1o/UP27SYxfGL2se4NzFKk7JVLeZ9yZFD6fc7TYrmMkGSl4+MOKrNyjffv\nyL2P8wwHu0KUOaJay939fezQNu5zX/hZOReVo0LfSEUFq9agh/CIwv7H8n3v/PgKtnZkAxvrXjzX\nw5DXK+p0AQaAL70sTM/PfelLpp/VWPXNzKBNScTdQ4EyV9bX4JA4Nia5bhBGyKmU4zEQb8zNISX5\nqcfzePbJJ3BWGyHMzhhvyPPs2XzmmWfw7ssvAwCeoudkNDpGkz2R2tzBsiyjcGMC8TRBxM2mzjUh\n9QNcfFzKKLt8ho+v3sCT7GUs1Br49nfk/J/8gjBk9w8O8P6REHKqmVzrz/7sp/HP/+XvAgCukMBz\n7tQKful5IVa5ZL5urK0iok8oKDFpd8d492Xp03z7G3JuG1mO9gmSnh9wM+LnHEdD9AeUoqSo+uxM\nwxgF2NowIM/hGJMOvqcmP3eY5ASFAhTns4bck3iMt96QDb22sITTT8ia2aT83+H+PtbWJKi3+DyW\nV1bhq/vbOH/qbqKU+j0A3wNwSSm1rZT6r/nWr+NemBYAPgPgbaXUmwD+AMA/yPP8+L6OaDqmYzqm\nYzqm42M8Pgqr9jf+mtf/iw957Q8B/OH9HsQwGuPV2zfQKFZR9CTirLDvqVKyMRpLtJAfSISXtLpw\nqarixamxa3K03qylkDmkZuseIWPWdOJ4T1h6GRF3/PVtI/czrHzyQdYH/gVgSA65mhhez1Bj8bB9\njI0HJDI9ZgZXrtQwtyQEmUuPyB+88PmfxbuM/guFAnaoH/vYoxJlLSzNo3ZAEgQj5h+9e8W0V1TY\n4zk7M4e0JJF1xgjuh2+/g7OnTgMAttibWZ5bNmoba6sS/R51Yly5JlDMYesYFnvcjkn6WZ+ZMb15\nmliUYhJRW7YmFk0Et4fs0xpniREorxYpxL68aPQ3tarIzt4OlKItVa1mWly04Pz8QgMrqzKfRkPd\njhJj+45E4D4kyl9eWEVEFs7xTTl+5TrG6b5BeKy/O0DvSL774gOSZT3y9CcQXJb2nit/dIiDH0k0\nHrEXNolHcDm3Q/a1jtPERMyKvY9pmMDnNamRAOc4Fjy+VmKUPIgzxCRiJSo3ZuJlBs5WrlBiS5aG\n0pNiANDEV1O7OoMhinW5trrv00ojpCSiRbz+WZbDZiuFUfcZ9tFry7kMxzkWdOsDr39jcR55QyA0\nl8f/1ltv4S4zsk1mbK1BD6OuZHFLZ4RosjZzGsXV0wCAq7nci91WDxHPqUrLu4W1dTRJODloHcFm\nxvZVkowuPv4Yzl4SCLO1J9/b6rVh8Rgd/tsPB/B4vTskq1hJgmUqZI2YSR3u72GDBga/8LnPynk6\nNh47J1nMggWEnFdFtmY9+sTjeOulbwMAbvOcz5RLyI9ZmmDG7FiTZ0TP4SAIjNF9X/eAugU8RU3e\nbbbtvfLm21C0vVuen8WQLTreGZmzW3fewT/57f8NAPBbvy76ruWZACskSX3v618FAHzqmWfw/DmB\nZXVL1p23r+D7r0gGG0XajH5oTBbmaGcYtg8mz3Xgoscnv0+j9MGobzTBtWKb5wJcquFzMfaTSfbp\ns4LmZLl5rWkRpfF802qk7fk8z8OVHwtJzy2VcPqStJwU9DoTxZNGK6IpnushJKLzUcdUOWg6pmM6\npmM6puM+xsdCqzZWwJ6d43jYQcD6VZHuErWsggob1GfnpE53yq3gZsQaZ5LB0m4m/DzLzmCxkzgz\nihBqos/50xQJ/n8Y9sQ/bGL2+9fWPeWXj44k0u2Ne6bdIWSW4iws4c9f+iYAIKflWlCvI6HdVJqE\nRj1jcVEy0zCMUWWd0qdqjVIWKowUj6iEs//eNXOMM1T+GCQJqvMTPVoA2G8dIdyT7PP9u6xFhxNi\nVLFSxUCTfthCkGQpUmPjpjMgG64zcXoARHs0ZGRaYJ1xnKRIPiAfkSWxEZ6oMVqemZ8xbTCHh0do\nUZ/zJmvBjuMgiSVL1bVOzytgnYIaIckzeZIaqvqku0gZ55gdavein2J9TbIYTePf6/awVpZrMn/6\nDJyL8v7uXSEg1VwfRUurWWn91kkNPtSWT1GESkNqm1p4omwBAZWy6jyWLFeINckNuXHDsAKpCSdR\nCi9j3ZOuGkliIbLk572R1NUO4yGCjHq0bGHI4shYiKWRjs9tKFujJPJKAmXuxeziIkKNorBWPUIK\nvyJzbcCM+rFnnkKhLsdYZaaiqgXsZYIYlKhCtX14iP5teS07I899EiampSInUcauVFFhdrY3GCAn\n6QfMln747jtYPC31x3nq0+4e7MP35F5U6loYY4wx655zRH4QJejsy3xPuS6dX1rCYxclI3NzOYbZ\nUoB5Pqfot1AkWQn8m5W1ZfzG3/stAMA3/kyUbobjvlEMcrTcU54ijiXT15SMoFg2LUgWl+tRr429\nbXEIqc4KkhK4Ck06vZw5cwYB//7NbSH4JLUUv/B3/xYA4NwDkh2nUQedPcmOcxrZv/6nf2ZQLF+3\nmSmFBi1aimzrihwf+1w/IgpjRI4NV9fxPQcHR/L+Lomc/RCYn5frND8j13joWPD18qCzTORQGkVk\nxulnymSmToUCIUmEkPOgSIPswPNNS+OtG9fx2ne+AwC48IgIkZxbWYWi6pQW9PBLRYT3l3B+PDZO\nuC7U8iKycYKETuRtyo0dbt9FlTuirdWCkhy6sU0lmRFjt7n6uzaQM51PjaemQs6FW6+KmZosAnqf\ny9Xk/ZMb7E/bbNUH/sbNrHvk9ADZQD/45yqHkRbS/XHnz583PVBNyl41U4X3mwK/XHxSCEMoFzEz\nI7DR9evXjcO9ZqeOo3DS28Ueu7X1U2geyITeOC3QItZPmWL9m68JAfrG9RuwaXGkZf/8ctUQajRk\ni0HfqPEctdo44OZy7oIsLnGSmHNW98DhFNLPJx6OevPWotzjJEaRfW9GFD5NkXAhSTTBCJkhHjVq\nJWyQ+TffkIdpb28PikLSu3doDhBFAHtbGyXZqBqLdSwShmtHcq2vXbuGxXn5HIcPWr1eh03B6Tev\nCrNyv9fD6rx8rypVUF2WDXrvfWlxTuMIRW70Du9Pr9PBkPdMW9R5jgWH14b68UhShZDi9I6RJXPg\nMBjy3MAQsCLIecYqgpXJa5aaKBaFWl6PakIVZUNpUXb21kVZaiiOGckx8IKJDyc32P44NP6RhVoN\nOyGVcvoCKfaTGCEDqQ7JRu12GxYDIy1BWK+X0GCQ9qMf0EvWH2BA27cjKuycXlw2ClBbhzJHeuMI\nDcKp65YFW/d3M5C6ev0GKt8TmPFnCK1ubKzhoLnPeyDB6vLKPKwBPTd5/HG7iyr7ei8Q7n3iwiXM\nkfG6dU0Cs5X5GXNfDrfvImBPanwg5J+qbeEMv7vLDf3gtVeh2EEw4jWqFAsoUiUo5oaQsGwBABUS\nJxNLYXtTArKfeVAC7F/7O78MvypBx2ypiBn+7vubso48+fCjWKmReNSSDf3d195C1pHjmSOJrbfb\nRLXOwI2kpMGgJ4sqpNcZADLXRsD7GHgyv/oFx/SIDscDjNifmtM7OQxjDLjOnCJTOB0ODbnT4uIp\n/+fPhHbzfOJl7JJ0NOqGCLkW5Oz1d7zIXCc7yfA6SVLzDDAeuPgAjjo9nBx5ECLNQtzPmEK10zEd\n0zEd0zEd9zE+FhlnnGXYGY0RJMA8CSulAi1kxgOAVOgjCjxf22siZB4TIYOjK83aZsrKDRnGSnW+\nkyEz+rW4598Pjnstv+5v6MxTZTgh7W79O75vgunmzAKeeuJJpIzkB4SAvv7GWziicsYiae5pIcAO\ntTb7/SEWqMeov7lYKBuSweGxZJmtTk+YOABGbKloHTVRIQTjUZXnyec+ZchKOsPrDIfo3dkEIJkD\nACjLwYULEo3Pry6jTfsyj+bB8WAAyzoZSQJZnJsMWGeSjuMYa59qRc7j6OjIQKdaSaRRq2B9VbI5\nDSEPeh2TNbmuhXFXjm1xVmDqo71tXDgtxzjqTwzf9tkX3NwWiGtw0MM8M0Vtm3Z99zqGJXlM5nyB\nHX23iBbp7bvM3i898jhOrcr1+uEbLyFntl5bFJhxtPM+0g/YaYVxbPpZfW3jZTsme85NT5UyZQjd\nW5znKRSbatMoNpZRRmc5THSSYGzRlGXDYRZQIpxaLRZMFuB5+j4p2FoKi1m2Ugo5/zYiCtLrJags\nFvhajIwwcELkZHZlCXsaEq3I77U6HZM1agu63aMjzM3J9T4iAWahWMDaJZnn46Ecy8a5B0y7xtVN\ngSoTuHC5ViwFAWxtc8YH8fadLbz+ilhZabvAz3/hc5ilFvS7nFd2GsNhVhxTmWauVMZzjwgJ5wKf\nrSAGnJ7MuzkiB05/gD7JOGmvhw7t/YoaVbEtgHDlo09LP3Lbc/Daq3Jcb7FlLMtz1Kmuped2lueo\n8VhbbFsplyo4OhAioIZnq4GH3kCu3ebVH2FAPda5MYXmswR//NU/BQD09+RYosM2HiABq8c2k0ap\nZBTFAtqmKc8yrUpDIh/jLEFG44ibhGyz88sYsH90Z+8u1qlVu0Ex9cDbQWuP/crsl/YSGz6F7W1t\nFQcLqS5hEM5OVTYp2vAHy1EGaTGm9sMxamzbKXo+uvtyrrfelcz71NopOKlusdKa0ZFptfqoY5px\nTsd0TMd0TMd03Mf4WGScubKQ+T4G4yFcNkorqgXZrgef2p5MlBC2uuix3lJyFOhFa3I3ZQOeFpxk\nFmqlGUa6Bs/fy/IP1Dbx4Vlh/lMyUPUhtUs3m2SuxopZnfg9c3yAxWPUtYIXv/pn6DICevLnpaDv\nlkrw2Nrw6LPPyUfUKnj/B6KHuby8jDNnJULf25MsNM0zOCRLVPi3hULBvF+hks/MwjJSRmGWK1lA\nZXYW0JR4WipVFpcMCadAC6bDw0PcJP3ecRxcvyU1RG1RtbCwgIBKOd4JcQGtZ5olmhlgmfvba8ln\nu7aNDZJ5eh3dOD3GgD8PSOaw8gxrzAii8QhtrX3JGmg27KOodV+ZkSRJgoepq9kuSySfRY7JbO9s\nScR+5+AWkrFEsJdf+CwAYPf6PuaoCxwUJXvqD8bY2pbrurJ+GnaH9mo7khm5vQ5anQGvA11wnAA+\nszxF4lCuFBK2FWgrO8uyDN3epqtJmufGWiuOImMWrpiRpQrIlNZppkpLmiCjIbPOTF3HR0pSmcPM\n1IUF7TlkMypXlmtswLTd1MJcFWVme2HqIqIK0hxbRYJCEVEoKEnOlp5eu4cyFZgS1i4Dz0NCQYb6\nvGQnd9+9hQcW2eJBEYxSpW7mzdysfMfGxroRujg6OsTRvmQ/ns9sMMtwxGzvm18TYo6bJnjuUyIM\nMEviYdrpIKdqzwtPiRjaxZUNlDk93YGsSzPFAPlQrvWN61LjVLUSQpKtig6MKXyZ7Tm2ytHdZ71z\nQY678chjeJR5y9aOtKh0jpoINGpG+zfHsSZWhXwvGg7QoQLRn/zRHwAAuuMITlkyRDguYrqC+Dty\n7eLKHZwjqfDtpjyjT51/AHffl/mp1yArCHCLdnwN1vtT14bNa9xjm1Kz3zW10PeomIVDoEYhksNB\niiVeu3pZnpXqso83t96S4zkQZKpWqsLJtOsOR54hYqYZ6RVaTZx2NCJjWRYse0I4BADX9Q3HI4sj\nuHwGrr4l31stVfHkc7J+5gGfFd+DXy3jfsbHYuO0LAtFvwKnVsCMS0IKd51W6xC9WC5yRMgwUxna\n3EyLno041gQTLT6dmZ4fV1veJRkGH9g4gZN+duBn37ux/vsOlVvGhT2/ZwPNPvCLmfnCs6dPAwDO\nP/IQjkjKKJ4VybIvv/r/4MFPyMN+6mHp8fzqt7+DemPJnJMWXteTaGPtFHbYgxmSadZqdeByA2uz\nSN454WOo3XXKM7MGLhpzsRqOB2bhctkjubCyaohFxWIRN97fBAC89Y5s6M8+84yBUyqEnBzHwZjk\nLw2xxNHYQNVz3NB3t7Yx5DFqAehwNEbGB6fIxfjMqXPYoG3TMEyQxbLg7vLcO40ZZNpeiKzU2LLM\nAlc1PWAllEn6qc8LzLt+Zh6vvvE9AMCrVKOZ8RfR2hfSz86eHN9GUDRWXY1iGUc9Od4x/QSX51Zx\n/aYQifSDvby2Cs8lo5qEqDgHLEcvmoRfc2CsWcUazrIUMp4/fB+eXlR4b7MkQ2xrn03Ky4UJMlrT\njTi5Y2V4dnAoNenkjpGL1L62Ci4SbZXH56wUlNDvkmjh1bHDTatBabduf4CQAvoR5005KGCGDMge\nraMWludxSEh+bU2g7R98+WtYqy3wfXkG7NzFiPTH82fktReefw4pCTTvvPVDNMk2HZNk2Lp7Fw4X\ngwFh4O+/+HVsEIZc5HyoZjkeflL6n8+zFDCjbHb4AiQ1A0mKSMvvsX/5zNNPwIOW0sxhk2mtnyk7\nTY0NX4tKSg2rgMWHhNhzgezvd15/DTaDZ5fB5v/X3pcGS3qd5T3nW3vvvvsyd/ZFo9FIHi0RAsm2\nsI0hxI6JWWJSFahUKuQHVCU/kpShUhUqRZEQCn6QqlAhgZRTQAyBEGPjsLgwNmYREkZIGo1GujNz\n78y9c/d7e+9vP/lxnnO6Z6QRc+0Jc4d8T9VU93T37T7f+c72vu/zPm8S9LDJTVLPn1ang3Fdv1Tz\nHX0XNeZnX79505Swa76kJCvXdiO0VpV790RNucWDZhcuN+geyUhOtQjbUe83Ob52+j3YXGM3SMJZ\n39vB4yRMgaXJllY28cxT6v65LtBrcW6X1Hcv1GaGMnJtnYtpvW0TSm0MayLrUqUWTA5oRMlDr+Aj\npeu4wNDQxPgUYtbF7bZ7qBRVP+2uq4PLX7zwAp543/MAhgeRoNtBf5++19xVmyNHjhw5cuwDB8Li\nlJlE0gtREK5JbWgzrw2uBZ/lh8IBizLPTWKTp/FavQQp1Ge7O+rUOlWqociDeWtFnbKm/QoK4ySs\n6PJdQaAC91AuKwDoNdsYkFZfZL7j3eD2dBTPsk0p60Tn28nMuMhsnlBdxzHpBwlVOdZvrGKT1t5r\nLysVjAwWTj2sisj+119WSofXmy186BPKrZSmqWm3tmi2trYMESWj29J1XUPOWFxUFtBeu2WKzs4d\nYs5ckmDAU6h2A3pFz1jHcaLaHASBsSjDOMIHqD+6SZWWer2OdVp+Oq+yWq4YndlyURcXt40rJqQ1\n2mm24BkXumW+T6dzHJlXeZizY2Vog6DsOxBag3JB5e8VM2B+Tlnm2k3da3eM3qxgcYAo66NMa8jX\nmqFxiMcfVtq/Z48rDV2r5+EPvqj0MC++wnSU7R2cpZrS+JRvCvBK5r/5fgn1gnKXawvienQTjQkS\nGSjW3R70TAHhAV1YUZpgQLdsQJd6mGbGBSvFUM1n0xTktUzBaX0+lsKFhCYRWeZvHVo5IV2n1YKP\nOY4RnVPb78UoU8+zRmst6G3Ad0kqq9YQhMrlqHWRkySBoP894ncHvb6xODWBb29zR1cBxHlaYen3\nfA+++iVl4S+w9JWIIlM67+aq0sPdWr2JVYYK/uSPvgyf60KbaSZRaxdH5pV7dJvWeri5gV/5Tz8L\nAPi+71f5lR/85g/AomXkBlx7hA2XE7ZFjVy7GwB8v0hrpyglMj4XWYYy0yFaOjc3jjBD8lPCOYV+\nCviqH596TmnDbm5vYW9Djc9xpt4lYWTKr8VcG4u+j5hpTBHohQOwS1WiiuMYcfQJ1kPbffMGXC5S\nNuWldlodJJx/tVll3b9+/RqWt1hAg0Uj/nJpDe/9RkVq2tplelwi8coVlRJzc1P1tR8D8a7yIhyf\nPozXF9U9Ojd5TF1yJ8Bj59T3TFfVNa2vriAm+bPG0mxxliHUqj5V5nSnMUKmx9RYhLzol7TkMmJe\n79r2JuhUQb1SR4dErzLzymWU4Pc+/SsAgGe/7VvVdZ48jvamkVy/K+QWZ44cOXLkyLEPHAiL05KA\nF0u49lBxxyFZIrYFYnLxBdTpqSNjfOZFpQX6oblZnCnzdMaTc831McHUgUpVnd7TfmIsMu0Xj9PE\nUP7tkSCzTcUVXXEiivQp/rZ283E0amnSUaSAUTZgdFNiVHCBib0jggtbDMovraxig6dLydP79Owh\nnDirLE6tmjJeLGKJ6SG+7w9JOIy1WZYFh/G7Ei2oer1u4p6a6DM2NoYaFYMCWgbbuzvmmsZ58rRt\ny/SdxmAwMLHQmUPTuHhRWcgNfl/R903canZ6qEQUMG1Fx52KxSJqJDcUSOyoFgvo7FJzk7kVKYBe\nX3kWrrMKSm98DOMkP5VLBUwzfWSLccZTx46jyO+crKvYWHuvb8bV7rr6jd2trhEkyBxGpKPYWEhh\nW51eq7Zr4rAFpjiF3T6WqW97NptEnff5MVpQi1/6UzTK6pRtsfrw8upNNPmds4yruV4ZUUbPAVNU\nkjBEj3G8FtWEeml2C+lMp2FEZarWSMuMPp3MoqxNxi7ZbiEBRxOA+F5RuPAomuBCjyUBoa1Ufr7R\nGMfuDhWI+hsYqIqCOE3PSKFSRZFxqTa9CO2dFnz+tuYxdHebxuJ58jlF3Hho6jBmq0zveU3Fpy4v\nXUWFKRBFinJcvXQRS4wd97a3EGpxBqpHzU40UCe5psc55UDi737k7wAA/v4HPgwAqEYx9rpM2eKE\nDpIMsY7x8j7VAAjyBXymt9hxaBSdUkhDjrB1GpCUxmMCrmtJJuHQmrU4vh5/5r34wm/9bwBAh2uO\n5zpGj9UQ6rLMzENpOIYCsDShwzH3t2Apj8AgyRAzHqq9F2utJlod9QXjDOJmEw1sbyurt0TPglve\nxBUWgi5xnmVbe+g1VZ9UfNX+bLCH4Lrq94X5eQRcg7W6z26YweIYChkrXW01YVN4AyyD59o+UvIm\nJL0EHiyTsuVrPV/YhiC3w3iyWyyZa5fdHgr0klQZ/43DBCvXlXX52suKMPT04TmUCjqafXc4EBsn\npISdpnAg4XAySZrjqS2R2ZoCyEEQh3iT8nT1KECXjK9p3vy6V0Cbk1vy5tVcF32KxWu3Vpym5rl2\n2QrbNq5HvZnq0k9fK7SCUCakYdqOEnUto6JD962wUKVroUellwzCVJwP+Dg2P49JshrjOEaPEl9a\nYD0aBIbJqt2z1WodTcprzcxQSL9WM4ogehMcGxszcmrafZ5lw01TqwkJYWOKG2uv1zNtmJpQrw0G\nA5jbR7dxuViEw9wuSTdwu93GxoZyq/+3X1eLx5NPPonSQ0qBqMH80jiM4GpFErqL19bWsLep3EvB\nYIAiDzw7VDH68Ie+xQg7a5euWygio5vrxAm1sT90CljZVJ17ZVu5vVav3sCR48ol3CeLt1KpabU0\nDOgKKlaHNU3r5RI6JPv01tU1PXz6zC1sQAAIogTbZPGuUaAfvq/+ASjxICELRaQkcWQlfkcYIqA7\nK0ZmFuaQ0oKAZSQOWSIXgAWLnxvWigXqzJ12yTSpOB58nXPKzzuWbcqJpRy9rU4Pkoe0KJEoeqq9\nC2R373W66PHA0yUR6D3nH0VrW/VNxMPA0088iWtbamH+6Z/6KQDA8uuLODKh+n2OikwFF+Zw1W2q\n+b946TXsUTS+7tsIKfx/YkaNv9bOFrZbahycpsTi3tYmBiTpOF214B4/vIBTZInurKr3Vt54E28x\nT1qSpDZXr5sc0ApDAqvLy5hiKCCVido8AXhaLtMvQbJv9fzyy1WzCCxeV/f+/Dc+Z4TTP/urv6R+\no1xCf0+13+N9EmliNs6UO2cqxfB+27ZRUQ/J/ApEhoyGRcx70k5jrHG+9prqN6xaBW3KmRYolzgz\nM4ONNfX+MxeOAQD65T24ZO7Mz6l+TZsB0ra6vup8AUfn1WdTEpU6SYKQoYa1dTW/ut0mqnRLe7Y6\nKDU8D4JkJFtL7kGgqIX56QoXroPDC8zVvqzyNMv1BlostVYsFlAqkJDIjTEYdMxc2/79LwIAzjx+\nAU05VGi6G+Su2hw5cuTIkWMfOBgWJyQgUwhkJm9Ml/tJRGrINY5Lcg8sZHRB3uwFSGn2z9PyLFTr\n8KjAUayoE0mrn0KGyi2o0zVEZhl3pT4lWpZlTmv6PeBtSSS3wMJIrqa5JMv4bU06ijXMn9N5nHLk\n7KILGNdrY6jQwnqZrkrX8SFpAbtU+YFbQJfFq6WURmB5ukTxbNhIeMLVaQN7u7v43Gc/CwD44IeU\nm+rxp540bdAUejfzUGIfatdvu9027uDdLVr8tSocEkDeurJkyBtaSH4wGBg9U5ft7/U6JoVFf1+1\nWjV0+8effgoAcObMQ7hCTU5dcqxY8LDAYtu6bFiYxKZivF8uY29XuXJbTEH5i1deNdenLZYzZ06g\nTMuuO1Df3WmG2KQ+qhauH8QRamPqXrRuKlee77uYYr7h7IxyP+92mlhiQeyXm1cxTivoOIXfT04e\nxkXqD0cMGUyO1+FQx3PxukqjaAVdVOvUCmW+auwMvSA1V7XfKxQxYB/2ogAh3XhVS9vUMOWo9KMQ\nwmgDa11gJwNqrnrN53sVx0KRc8DjGHYtAUunxDBtqFivA0L93uLidQQcB03mbu5t3IRkLqBFa+fq\n8hKePa/UeJKuavPl1y8ho4v5Ix/9qPqOJ7ewfo1WSZP6p/0dFDzVhsU11V/tnS0kLA7g2wIiYdpS\nV437hm9jQGsxZWmwMc/BPN0FSevgAAAgAElEQVSQR1hA2/Y9XH2JCkMca/O1Bs7QXQx6FkQQos0w\nRoter1/7tf+J7/zEdwEAzj78iBFvTzWBbjAAZYNRYt6vdEqmmLhN9+fmjVXMnn1Y3YMxNa72tm5i\nliUWd+m9sNIMKT01w9DJyHqTphD0anR06TkLsKn8bgo4N6ooUzl9wDW0122hxCWpyLVpvjGGvSVa\n6PQ+zRUqCLpUMmPO/eyZR7HOHOpioYyIOeEtrp7rQQ/bLGS9SvKWI4BKqu7ZJK+pbPso6BQxXp8b\nJvCiW1NUut0Qxx9TqWcTzNW1KxUEXMPGKmU0mX8rBMXzhdAV+LD4pkop67Tb6L3rCv92HJCNE8is\nDFJkRvxb1yS00xQJfZRa1DoOAPSZRN5oIEzVDXyTSbWWv4GJR5X7bWZaTZClN2+gTBeedl8CQMB8\nSS2GbgrFYcgm/VogRwTkRyX+RvNF+cx8wKOgdDjom4PBLsWsn/3oWczMqmvqcVJsRRFqlDIbDAYY\ncKPQI8N3CyjTRVGrqL+1hYXu+58HAPQ5Wf7kK39k2J1j43rTBfoj8nQAMDE2btiDY4xhJkmCJjeq\nsD/AiWOKAelys7VLZRRMTcehYPPt4vNxEho31hHWNjxy+hiqO2qh0S6smzdW8Mobr7O/1G/Mzx4y\nB4P5mVlklHKzdd5orWYEFHYYR94NAkzMqwNIc10tqEE3Nf3uTqjFoJ8GpmamQ3Hp3fYuPG7aj75H\nxfMuX7uGcEstAFeuXEJ/c0ndA4ts5q1t7LCf+gN1GMoCAYv3fH5OLY6lXg9dioQHPcaxXA+WFtrn\nYuQ4Lnz2cdn1EXMR9lzGwTC6cYKPJsUcDl+0JSAZNy1xXJUE4JIT7unkdEvJ/AFDRnW7G0OTRLcG\nXbz3Y98NAHjsm1QRgpVqARfpft9eU4eOr37hD9Bg7G/hsHLxjU9NYo8i2z29CVbLePiCig+/+iIL\nHuzdhEzVQVgwnveBDz5rEuhFFOIk3bELk+rw8eQj51HiwWCaBQOq5TL63Px8ui2vfuXLsD2uOXR/\neo6LTPMbeNgpOw4KjNU3WGu0WC0ZVvqlNy9ji6zphXnF6p6emDYH5F5LXd+gYEHysHOI9S+XL13E\n9AlVeOF7/8kPAAA+/bP/ERubyl3saeqxELB0KGoo+2I2TiEtCM2eLmp1mBRS3BoXnRmvo8xKNSvb\n6v601jo4xOojBUp8Vm0XhyjmMCDrt+4WTGwy7VOIpDqFCrkEgWNhlRKpWxS1Wdrbxm6g1hS/xphw\nlppqJk3m6c/IAsrMIdUyfDKMEXGMlKuq/zthiJTM+EcevQAAuN7cwnGykB3Hw9WLbwIAYopzNPwK\nfJ3LzfE80ZhA2d+f8zV31ebIkSNHjhz7wIGwOKUAEidDZmVGVFrn6llhCEEShK3r/HVCIFPP49TC\ngDJiXVpub2zvoHxd5RA9Nq0sIGu8gTIJClrZw4GEpaXKTG08MbSMtIs1fZsj9m24/QSSjUieaf6j\nctXydDzyOe0ILpIQtLvXQghlQen8o8ceuzBki2lyU5Jij2WBCoUCxiaVW0kTOtI4hTSybAHbInBo\nTuW1lUu0yHwPHbpdbjJw3uv3UWfNvJkZRXxobu+hSsJAREbr5OQkXnzxRQDANz//vMmT1K7FOByg\n3x+W/wKASqkMf0xZUBHJLOvr6yZo/8Qzf0u9hxQbdOnUSCoojNVwhKffkJZSICQCegputvZM2bSb\nN5R7aeHkabh1dQotl9UJe3l1DU1BNzjHUmVsDE5BXV9aIrlCptjuaWaveq1YqkJ0VB9PMUdwrbmN\nIFLfna6l8OmCzXhqv7b6lqlBWiiTARunyGjlNWjBFioeuswrbdE9GMkUMYlFCR9he0YdpuZ7xnJ1\nA9YTFcOwQKpDDxgRyOYdcTIgAZWf6Ob1RQaZ6RqQZH4KCwlLRmkFr8qhQ1h7iy5TpDhBCzGh1SGL\nHsokjk3OKkvQDWNUx9S9uLGqXLH9TQBVZQVUaC24mWsY6t/wTSqUcPL0AkokSb3+8ssAgGOH5iAC\nZYl4MsUzF5T6z0NHlLVXcRzEJGC5HDcAsP26ct+ntCSnxifMc4uu2rLlIknVdye0iqI4UYwqAB4t\nF9gWxueVR2f88GFs31Qs4AHdhFsb25C0jLSlmMzMm5qUa6uqD88/8SR6W2oO2FTUOnryDL5EhaIj\ntKLt1IakJwMppRqlNGQ+y7LMWuHSSzcIU8QkY2VkjjfKFUxwPgi6szMXZlyVuSaUKjWcnVdrgM6L\nnJ2uI6ixjivX6jcHOwi4fu+0eri6rfohIfmnLVN0NEvWZ+mvLDEWp87dHCU6JSZBPjVKP2UWUAgh\nsU7y1mMfVLmwTSvDzPFjqt+3dvAWy/6FvKf9OISXaWtd9VepVIZf0vTBu0NucebIkSNHjhz7wAGx\nOCUSRyJBhkTokxnTRKLECJDblAOKOwFgqxNLGKSGrOCSHLSXRPhjntL6XfV98+UGpnQsRAxPZqNl\nrQDAtlxDHtJxOF2VfX8XZUHeRg6SeHvccxQ9xukEhgWeD1PJZ25uDld6KoYbl1jeqlIyhYYlUgRU\nNOknDKKHMWz+oBaQd90CVq4rpZWjFDmfqlYhqox5uSpWk0Kiy9Pl8lWlMDkxNoWri0r95xhjmZ/7\nzc/iIx/5CABgbWUVR46o129QzSXNYkMA0m1IkgQbLIuktWpLpRIuXFBxilUSa+bm5jBG8k3AzyVx\njCpPyRZzU6NBhJOHlYWRRCl2SbHXVuirb71lxNEXKBo/e+IY3JLqr4zV3zu9EBHp9JWiiuHWZiaR\n6lJVnC1LN5bQqKh+On5GqQlNHZ7FzTf+HADQwi78S8ryG7SV1TtRdYeFvIWO39gISPAJGN+1bB/j\nNeZvkixmJxkyWlURC0ynWQ8pY4WZPyxkXYe6ZxIWUqroJFrvU8BYJRp2BvicF2XOPVdYJlVExzWl\n5Rgt4ShWHXZ9eRlNWmlnHz2PJ59Vsc1VhlJ7WQyXqQM+rZip+VnMHlZ9NzmrLKiBLbHcVF6C6+vM\nMR4kmB9Tcd8bO4rEMTs9jRUqUtXGWEC77OHYKRUTPzo9jZMz6juFzt2yAJdxvh5LcK0vXzfWpc/5\nbwkJwXmTMm8yTVKktM4ck1LlIGL5Meg4nOugz6LUqbANOWh8jMSoOiAjEoWYW3xT2HjhJTVefuYn\nfwIA8G8/+a9w7oia7+UpZaF/43d+Nwr0WP3FH31FtSWJIGn1aw+dlPKWdU0/9xnfTZIEHq04i3/j\nBxFcdtMULbLa5BR0Yob+nJPGcGiRScYZhZMic1lejgL3r3RiDOgR6UQhmuxHm/FDr1pBkWuituA9\nAJYW0tf5xEIg4bjTFqzr2nBp4es+dFwbGyRPXmOZueJ4DR16w7xyGaUGc0zbVK6KU0Mw0WtwEiXI\nnP3ZkAdi4wSAzJbIbslu1AyxDGCAXsuXpYPY+KEKRc+wNQU9J4NBC62u6rzLa8ple7m9iAsPc1PQ\nycNSmo1Muxt8z4fNCaFdtp3O/jfOv6qiyq1XqaDzHOv1CrZJHSsy39F1XbPJtOh+bYcRij7dG5aF\nAt11mm1qeQUMuIloN2iv2cUjjzzC61O/2+40DXGkQNeO6xXQoNtsnm6onfUdHGGi/i9+6hcBAA+f\newhvkC06MzON5WW1YXqsw+gIyyQx6wRu27bNZqrvxeghRhMWNnY3IdmRmjhVbtTgcBPU96UXDpAx\nN1WmGXokHH3zt3wLALUp71CO8XUy6TzPQydQk+3MccVknB6bQ0o3aYdi4mESo0eB+RoT1efPzGNn\nTU3EG3SzjU9P4ehRtYA3Su/FTqw2guUV9XsZIiPrGPKw02y1EDHPziEz0bEsBD3V/qmJMX5eok+3\ntBZoGAQJEorUp1GMjCydapGbvCURczHUFLfUFsh4GDSLrBjWgfUpzGCLDClfi+metSSQMddNi6pv\ntCMUuDGeOHvGLFJasL3vjUGQHd5ksvxeu4OQ4ZGIi+xeMgB4WD3KQgdZkEDykOBQiu3NK5fxO7/1\neQDAP/guxWI9dvIYnqSofAFAn2uEdsqGnQG6FGWPOBeWl6/hNA94ur5pGA5Q5FjLSH5yHQseXcNw\nhwny0S7dmiyq4Ps+Qs7JJIvNmLW4aXm2B9vRm5Z6b3x82tTZ/Jc//CMAgLn5WZODvbui2OTotfD4\ns+8FAFx8UbF+LQuGNSsTHQYZ3lMhhJlLMcNTWRSZA6fPA6zIMiPq4XMjm5mcQIfM2YhtDpMYbW6C\ng0Bd885yE9s8WG+qJuNGzTYLX2VsDD4Z5ToMJKSPIt2sggfFNAzNxukwtGVZDhKGCsBx6Hj2sIIJ\njaFytY7xirqWa9dUfz197sP487fUenT+kUdxmMbBla8qYRY7BSwe4go22yKHgjt3i9xVmyNHjhw5\ncuwDB8LilKlE0kyQlFJ0JWWxeCqvl1JMO3Rj0ar48X/3rzE+qU6CoZSIJbXTYq3XNwapsiqwyhOQ\nrAA/dk1ZQ4em1An2zMJRHKI6SY0WntcLUaCbx+eJ3c1sCC2RRy53ImJTFT22UuNi1oSM7iCAp/Pi\n2KwpaRmZMS3LFWcSfVq78Yxq9Ea9iqu0pi68R5UQa8Y9LDCgHpPinwqBgs79HGsgoQlZIAmiUK9i\nmYosNgkS7zl1HJ1YuZUi5t0ltoOEVpwuX5Wk0tRu1E22/ACHDyur6n3f+k0AgLNnz2FvW1kYzW4H\nnY5W7VBtnZmaNpaFlknzPYHFy+qE+L7n1PdsbWwCLAdUYCfW/DFjkQ4o2Zb0+5iYUYScOGWNxIk5\nc9q+vrqCGl3ZMfsmK/io8PR76swJtq+Ezp5yA8dtdSJ+9c2XTH5mRB+WaKc41FDu2Na2OlpLN4Wt\nxaf7yrLs2B2cOEzFn36K15bVPfIDZVWUiyUj3SjZH55sQOg8YrqL48AyajxdpmakkEhpN1quTteK\nYfG1RGYm73TLV31j0qtGno+mARkIQNKqGli6pqELyx+mGwFKzF/XXQhD9R3PpBJ9lzKCwsMuvRZR\nUVmeFXca7Q01dycc5ba8OShiJ1TztZ/w9wpVlHSqQURCXS9GQAUYt636/dvOncdhWkbf92GVg9xa\nu4n1P1Zi8KfmF1DkuuHq4q7tDjLmb5bp+Rjr9nG4pHOhVVu6W1uwmEtqkyfSSXomnUurPgVBgALz\nLnvsEJk58CnTWXHdoTIUQye9qGWUu6SrrnMm2UKnryzXSqSub3biJGJaUM6C8o4lwQBtupUf+egn\nAAAvfPn30VxTbucKXYxeGqJE0pKdJehz/bArajwnIkOT8yF1WE7LBiS9BNuxus7fvbmNvq/6ZndA\nos9ggJYu/0fL0xIpPFpunuoObNYteEylira3MEFLcoa7zLh3CJc3mVPrKTe840hYllqjCkwx8gYr\nmGF1B5f95Yki9ADseOq1mm8jZN7o7LhqxFuf+w2co9ei84d/iDNldX1vME/61Lmz2GCutkeCoj3V\nwFpzKDF6N8gtzhw5cuTIkWMfOBAWp23bqFWqKHgeIG8tjZVFsVGU+TTLwfR6XwNZB0CB5XSaHfUb\nr11eRKuhrLyTUyqON1+pGKV5nXLRzoaxEKMqJGxIyq8kjoWUYsL6/ThKh9qzfC3JLFianKHjfhaQ\nkEywSSUSt+hjZ6AThdVJ6vrmJmymVHhVdSKsNMYgmGQcywwtxjNSnnSdThu7FDmw3KH4wzgt1wGt\nuU6YoktrT+vRShHDYvqExfY1Gg1sUuxZl0ey5FBQolKuYXyclHnev6uLVwyNvFJSlvDYeN3EO3Xc\n1nEcxPGwRJJqS2bivhrtdtfEa3Xx2rGxMVy9akrkokJlJZMSE8dGb1fDdRPTBq12NFYpQjJd6PNf\n/F3VN2mCyWlauF31HefPnDP09ckCLdSsgxWmQJ2MY2SMeU3zu+Vgy/x2NmIBaktRx/fFCHlHWy6Q\nckTvmC8J28TghRBG+Wp3d9f8rb4Hug8dxzHPTVEDyzLzKRnRKzZaqHxMkqE+qrbu6/UaYl22TiYm\ntUgXrZZhCJ14pWPalXLZKBBZusyVGMbG0kinf4RIOcbKtKrmpmcw/X4V7ztEneWFRgMRxQyyXg+X\nL6lY1jrJImPFIqY4x6c5NovF4jDAP3KdRV0ej2NlMBjAZ2xdazO7IxZlh14cPc5ux2jMUd4WW5ZS\nmrGv1zcp5S0xf/0o+VxzE6ZqJfzZl34fANCnILufRejtbJp+1fdZCyFYEEPCpdSpdxlkSnEZdocv\nBG6sqZhwj3rhGeyh1rMmUQoLNgk8lo7TdyM0SKSbrgCHmNpV1V6JYhUlR61Nbc51YdvQw9yQMkU6\n9JKMcEX0c5/zPk1T0/fNprLai9UK2ua+eCNzXK0JxWIRFXomG4z5wnHMfLhbHIiNU0DAcRy1ABiZ\nuyHDSnfiZz7zGQCAl6TQl2nd5nl6N4SkRUq9QKQJ4oFaaJp7ahAv+UXUdb03Tuypet2oicAsdClS\nst0SkY6os/D9SjZc7OTwkbwDWBywKSSoZwyPG0tSrcDhZnX6KZWX1rQcxKwOsMOBce36MiaZI5XJ\nFK7OBdRs0yRG3GfOIAkuV69eRaXBxZzXKWwPVRJXKq6upGENazbSddrv97C8rBYkvRDevhjrChoa\nJ06cMItAyJzG3d1tvPTSS3xNLdqPPHzOuEkHvD9hFJnFRf/G2NiY2TD0pnPp0iX06cYpVsqoVmum\nPYBaCEeJSYDaCLTai6T7L+4mKJbVdc3Oqry19114D2ZYoeYG3csXX3kVA6qhVKbU5Dt+cg51uv8q\nERCzpmZAl5lnZ2Zs63ZLgRHR/+EiixF2pPqgVJuL/iP1BNobmWUZUs6RPkMGWRojoVut103MNadm\n3OlvAWZIQhrdJHUf6zb4vm9Evw2JDR46bIPneWYRc+lmC5HCIulCV7cp+Z5RrNKskLJfQjtQr+kC\nBON+GQ9zo3juYeUqD7t99Jm3rOdPp7mHPg8LNcfGqRPqsw+TqNXe3sXGDXWgeZFVVF6/eBHb3GQu\nPKbk/+r1Kroca3pzKxQKQ5INx0+SJOagqD83qkQ2ilGWa3Ybo19KaeQtJycnzd8kWoaPuYa2bZl+\ndTgGFs6fx9Kl1wAAyztqk3Mcx/yG7TkocX4O6Pr2hQ2pxx+HkGdbRgXKYXiqIlwUuBFG3NxCCQiG\nBYQWsAdQ4O7h8mBztlDHOHN4Zx0bs2Ut2UmFrsiGq2sTk5lsyZKZk/o6hYhN9ahUE7ZsC7poqyQT\nPU4SExLqtIaHEK2g5ngp9iiDqcdsEATGzaozADBS7ONukbtqc+TIkSNHjn3gQFicmcwQBAEyy0JC\ny6HuUNXGcfA60x0GW8rdVZuZQ6zzmDCsgTlq1mtLNBv5TJ+nr1JBuT89x0HE9IOlpjqZLMkWaMCj\nypqEk/0BPC16zVNR0XfhFam04pfhusN6ngDQG3QQaR4Q7eM0G7pEtPsylkBfu3QYqH9rZxugHuaA\nAum9VKDAk6nH06Q/COAwdabV3kOkSUa0jrv9LiKeEF0SQGSaYZtqG7q+XalcQ6nEz3la31QOhaTZ\n5h3Rh8vrn9OlhEZUlYIgMOXJanSDxElsdGv1yfzo0aN47rnnAADjvOYkSfDCCy8AAA4xuD8xOWlO\nitqd2Ol0hqd3WuWrq6vm1F4sFo1bTWvfJkliTrWj1sHmjhKGLjGv0kpTtEgk0ZaG67qmVJo+3R4+\n/yj61Ny8vq0s8D/74z/BJAkujfFpnDv9kOqTrhq73aCNWJ+iMfQ2vC1tyRIm1cBYnkLAwW1pJBiW\n95Ji6PKdnVRuMSnlsIDBiDtSPx/VDdbXqtvliuGyoPu/UCigRI+I7kM3lHBp4RbKBZOaUvYYhhhR\nxdK52DJLENPzQNlddJs7kHTzztC1fXbhCM6dUFZjjW25vLGGaaZIacWviuehQ2/KdreDKnNbYxJv\nfGHjyBGVQnWMj2ONmnFLb2wpy3Px6hUsHDt6y/VZ1rD+rPZoxHFsrM8u01Gq1eo7krFGLc7bXbBZ\nnJjvPH5cWclplt1yXwDAdmxIril9hmUqxTpm6BFZv6q0WMPOnhn3nmujwOdxqN3rDjJJHWMOOpEB\nYEiBEsdouC58umArtKs8WBBM3SjSzKyXi6iTyFSk18v1CigJ9UXFJESJ6U3aqt3aawJUMNO1XyEk\nXPfW9QEyMN4ZXZIQloDuYrPmCGHWUQ3LskZCDgmaTdVnWoENmTT9dOb0afCHUWfa1N0itzhz5MiR\nI0eOfeBAWJxSqlNEMlLZ3FgVUuALX/gCAKBIq0IIcdexzVFr1GW5rYSnmIG0YDMu6JIwI+IUA9K/\ndeWUld1tUwBZV68vFXyUdCKt75rTksMjkt9wwQpI6POxKAFXp8fQjIswTANYpNrRxa1dfPfz7wcA\n9GgpbvcG8JjsPOBrjbl5uIEmSmXmpKUPYQMp4DDZucQiuFkUo8hSULZWsAkTyEid0EOpTtFpKpEw\niK7vReHkJA6zpFeNeqPbW7vweZqzXR8xK6oUWZKsv7k1tFR4sgy6HXMa1989MzODyUl1f1ZYweTG\njRvmVK8tn/n5BUxPK2JIh0pKnucZsYZiqWRO69riFEKYNujvSZIU4D3TqjZObGNrW/32MVq9lgT6\ntDh1wnqtVEFMgYSjFIS4cP4UwhuKoPTbP/8pHLmuvCOTOn6KbKToMPtVjtS2sIYxThMH0+9hqG1s\nj5A9HB1Dt4YWSrvfxe3Q3+cKYeJRYqRSij6B6+/IsuyWFBb1eYmEpDP9mLllkyaTpgk6HWWt9xlE\nC+wMmaSmNPvLFpkppyU0OW23i8OsDvMNjz4GADhSLOmPgc4cxO0OUv7n1UVlafkyQ4k9VSsWUeTz\nIKTnJI6QScYIeb/n5maHmqu03AaDAa6vKO1c7Z0QQqDOMnR6/NTrdfN+m94J7Ym4HYYcNBLj1OMv\niiJICli49CAlvZ6xSLU3BbZl6mhpHV8IidOPPgoA2F1dAgAsvrpjrKYsHJj0GVcUzdcktPwkU+Es\nSyChhq5L1aSa4+LUuCLDJSzEbfkluAVal4xhFm0LLtNHHC6ylcwDs6WQRQOTLtVlRD1uteDwuW1Y\nKkMCoBZNEZGANOWjtAfMNtqyur8TmaHD9UGXKWzu7sGiVyyKEjNfbK6xcRgB9KppnkbSaqEvHsCy\nYpYl4Ps+3ExC8mL0oIvCCK++/JcAYAZGsLP3jg03XS1H6l6O/g7VP/SCOkgSQ7DQG5/tABkXeC2M\nLl3HuD8DzuZuksGmFJ/dkcZloPM9o7UM1AQHtUdQlICnBxYfYwA9LVHGslXbKXDqKVWT0uMmIZpN\n7HEl7Saa7JHBo6s5clzDJi25WkGoSGYjkJH40Gt3UeGEcEnO8G1L61abiRT2+hhwEwyoVtOddNGo\nq81NbyZBEKBC5q9XKKHLv9FuqGqjjpBycc29XbahZaTvJsfVYpAlQzep3hg933/bJnjjxireeOMN\nAMDKTbXQzc8tmGuHbSHkZqX/1nGcW9xvABDHiRHp7rbUtbQ319Ei+eTJZ59W/QBgb49lx5hLur7X\nx+ysauMrb6mx+ZM//p+x9rISuz+0uYsf+/B3qP7cUK6iBJnJs9VEHuWqNewg1WZLGFm87JbiAnL0\nY2oz5edsOXynTnWVO7lqDbFKs6elRBzd6lq0bdswqUc3U+26198RwUagt/5eGzdWVJ70OsXi4+oE\nKiXmEfL+FXwXHebezUyrcXP80BzOHFdu0nEewlwMD4BaKH/n5gomuLiW2b6icCBCLYDfA8iCHafi\nVthuGQZ4xPlsOTb6ZKDr7vdLBZw4oXJ8NUklCALDrNds5SAIzKZ0ZVGRjT7+8Y8jCoasbd1nQ3LX\nkFxk1rUoGromR5TMtGqZ42k2+YiFwPfQb5tQjg5RLGK4hiVRiJ6WsnTL/F0bGe+f1KxmWABd6BY3\n1XqpjPICFauYKRALy8iaCv35qAeLz0VG92xcgCt4WE0HsHyzuKrfTUI4vH6HYzdFCpsKSw6LeFiJ\nhSw2R0oAaqOVhmQ5dHvre6EPM1EUocqNtdcdIKUr2mYbojgyBwh9T5eWljBw3mHDeBfkrtocOXLk\nyJFjHxBvUxK5H40QYgtAD8D2/W7L3xBMIu/Le4G8H+8N8n68d8j78t7gTv14VEo59Vf98YHYOAFA\nCPGSlPKp+92OvwnI+/LeIO/He4O8H+8d8r68N/h6+zF31ebIkSNHjhz7QL5x5siRI0eOHPvAQdo4\nf+5+N+BvEPK+vDfI+/HeIO/He4e8L+8Nvq5+PDAxzhw5cuTIkeNBwEGyOHPkyJEjR44Dj3zjzJEj\nR44cOfaBA7FxCiG+TQhxWQixKIT45P1uz4MEIcSSEOJVIcTLQoiX+Nq4EOL3hBBv8XHsfrfzIEII\n8QtCiE0hxGsjr71j3wmFn+EYfUUI8cT9a/nBwh368UeFEKscly8LIb595L0fZj9eFkJ86/1p9cGD\nEOKwEOKLQojXhRAXhRD/jK/nY3IfeJd+vHdjUkp5X/9BFd68AuAEVJm3vwRw7n6360H5B2AJwORt\nr/0HAJ/k808C+In73c6D+A/A+wA8AeC1v6rvAHw7gP8DpQH2DIAX7nf7D8q/O/TjjwL4F+/w2XOc\n4z6A45z79v2+hoPwD8AcgCf4vArgTfZXPibvTT/eszF5ECzOpwEsSimvSikjAJ8G8LH73KYHHR8D\n8Ck+/xSA77iPbTmwkFJ+GcDubS/fqe8+BuC/S4U/BdAQQsz99bT0YOMO/XgnfAzAp6WUoZTyGpTM\n6tP/zxr3AEFKuSal/CqfdwBcAnAI+ZjcF96lH++EfY/Jg7BxHgJwY+T/K3j3i8xxKySA3xVC/LkQ\n4gf42oyUco3P1wHM3J+mPZC4U9/l43T/+CG6EH9hJFyQ9+NdQAhxDMDjAF5APia/ZtzWj8A9GpMH\nYePM8fXhOSnlEwD+NoAfFEK8b/RNqXwRec7R14C8774u/CyAkwAuAFgD8FP3tzkPDoQQFQC/DuCf\nSynbo+/lY/Lu8Q79eJEo2zUAAAHGSURBVM/G5EHYOFcBHB75/wJfy3EXkFKu8nETwG9AuRg2tMuG\nj5v3r4UPHO7Ud/k43QeklBtSylRKmQH4Lxi6vvJ+fBcIIVyoxf6XpJT/iy/nY3KfeKd+vJdj8iBs\nnC8COC2EOC6E8AB8AsBv3uc2PRAQQpSFEFX9HMCHAbwG1X/fz499P4DP3J8WPpC4U9/9JoDvI5Px\nGQCtEfdZjttwW6zt70GNS0D14yeEEL4Q4jiA0wD+7K+7fQcRQhXr/HkAl6SUPz3yVj4m94E79eO9\nHJP3vZC1lDIRQvwQgN+BYtj+gpTy4n1u1oOCGQC/ocYJHAC/LKX8bSHEiwB+VQjxjwEsA/ie+9jG\nAwshxP8A8DyASSHECoB/A+Df45377vNQLMZFAH0A/+ivvcEHFHfox+eFEBeg3IpLAP4pAEgpLwoh\nfhXA6wASAD8opUzf6Xv/P8SzAP4hgFeFEC/ztR9BPib3izv14/feqzGZS+7lyJEjR44c+8BBcNXm\nyJEjR44cDwzyjTNHjhw5cuTYB/KNM0eOHDly5NgH8o0zR44cOXLk2AfyjTNHjhw5cuTYB/KNM0eO\nHDly5NgH8o0zR44cOXLk2Af+L5/WnGFxqoymAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATsAAAFoCAYAAAAoxlyeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1m3EVowAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAEOCAYAAABLkFkYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVwAAAFoCAYAAAAb/UOXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtSYFr8g7wnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-TfKtv-826o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7lVUOvu83AE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_0oXrel83Fj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsqlB4Ou83LS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLn07jfc83QZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA-1aoMc83Yo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gch25hQW83cq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRqk3P4B83Wv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMuiILYh83PX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHGoIGVY83KC",
        "colab_type": "code",
        "outputId": "3ed5d753-0ed0-4e74-aa28-67226499e6b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# used in tensorflow object detection api for videos object detection\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "from utils import label_map_util\n",
        "\n",
        "from utils import visualization_utils as vis_util\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "# Path to frozen detection graph. This is the actual model that is used\n",
        "# for the object detection.\n",
        "PATH_TO_CKPT = '/content/models/research/object_detection/inference-graph/frozen_inference_graph.pb'\n",
        "\n",
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = os.path.join('/content/models/research/object_detection/training/labelmap.pbtxt')\n",
        "\n",
        "NUM_CLASSES = 1\n",
        "\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "def detect_in_video():\n",
        "\n",
        "    # VideoWriter is the responsible of creating a copy of the video\n",
        "    # used for the detections but with the detections overlays. Keep in\n",
        "    # mind the frame size has to be the same as original video.\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "    out = cv2.VideoWriter('butterfly.mp4', fourcc, 5, (1920,1080))             # (width, height)\n",
        "                                                                          # frame shape is (height, width, channel) used below\n",
        "    detection_graph = tf.Graph()\n",
        "    with detection_graph.as_default():\n",
        "        od_graph_def = tf.GraphDef()\n",
        "        with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "            serialized_graph = fid.read()\n",
        "            od_graph_def.ParseFromString(serialized_graph)\n",
        "            tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "    label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "    categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "    with detection_graph.as_default():\n",
        "        with tf.Session(graph=detection_graph) as sess:\n",
        "            # Definite input and output Tensors for detection_graph\n",
        "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "            # Each box represents a part of the image where a particular object\n",
        "            # was detected.\n",
        "            detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "            # Each score represent how level of confidence for each of the objects.\n",
        "            # Score is shown on the result image, together with the class\n",
        "            # label.\n",
        "            detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "            detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "            cap = cv2.VideoCapture('/content/cc.mp4')\n",
        "            ct=0\n",
        "            while(cap.isOpened()):\n",
        "                # Read the frame\n",
        "                ret, frame = cap.read()\n",
        "\n",
        "                # Recolor the frame. By default, OpenCV uses BGR color space.\n",
        "                # This short blog post explains this better:\n",
        "                # https://www.learnopencv.com/why-does-opencv-use-bgr-color-format/\n",
        "                ct=ct+1\n",
        "                if ret==False:\n",
        "                  break\n",
        "                print(frame.shape,ct,\"   width=\",cap.get(3),\"   height=\",cap.get(4))\n",
        "                # width=cap.get(3)    height=cap.get(4)\n",
        "                color_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                image_np_expanded = np.expand_dims(color_frame, axis=0)\n",
        "\n",
        "                # Actual detection.\n",
        "                (boxes, scores, classes, num) = sess.run(\n",
        "                    [detection_boxes, detection_scores,\n",
        "                        detection_classes, num_detections],\n",
        "                    feed_dict={image_tensor: image_np_expanded})\n",
        "\n",
        "                # Visualization of the results of a detection.\n",
        "                # note: perform the detections using a higher threshold\n",
        "                vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "                    color_frame,\n",
        "                    np.squeeze(boxes),\n",
        "                    np.squeeze(classes).astype(np.int32),\n",
        "                    np.squeeze(scores),\n",
        "                    category_index,\n",
        "                    use_normalized_coordinates=True,\n",
        "                    line_thickness=8,\n",
        "                    min_score_thresh=.20)\n",
        "\n",
        "                # cv2_imshow(frame)\n",
        "                output_rgb = cv2.cvtColor(color_frame, cv2.COLOR_RGB2BGR)\n",
        "                out.write(output_rgb)\n",
        "\n",
        "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "                    break\n",
        "\n",
        "            out.release()\n",
        "            cap.release()\n",
        "            cv2.destroyAllWindows()\n",
        "\n",
        "detect_in_video()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1080, 1920, 3) 1    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 2    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 3    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 4    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 5    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 6    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 7    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 8    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 9    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 10    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 11    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 12    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 13    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 14    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 15    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 16    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 17    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 18    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 19    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 20    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 21    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 22    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 23    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 24    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 25    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 26    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 27    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 28    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 29    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 30    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 31    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 32    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 33    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 34    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 35    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 36    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 37    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 38    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 39    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 40    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 41    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 42    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 43    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 44    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 45    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 46    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 47    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 48    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 49    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 50    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 51    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 52    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 53    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 54    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 55    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 56    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 57    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 58    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 59    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 60    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 61    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 62    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 63    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 64    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 65    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 66    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 67    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 68    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 69    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 70    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 71    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 72    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 73    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 74    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 75    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 76    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 77    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 78    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 79    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 80    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 81    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 82    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 83    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 84    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 85    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 86    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 87    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 88    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 89    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 90    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 91    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 92    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 93    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 94    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 95    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 96    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 97    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 98    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 99    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 100    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 101    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 102    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 103    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 104    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 105    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 106    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 107    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 108    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 109    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 110    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 111    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 112    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 113    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 114    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 115    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 116    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 117    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 118    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 119    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 120    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 121    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 122    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 123    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 124    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 125    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 126    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 127    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 128    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 129    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 130    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 131    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 132    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 133    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 134    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 135    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 136    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 137    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 138    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 139    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 140    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 141    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 142    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 143    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 144    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 145    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 146    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 147    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 148    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 149    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 150    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 151    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 152    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 153    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 154    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 155    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 156    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 157    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 158    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 159    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 160    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 161    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 162    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 163    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 164    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 165    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 166    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 167    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 168    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 169    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 170    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 171    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 172    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 173    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 174    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 175    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 176    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 177    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 178    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 179    width= 1920.0    height= 1080.0\n",
            "(1080, 1920, 3) 180    width= 1920.0    height= 1080.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5BkZXV183EI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_xFX2Z482-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSpuh5YH824f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}