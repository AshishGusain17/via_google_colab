{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "face_expressions_detector.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshishGusain17/via_google_colab/blob/master/face_expressions_detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "q25bvEMgD4yy",
        "colab_type": "code",
        "outputId": "17390d11-23de-4577-dd71-7b2cbdf852d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "# importing all the required packages for the code\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import os,shutil,math,scipy,cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random as rn\n",
        "\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix,roc_curve,auc\n",
        "\n",
        "from PIL import Image\n",
        "from PIL import Image as pil_image\n",
        "from PIL import ImageDraw\n",
        "\n",
        "from time import time\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from skimage.io import imread\n",
        "from IPython.display import SVG\n",
        "\n",
        "from scipy import misc,ndimage\n",
        "from scipy.ndimage.interpolation import zoom\n",
        "# from scipy.ndimage import imread\n",
        "\n",
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras import layers\n",
        "from keras.preprocessing.image import save_img\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from keras.applications.vgg16 import VGG16,preprocess_input\n",
        "from keras.models import Sequential,Input,Model\n",
        "from keras.layers import Dense,Flatten,Dropout,Concatenate,GlobalAveragePooling2D,Lambda,ZeroPadding2D\n",
        "from keras.layers import SeparableConv2D,BatchNormalization,MaxPooling2D,Conv2D\n",
        "from keras import regularizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam,SGD\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras.callbacks import ModelCheckpoint,EarlyStopping,TensorBoard,CSVLogger,ReduceLROnPlateau,LearningRateScheduler"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAPVdbg9EmWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code trained on google colab, so mounting the google drive for it\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "b3b329542117805842c5144474ba6425d9ee4509",
        "id": "DH21jgfCD4y5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function will be used later to plot the graphs for loss and accuracy of both training and test data-set\n",
        "def show_final_history(history):\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
        "    ax[0].set_title('loss')\n",
        "    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
        "    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
        "    ax[1].set_title('acc')\n",
        "    ax[1].plot(history.epoch, history.history[\"acc\"], label=\"Train acc\")\n",
        "    ax[1].plot(history.epoch, history.history[\"val_acc\"], label=\"Validation acc\")\n",
        "    ax[0].legend()\n",
        "    ax[1].legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpGkGu7lFjE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing h5py package as my data is stored in the form of h5 file, so to extract the data.\n",
        "# Now, the location of the file given in brackets is the location from the google drive.\n",
        "\n",
        "import h5py\n",
        "train = h5py.File('/content/drive/My Drive/face-dataset/img150.h5', \"r\")\n",
        "test=   h5py.File('/content/drive/My Drive/face-dataset/img150_test.h5', \"r\")\n",
        "\n",
        "X_train = train[\"X\"][:]\n",
        "Z_train = train[\"Z\"][:]\n",
        "name_train = train[\"name\"][:]\n",
        "X_test = test[\"X\"][:]\n",
        "Z_test = test[\"Z\"][:]\n",
        "name_test = test[\"name\"][:]\n",
        "# num = XX.shape[0] \n",
        "print(X_train.shape,Z_train.shape,X_test.shape,Z_test.shape,name_train.shape,name_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I39R6fkb-L8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "while 1:\n",
        "  a=np.random.rand(100000,100000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lReV4j5uid14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Shape of each image is 150*150*3\n",
        "imgsize=150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "6645009ce15af53646b2c5c068b16ad34981b32b",
        "id": "xW0GrPISD4zD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting the indices into the categorical form\n",
        "# Example: If 3 is the value of output, it gets converted to [0, 0, 1, 0, 0, 0, 0]\n",
        "Z_train=to_categorical(Z_train,7)\n",
        "Z_test=to_categorical(Z_test,7)\n",
        "print(X_train.shape,Z_train.shape,X_test.shape,Z_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "a30d0a12e600f130543f1dcb1e6d6500ac688c33",
        "id": "DVPZYIB0D4zG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here, using image data generator to get various variation of images from a single image.\n",
        "augs_gen = ImageDataGenerator(\n",
        "        featurewise_center=False,  \n",
        "        samplewise_center=False, \n",
        "        featurewise_std_normalization=False,  \n",
        "        samplewise_std_normalization=False,  \n",
        "        zca_whitening=False,  \n",
        "        # rotation_range=20,  \n",
        "        # zoom_range = 0.1, \n",
        "        # width_shift_range=0.2,  \n",
        "        # height_shift_range=0.2, \n",
        "        # horizontal_flip=True,  \n",
        "        vertical_flip=False) \n",
        " \n",
        "augs_gen.fit(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "524ad38c7c4952197742756a87c712e54f0e598f",
        "scrolled": true,
        "id": "J5hJNq36D4zI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plotting, some of the face expressions randomly.\n",
        "fig,ax=plt.subplots(5,5)\n",
        "fig.set_size_inches(15,15)\n",
        "for i in range(5):\n",
        "    for j in range (5):\n",
        "        l=rn.randint(0,len(X_train))\n",
        "        ax[i,j].imshow(X_train[l])\n",
        "        print(name_train[l][:])\n",
        "        ax[i,j].set_title('Face-expressions: '+ str(name_train[l]))\n",
        "        \n",
        "plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8ac2c945856a9bbcce4be1358c76e87abf9178ed",
        "id": "3AhuctQ3D4zL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the VGG16 model which has some pre-trained weights.\n",
        "# We require just the convolutional and pooling layers, not the end functional layers, so kept include_top equals to false.\n",
        "\n",
        "base_model = keras.applications.mobilenet.MobileNet(include_top=False,\n",
        "                  input_shape = (imgsize,imgsize,3),\n",
        "                  weights = 'imagenet')\n",
        "\n",
        "# Getting the summary of this model in the form of a chart\n",
        "base_model.summary()\n",
        "\n",
        "# Now, creating my own model and adding the layers of VGG16 to it \n",
        "model = Sequential()\n",
        "for layer in base_model.layers:\n",
        "  model.add(layer)\n",
        "\n",
        "# Here, I am keeping my layers as trainable or not-trainable as per the accuracy I am getting.\n",
        "for layer in base_model.layers[:-1]:\n",
        "    layer.trainable = False\n",
        "    print(layer,layer.trainable)\n",
        "\n",
        "# Now, flattening all the layers into functional layers, earlier they were in rgb format.\n",
        "model.add(Flatten())\n",
        "\n",
        "# Now, I am adding the last functional dense layer which has the same number of neurons as total number of expressions we have, that is 7\n",
        "model.add(Dense(7,activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "# Now, with the help of some graphs and pictures, visualising my model.\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "282e3b30dd7f57ca4cd6394b151fd0dbc57800ec",
        "id": "ulcl3e93D4zO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here, I have used some of the callbacks that are helpful during the training time.\n",
        "# Tensorboard helps in visualising our various kinds of losses.\n",
        "# Earlystop can be used if we are not getting improved result.\n",
        "# csvlogger stores our epoch, training-accuracy, training-loss, validation-accuracy, validation-loss.\n",
        "\n",
        "earlystop = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=0.001,\n",
        "    patience=50,\n",
        "    verbose=1,\n",
        "    mode='auto'\n",
        ")\n",
        "tensorboard = TensorBoard(\n",
        "    log_dir = './logs',\n",
        "    histogram_freq=0,\n",
        "    batch_size=16,\n",
        "    write_graph=True,\n",
        "    write_grads=True,\n",
        "    write_images=False,\n",
        ")\n",
        "checkpoint = ModelCheckpoint(\n",
        "    './base.model',\n",
        "    monitor='val_acc',\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode='max',\n",
        "    save_weights_only=False,\n",
        "    period=1\n",
        ")\n",
        "csvlogger = CSVLogger(\n",
        "    filename= \"training_csv.log\",\n",
        "    separator = \",\",\n",
        "    append = False\n",
        ")\n",
        "\n",
        "reduce = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.1,\n",
        "    patience=3,\n",
        "    verbose=1, \n",
        "    mode='auto'\n",
        ")\n",
        "\n",
        "callbacks = [earlystop,tensorboard,csvlogger,reduce]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "87bebfd0e9ce813e0b7ca38d7bdc05ba0f899fac",
        "id": "jgL1Xn6bD4zQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here, I am using Adam as my adaptive learning rate optimization algorithm\n",
        "opt = SGD(lr=1e-4,momentum=0.99)\n",
        "opt1 = Adam(lr=1e-3)\n",
        "\n",
        "# Now, compiling my model and providing it with the parameters like optimization technique, metrics and the loss\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=opt1,\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Finally, training my model with the parameters given as below.\n",
        "# Our batch-size is 32 and we are doing total 10 epochs and also shuffling is done after every batch training.\n",
        "history = model.fit_generator(\n",
        "    augs_gen.flow(X_train,Z_train,batch_size=32),\n",
        "    validation_data  = (X_test,Z_test),\n",
        "    # validation_steps = 100,\n",
        "    # steps_per_epoch  = 100,\n",
        "    epochs =40, \n",
        "    verbose = 1,\n",
        "    callbacks=callbacks,\n",
        "    shuffle=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "7db74b4dd50613ae264f3de7e7ca2a7190d58a8d",
        "id": "W7ISg5QeD4zS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function was declared at the starting and is used for visualising the losses and accuracy.\n",
        "show_final_history(history)\n",
        "\n",
        "# Now, saving my model along with its weights.\n",
        "model.save(\"model.h5\")\n",
        "print(\"Weights Saved\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNiUDT85mWNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here, I can test my entire test data set together \n",
        "a=model.evaluate(x_test,y_test)\n",
        "print(a)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSmeLmjcnQPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}