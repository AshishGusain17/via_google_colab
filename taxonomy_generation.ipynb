{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "taxonomy_generation.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshishGusain17/via_google_colab/blob/master/taxonomy_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4w-2BzXEIVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCcd-BvHGUs6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "902234f1-6f68-47d5-9429-0bc261d95c26"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip /content/glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-13 16:48:17--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-09-13 16:48:18--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-09-13 16:48:18--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.21MB/s    in 6m 30s  \n",
            "\n",
            "2020-09-13 16:54:49 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  /content/glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK8_ozsVGahI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e7d0be94-e6b4-4f12-d2b6-7af05973ff3a"
      },
      "source": [
        "embeddings_index = {}\n",
        "f = open(r'/content/glove.6B.100d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "print('Total number of word vectors are:' , len(embeddings_index))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "max_words = len(embeddings_index)\n",
        "embedding_dim = 100\n",
        "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
        "count = 0\n",
        "for word, i in embeddings_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[count] = embedding_vector\n",
        "        count+=1\n",
        "\n",
        "embedding_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of word vectors are: 400000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400000, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxNy3982kdRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxWukBYtq0r1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def process(line):\n",
        "    line = line.lower()\n",
        "    # line = line.replace('\"', ' ')\n",
        "    # line = line.replace('\\\\', ' ')\n",
        "    # line = line.replace('/', ' ')\n",
        "    # line = line.replace(\".\",' ')\n",
        "    # line = line.replace(\"|\",' ')\n",
        "    # line = line.replace(\"#\",' ')\n",
        "    # line = line.replace(\"&\",' ')\n",
        "    # line = line.replace(\"!\",' ')\n",
        "    # line = line.replace(\";\",' ')\n",
        "    # line = line.replace(\":\",' ')\n",
        "    # line = line.replace(\",\",' ')\n",
        "    # line = line.replace(\"~\",' ')\n",
        "    # line = line.replace(\")\",' ')\n",
        "    # line = line.replace(\"(\",' ')\n",
        "    # line = line.replace(\"}\",' ')\n",
        "    # line = line.replace(\"{\",' ')\n",
        "    # line = line.replace(\"[\",' ')\n",
        "    # line = line.replace(\"]\",' ')\n",
        "    # line = line.replace(\"$\",' ')\n",
        "    # line = line.replace(\"_\",' ')\n",
        "    # line = line.replace(\"*\",' ')\n",
        "    # line = line.replace(\"+\",' ')\n",
        "    # line = line.replace(\"-\",' ')\n",
        "    # line = line.replace(\"@\",' ')\n",
        "    # line = line.replace(\"-\",' ')\n",
        "\n",
        "    line = re.sub(r\"[^A-Za-z]+\", ' ', line)\n",
        "\n",
        "    return line\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjr9SosRReo-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "7a194b56-0dcb-4f27-c747-03cc5dbe6f8d"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words(\"english\")\n",
        "print(len(stop_words) , stop_words)\n",
        "\n",
        "for i in range(97,97+26):\n",
        "    stop_words.append(chr(i))\n",
        "print(len(stop_words) , stop_words)\n",
        "\n",
        "stop_words.extend(['also', 'base', 'big', 'called', 'item', 'conceptual', 'contr', 'contract', 'date', 'day', 'defined', 'different', 'energy', 'example', 'figure', 'fixed', 'form', 'italia', 'ser', 'hoc', 'relations', 'code', 'items', 'kind', 'telecoms', 'kinds', 'level', 'logical', 'made', 'main', 'make', 'many', 'may', 'mean', 'measurement', 'measurements', 'methodology', 'might', 'model', 'models', 'much', 'need' , 'new', 'night', 'normal', 'number', 'often', 'old', 'one', 'part', 'parts', 'performance', 'pp', 'qoe', 'qos', 'quality', 'query', 'rate', 'refers', 'rules', 'small', 'source', 'sources', 'standard', 'support', 'table', 'taxonomy', 'terms', 'thus', 'time', 'time', 'two', 'type', 'types', 'use', 'used', 'using', 'ver', 'via', 'vol', 'warehouse', 'way'])\n",
        "print(len(stop_words) , stop_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "179 ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
            "205 ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
            "287 ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'also', 'base', 'big', 'called', 'item', 'conceptual', 'contr', 'contract', 'date', 'day', 'defined', 'different', 'energy', 'example', 'figure', 'fixed', 'form', 'italia', 'ser', 'hoc', 'relations', 'code', 'items', 'kind', 'telecoms', 'kinds', 'level', 'logical', 'made', 'main', 'make', 'many', 'may', 'mean', 'measurement', 'measurements', 'methodology', 'might', 'model', 'models', 'much', 'need', 'new', 'night', 'normal', 'number', 'often', 'old', 'one', 'part', 'parts', 'performance', 'pp', 'qoe', 'qos', 'quality', 'query', 'rate', 'refers', 'rules', 'small', 'source', 'sources', 'standard', 'support', 'table', 'taxonomy', 'terms', 'thus', 'time', 'time', 'two', 'type', 'types', 'use', 'used', 'using', 'ver', 'via', 'vol', 'warehouse', 'way']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVuVqB-mqUU2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4ec95407-79eb-430a-9770-9e9bd3cec497"
      },
      "source": [
        "from collections import defaultdict , Counter\n",
        "org_words = []\n",
        "\n",
        "with open(\"/content/telecom1.txt\") as f:\n",
        "    entire = f.readlines()\n",
        "    for line in entire:\n",
        "        line = process(line)\n",
        "        for w in line.split():\n",
        "            if w not in stop_words:\n",
        "                org_words.append(w)\n",
        "\n",
        "with open(\"/content/telecom2.txt\") as f:\n",
        "    entire = f.readlines()\n",
        "    for line in entire:\n",
        "        line = process(line)\n",
        "        for w in line.split():\n",
        "            if w not in stop_words:\n",
        "                org_words.append(w)\n",
        "\n",
        "with open(\"/content/telecom3.txt\") as f:\n",
        "    entire = f.readlines()\n",
        "    for line in entire:\n",
        "        line = process(line)\n",
        "        for w in line.split():\n",
        "            if w not in stop_words:\n",
        "                org_words.append(w)\n",
        "\n",
        "with open(\"/content/telecom4.txt\") as f:\n",
        "    entire = f.readlines()\n",
        "    for line in entire:\n",
        "        line = process(line)\n",
        "        for w in line.split():\n",
        "            if w not in stop_words:\n",
        "                org_words.append(w)\n",
        "\n",
        "with open(\"/content/telecom5.txt\") as f:\n",
        "    entire = f.readlines()\n",
        "    for line in entire:\n",
        "        line = process(line)\n",
        "        for w in line.split():\n",
        "            if w not in stop_words:\n",
        "                org_words.append(w)\n",
        "\n",
        "print(\"total words: \",len(org_words))\n",
        "primary_words = list(set(org_words))\n",
        "print(\"unique words: \",len(primary_words))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total words:  13700\n",
            "unique words:  3408\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o65GFqbvh8J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f093697a-76f4-4855-bde8-fe18949afbd6"
      },
      "source": [
        "dictset = defaultdict(int)\n",
        "for i in org_words:\n",
        "    dictset[i] = dictset[i] + 1\n",
        "\n",
        "dictset = Counter(dictset)\n",
        "choose = dictset.most_common(100)\n",
        "choose"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('data', 580),\n",
              " ('metrics', 154),\n",
              " ('network', 119),\n",
              " ('customer', 95),\n",
              " ('information', 94),\n",
              " ('system', 86),\n",
              " ('service', 80),\n",
              " ('enterprise', 74),\n",
              " ('applications', 71),\n",
              " ('telecommunications', 71),\n",
              " ('governance', 68),\n",
              " ('design', 62),\n",
              " ('telecom', 61),\n",
              " ('networks', 61),\n",
              " ('services', 58),\n",
              " ('integration', 55),\n",
              " ('business', 49),\n",
              " ('systems', 47),\n",
              " ('application', 41),\n",
              " ('state', 40),\n",
              " ('customers', 36),\n",
              " ('schema', 36),\n",
              " ('based', 34),\n",
              " ('integrated', 33),\n",
              " ('telecommunication', 33),\n",
              " ('management', 33),\n",
              " ('particular', 33),\n",
              " ('approach', 33),\n",
              " ('value', 33),\n",
              " ('set', 32),\n",
              " ('important', 32),\n",
              " ('correspondences', 32),\n",
              " ('assertions', 32),\n",
              " ('analysis', 31),\n",
              " ('primary', 31),\n",
              " ('entity', 31),\n",
              " ('section', 31),\n",
              " ('tool', 31),\n",
              " ('knowledge', 30),\n",
              " ('following', 30),\n",
              " ('since', 30),\n",
              " ('ad', 30),\n",
              " ('specification', 29),\n",
              " ('modeling', 28),\n",
              " ('key', 28),\n",
              " ('structure', 28),\n",
              " ('mobile', 28),\n",
              " ('internet', 28),\n",
              " ('concepts', 28),\n",
              " ('fact', 28),\n",
              " ('switch', 28),\n",
              " ('reconciliation', 27),\n",
              " ('large', 27),\n",
              " ('development', 27),\n",
              " ('contractdb', 27),\n",
              " ('properties', 26),\n",
              " ('adorned', 26),\n",
              " ('elements', 26),\n",
              " ('content', 25),\n",
              " ('several', 25),\n",
              " ('required', 25),\n",
              " ('describe', 25),\n",
              " ('case', 25),\n",
              " ('link', 25),\n",
              " ('framework', 24),\n",
              " ('first', 24),\n",
              " ('relation', 24),\n",
              " ('queries', 24),\n",
              " ('however', 24),\n",
              " ('val', 24),\n",
              " ('processing', 23),\n",
              " ('process', 23),\n",
              " ('end', 23),\n",
              " ('desc', 23),\n",
              " ('security', 23),\n",
              " ('view', 22),\n",
              " ('organization', 22),\n",
              " ('mediator', 22),\n",
              " ('warehouses', 22),\n",
              " ('relationship', 22),\n",
              " ('acq', 22),\n",
              " ('cess', 22),\n",
              " ('transmission', 22),\n",
              " ('representation', 21),\n",
              " ('organizations', 21),\n",
              " ('needs', 21),\n",
              " ('architecture', 21),\n",
              " ('implementation', 21),\n",
              " ('common', 21),\n",
              " ('cost', 21),\n",
              " ('identify', 21),\n",
              " ('year', 21),\n",
              " ('operational', 20),\n",
              " ('provide', 20),\n",
              " ('database', 20),\n",
              " ('legacy', 20),\n",
              " ('telephone', 20),\n",
              " ('associated', 20),\n",
              " ('step', 20),\n",
              " ('digital', 20)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwkTq4JFxi96",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "88f44cb6-f2ba-48ff-9e6a-85cb75d2a7eb"
      },
      "source": [
        "initials = []\n",
        "num = 16\n",
        "for i in range(num):\n",
        "    word = choose[i][0]\n",
        "    initials.append(word)\n",
        "initials\n",
        "\n",
        "taxonomy_words = []\n",
        "for i in range(num):\n",
        "    word = choose[i][0]\n",
        "    if word[-1] == \"s\" and word[:-1] in initials:\n",
        "        pass\n",
        "    else:\n",
        "        taxonomy_words.append(choose[i][0])\n",
        "\n",
        "if \"telecommunications\" in taxonomy_words:\n",
        "    if \"telecom\" in taxonomy_words:\n",
        "        taxonomy_words.remove(\"telecom\")\n",
        "\n",
        "len(taxonomy_words) , taxonomy_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13,\n",
              " ['data',\n",
              "  'metrics',\n",
              "  'network',\n",
              "  'customer',\n",
              "  'information',\n",
              "  'system',\n",
              "  'service',\n",
              "  'enterprise',\n",
              "  'applications',\n",
              "  'telecommunications',\n",
              "  'governance',\n",
              "  'design',\n",
              "  'integration'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQ8cYoJWzCtG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in taxonomy_words:\n",
        "    if i not in embeddings_index:\n",
        "        print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1zgF2s0vSjY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1894ef6a-572a-480a-fb08-9fb9f860a3e3"
      },
      "source": [
        "def cosine_individual(v1, v2):\n",
        "    if norm(v1) > 0 and norm(v2) > 0:\n",
        "        return dot(v1, v2) / (norm(v1) * norm(v2))\n",
        "    else:\n",
        "        return 0.0\n",
        "\n",
        "ma = 0\n",
        "lt = []\n",
        "for ind,w1 in enumerate(taxonomy_words):\n",
        "    for j in range(ind+1,len(taxonomy_words)):\n",
        "        w2 = taxonomy_words[j]\n",
        "        if w1 in embeddings_index and w2 in embeddings_index:\n",
        "            ans = cosine_individual(embeddings_index[w1] , embeddings_index[w2])\n",
        "            lt.append([w1 , w2 , ans])\n",
        "\n",
        "\n",
        "lt = sorted(lt,key=lambda l:l[2], reverse=True)\n",
        "lt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['data', 'information', 0.79204017],\n",
              " ['network', 'service', 0.6799495],\n",
              " ['data', 'system', 0.6736716],\n",
              " ['data', 'applications', 0.6660566],\n",
              " ['system', 'service', 0.663617],\n",
              " ['network', 'system', 0.656837],\n",
              " ['information', 'service', 0.6545518],\n",
              " ['information', 'applications', 0.6187835],\n",
              " ['system', 'applications', 0.6133982],\n",
              " ['governance', 'integration', 0.6069967],\n",
              " ['service', 'enterprise', 0.6011461],\n",
              " ['system', 'design', 0.5989767],\n",
              " ['network', 'information', 0.5945682],\n",
              " ['information', 'system', 0.59039307],\n",
              " ['customer', 'service', 0.58424157],\n",
              " ['system', 'integration', 0.5734923],\n",
              " ['customer', 'information', 0.56050134],\n",
              " ['system', 'enterprise', 0.5580179],\n",
              " ['applications', 'design', 0.55585337],\n",
              " ['network', 'enterprise', 0.5536174],\n",
              " ['data', 'customer', 0.5478863],\n",
              " ['data', 'service', 0.5401943],\n",
              " ['enterprise', 'integration', 0.5375696],\n",
              " ['system', 'governance', 0.5262511],\n",
              " ['customer', 'applications', 0.52600604],\n",
              " ['network', 'telecommunications', 0.5246473],\n",
              " ['data', 'network', 0.52381754],\n",
              " ['service', 'telecommunications', 0.5235595],\n",
              " ['enterprise', 'design', 0.50773066],\n",
              " ['enterprise', 'telecommunications', 0.50379246],\n",
              " ['enterprise', 'governance', 0.50084853],\n",
              " ['information', 'enterprise', 0.5002328],\n",
              " ['enterprise', 'applications', 0.4949332],\n",
              " ['customer', 'enterprise', 0.49171734],\n",
              " ['customer', 'system', 0.4879674],\n",
              " ['applications', 'integration', 0.48211312],\n",
              " ['service', 'applications', 0.466248],\n",
              " ['information', 'telecommunications', 0.46275172],\n",
              " ['data', 'metrics', 0.46050316],\n",
              " ['applications', 'telecommunications', 0.46001196],\n",
              " ['system', 'telecommunications', 0.4574528],\n",
              " ['network', 'customer', 0.45236585],\n",
              " ['data', 'integration', 0.45165974],\n",
              " ['data', 'enterprise', 0.44233897],\n",
              " ['data', 'telecommunications', 0.43906456],\n",
              " ['network', 'integration', 0.43880132],\n",
              " ['network', 'applications', 0.43503526],\n",
              " ['service', 'design', 0.43253964],\n",
              " ['data', 'design', 0.42503965],\n",
              " ['design', 'integration', 0.4226122],\n",
              " ['telecommunications', 'integration', 0.4188819],\n",
              " ['metrics', 'applications', 0.40793324],\n",
              " ['service', 'integration', 0.407487],\n",
              " ['information', 'integration', 0.4062973],\n",
              " ['network', 'design', 0.40473878],\n",
              " ['information', 'design', 0.40468132],\n",
              " ['customer', 'telecommunications', 0.39972246],\n",
              " ['customer', 'design', 0.39435515],\n",
              " ['information', 'governance', 0.38619053],\n",
              " ['customer', 'integration', 0.377292],\n",
              " ['telecommunications', 'governance', 0.37276706],\n",
              " ['metrics', 'governance', 0.37025657],\n",
              " ['data', 'governance', 0.36653388],\n",
              " ['governance', 'design', 0.36550927],\n",
              " ['network', 'governance', 0.34011167],\n",
              " ['applications', 'governance', 0.33459064],\n",
              " ['service', 'governance', 0.31421438],\n",
              " ['metrics', 'design', 0.3056629],\n",
              " ['metrics', 'information', 0.29398492],\n",
              " ['telecommunications', 'design', 0.28664818],\n",
              " ['metrics', 'integration', 0.27568874],\n",
              " ['customer', 'governance', 0.27321774],\n",
              " ['metrics', 'customer', 0.2633444],\n",
              " ['metrics', 'enterprise', 0.26298362],\n",
              " ['metrics', 'system', 0.22314146],\n",
              " ['metrics', 'telecommunications', 0.201842],\n",
              " ['metrics', 'network', 0.1649588],\n",
              " ['metrics', 'service', 0.13289788]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnCMTdUybuMj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "outputId": "8e247b2a-dd26-415c-f352-f3a76b37888a"
      },
      "source": [
        "graph = {}\n",
        "for i in taxonomy_words:\n",
        "    graph[i] = []\n",
        "\n",
        "for i in lt:\n",
        "    if i[2]>0.595:\n",
        "        graph[i[0]].append(i[1])\n",
        "        graph[i[1]].append(i[0])\n",
        "\n",
        "graph"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'applications': ['data', 'information', 'system'],\n",
              " 'customer': [],\n",
              " 'data': ['information', 'system', 'applications'],\n",
              " 'design': ['system'],\n",
              " 'enterprise': ['service'],\n",
              " 'governance': ['integration'],\n",
              " 'information': ['data', 'service', 'applications'],\n",
              " 'integration': ['governance'],\n",
              " 'metrics': [],\n",
              " 'network': ['service', 'system'],\n",
              " 'service': ['network', 'system', 'information', 'enterprise'],\n",
              " 'system': ['data', 'service', 'network', 'applications', 'design'],\n",
              " 'telecommunications': []}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5DMmUBKtQXU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a1177eeb-18e4-4b53-fc1e-bf121cf90390"
      },
      "source": [
        "ma = [0]*20\n",
        "for i,j in graph.items():\n",
        "    ma[len(j)] = ma[len(j)] + 1\n",
        "print(ma)\n",
        "\n",
        "for j in range(19,-1,-1):\n",
        "    if ma[j]!=0:\n",
        "        ind,val = j,ma[j]\n",
        "        break\n",
        "print(ind,val)\n",
        "\n",
        "root = \"\"\n",
        "if val==1:\n",
        "    for i,j in graph.items():\n",
        "        if len(j)==ind:\n",
        "            root = i\n",
        "            break\n",
        "else:\n",
        "    big = 0\n",
        "    for i,j in graph.items():\n",
        "        lent = 0\n",
        "        if len(j)==ind:\n",
        "            for inner in j:\n",
        "                lent = lent + len(graph[inner])\n",
        "            if lent>big:\n",
        "                big = lent\n",
        "                root = i\n",
        "print(\"root: \",root)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3, 4, 1, 3, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "5 1\n",
            "root:  system\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XvYPy3KtNbl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "outputId": "013f6809-2a77-4a89-abe2-7b3012df635b"
      },
      "source": [
        "# !pip install treelib\n",
        "# value , key , parent\n",
        "from treelib import Node, Tree\n",
        "\n",
        "tree = Tree()\n",
        "tree.create_node(root,root)\n",
        "ct = 100\n",
        "for ind,i in enumerate(graph[root]):\n",
        "    ct = ct + 1\n",
        "    tree.create_node(i,ind,root)\n",
        "    for ind2,j in enumerate(graph[i]):\n",
        "        ct = ct + 1\n",
        "        if j not in root:\n",
        "            tree.create_node(j,ct,ind)\n",
        "tree.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "system\n",
            "├── applications\n",
            "│   ├── data\n",
            "│   └── information\n",
            "├── data\n",
            "│   ├── applications\n",
            "│   └── information\n",
            "├── design\n",
            "├── network\n",
            "│   └── service\n",
            "└── service\n",
            "    ├── enterprise\n",
            "    ├── information\n",
            "    └── network\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSui_a9fIKBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# norms = []\n",
        "# for i,j in embeddings_index.items():\n",
        "#     norms.append(norm(j))\n",
        "# print(len(norms))\n",
        "\n",
        "# def cosine(v1, v2):\n",
        "#     return dot(v1, v2) / (np.array(norms) * norm(v2))\n",
        "\n",
        "\n",
        "# embeddings_words = list(embeddings_index.keys())\n",
        "# keywords = [\"data\" , \"information\" , \"animals\" , \"in\"]\n",
        "# for word in keywords:\n",
        "#     if word in embeddings_index:\n",
        "#         similarities = cosine(embedding_matrix , embeddings_index[word])\n",
        "#         indices = similarities.argsort()[-10:][::-1]\n",
        "#         print(word,indices)\n",
        "#         for ind in indices:\n",
        "#             print(embeddings_words[ind])\n",
        "#         print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PihlT9nA73G9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}