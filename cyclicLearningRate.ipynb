{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cyclicLearningRate.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNIJZBbe/MhPtLp3vHXYSuw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshishGusain17/via_google_colab/blob/master/cyclicLearningRate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e79dwC94WnZG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# example of saving models for a snapshot ensemble\n",
        "from sklearn.datasets import make_blobs\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import Callback\n",
        "from keras.optimizers import SGD\n",
        "from keras import backend\n",
        "from math import pi\n",
        "from math import cos\n",
        "from math import floor\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-SJEuuzZsZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import *\n",
        "import numpy as np\n",
        "\n",
        "class CyclicLR(Callback):\n",
        "\n",
        "    def __init__(self, base_lr=0.001, max_lr=0.006, step_size=2000., mode='triangular',\n",
        "                 gamma=1., scale_fn=None, scale_mode='cycle'):\n",
        "        super(CyclicLR, self).__init__()\n",
        "\n",
        "        self.base_lr = base_lr\n",
        "        self.max_lr = max_lr\n",
        "        self.step_size = step_size\n",
        "        self.mode = mode\n",
        "        self.gamma = gamma\n",
        "        if scale_fn == None:\n",
        "            if self.mode == 'triangular':\n",
        "                self.scale_fn = lambda x: 1.\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'triangular2':\n",
        "                self.scale_fn = lambda x: 1/(2.**(x-1))\n",
        "                self.scale_mode = 'cycle'\n",
        "            elif self.mode == 'exp_range':\n",
        "                self.scale_fn = lambda x: gamma**(x)\n",
        "                self.scale_mode = 'iterations'\n",
        "        else:\n",
        "            self.scale_fn = scale_fn\n",
        "            self.scale_mode = scale_mode\n",
        "        self.clr_iterations = 0.\n",
        "        self.trn_iterations = 0.\n",
        "        self.history = {}\n",
        "\n",
        "        self._reset()\n",
        "\n",
        "    def _reset(self, new_base_lr=None, new_max_lr=None,\n",
        "               new_step_size=None):\n",
        "        \"\"\"Resets cycle iterations.\n",
        "        Optional boundary/step size adjustment.\n",
        "        \"\"\"\n",
        "        if new_base_lr != None:\n",
        "            self.base_lr = new_base_lr\n",
        "        if new_max_lr != None:\n",
        "            self.max_lr = new_max_lr\n",
        "        if new_step_size != None:\n",
        "            self.step_size = new_step_size\n",
        "        self.clr_iterations = 0.\n",
        "        \n",
        "    def clr(self):\n",
        "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
        "        x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
        "        if self.scale_mode == 'cycle':\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(cycle)\n",
        "        else:\n",
        "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0, (1-x))*self.scale_fn(self.clr_iterations)\n",
        "        \n",
        "    def on_train_begin(self, logs={}):\n",
        "        logs = logs or {}\n",
        "\n",
        "        if self.clr_iterations == 0:\n",
        "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
        "        else:\n",
        "            K.set_value(self.model.optimizer.lr, self.clr())        \n",
        "            \n",
        "    def on_batch_end(self, epoch, logs=None):\n",
        "        \n",
        "        logs = logs or {}\n",
        "        self.trn_iterations += 1\n",
        "        self.clr_iterations += 1\n",
        "\n",
        "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
        "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
        "\n",
        "        for k, v in logs.items():\n",
        "            self.history.setdefault(k, []).append(v)\n",
        "        \n",
        "        K.set_value(self.model.optimizer.lr, self.clr())\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbMC-2CfWqbP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "70ec24ac-0014-4d8d-acb6-4be086b95f75"
      },
      "source": [
        "print(\"[INFO] loading CIFAR-10 data...\")\n",
        "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
        "trainX = trainX.astype(\"float\")\n",
        "testX = testX.astype(\"float\")\n",
        "print(trainX.shape , testX.shape)\n",
        "\n",
        "# apply mean subtraction to the data\n",
        "mean = np.mean(trainX, axis=0)\n",
        "trainX -= mean\n",
        "testX -= mean\n",
        "\n",
        "# convert the labels from integers to vectors\n",
        "lb = LabelBinarizer()\n",
        "trainY = lb.fit_transform(trainY)\n",
        "testY = lb.transform(testY)\n",
        "print(trainY.shape , testY.shape)\n",
        "\n",
        "\n",
        "\n",
        "# construct the image generator for data augmentation\n",
        "aug = ImageDataGenerator(width_shift_range=0.1,\n",
        "\theight_shift_range=0.1, horizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading CIFAR-10 data...\n",
            "(50000, 32, 32, 3) (10000, 32, 32, 3)\n",
            "(50000, 10) (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_jP2KNXWtOM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "026fb9c7-6103-4a2d-9de3-874b01a325de"
      },
      "source": [
        "ct = 0\n",
        "import keras\n",
        "\n",
        "\n",
        "\n",
        "m1 = keras.applications.ResNet50(include_top=False,\n",
        "                  input_shape = (32,32,3),\n",
        "                  weights = 'imagenet')\n",
        "\n",
        "model = keras.models.Sequential() \n",
        "model.add(m1)\n",
        "\n",
        "for layer in model.layers:\n",
        "  ct=ct+1\n",
        "\n",
        "for layer in model.layers:\n",
        "  if ct>10:\n",
        "    layer.trainable = False\n",
        "  else:\n",
        "    layer.trainable = True\n",
        "  ct=ct-1\n",
        "\n",
        "\n",
        "model.add(keras.layers.Flatten())\n",
        "\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
            "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50 (Model)             (None, 1, 1, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                20490     \n",
            "=================================================================\n",
            "Total params: 23,608,202\n",
            "Trainable params: 23,555,082\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ueDYd93JX1XX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", \n",
        "              optimizer='adam',\n",
        "\t          metrics=[\"accuracy\"])\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg8gQkIPWy4M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11d41866-fb6a-4098-9a3b-acd8a2b4613e"
      },
      "source": [
        "\n",
        "# initialize the cyclical learning rate callback\n",
        "print(\"[INFO] using '{}' method\".format(\"triangular\"))\n",
        "clr = CyclicLR(\n",
        "\tmode = \"triangular\",\n",
        "\tbase_lr = 1e-7,\n",
        "\tmax_lr = 1e-2,\n",
        "\tstep_size = 8 * (trainX.shape[0] // 64))\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] using 'triangular' method\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVxcJpoBW1qS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "outputId": "521f9c75-82b6-4051-d75b-20bf660199a5"
      },
      "source": [
        "steps_per_epoch = 512         # number of steps in each epoch\n",
        "epochs = 15\n",
        "\n",
        "# train the network\n",
        "print(\"[INFO] training network...\")\n",
        "H = model.fit(\n",
        "\tx=aug.flow(trainX, trainY, 32),\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tsteps_per_epoch=steps_per_epoch,\n",
        "\tepochs=epochs,\n",
        "\tcallbacks=[clr],\n",
        "\tverbose=1)\n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training network...\n",
            "Epoch 1/15\n",
            "512/512 [==============================] - 153s 299ms/step - loss: 1.8494 - accuracy: 0.4301 - val_loss: 2.4851 - val_accuracy: 0.5341\n",
            "Epoch 2/15\n",
            "512/512 [==============================] - 127s 249ms/step - loss: 1.6573 - accuracy: 0.4999 - val_loss: 144.8996 - val_accuracy: 0.3807\n",
            "Epoch 3/15\n",
            "512/512 [==============================] - 128s 251ms/step - loss: 2.5711 - accuracy: 0.2265 - val_loss: 120.1006 - val_accuracy: 0.1312\n",
            "Epoch 4/15\n",
            "512/512 [==============================] - 128s 250ms/step - loss: 2.4990 - accuracy: 0.1843 - val_loss: 126.8413 - val_accuracy: 0.1943\n",
            "Epoch 5/15\n",
            "512/512 [==============================] - 130s 254ms/step - loss: 2.2438 - accuracy: 0.2304 - val_loss: 4.8253 - val_accuracy: 0.2488\n",
            "Epoch 6/15\n",
            "512/512 [==============================] - 130s 254ms/step - loss: 1.9425 - accuracy: 0.2910 - val_loss: 2.6166 - val_accuracy: 0.2103\n",
            "Epoch 7/15\n",
            "512/512 [==============================] - 131s 257ms/step - loss: 1.7138 - accuracy: 0.3671 - val_loss: 1.6819 - val_accuracy: 0.3582\n",
            "Epoch 8/15\n",
            "512/512 [==============================] - 131s 257ms/step - loss: 1.5994 - accuracy: 0.4068 - val_loss: 2.7382 - val_accuracy: 0.3004\n",
            "Epoch 9/15\n",
            "512/512 [==============================] - 130s 254ms/step - loss: 1.4941 - accuracy: 0.4471 - val_loss: 2.0690 - val_accuracy: 0.3885\n",
            "Epoch 10/15\n",
            "512/512 [==============================] - 129s 251ms/step - loss: 1.4596 - accuracy: 0.4741 - val_loss: 1.7170 - val_accuracy: 0.4157\n",
            "Epoch 11/15\n",
            "512/512 [==============================] - 128s 249ms/step - loss: 1.3827 - accuracy: 0.5045 - val_loss: 1.7092 - val_accuracy: 0.4164\n",
            "Epoch 12/15\n",
            "512/512 [==============================] - 133s 259ms/step - loss: 1.3253 - accuracy: 0.5314 - val_loss: 1.9556 - val_accuracy: 0.4290\n",
            "Epoch 13/15\n",
            "512/512 [==============================] - 131s 256ms/step - loss: 1.2764 - accuracy: 0.5513 - val_loss: 1.3228 - val_accuracy: 0.5545\n",
            "Epoch 14/15\n",
            "512/512 [==============================] - 130s 255ms/step - loss: 1.2164 - accuracy: 0.5713 - val_loss: 2.1968 - val_accuracy: 0.5329\n",
            "Epoch 15/15\n",
            "512/512 [==============================] - 128s 251ms/step - loss: 1.1707 - accuracy: 0.5906 - val_loss: 1.7897 - val_accuracy: 0.4919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Rxweq7OW4MW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "aed19d6c-bb96-4058-d526-2513ab3d0fdf"
      },
      "source": [
        "import os\n",
        "\n",
        "\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(x=testX)\n",
        "print(classification_report(testY.argmax(axis=1) , predictions.argmax(axis=1) , target_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\",\"frog\", \"horse\", \"ship\", \"truck\"]))\n",
        "\n",
        "\n",
        "# plot the training loss and accuracy\n",
        "N = np.arange(0, epochs)\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(N, H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(N, H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(N, H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(N, H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")\n",
        "plt.savefig(\"training_plot.png\")\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.36      0.74      0.48      1000\n",
            "  automobile       0.61      0.88      0.72      1000\n",
            "        bird       0.39      0.05      0.09      1000\n",
            "         cat       0.31      0.06      0.10      1000\n",
            "        deer       0.70      0.38      0.49      1000\n",
            "         dog       0.57      0.45      0.50      1000\n",
            "        frog       0.33      0.94      0.49      1000\n",
            "       horse       0.64      0.70      0.67      1000\n",
            "        ship       0.77      0.18      0.30      1000\n",
            "       truck       0.82      0.53      0.65      1000\n",
            "\n",
            "    accuracy                           0.49     10000\n",
            "   macro avg       0.55      0.49      0.45     10000\n",
            "weighted avg       0.55      0.49      0.45     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mWLJ1i-ihjB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot the learning rate history\n",
        "N = np.arange(0, len(clr.history[\"lr\"]))\n",
        "plt.figure()\n",
        "plt.plot(N, clr.history[\"lr\"])\n",
        "plt.title(\"Cyclical Learning Rate (CLR)\")\n",
        "plt.xlabel(\"Training Iterations\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.savefig(\"clr_plot.png\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozyfZ4m0W655",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "perEpoch = np.arange(0, epochs)\n",
        "cyclicLR = []\n",
        "clr_all_iter = clr.history[\"lr\"]\n",
        "for ind in range(len(clr_all_iter)):\n",
        "    if ind % steps_per_epoch==0:\n",
        "        cyclicLR.append(clr_all_iter[ind])\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(perEpoch, cyclicLR)\n",
        "plt.title(\"Cyclical Learning Rate (CLR)\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.savefig(\"clr_epochs.png\")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlfDx-eyjjmI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}